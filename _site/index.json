{
  "Assets/Packages/Microsoft.Bcl.AsyncInterfaces.8.0.0/PACKAGE.html": {
    "href": "Assets/Packages/Microsoft.Bcl.AsyncInterfaces.8.0.0/PACKAGE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "About As of C# 8, the C# language has support for producing and consuming asynchronous iterators. The library types in support of those features are available in .NET Core 3.0 and newer as well as in .NET Standard 2.1. This library provides the necessary definitions of those types to support these language features on .NET Framework and on .NET Standard 2.0. This library is not necessary nor recommended when targeting versions of .NET that include the relevant support. Key Features Enables the use of C# async iterators on older .NET platforms How to Use using System; using System.Collections.Generic; using System.Threading.Tasks; internal static class Program { private static async Task Main() { Console.WriteLine(\"Starting...\"); await foreach (var value in GetValuesAsync()) { Console.WriteLine(value); } Console.WriteLine(\"Finished!\"); static async IAsyncEnumerable<int> GetValuesAsync() { for (int i = 0; i < 10; i++) { await Task.Delay(TimeSpan.FromSeconds(1)); yield return i; } } } } Main Types The main types provided by this library are: IAsyncEnumerable<T> IAsyncEnumerator<T> IAsyncDisposable<T> Additional Documentation C# Feature Specification Walkthrough article Feedback & Contributing Microsoft.Bcl.AsyncInterfaces is released as open source under the MIT license. Bug reports and contributions are welcome at the GitHub repository."
  },
  "Assets/Packages/System.Text.Json.8.0.4/PACKAGE.html": {
    "href": "Assets/Packages/System.Text.Json.8.0.4/PACKAGE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "About Provides high-performance and low-allocating types that serialize objects to JavaScript Object Notation (JSON) text and deserialize JSON text to objects, with UTF-8 support built-in. Also provides types to read and write JSON text encoded as UTF-8, and to create an in-memory document object model (DOM), that is read-only, for random access of the JSON elements within a structured view of the data. Key Features High-performance reader and writer types for UTF-8 encoded JSON. A fully-featured JSON serializer for .NET types using reflection or source generated contracts. A high-performance read-only JSON DOM (JsonDocument) and a mutable DOM that interoperates with the serializer (JsonNode). Built-in support for async serialization, including IAsyncEnumerable support. Fully customizable contract model for serializable types. How to Use The System.Text.Json library is built-in as part of the shared framework in .NET Runtime. The package can be installed when you need to use the most recent version in older target frameworks. Serialization: using System; using System.Text.Json; WeatherForecast forecast = new (DateTimeOffset.Now, 26.6f, \"Sunny\"); var serialized = JsonSerializer.Serialize(forecast); Console.WriteLine(serialized); // {\"Date\":\"2023-08-02T16:01:20.9025406+00:00\",\"TemperatureCelsius\":26.6,\"Summary\":\"Sunny\"} var forecastDeserialized = JsonSerializer.Deserialize<WeatherForecast>(serialized); Console.WriteLine(forecast == forecastDeserialized); // True public record WeatherForecast(DateTimeOffset Date, float TemperatureCelsius, string? Summary); Serialization using the source generator: using System.Text.Json; using System.Text.Json.Serialization; WeatherForecast forecast = new (DateTimeOffset.Now, 26.6f, \"Sunny\"); var serialized = JsonSerializer.Serialize(forecast, SourceGenerationContext.Default.WeatherForecast); Console.WriteLine(serialized); // {\"Date\":\"2023-08-02T16:01:20.9025406+00:00\",\"TemperatureCelsius\":26.6,\"Summary\":\"Sunny\"} var forecastDeserialized = JsonSerializer.Deserialize<WeatherForecast>(serialized, SourceGenerationContext.Default.WeatherForecast); Console.WriteLine(forecast == forecastDeserialized); // True public record WeatherForecast(DateTimeOffset Date, float TemperatureCelsius, string? Summary); [JsonSourceGenerationOptions(WriteIndented = true)] [JsonSerializable(typeof(WeatherForecast))] internal partial class SourceGenerationContext : JsonSerializerContext { } Using the JSON DOM: using System; using System.Text.Json; using System.Text.Json.Nodes; string jsonString = @\"{ \"\"Date\"\": \"\"2019-08-01T00:00:00\"\", \"\"Temperature\"\": 25, \"\"Summary\"\": \"\"Hot\"\", \"\"DatesAvailable\"\": [ \"\"2019-08-01T00:00:00\"\", \"\"2019-08-02T00:00:00\"\" ], \"\"TemperatureRanges\"\": { \"\"Cold\"\": { \"\"High\"\": 20, \"\"Low\"\": -10 }, \"\"Hot\"\": { \"\"High\"\": 60, \"\"Low\"\": 20 } } } \"; JsonNode forecastNode = JsonNode.Parse(jsonString)!; // Get value from a JsonNode. JsonNode temperatureNode = forecastNode[\"Temperature\"]!; Console.WriteLine($\"Type={temperatureNode.GetType()}\"); Console.WriteLine($\"JSON={temperatureNode.ToJsonString()}\"); //output: //Type = System.Text.Json.Nodes.JsonValue`1[System.Text.Json.JsonElement] //JSON = 25 // Get a typed value from a JsonNode. int temperatureInt = (int)forecastNode[\"Temperature\"]!; Console.WriteLine($\"Value={temperatureInt}\"); //output: //Value=25 // Get a typed value from a JsonNode by using GetValue<T>. temperatureInt = forecastNode[\"Temperature\"]!.GetValue<int>(); Console.WriteLine($\"TemperatureInt={temperatureInt}\"); //output: //Value=25 // Get a JSON object from a JsonNode. JsonNode temperatureRanges = forecastNode[\"TemperatureRanges\"]!; Console.WriteLine($\"Type={temperatureRanges.GetType()}\"); Console.WriteLine($\"JSON={temperatureRanges.ToJsonString()}\"); //output: //Type = System.Text.Json.Nodes.JsonObject //JSON = { \"Cold\":{ \"High\":20,\"Low\":-10},\"Hot\":{ \"High\":60,\"Low\":20} } // Get a JSON array from a JsonNode. JsonNode datesAvailable = forecastNode[\"DatesAvailable\"]!; Console.WriteLine($\"Type={datesAvailable.GetType()}\"); Console.WriteLine($\"JSON={datesAvailable.ToJsonString()}\"); //output: //datesAvailable Type = System.Text.Json.Nodes.JsonArray //datesAvailable JSON =[\"2019-08-01T00:00:00\", \"2019-08-02T00:00:00\"] // Get an array element value from a JsonArray. JsonNode firstDateAvailable = datesAvailable[0]!; Console.WriteLine($\"Type={firstDateAvailable.GetType()}\"); Console.WriteLine($\"JSON={firstDateAvailable.ToJsonString()}\"); //output: //Type = System.Text.Json.Nodes.JsonValue`1[System.Text.Json.JsonElement] //JSON = \"2019-08-01T00:00:00\" // Get a typed value by chaining references. int coldHighTemperature = (int)forecastNode[\"TemperatureRanges\"]![\"Cold\"]![\"High\"]!; Console.WriteLine($\"TemperatureRanges.Cold.High={coldHighTemperature}\"); //output: //TemperatureRanges.Cold.High = 20 // Parse a JSON array JsonNode datesNode = JsonNode.Parse(@\"[\"\"2019-08-01T00:00:00\"\",\"\"2019-08-02T00:00:00\"\"]\")!; JsonNode firstDate = datesNode[0]!.GetValue<DateTime>(); Console.WriteLine($\"firstDate={ firstDate}\"); //output: //firstDate = \"2019-08-01T00:00:00\" Using the low-level JSON reader/writer types using System; using System.IO; using System.Text; using System.Text.Json; var writerOptions = new JsonWriterOptions { Indented = true }; using var stream = new MemoryStream(); using var writer = new Utf8JsonWriter(stream, writerOptions); writer.WriteStartObject(); writer.WriteString(\"date\", DateTimeOffset.Parse(\"8/2/2023 9:00 AM\")); writer.WriteNumber(\"temp\", 42); writer.WriteEndObject(); writer.Flush(); var jsonBytes = stream.ToArray(); string json = Encoding.UTF8.GetString(jsonBytes); Console.WriteLine(json); // { // \"date\": \"2023-08-02T09:00:00+00:00\" // \"temp\": 42 // } var readerOptions = new JsonReaderOptions { AllowTrailingCommas = true, CommentHandling = JsonCommentHandling.Skip }; var reader = new Utf8JsonReader(jsonBytes, readerOptions); while (reader.Read()) { Console.Write(reader.TokenType); switch (reader.TokenType) { case JsonTokenType.PropertyName: case JsonTokenType.String: { string? text = reader.GetString(); Console.Write(\" \"); Console.Write(text); break; } case JsonTokenType.Number: { int intValue = reader.GetInt32(); Console.Write(\" \"); Console.Write(intValue); break; } // Other token types elided for brevity } Console.WriteLine(); } // StartObject // PropertyName date // String 2023-08-02T09:00:00+00:00 // PropertyName temp // Number 42 // EndObject Main Types The main types provided by this library are: System.Text.Json.Utf8JsonWriter System.Text.Json.Utf8JsonReader System.Text.Json.JsonSerializer System.Text.Json.JsonConverter System.Text.Json.JsonDocument System.Text.Json.Nodes.JsonNode System.Text.Json.Serialization.Metadata.JsonTypeInfo Additional Documentation Conceptual documentation API documentation Related Packages Lightweight data formats abstraction: System.Memory.Data Serialization of HttpContent: System.Net.Http.Json Feedback & Contributing System.Text.Json is released as open source under the MIT license. Bug reports and contributions are welcome at the GitHub repository."
  },
  "Library/PackageCache/com.github-glitchenzo.nugetforunity@a011c51ed6/LICENSE.html": {
    "href": "Library/PackageCache/com.github-glitchenzo.nugetforunity@a011c51ed6/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "MIT License Copyright (c) 2018 Patrick McCarthy Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [9.1.1] - 2024-05-06 Fixed Fixed the the memory leak in the SpriteSkin component. (case DANB-602) Fixed the IK bones flipped at certain angels. (case DANB-583) Sprite Library's labels and categories cannot be reordered. (case DANB-592) Fixed the incorrect transform cache capacity in the SpriteSkin component. (case DANB-614) Added Added safety checks to SpriteSkin's APIs. [9.1.0] - 2023-12-14 Fixed Blend weight vertex attribute is added only when sprite has bones. (case DANB-520) Sprite Library editor drag and drop interactions. (case DANB-535) Sprite Library editor drag and drop blocked by labels. (case DANB-558) Adjust the copy-paste logic to not paste sprite mesh to the same sprite twice. (case DANB-530) Sprite Library Asset is selected on creation. (case DANB-542) Sprite Resolver previews not visible after editor regained focus. (case DANB-564) Added SpriteSkin's Auto Rebind property can now be accessed from scripts. (case DANB-490) Sprite Library public API to save an asset as a .spriteLib SpriteLibrarySourceAsset. [9.0.4] - 2023-09-05 Fixed Fixed an issue where the FK doesn't blend correctly with the IK if solver solves from the bind pose. (case DANB-482) Added correct help documentation link to Sprite Library Asset. (case DANB-486) [9.0.3] - 2023-04-18 Fixed Fixed Sprite Resolver inspector not able to set category to 'No Category' if it contains the old hash value. (case DAB-395) Fixed Sprite Resolver inspector not updating its previews when the category is set externally to 'No Category'. (case DANB-389) Fixed an issue where the Limb IK solver will become unstable when the child bones have different Z position. (case DANB-413) Fixed an issue where changing Sprite Library reference in the Inspector will result in an exception. (case DANB-426) Fixed an issue where the CCD and Fabrik solvers will become unstable when the child bones have different Z position. (case DANB-418) Added Updated IK parameter names and comments in public APIs. [9.0.2] - 2023-02-27 Added Added support for Collections 2.0.0. Fixed an issue where \"System.ArgumentException\" thrown when opening sprite Prefab with Script. (DANB-342) Fixed Fixed an issue where IKEditorManager updates even when there are no active IK Manager 2Ds in the Scene. (case DANB-345) Fixed an issue where undoing vertex painting results in a displaced mesh. (case DANB-355) Fixed an issue where IKGizmos will throw an exception in the editor when IKSolver has an unassigned Solver in its list. (case DANB-371) Fixed SpriteResolver does not animation with animation clip when upgrading from 2020.3. (case DANB-377) IMGUIContainer:ProcessEvent error occurs when selecting a PSD embedded SpriteLibraryAsset as a Main Library of another Sprite Library Asset. (case DANB-380) [9.0.1] - 2022-10-11 Fixed Fixed a case where pasting bones in the Skinning Editor would move bones rather than copy them. (case DANB-179) Fixed an issue where selecting bones in the Skinning Editor after removing any bone in the skeleton will throw an exception. (case DANB-186) Fixed a case where setting IKManager2D's or Solver2D's weight to '0' doesn't update solver's effector position. (case DANB-191) Fixed an issue where undo the addition of a Sprite Skin component would crash the editor. (DANB-201) Fixed a case where new bones are not selected after pasting them in the Skinning Editor and an exception is thrown. (DANB-209) Fixed a case where the auto weight generation would associate incorrect bones to vertices. (case DANB-22) Improved the Auto Geometry generation speed. Fixed a case where a .psd/.psb with a Main Skeleton assigned would generate incorrect bind poses. (Case DANB-225) Fixed IK Manager 2D's inspector slow downs. (case DANB-215) Fixed an issue where the Sprite Skin editor would throw an exception if Sprite Renderer doesn't have a Sprite assigned to it. Changed Expand and frame on bone selection. [9.0.0] - 2022-08-03 Added Added bone weight index validation in SpriteSkin's validate method, to ensure valid data before continuing with deformation. Fixed Fixed a case where moving vertices forcefully in the Skinning editor could cause a quad reset of the mesh. (case DANB-7) Fixed a case where multi selecting Sprite Skins would cause a null reference exception to be thrown. (case DANB-126) Changed Refactored internal triangulation and tessellation APIs. [9.0.0-pre.3] - 2022-05-31 Changed Update dependency package version. [9.0.0-pre.2] - 2022-05-20 Fixed Creating a new vertex or an edge outside of the main geometry is now handled correctly. (case 1398541) Fixed an issue where null reference exceptions would show when the Skinning Editor was open during play mode. (case 1419720) Fixed Sprite Library Asset 'Revert' behavior. (case 1417743) Fixed Sprite Library Asset multi-editing in the Inspector window. (case 1417747) Fixed an issue where Variant Sprite Libraries would not be updated when the Main Library is changed. (case DANB-5) Changed Added ability to create Sprite Library Asset variant from the create menu. Added dialog box to the Skinning Editor when entering Play Mode to allow saving unsaved changes. [9.0.0-pre.1] - 2022-03-21 Added Added the ability to cancel mesh generation in the Skinning Editor. Changed 2D Animation now depends on the Collections package. Sprite Skin's AutoRebind can now swap between all bones underneath the rootBone. Updated Visibility Tab documentation page. Sprite Skins are now registered/deregistered in batches for improved instatiation/destroy performance. Updated ListView event listeners to use new selection API. Fixed Fixed an issue where the animation window's preview of IK targets would not be the same as in Play Mode. (case 1391590) Sprite Library cannot reference itself in the Main Library field or any asset that references it. (case 1401464) Fixed an issue where moving vertices in the Skinning Editor might result in invalid edges. (case 1386153) Fixed an issue where the SpriteSkin components would not get initialized on editor launch. (case 1401139) Fixed an issue when Skinning Editor will lose reference after exiting Play mode. (case 1405289) Fixed an issue where the Skinning Editor's copy/paste tool would fail if two bones shared the same name. (case 1405028) [8.0.0] - 2022-01-25 Changed Package release version. Fixed Sprite Skin's help button now leads to the correct documentation page. (case 1383765) Fixed the isolate behavior in the Sprite tab in the Visibility panel. (case 1387184) [8.0.0-pre.4] - 2021-11-24 Added Added support in the asset upgrading tool for animation clips authored across multiple Unity editor versions. Added a check to validate collinearity among vertices before tessellation. Changed Updated the 2D Animation Upgrader documentation section with new information regarding Animation Clip upgrading. Fixed Added additional fallback for when the bursted tessellation step fails. (case 1372686) Sprite selection now reacts only to the left mouse button. (case 1371567) Fixed an issue where a Sprite Skin outside of the camera frustum enters the frustum, which could cause an editor and player crash. (case 1377867) Slider labels in the Skinning Editor now register input for easier value tweaking. (case 1294945) [8.0.0-pre.3] - 2021-10-21 Changed Update to latest com.unity.2d.common package [8.0.0-pre.2] - 2021-10-11 Changed Sprite Library Asset are now named \"New Sprite Library Asset.spriteLib\" by default on creation. Updated Toolbar and Visibility tab buttons' selection color. Updated package documentation. Fixed Sprite selection actions now work with Undo. (case 1367257) Fixed an issue where removing an edge in the Skinning editor would result in the mesh falling back to a quad. (case 1365831) Quads are now generated at correct positions after removing all vertices from Sprite meshes. (case 1366633) [8.0.0-pre.1] - 2021-08-06 Added Added an asset upgrading tool, which can upgrade older Sprite Library Assets and Animation Clips to the latest version. Changed SpriteResolver.SetCategoryAndLabel and SpriteResolver.ResolveSpriteToSpriteRenderer now returns a bool to signal if the methods managed to resolve the request or not. Orientation function being replaced with a simpler version. Fixed Thumbnails in Sprite Library Asset flicker when the Library Asset contains many Categories and Labels. (case 1333228) SpriteLibraryAsset Category & Label does not generate hash in Inspector. (case 1340587) SpriteResolver inspector selects first element when failing to resolve. (case 1340070) IKManager2D does not detect classes inheriting from Solver2D. (case 1343260) Skinning Editor tooltips updated. Bone and Sprite influence lists are displayed correctly. (case 1349041) Sprite Library Assets are now being cached properly. (case 1347339) Sprite outline in the Skinning Editor is now rendered based on Sprite's geometry. (case 1335586) Animation Preview windows can now show Sprite deformation, Sprite Swapping and IK controlled movement. Removed the need to set Broken and Constant tangent on each key when animating a SpriteResolver. Fixed render texture size error in the Skinning Editor. (case 1357552) Skinning Editor toolbar buttons now focus on hoykey presses. (case 1358714) Fixed an issue where opening certain .psb files would result in errors. (case 1358972) Fixed a case where quads generated in the Skinning Editor would be created with the wrong size and position. (case 1361053) Fixed an issue where variant Sprite Libraries would not display its main library content. (case 1362389) Fixed an issue where IK Solvers would not be updated when previewing an animation clip. (1354389) Fixed an issue where copying mesh and bone data from a .psb containing a single sprite would throw an exception. (case 1351543) Fixed an issue where an error would show up when destroying a Sprite Skin component while deep profling. (case 1364910) [7.0.0-pre.3] - 2021-07-05 Fixed Thumbnails in Sprite Library Asset flicker when the Library Asset contains many Categories and Labels. (case 1333228) SpriteLibraryAsset Category & Label does not generate hash in Inspector. (case 1340587) SpriteResolver inspector selects first element when failing to resolve. (case 1340070) IKManager2D does not detect classes inheriting from Solver2D. (case 1343260) Skinning Editor tooltips updated. [7.0.0-pre.2] - 2021-05-19 Fixed Fixed Sprite Resolver component not updated when new categories/labels are added into Sprite Library asset. (case 1321069) [7.0.0-pre.1] - 2021-05-05 Changed Version bump for Unity 2021.2. Moved Copy & Paste Rig buttons in the Skinning Editor into their own Rig category. Moved Preview & Restore Pose button in the Skinning Editor into their own Pose category. Replaced Triangle.Net with our own tessellation solution. Added Added shortcuts at the back of the Skinning Editor buttons tooltips for better discoverability. Added a color picker for each bone in the Skinning Editor's Visiblity tab. Added the Sprite Influence panel that allows to change a bone influence on the selected Sprite. Fixed Fixed crash when disabling Sprite Skin when multithreaded rendering is enabled. (case 1296355) [6.0.0] - 2021-03-17 Changed Update version for release. [6.0.0-pre.3] - 2021-03-15 Changed Updated manual. Fixed Deleting bones from a skeleton referenced by another character sometimes throws IndexOutOfRangeException. (case 1304768) [6.0.0-pre.2] - 2021-01-16 Changed Update license file. Added Initial documentation update for new features for 6.0.0. Fixed SpriteResolver resets to the current Sprite from SpriteRenderer if exist in Sprite Library. [6.0.0-pre.1] - 2020-11-02 Changed Sprite Swap related features moved out of experimental namespace. Removed editing of Sprite Swap feature in Skinning Module. Updated Sprite Swap workflow focusing on Project Window and Inspector. Sprite Library Asset is created via AssetImporter. Added Sprite Library Asset supports variant. Sprite Library supports override during editing. Supports sharing of bone structures in Skinning Module. Added position, rotation and bone color editing in Skinning Module. Fixed Added missing tooltips in the Sprite Skin inspector. (case 1285255) [5.0.3] - 2020-10-15 Fixed Fixed Sprite with no animation data is being processed during AssetPostProcessor. Fixed properties under the Sprite Library Asset overlapping in inspector. (case 1280017) Fixed vertical slider handle is not aligned and placed slightly to the right side in the Bone Influence window. (case 1260568) [5.0.2] - 2020-08-31 Fixed Fixed Visibility window overlaps with weights and geometry window when Sprite Editor Window resizes. (case 1263353) Fixed 'Depth' column label gets clipped in Visibility Tool Window. (case 1257991) Fixed 'Invalid worldAABB' error message when repeatedly pressing Pack Preview button. (case 1270150) Fixed Null reference exception when changing values of a material while recording animation with Skinning Module enabled. (case 1267300) Improved memory and speed of Animation SpritePostProcess for large sprite count. [5.0.1] - 2020-07-24 Fixed Fixed Skinning module flickers when creating in category in Visibility Window. (case 1244097) Fixed NullReferenceException when creating Preset for SpriteSkin component. (case 1254873) Updated optional dependency support for Collections to 0.9.0-preview.6 and Burst 1.3.3. (case 1255839) [5.0.0] - 2020-05-11 Changed Version bump for Unity 2020.2. Added Combined 2D IK package with 2D Animation package. Fixed Remove unused XR dependency. (case 1249390) Fixed NullReferenceException when creating prefab with SpriteSkin component. (case 1245149) [4.2.4] - 2020-05-19 Fixed Fixed compilation error by depending on latest 2D Common package. [4.2.3] - 2020-04-26 Changed Improved performance by batching buffer submission when Collection and Burst package is installed Fixed Fix 'ArgumentException' when creating UXML Template Asset with 2D Animation package installed (case 1239680) [4.2.2] - 2020-03-26 Fixed Fixed bone name field in weight slider does not display bone name (case 1226249) Fixed SpriteResolver's Inspector not updated when GameObject is disabled Changed Improved deformation performance when Collection and Burst package is installed Added Allow reordering of bone order in Bone Influence window. This is to allow fine tuning of bone order when shown in SpriteSkin's Inspector [4.2.1] - 2020-03-20 Fixed Fixed inconsistent line ending [4.2.0] - 2020-03-11 Added Add alwaysUpdate option to SpriteSkin to determine if SpriteSkin execution should occur even when the associated SpriteRenderer is culled Added message to inform user on dependent packages when viewing certain sample Scenes Added API to access deformed vertices from SpriteSkin Changed Improved SpriteSkinEditor UI Adjust length of popup and value fields for Weight Slider Window Removed Remove Bounds Gizmo from SpriteSkin Remove Reset Bounds button from SpriteSkinEditor Fixed Fixed Sprite asset used by SpriteSkin in Scene is being deleted Fixed broken documentation links in inspectors Fixed Sprite deformation not updated when GameObject is being enabled Fixed exception after reverting from creating new vertices and edges Fixed visual defect after undoing changes to Bone Transform properties in SpriteSkin's Inspector [4.1.1] - 2020-01-20 ###Fixed Fix 2D Animation not working when reloading scene in runtime (case 1211100) ###Added Bone visibility persist after apply Sprite visibility persist after apply ###Changed Deformed Sprite's bounds are now calculated and bounds property is removed from SpriteSkin's inspector (case 1208712) [4.1.0] - 2019-12-18 Changed Changed default shortcut key for \"Animation/Create Vertex\" from \"Shift-D\" to \"Shift-J\" Changed default shortcut key for \"Animation/Weight Brush\" from \"Shift-C\" to \"Shift-N\" Fixed Fix visual glitch when using SpriteSwap with Multi-threaded rendering (case 1203380) Fix bone name misaligned under Weight Slider Inspector when a name contains more than 26 letters (case 1200873) Fix bones not chained correctly when splitting bone in certain cases Fix 'Label' and 'Sprite' name overlaps with its input field when preset of \"Sprite Library Asset\" is created (case 1201061) Fix bone names can be empty (case 1200861) Fix bone gets created even though clicked on Visibility Panel (case 1200857) Fix NullReferenceException when using shortcut 'Shift+1' in certain cases (case 1200849) Added Expose SpriteSkin component to be accessible from scripts. [4.0.1] - 2019-11-26 Changed Changed how Samples are imported into the user's project Updated Third Party Notices file Fixed Fix Animation Samples crashes when installing on certain machines (case 1185787) [4.0.0] - 2019-11-06 Changed Version bump for Unity 2020.1 Improve optional performance boost by installing Burst and Collections package. Currently tested with com.unity.collections 0.1.1-preview com.unity.burst 1.1.2 Added Skinning Module now persists the following state after Apply or Revert is clicked in Sprite Editor Window Current view mode i.e. Character or Spritesheet Mode Sprite Selection Bone Selection Preview Pose Vertex Selection Visibililty Tool Active State Weight Brush Settings Fixed Update to use new UIElements ListView API [3.0.7] - 2019-10-18 Fixed Fix Search reset button is visible in Visibility tool when nothing is entered into the search field (case 1182627) Fix Sprite outline disappears when the Selected Outline Color alpha value is less than 255 (case 1186776) Fix button's label spelling error in 'Generate For All Visible' (case 1188621) [3.0.6] - 2019-09-18 Changed Remove usage of Resource folder for assets needed by package. Fixed Fix GC allocation when using Sprite Resolver. [3.0.5] - 2019-09-06 Added Optional performance boost by installing Burst package. Samples showing different how to produce different outcomes Changed Sprite and Group in Sprite Visibility Window appear in same order as original art source file Fixed Fix missing bone data in Sprite when importing with AssetDatabase V2 [3.0.4] - 2019-08-09 Added Add related test packages Added tangent deform for lighting support Fixed Fixed Amount slider not working in Weight Slider Panel Fixed exception when changing size to less than 0 in SpriteLibraryAssetInspector Fixed Sprite visual corruption when swapping Sprite using SpriteResolver ###Changed Make Size property field in Weight Brush draggable for changing brush size Rename SpriteLibraryAsset::GetCategorylabelNames to SpriteLibraryAsset::GetCategoryLabelNames Change string hash for Category and Label name. This might break existing animation usage with SpriteResolver. Add Experimental tag on Sprite Swap related features [3.0.3] - 2019-07-17 Changed Update documentation Update to latest Mathematics package version [3.0.2] - 2019-07-13 Changed Mark package to support Unity 2019.3.0a10 onwards. [3.0.1] - 2019-07-12 Changed Fix path length due to validation failure. [3.0.0] - 2019-06-17 Changed Remove preview tag. Remove experimental namespace [2.2.0-preview.3] - 2019-06-06 Added BoneGizmos can be toggled in the SceneView Gizmos dropdown Scrollbar does not show for toolbar when required to scroll Change Sprite Library implementation. APIs redesigned. This will cause compilation errors if previous APIs are used Data serialization change. Previous Asset and Component data will not be compatible [2.2.0-preview.2] - 2019-05-10 Added BoneGizmos will only show in selected hierarchies. Associate nearest Bone to Sprite intead of root Bone when no Bones are overlapping the Sprite Fixed Sprite not showing after it is being culled due to bone animation Add icons for Sprite Library Asset, Sprite Library Component and Sprite Resolver Component Fixed Sprite Library Asset Inspector Property Field text clipping SpriteResolver will assign Sprite to SpriteRenderer even it resolves to a missing Sprite Add visual feedback in SpriteResolver Inspector for missing Sprite [2.2.0-preview.1] - 2019-05-09 Added Upgrade for 2019.2 Copy and Paste rework Visibility Window remains open when switching between tools Reparent Bone tool removed and functionality moved into Bone Visibility Panel Added Sprite Library feature Add Layer Grouping support in Sprite Visibility Panel [2.1.0-preview.4] - 2019-04-29 Added Fix skinning not in sync with the rendering. [2.1.0-preview.3] - 2019-04-24 Added Set Burst compilation off for internal build [2.1.0-preview.2] - 2019-02-25 Added Fix enable skinning on add SpriteSkin component Upgrade dependency package version for Unity 2019.1 support Fix case 1118093: SpriteSkin.onDrawGizmos() increases memory usage. [2.1.0-preview.1] - 2019-01-25 Added Update package to work with 2019.1 Improve animation runtime performance Fix bone reparenting sibling order Fix Sprite Visibility Tool in disabled state in certain cases Update documents [2.0.0-preview.1] - 2018-11-20 Added Overhauled 2D Animation workflow. Refer to updated documentation for workflow changes. Single Sprite Editor Window module for 2D Sprite Rigging workflow Unified Bone, Geometry and Weight tools in a single window Supports Multiple Sprite Single Character rigging workflow through 2D PSD Importer Package. SpriteSkin now uses user define bounds for renderer culling [1.0.16-preview.2] - 2018-11-14 Added Fix 2 Issues: Prefabs with SpriteSkin loses references to bone hierarchy when Library folder is rebuilt/different. The scene viewport shows the character without any bones applied, needing an re-import. [1.0.16-preview.1] - 2018-07-18 Added Fix error log about VertexAttribute [1.0.16-preview] - 2018-06-20 Added Fix Documentation warnings Fix error log complaining about DidReloadScripts signature. Fix issues with generate outline [1.0.15-preview] - 2018-04-12 Added New Version suffix (preview) Improved Scene View gizmos for better manipulation of bone rotation and position Added notification when Sprites are imported with incorrect weights Fixed bug where textures with max texture size could not generate geometry"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/2DIK.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/2DIK.html",
    "title": "2D Inverse Kinematics (IK) | mmo-rpg-unity",
    "keywords": "2D Inverse Kinematics (IK) Overview The 2D Inverse Kinematics (IK) feature set allows you to apply 2D IK to the bones and Transforms of your characters’ animation skeletons. 2D IK automatically calculates for the positions and rotations of a chain of bones moving towards a target position. This makes it easier to pose and animate character limbs for animation, or to manipulate a skeleton in real-time. Applying 2D IK to character skeletons The following workflow continues from the 2D Animation package animation workflow, and demonstrates how to apply 2D IK to your character skeletons. Refer to the hierarchy of bones created with the 2D Animation package's Bone tools of the Skinning Editor. Add the IK Manager 2D component to the GameObject at the top of the hierarchy. This is usually the main root bone of the entire character skeleton. Add to the IK Solvers list by selecting which type of IK Solver to use. The IK Solvers are also added as additional GameObjects in the hierarchy. With an IK Solver selected, create and set the Effector and Target for the IK Solver. Position bones by moving the Target's position to move the chain of bones with IK applied. Example demonstrating how to use the IK Manager 2D The IK Manager 2D component controls the IK Solvers in the hierarchy. Add the Manager component to the highest bone in the hierarchy, commonly referred to as the Root bone. In this example, add the component to Plunkah as it is the Root bone in the hierarchy: To add an IK Solver, select the + symbol at the bottom right of the IK Solvers list (see below). Select an IK Solver from the three options in the dropdown menu - Chain (CCD), Chain (FABRIK), and Limb. Each type of IK Solver uses a different algorithm to solve for the position of Effectors. IK Solvers are iterated in descending order, with Solvers lower in the list referring to the positions set by the Solvers higher in the list. The order of Solvers usually reflects the order of bones/Transforms in the skeleton hierarchy. For example, if the arm bone is the child of the torso bone, then the torso's IK Solver should be set above the arm’s Solver in the list. Rearrange the Solvers by dragging the leftmost edge of a row up or down. Weight Weight measures the degree that a Solver’s solution affects the positions of the bones/Transforms in the chain. The IK Manager 2D has a master Weight property that affects all Solvers it controls. It is applied in addition to the Solver’s individual Weight settings. Restore Default Pose Select this to reset all bones and Transforms back to their original positions. IK Solvers The IK Solver calculates the position and rotation the Effector and its connected bones should take to achieve their Target position. Each type of IK Solver has its own algorithm that makes them better suited to different kinds of conditions. The following properties are available to all Solvers: Property Description Effector Define the bone or Transform the IK Solver solves for. Target The Transform which is used to indicate the desired position for the Effector. Constrain Rotation This constrains the rotation of the Effector to the rotation of the Target. Restore Default Pose Enable to restore the bones to their original positions before 2D IK is applied. Disable to apply 2D IK in relation to the Effector’s current position and rotation. Weight Use the slider to adjust the degree the IK Solver’s solution affects the original Transform positions. At the lowest value of 0, the IK solution is ignored. At the maximum value of 1 the IK solution is fully applied. This value is further influenced by the IK Manager's master Weight setting. The following properties are only available to Chain (CCD) and Chain (FABRIK) - Chain Length The number of bones/Transforms (starting from the Effector) in the chain that the IK solution is applied to. Iterations The number of times the algorithm runs. Tolerance The threshold where the Target is considered to have reached its destination position, and when the IK Solver stops iterating. Limb This is a standard two bone Solver that is ideal for posing joints such as arms and legs. This Solver’s chain length is fixed to three bones - starting from the Effector bone/Transform and including up to two additional bones in its chain. Chain (CCD) - Cyclic Coordinate Descent This IK Solver uses the Cyclic Coordinate Descent algorithm, which gradually becomes more accurate the more times the algorithm is run. The Solver stops running once the set tolerance or number of iterations is reached. The following property is only available to the Chain (CCD) IK Solver: Property Description Velocity The speed the IK algorithm is applied to the Effector until it reaches its destination. Chain (FABRIK) - Forward And Backward Reaching Inverse Kinematics This IK Solver uses the Forward And Backward Reaching Inverse Kinematics (FABRIK) algorithm. It is similar to Chain (CCD) as its solution becomes more accurate the more times its algorithm is run. This Solver stops running once the set Tolerance or number of Iterations is reached. The Chain (FABRIK) IK Solver generally takes less iterations to reach the Target's destination compared to Chain (CCD), but is slower per iteration if rotation limits are applied to the chain. This Solver is able to adapt quickly to if the bones are manipulated in real-time to different positions. ##Creating an Effector and its Target After creating an IK Solver, the next step is to set the Effector and its Target. A Target is a Transform that represents the target position the Effector attempts to reach. As the Effector moves towards the Target position, the IK Solver calculates for the position and rotation of the Effector and the chain of bones it is connected to. Follow the steps below to set a Target: Select the last bone in the chain. Create an empty Transform (right-click > Create Empty). It is automatically created as a child of the highlighted bone. Move the position of the Transform to the tip of the last bone in the chain. Select the IK Solver. With its Inspector window open, drag the Transform from the hierarchy onto the Effector field. Click the Create Target button. A Target is created at the Transform's position. If the Create Target button appears inactive, ensure that the Chain Length value is set to one or greater. The Target is created as a child of the IK Solver. It appears as a circle gizmo in the Scene view. Move the Target to manipulate the connected chain of bones. The Scene view Gizmo Toggle or customize the display settings of the IK Gizmos to adjust their visibility when animating your characters. This is useful when you need to improve their readability or to reduce on-screen noise when editing animating your characters. Global IK Gizmos Toggle You can toggle the IK Gizmos by going to the Gizmos drop-down menu at the upper right of the Scene view window, then select or clear IKManager2D (menu: Gizmos > Scripts > IKManager2D) to enable or disable the Gizmos respectively. Solver Gizmos Customize Solver Gizmos via the IK Manager 2D component that manages the Solvers. From the IK Manager 2D Component Inspector, you can individually hide the Solver's Gizmo to isolate only the Solvers that you are interested in. To further distinguish the Gizmos, you can also customize the colors of the Gizmos from the IK Manager 2D Component Inspector Scripting API Reference Adding New Solvers You can add your own solver by extending from the class Solver2D. Your extended class will then show up as a new solver under the solver menu in the IKManager2D component. Solver2D This is the base class for all IK Solvers in this package. IKManager2D will detect all classes extending this and accept it as a Solver it can control. Implement or override the following methods to create your own IK Solver: protected abstract int GetChainCount() This function returns the number of IK chains the solver owns. Use this to return the number of IK chains your solver owns. public abstract IKChain2D GetChain(int index) This function returns the IKChain2D at the given index. Use this to return the IKChain2D your solver owns at the given index. protected virtual bool DoValidate() This function does validation for all parameters passed into the solver. Use this to check if your solver is set up correctly with all inputs. protected virtual void DoInitialize() This function initializes the solver and builds the IK chains owned by the solver. This is called whenever the solver is invalid after changing the target of the solver or other parameters of the solver. Use this to initialize all the data from the parameters given to the solver, such as the IK chains owned by the solver. protected virtual void DoPrepare() This function prepares and converts the information of the Transforms (position, rotation, IK parameters etc) to structures which can be used by the IK algorithms. Use this to do any work to gather data used by your solver when updating the IK positions. protected abstract void DoUpdateIK(List effectorPositions) This function calculates and sets the desired IK positions for the Transforms controlled by the solver given a list of effector positions for each chain owned by the solver. The effector positions may be overridden by user positions if manipulated from the SceneView. protected virtual Transform GetPlaneRootTransform() This function returns the transform whose localspace XY plane is used to perform IK calculations. Use this to define the Transform used. IKChain2D This is the class which stores the transforms involved in an IK chain. When a chain is set up with a target and a transform count, initializing the Solver will populate the chain with the right transforms if valid. Target - The transform which is used as the desired position for the target. Effector - The transform to perform IK on to reach a desired position. TransformCount - The number of transforms involved in the IK solution starting from the target. This is generally equivalent to ChainLength in solvers. Transforms - All transforms involved in the chain. In general, the last transform in this is the target transform and the first transform is considered the root transform for the chain. Lengths - The lengths between each transform in the chain. Solver2DMenu This attribute allows you to tag your Solver2D with a different name under the IKManager2D. Use this if you do not want to use the name of the class of the Solver2D. Example when giving the LimbSolver2D the name 'Limb' in the menu: [Solver2DMenuAttribute(\"Limb\")]"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/Animating-actor.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/Animating-actor.html",
    "title": "Animating an actor | mmo-rpg-unity",
    "keywords": "Animating an actor After importing and rigging an actor, you can begin animating by simply dragging the rigged actor into the Scene view. By repositioning the different bones of the actor on the Animation timeline with Unity's animation workflow and tools. The mesh of the actor deforms with the positioning of the rigged bones, creating smooth animation transitions. Aside from this method, there are other ways that you can animate with the 2D Animation package. The following are a few examples based on the Sample scenes available for you to import to use with the package. Sprite Swap The 2D Animation package allows you to use the Sprite Swap feature to swap to different Sprites at runtime, from swapping only a single part of an actor to swapping the entire Sprite Library Asset it refers to. Other Sample projects Sample projects are distributed with the 2D Animation package and available for import. These projects include examples of the different ways you can animate with the package features such as an Animated Swap. Refer to the respective Sample documentation pages for more information."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/AssetUpgrader.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/AssetUpgrader.html",
    "title": "2D Animation Asset Upgrader | mmo-rpg-unity",
    "keywords": "2D Animation Asset Upgrader The 2D Animation package and its assets are often updated with major and minor tweaks over time. Some asset improvements can be automatically applied when you upgrade to the latest version of the package. However, some of these changes require a manual step in order to have the assets use the latest code path. The 2D Animation Asset Upgrader tool eases the transition and upgrade of older assets to newer ones. This tool has the following features: Upgrades Sprite Library Asset files ending in .asset to Sprite Library Source Asset files ending in .spriteLib. Moves Sprite Library Assets baked into .psb files created in Unity 2019 and Unity 2020 out into their own separate Sprite Library Source Asset files ending in .spriteLib. Upgrades Animation Clips that animate Sprites based on the Sprite Resolver component's Category and Label hash in Unity 2019 and Unity 2020, to Sprite Resolver's new Sprite Hash property from Unity 2022 onwards. Upgrades Animation Clips animating the Sprite Resolver component's Sprite Key property in Unity 2021, to Sprite Resolver's new Sprite Hash property from Unity 2022 onwards. Getting Started Before upgrading any assets in your current project, make sure to source control or back up your project. Go to Window > 2D > 2D Animation Asset Upgrader to open the 2D Animation Asset Upgrader. Upgrading Sprite Libraries Follow these steps to upgrade the Sprite Libraries in the project. Open the 2D Animation Asset Upgrader. Select the Sprite Libraries button to open the Sprite Libraries tab. Select the Scan project button. The window then displays a list of all the Sprite Libraries that you can upgrade. Clear any Sprite Library Assets which you do not want to upgrade. Select the Upgrade selected button to begin the upgrading process. The editor then displays a pop-up window to inform you that the upgrade cannot be reverted, and any Asset Bundles connected to the Sprite Libraries will need to be rebuilt. Select Yes to proceed with the upgrade, or No to cancel the upgrading process. Once the upgrading process is complete, the 2D Animation Asset Upgrader will display the status of the upgrading process for each of the selected assets. Select the Open upgrade log button to get more detailed information about the different upgrade warnings and errors that may appear. The upgrade log will also list all the Asset Bundles that need to be rebuilt for the upgrading process. Upgrade Animation Clips Follow these steps to upgrade the Animation Clips in the project: Open the 2D Animation Asset Upgrader. Select the Animation Clips button to open the Animation Clips tab. Select the Scan project button. The window then displays a list of all the Animation Clips that you can upgrade. Clear any Animation Clips which you do not want to upgrade. Select the Upgrade selected button to begin the upgrading process. The editor then displays a pop-up window to inform you that the upgrade cannot be reverted, and that any Asset Bundles connected to the Animation Clips will need to be rebuilt. Select Yes to proceed with the upgrade, or No to cancel the upgrading process. Once the upgrading process is complete, the 2D Animation Asset Upgrader will display the status the upgrading process for each of the selected Animation Clips. Select the Open upgrade log button to get more detailed information about the upgrade warnings and errors that may appear. The upgrade log will also list all the Asset Bundles that need to be rebuilt for the upgrading process. Common upgrading errors and solutions The following are the common errors you may face when upgrading your projects, and their suggested solutions. Referring to the upgrade log for general debugging The first step to debugging an upgrade failure is to refer to the upgrade log. The 2D Animation Asset Upgrader writes each action it takes into the log, helping you to track down the point of failure. 9/11/2021 2:06:23 PM Asset Upgrading --------------- Verifying if the asset Talk (UnityEngine.AnimationClip) is an AnimationClip. Extracting SpriteHash bindings from clip. Found 0 bindings. Extracting SpriteKey bindings from clip. Found 0 bindings. Extracting Category bindings from clip. Found 0 bindings. Extracting Label keyframes from clip. Found 3 keyframes. Extracting Label bindings from clip. Found 1 bindings. Merging different types keyframes from the same bindings, into the same binding list. We now have 1 binding lists. Order the keyframe data in binding=Hand by time. Converting keyframes into uniformed format for binding=Hand Cannot find a category for keyframe at time=0 in binding=Hand. Cannot find a category for keyframe at time=3.383333 in binding=Hand. Cannot find a category for keyframe at time=4.966667 in binding=Hand. Expected 3 keyframes after cleanup for binding=Hand, but ended up with 0. The upgrade of the clip Talk failed. Some keyframes could not be converted in the animation clip. In this example, the upgrade log shows the actions and results from upgrading an Animation Clip that contains only Label hashes, but no Category hashes. The 2D Animation Upgrader writes to the log that it cannot find a Category hash for three out of three keyframes. This results in a failure to upgrade the Animation Clip. When some keyframes could not be converted in the Animation Clip One of the most common reasons for this error is when an Animation Clip contains either Sprite Resolver Category hash keys or Sprite Resolver Label hash keys, but not both types of hash keys at the same time. This example shows an incorrect Animation Clip setup where the Animation Clip contains only the Label hash, but not a Category hash, which leads to the above error. This example shows the corrected setup, where the Animation Clip contains both the Label hash and the Category hash. Fix this error by recording a Sprite Swap on the first frame in the Animation Clip. Once the Sprite Swap is added, the 2D Animation Asset Upgrader is able to upgrade the Animation Clip."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/CharacterParts.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/CharacterParts.html",
    "title": "Swapping individual Sprites | mmo-rpg-unity",
    "keywords": "Swapping individual Sprites You can use Sprite Swap to change only one Sprite on the actor without affecting the other Sprites. This allows you to alter part of an actor's visuals (for example, changing its clothes or skin to a different color) while keeping the rest of the visuals the same. In the following example, there are two Sprites that are variations of the actor’s scarf, with one being green and the other being blue. This workflow demonstrates how to switch from one to the other in the same actor: Left: The original green scarf Sprite. Right: An alternate blue scarf Sprite. Place the Sprites for both scarves into the same Sprite Library Asset, and add them both to the same Category (named Scarf). Give each of the Sprites a unique Label name (in this case green scarf and blue scarf respectively). This and the previous step can be automated by dragging and dropping sprites into the Categories tab empty space. In the Scene, select the Instantiated Prefab and then select the Scarf GameObject in the Hierarchy window. Go to the Sprite Resolver component of the Scarf GameObject. The Sprite Resolver‘s visual selector displays the two Sprites available in the Scarf Category. Select the blue scarf to switch the Sprite rendered by the Scarf GameObject to it instead. The Sprite Resolver's Label is set to blue scarf. If you want to switch more than one Sprite at a time, consider swapping the Sprite Library Asset to switch to an entire alternate set of Sprites. Sprites pivot alignment When working with skinned Sprites, the positions of their Meshes' vertices are calculated based on the current skeleton pose, and are unaffected by each Sprite’s individual pivot. However, when swapping Sprites which are not skinned (that is not Rigged to an actor’s skeleton), then they may not align correctly as their pivots are not in the same relative positions. This is especially noticeable if the Sprites are of very different sizes. The following example shows how Sprites can misalign when a skinned Sprite is swapped with an unskinned one: Figure 1: The original open hand Sprite. Figure 2: Swapping to the thumbs up Sprite. In this example, the GameObject containing the Sprite and the Sprite Swap component are aligned to match the open hand Sprite in the Skinning Editor. As the thumbs up Sprite is not rigged to the same skeleton, it appears misaligned as its pivot location is not in the same relative position as the original Sprite. To align the unskinned thumbs up Sprite, you must adjust its pivot to match the relative position of the open hand Sprite’s pivot. Note: If a Sprite is rigged to a skeleton, then its individual pivot location is overridden by the influence and position of the bone it is weighted to . To change the pivot position of a Sprite, first select the Sprite in the Sprite Editor, which causes the Sprite panel to appear at the bottom right of the Sprite Editor window. The Sprite panel shows details of the selected Sprite, such as its Name, Position, and Pivot properties. You can select from a dropdown list of predefined pivot options from the Pivot menu. These include options such as Center and Top Left, as well as Custom Pivot (this unlocks the Custom Pivot position property settings, allowing you to input your own custom position for the pivot). In this example, the two swapped Sprites are aligned by changing the Pivot property from Center to Custom Position, and inputting the Custom Pivot position that aligns the thumbs up Sprite with the open hand Sprite. After applying the changes, the swapped Sprite is now aligned with the rest of the actor after the Sprite Swap."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/CharacterRig.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/CharacterRig.html",
    "title": "Actor skinning and weighting workflow | mmo-rpg-unity",
    "keywords": "Actor skinning and weighting workflow The following steps are the general workflow for preparing your actor for animation with the Skinning Editor, after you have imported it into Unity. Follow the steps below to create the bones, generate the meshes, and adjust the weights for your actor. For more specific samples and examples, refer to the samples distributed with the 2D Animation package and the sample documentation included here. Use the Create Bone tool to build the bones of the actor skeleton. With the tool selected, click to define the start-point of the bone. Then move the cursor to where the bone should end, and click again to set the bone’s end-point. After creating a bone, the tool allows you to set the end-point of the second bone and so on, in order to create a chain of bones. To continue a chain of bones from any bone, select the Create Bone tool and click an existing bone, then click its end-point. A new bone is started from the end-point, creating a chain. Alternatively, you can set the start-point of the new bone away from its parent bone. The child bone still belongs to the same chain and this is reflected in the bone hierarchy. A faded link shows the red and blue bones are connected in a chain. After creating the bones of the actor, generate the geometry Mesh for the Sprites. It is recommended to use the Auto Geometry tool to auto-generate the geometry Mesh. With the Auto Geometry tool selected, select a Sprite and then select the Generate For Selected button to generate a Mesh for that Sprite only. To Generate For All Visible Sprites, click the generate button without selecting any Sprite. Refine the generated Meshes further by using the Edit Geometry Geometry tool, or create your own Mesh outline with the Create Vertex and Create Edge Geometry tools. Paint weights onto the Sprite geometry to adjust how much influence a bone has on the vertices of the Mesh. This affects how the mesh deforms when the actor is animated. It is recommended to use the Auto Weights tool to auto-generate the weights. The Auto Weights tool only generates weights for Sprites that have both a geometry Mesh, and bones intersecting their Mesh: The Generate For All Visible button is available when you do not select any specific Sprite. Select it to generate weights for all valid Sprite Meshes in the editor. The Generate For Selected button is available when you have a Sprite selected in the editor. Select it to generate weights for only the selected Sprite. Use the Weight Slider and Weight Brush tools to further adjust the weights of the Mesh vertices. To edit which bones influence a Sprite, select it and then go to the Bone Influence tool. A list of bones currently influencing the Sprite’s Mesh are listed in this panel at the bottom-right of the editor. To remove a bone, select it from the list and select Remove (-) at the bottom right of the list. Select Remove (-) at the bottom right of the panel. To add a bone as an influencer to the currently selected Sprite Mesh, select the bone in the editor window and select Add (+) to add it to the list. To do the reverse and edit which Sprites are being influenced by a bone, select the bone you want to examine, and then go to the Sprite Influence tool. Similarly to the Bone Influence tool, there is an Add (+) and Remove (-) button. Test your rigged actor by posing it with the Preview Pose tool. Move and rotate the different bones to check that the geometry Mesh deforms properly. Previewing poses can also be done while the following tools are selected: the Weight Brush, Weight Slider, Bone Influence, Auto Weights, and Visibility tools. To restore a rigged actor to its original pose, select Reset Pose from the Pose toolbar. Edit the default pose by moving the actor bones and joints with the Edit Bone tool. After you have completed rigging your actor, you are now prepared to animate the actor."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/Examples.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/Examples.html",
    "title": "Importing Samples | mmo-rpg-unity",
    "keywords": "Importing Samples Sample scenes are available for import from the Package Manager under Samples, which demonstrate the different ways you can use the features in the 2D Animation package to achieve a variety of effects and outcomes. Select Import to download and install the Sample projects and Assets. Each Sample project contains specific examples with ready-made Assets, demonstrating how to use the 2D Animation package's features and the results and outcomes you can achieve with them. When the import is complete, Unity installs the Sample projects to Assets/Samples/2D Animation/[X.Y.Z]/Samples; where [X.Y.Z] is the version of the installed 2D Animation package. The following is the list of Sample projects and their respective documentation. Note that some of these Samples require and refer to the PSD Importer package: Simple - a single Sprite rig with simple bone hierarchy and rigging. Single Skinned Sprite - a more advance single Sprite actor. Character - Imported with the PSD Importer Sprite Swap - - Contains examples of the different ways to use Sprite Swap. Animated Swap Part Swap Full Skin Swap DLC Swap Skeleton Sharing Runtime Swap"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/PreparingArtwork.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/PreparingArtwork.html",
    "title": "Preparing and importing artwork | mmo-rpg-unity",
    "keywords": "Preparing and importing artwork Use the 2D Animation package together with the PSD Importer package to import your artwork for animation. The PSD Importer imports the graphic data from each Photoshop Layer as Sprites, and provides various importer options that prepare your artwork for animation. The PSD Importer only supports the Adobe Photoshop .psb file format, thus it is recommended to create your artwork in Adobe Photoshop or any other graphic software which supports the Adobe .psb file format. When preparing your character or prop artwork, it is recommended to prepare them in a neutral or idle position. Depending on the complexity and use of your animation, it is also recommended to separate the individual parts of the artwork onto different Photoshop Layers (see Example 1 below). The artwork file must be saved in the Adobe Photoshop .psb file format, which is functionally identical to the more common Adobe .psd format, but supports much larger images than the .psd format (up to 300,000 pixels in any dimension). To convert artwork from the .psd format to the .psb format, open and save the .psd files as .psb files in Adobe Photoshop. Example 1: Layered character artwork in Adobe Photoshop. PSD Importer features The PSD Importer has many features and options that prepare the actor for animation. For example, enable the Mosaic option to have Unity automatically generate a Sprite sheet from the imported layers; or enable Character Rig to have Unity generate a Prefab with Sprites generated from the imported source file, with the Sprites arranged into their original positions based on the source file. Refer the PSD Importer's documentation for more information about the different options and their functions. Example 2: The imported actor's layers arranged into a Sprite sheet, and reassembled into their original positions in the generated Prefab. Workflow between 2D Animation and PSD Importer There are several ways to animate with the 2D Animation package, depending on how your artwork is prepared and how your animation will be used in your Unity Project. The 2D Animation package contains sample projects with examples of the different ways to use the package. You can import these using the Package Manager. Refer to the Importing Samples documentation for more information. The following is a general workflow for importing a multilayered and multipart character into Unity for 2D animation with the PSD Importer. For a more detailed specific example, see Rigging a character imported with the PSD Importer: Save your artwork as a .psb file in Adobe Photoshop by selecting the Large Document Format under the Save As menu, or convert an existing .psd file into the .psb format. Import the .psb file into Unity with the PSD Importer, which generates a Prefab containing Sprites based on the layers of the source file. This Prefab is referred to as an 'actor' when used with the 2D Animation package. Select the actor and go to its Inspector window to select its Importer settings. Refer to the PSD Importer documentation and the imported Samples and respective documentation to determine which settings are a best fit for your Project. For example, the following are the recommended import settings for a character with multiple limbs and layers in its source file: Set Texture Type to Sprite(2D and UI). Set Sprite Mode to Multiple. Select the Mosaic check box. Select the Character Rig check box. Select the Use Layer Grouping check box to preserve any Layer Groups in the original .psb source file. Select Apply to apply the above settings. Once the artwork is imported, a Prefab is generated from the graphic data of each layer as individual Sprites, which may be arranged in their original position or as a Sprite sheet depending on the selected importer options. The generated Prefab is referred to as an 'actor' when used with the 2D Animation package. The generated actor is now ready for rigging. Drag the actor Prefab into the Scene view to begin animating. Unity automatically adds the Sprite Skin component to the actor which deforms the Sprite using GameObject Transforms to represent the bones that are rigged and weighted to the Sprite in the Skinning Editor."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Asset.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Asset.html",
    "title": "Sprite Library Asset in Unity | mmo-rpg-unity",
    "keywords": "Sprite Library Asset in Unity The Sprite Library Asset is an Unity asset that contains the Sprites that you want to use for Sprite Swapping. This page explains what are the Sprite Library Asset properties and how to create a Sprite Library Asset or a Sprite Library Asset variant. A Sprite Library Asset groups the Sprites it contains into Categories, and you can give these Sprites unique names called Labels to differentiate them. You can edit the Sprite Library Asset's content in the Sprite Library Editor window (refer to its documentation for more details). In the Sprite Swap workflow, after creating a Sprite Library Asset or several assets, you can select the Sprite Library Asset you want to use with the Sprite Library component, and the Sprite Resolver component will pull information from the asset selected. Create a Sprite Library Asset To create a Sprite Library Asset, go to Assets > Create > 2D > Sprite Library Asset. Sprite Library Asset properties Select the Sprite Library Asset and go to its Inspector window to view the following properties. Property Description Open in Sprite Library Editor Select this to open the Sprite Library Editor window to edit the content of this asset. Main Library Leave this property empty to have this Sprite Library Asset refer to its own Categories and Labels. Assign a different Sprite Library Asset to have it become the Main Library of the selected Sprite Library Asset, which will now refer to the second asset's Categories and Labels instead. Doing so also converts the selected Sprite Library Asset into a Variant asset of the Sprite Library Asset set as the Main Library. Revert Select this to reset property changes back to the last saved state. Selecting this removes all unsaved changes. Apply Select this to save the current property settings. Create a Sprite Library Asset Variant A Sprite Library Asset Variant inherits Categories and Labels from a selected Sprite Library Asset, instead of referring to its own. There are two ways to create a Variant. Create through the menu After creating a Sprite Library Asset, select it in the Project window, then go to Assets > Create > 2D > Sprite Library Asset Variant to create a Variant asset that references it. Convert a Sprite Library Asset into a Variant You can convert an existing Sprite Library Asset into a Variant of another by setting another Sprite Library Asset as its Main Library. Additional resources Sprite Library Editor Setting up for Sprite Swap Overrides to the Main Library"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Drag.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Drag.html",
    "title": "Drag sprites to create or edit Categories and Labels | mmo-rpg-unity",
    "keywords": "Drag sprites to create or edit Categories and Labels This page shows the different ways you can create or edit Categories and Labels in a Sprite Library Asset by dragging sprites directly into the Sprite Library Editor window. You can automatically create new Categories and Labels by dragging sprites or PSD Importer supported file types directly into the Sprite Library Editor window. Prerequisites PSD Importer package is required for the Sprite Library Editor to recognize imported .psb files. Create a new Category In the open Sprite Library Editor window, drag a sprite directly onto the Categories column to create a new Category. You can't create Labels without selecting an existing Category first. Create a new Label for each sprite Select a Category, then drag a or a selection of sprites into an empty space in the Labels column. Dragging the head sprite into the Labels column creates a new Label named head in the selected Category. Unity creates a new Label for each sprite in the selection and gives it the same name as the sprite it references. Note: If an existing Label with the same name already exists at the destination, then the editor appends _X to the new Label's name, where X is the next number in sequence, starting from zero. Dragging in a selection of sprites all named head results in additional Labels created with the _X suffix for each sprite. Replace a Label's sprite reference Drag a sprite onto an existing Label. The editor replaces the sprite reference to the new sprite. The Label's name remains unchanged. Create a single Category with multiple Labels Select multiple sprites from the Project window. Drag the selected sprites into the Categories column to create a new Category. The Category is automatically named after the first sprite in the selection. Note: If an existing Category with the same name already exists at the destination, then the editor appends _X to the new Category's name, where X is the next number in sequence, starting from zero. Create Categories for each Layer and Layer Group After you prepare the .psb of your character, import it into Unity with the PSD Importer package. Note: The following requires the PSD Importer package to be installed. Enable Use Layer Group in the imported .psb's properties. Drag the imported .psb file into the Sprite Library Editor's Categories column. The editor creates a Category for each Layer and Layer Group, and creates Labels for each sprite. Sprites which belonged to the same Layer Group are automatically grouped into the same Category. Replace each Labels' sprite references The following steps how to replace each Label's sprite reference with sprites from a different imported .psb. Note: This method only works if the imported .psb has Layers and Layer Groups with the same exact names as the original .psb used to create the Categories and Labels. This method is useful when you have multiple characters with the same Layers and Layer Groups and want to replace their respective sprites without creating a new Sprite Library Asset. Enable Use Layer Groups in the replacement .psb file's properties. Drag the replacement .psb onto an empty space in the Categories column and release. All sprite references of the same name and in the same Categories are automatically replaced with their respective counterparts from the replacement .psb. Additional resources PSD Importer package Preparing and importing artwork"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Editor-UI.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Editor-UI.html",
    "title": "Sprite Library Editor reference | mmo-rpg-unity",
    "keywords": "Sprite Library Editor reference The Sprite Library Editor window displays the content of the selected Sprite Library Asset. Use the editor to view, create, or edit the Categories and the Labels in the selected Sprite Library Asset. A: The name of the Sprite Library Asset opened in this editor. B: This displays this asset's Main Library if it's a Variant asset. Refer to Variant asset-specific properties for more information. C: The saving options for changes made in this editor. D: Enter a text string here to filter the Categories or Labels by name. Select the magnifying glass icon to the left of the filter to bring up its context menu. Saving options Property Description Revert Select this to discard all unsaved changes and to return to the last saved state of the asset. Save Select this to keep all unsaved changes and include them in the saved state of the asset. Auto Save Enable this option to have the editor automatically save when you make any changes to the asset. Main Library Property Description Assign a Sprite Library Asset to this to set it as the opened Sprite Library Asset's Main Library, and it will inherit the Main Library's Categories and Labels. Doing so also converts the opened Sprite Library Asset into a Sprite Library Asset Variant. Filter context menu Property Description Category and Label Search for the entered search string in both Category and Label names. Category Search for the entered search string in only Category names. Label Search for the entered search string in only Label names. Categories and Labels columns Property Description Categories Displays all Categories the opened Sprite Library Asset contains. Select Add (+) at the top left of this column to add a new empty Category to this asset. Local foldout group Groups all Categories created in this Sprite Library Asset. Inherited foldout group Groups all Categories inherited from this Sprite Library Asset Variant's Main Library. Note: This is only available if the opened Sprite Library Asset is a Variant asset. Labels Displays all Labels a selected Category contains, when you select one from the Categories column. Select Add (+) at the top left of this column to add a new empty Label to this asset. (Sprite) object field Displays the sprite that this Label refers to. This is blank by default. Select a sprite by opening the object picker, or drag a sprite directly onto this field. Variant asset-specific properties The following properties and UI features are visible only when you open a Sprite Library Variant Asset in the Sprite Library Editor. E: The breadcrumb trail showing the names of the opened Variant asset and Library assets it inherits from. F: The Main Library the Variant asset inherits from. G: The Inherited group type that displays all Categories inherited from the Main Library. H: A vertical white line which shows that an override is present. Label context menu Right-click over a Label in the Labels column to open this context menu. Property Description Create a new Label Create a new local Label in the selected Category. Rename Label Rename the selected Label. This is unavailable if it's an inherited Label. Delete Selected Labels Deletes all selected Labels. This is unavailable if they're inherited Labels. Revert Selected Overrides Removes all overrides made in the selected Labels, and returns them back to their inherited state. Removes all overrides in the selected Category. Show Label Location This is only available if the selected Label has a set sprite reference. Select this to open the sprite that the Label references. Additional resources Sprite Library Editor fundamentals Setting up for Sprite Swap"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Editor.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Editor.html",
    "title": "Sprite Library Editor fundamentals | mmo-rpg-unity",
    "keywords": "Sprite Library Editor fundamentals The Sprite Library Editor window is where you edit the content of a selected Sprite Library Asset. Select a Sprite Library Asset and then select Open in Sprite Library Editor in its Inspector window to open this editor. You can also open the Sprite Library Editor window directly by going to Window > 2D > Sprite Library Editor. A Sprite Library Asset groups the sprites it contains into Categories and Labels, and you edit their contents in the Sprite Library Editor window. This page shows you the basic features of the Sprite Library Editor and how to begin editing a Sprite Library Asset. Categories Creating a new Category in the Categories column. Use Categories to contain and group Labels together for a common purpose to make it easier to organize your sprites. For example, you can create a Category named 'Hat' for Labels which refer to sprites of hats for your character. To create a new Category, select Add (+) in the Categories column, or drag sprites directly into the Sprite Library Editor window. Give each Category a unique name to ensure that the editor correctly identifies each individual Category. Local and inherited Categories Inherited and Local foldout groups in the Categories column. There are two types of Categories: Local: A Local Category is a Category created in the open Sprite Library Asset in the editor window. Inherited: An Inherited Category is a Category retrieved from the Sprite Library Asset set as the Main Library. Note: You can't rename inherited Categories, to ensure that the Category names in the Sprite Library Asset Variant matches the originals in the Main Library. This ensures that the Variant asset can inherit all Categories and Labels from the Main Library. To make changes to an inherited Category's content, you can create overrides to an inherited Category or Label such as adding new Labels or changing the Sprite an inherited Label references instead. Labels A Category contains multiple Labels, with each Label referencing a single sprite in the project. When you are setting up for Sprite Swap, Labels with similar functions are commonly placed in the same Category. For example, a Category named 'Hats' may contain Labels which each reference a different hat sprite. To create a new Label, select Add (+) in the Labels column, or drag Sprite directly into the Sprite Library Editor window. Create a new Label by selecting Add (+). Note: If a Label is inherited from a Main Library and exists in an inherited Category, you can't rename the inherited Label to ensure that it matches the original's name in the Main Library. This ensures that the Variant asset can inherit all Categories and Labels from the Main Library. You can create new Labels or edit the sprite reference of an inherited Label as overrides to an inherited Category or Label. Refer to Overrides in the Main Library for more information. Useful editor features The following editor features make it more convenient to edit the contents of a Sprite Library Asset. For more information about all available editor features, refer to the Sprite Library Editor reference. Navigate between different assets When you open a Sprite Library Asset Variant in the Sprite Library Editor, you can use the Sprite Library Editor breadcrumb trail to navigate between different Sprite Library Assets that the opened asset inherits from. Select an asset in the breadcrumb trail to select it in the Project window. Toggle between list or grid view You can view the sprite content of Labels in a list or in a grid. To toggle between these two views, select the respective icon at the lower right of the editor window, and use the slider to adjust the size of the visual preview. Filter Categories and Labels by name Filter the Categories and Labels by entering a text string into the filter bar in the upper right of the window. You can adjust the parameters of the filter by using the filter context menu. Additional resources Sprite Library Editor reference Drag sprites to create or edit Categories and Labels Overrides to the Main Library"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Main-Library.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Main-Library.html",
    "title": "Overrides to the Main Library | mmo-rpg-unity",
    "keywords": "Overrides to the Main Library When you create a Sprite Library Asset, you have the option of converting it into a Sprite Library Asset Variant, or creating a Variant asset of the selected Sprite Library Asset. A Variant asset inherits all the Categories and Labels from the Sprite Library Asset as its Main Library. You can't directly change the Categories and Labels inherited from the Main Library, but you can add to the inherited content by adding new Categories and Labels in the form of overrides. Inherited Categories and Labels limitations Assigning another existing Sprite Library Asset to the Main Library property of the current Sprite Library Asset allows the current Asset to access all Categories and Labels contained in the assigned Sprite Library Asset. Inherited Categories are visible in the Sprite Library Editor window in the Inherited foldout group, while the Local foldout group contains all Categories that exist solely in the current asset. You can't rename or remove the Labels of inherited Categories, but you can add new Labels to an inherited Category as an override. Create overrides An override is any change you make to the contents of an inherited Category. While you can't rename or remove inherited Labels, you can do the following in an inherited Category: Create a new Label. Change the sprite that the Label references. Revert overrides in selected Labels or for all inherited Categories and Labels. The Sprite Library Editor window displays a vertical white line next to inherited Categories and inherited Labels when an override is present. Change the sprite reference You can change a Label's sprite reference by selecting a different sprite from the object picker next to the Sprite object field. You can also change the sprite reference by dragging the desired sprite directly onto to a Label. To revert sprite reference changes made to selected Labels, right-click the Label(s) and select Revert Selected Overrides from the context menu to restore all sprite references back to their original inherited state from the Main Library. Revert changes to Labels in inherited Categories by selecting Revert Selected Overrides. To revert all overrides in the selected inherited Category, select Revert All Overrides from the context menu. Caution: Overrides aren't included in the save state of the Sprite Library Editor, and reverting overrides will remove all overrides regardless of the previous save state. To undo the last action, press Ctrl+Z (macOS: Cmd+Z)."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Resolver.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-Resolver.html",
    "title": "Sprite Resolver component in Unity | mmo-rpg-unity",
    "keywords": "Sprite Resolver component in Unity The Sprite Resolver component pulls information from the Sprite Library Asset assigned to the Sprite Library component at the root of the actor Prefab, and displays the Sprites available for selection. This component is part of the Sprite Swap setup and workflow, where attaching the Sprite Resolver component to a GameObject that's part of an actor Prefab allows you to change the Sprite rendered by that GameObject's Sprite Renderer component. Property settings The component contains two properties - Category and Label - and the Visual variant selector interface which displays thumbnails of the Sprites within the Sprite Library Asset. Inspector window properties of Sprite Resolver component. Property Function Category Select the Category that contains the Sprite you want to use for this GameObject. Label Select the Label name of the Sprite you want to use for this GameObject. Visual variant selector Select the thumbnail of the Sprite you want to use. This selector displays all Sprites contained in the selected Category above. Additional resources Setting up for Sprite Swap Sprite Library Asset in Unity Sprite Library component in Unity"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-component.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SL-component.html",
    "title": "Sprite Library component in Unity | mmo-rpg-unity",
    "keywords": "Sprite Library component in Unity The Sprite Library component defines which Sprite Library Asset a GameObject refers to at runtime. When you attach this component to a GameObject, the Sprite Resolver component attached to the same GameObject or child GameObject will refer to the Sprite Library Asset set by the Sprite Library component. This allows you to change the Sprite referenced by a Sprite Renderer with the Sprite Resolver component. Property settings In the Sprite Library component’s Inspector window, assign the desired Sprite Library Asset to the Sprite Library Asset property. After assigning a Sprite Library Asset, the Inspector window shows a visual preview of the content in the selected Sprite Library Asset. Component functions Within the Sprite Library component Inspector window, you can commit the same overrides to the assigned Sprite Library Asset as you would to the Main Library in the Sprite Library Editor window. You add or remove new Categories, add or remove new Labels in a Category, and change the sprite a Label refers to. Modified Sprites Example: A modified sprite retrieved from the Sprite Library Asset. The + icon appears at the upper left of a Label entry when: You add a new Label to a Category from the retrieved Sprite Library Asset. You change the sprite reference of a Label from the original sprite reference retrieved from the Sprite Library Asset. Category and Label name conflict behavior The following are the ways Unity resolves any name conflicts that may occur when you replace the assigned Sprite Library Asset in the Sprite Library Asset property with another Sprite Library Asset. If the same Category name already exists in the current set Sprite Library Asset, then Unity merges the Labels from Categories with the same name in both Sprite Library Assets into a single Category with that name. If there are Labels with the same name within the same Category when you assign the Sprite Library Asset, then Unity merges the Labels into a single Label. The merged Label uses the sprite reference from the replacement Sprite Library Asset instead. Note: When you remove a Sprite Library Asset from the Sprite Library Asset property, overrides aren't saved to that Sprite Library Asset. All changes remain in the Sprite Library component. Additional resources Swapping Sprite Library Assets Overrides to the Main Library"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SLASwap.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SLASwap.html",
    "title": "Swapping Sprite Library Assets | mmo-rpg-unity",
    "keywords": "Swapping Sprite Library Assets If swapping each Sprite of an actor individually takes too much effort, you can instead swap the entire Sprite Library Asset to another one containing alternate Sprites. The following example shows how to switch from a Sprite Library Asset of color Sprites to another one containing identical Sprites but in grayscale: Left: An actor with the color Sprite Library Asset. Right: The same actor with the grayscale Sprite Library Asset. Create visual variants of your actor's artwork. In this example, the original artwork is in color and a grayscale variant of it is created as an alternate Sprite set. Both should be saved to separate .psb files. Import both .psb files into the Unity Editor. Both become separate Model Prefabs in the Asset window. Create a Sprite Library Asset and assign each Sprite of the actor to a unique Category. For convenience, name each Category and Label after the respective body part of the actor. You can also drag and drop your Sprites into the empty space in the Categories tab to populate them automatically. Save the changes once complete. The Category and Label names for the parts of the color actor. Repeat step 3 for the grayscale actor. Use the same Category and Label names for the corresponding gray Sprites. Remember that you can drag and drop your Sprites to empty space in the Categories and their corresponding Labels should now have a new Sprite reference. The grayscale Sprites with the same corresponding Category and Label names. Drag the color Model Prefab into the Scene view, and go to the root GameObject. Add a Sprite Library component to the root GameObject and assign the color Sprite Library Asset created in step 3 to the Sprite Library Asset property. For every Sprite Renderer in the Instantiated Prefab, add a Sprite Resolver component and ensure that the Sprite Resolver component has the same Sprite selected as the Sprite Renderer. With the Inspector window of the color Prefab root GameObject remaining open, go to the Asset window and assign the Sprite Library Asset created in step 4 to the Sprite Library Asset property of the Sprite Library component. The Sprites of the color Prefab should have switched to their grayscale counterparts of the grayscale Sprite Library Asset. The Sprite Library Asset property is set to the grayscale version of the original Sprite Library Asset and the actor's Sprites have switched accordingly."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SLAsset.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SLAsset.html",
    "title": "Sprite Library Asset | mmo-rpg-unity",
    "keywords": "Sprite Library Asset A Sprite Library Asset groups multiple Sprites into Categories and unique Label names. It is used in combination with the Sprite Library component and Sprite Resolver component to swap Sprite graphics at runtime. To create the Asset, go to Assets > Create > 2D > Sprite Library Asset. To create the Asset variant that inherits Categories and Labels from a selected Sprite Library Asset, first select the main asset in the Project window, then go to Assets > Create > 2D > Sprite Library Asset Variant. Sprite Library Asset Inspector window Once the Sprite Library Asset is created, select the Asset and go to its Inspector window. Sprite Library Asset Inspector properties Property Function Open in Sprite Library Editor Select this button to open a Sprite Library Editor window where the content of the Asset can be edited. Main Library Assign another Sprite Library Asset here to make it the main reference for the current Sprite Library Asset. The current Sprite Library Asset becomes a variant of the Main Library, which allows it to access the Main Library's Categories and Entries. Revert This resets changes in the Inspector back to the last saved state. Unsaved changes are removed. Apply This saves the current value of Main Library in the Sprite Library Asset. Sprite Library Editor window Sprite Library Editor window allows editing the content of the Sprite Library Asset. It can be accessed by double-clicking on the selected Sprite Library Asset in Project window, selecting the Open in Sprite Library Editor button in the Inspector, or by selecting it from menu Window > 2D > Sprite Library Editor. Categories A Category contains selected Labels that have been grouped together for a common purpose. Make sure that each Category has a unique name. To create a new Category, select the '+' button, or drag and drop Sprites directly into the Sprite Library Editor window. Categories tab with the '+' button The Categories Tab can contain Local and Inherited Categories: Local Categories are Categories created in the Sprite Library Asset currently being edited. Inherited Categories are retrieved from the Main Library. Inherited categories cannot be renamed to ensure that the Main Library and variant Sprite Library Assets contain Categories with exactly the same name. Any inherited Category can be overridden by adding new Labels or changing the Sprite reference in a inherited Label. Local & Inherited foldout groups in the Categories tab. Labels Each Category can contain many Labels and each Label can reference a single Sprite in the project. To create a new Label, select the '+' button, or drag and drop Sprite directly into the Sprite Library Editor window. Labels tab with the '+' button If the Label exist in the Inherited Category, it cannot be renamed to ensure that the Main Library and Assets that reference that Sprite Library contain the same Categories and Labels. To revert changes in the inherited Category, select the Labels you wish to revert and right-click to open the context menu and select Revert Selected Overrides or Revert All Overrides if you want to make the entire Category the same as it is in the Main Library. Changes to Labels in inherited Categories can be reverted in the Labels tab. Sprite Library Editor window allows Labels to be viewed in a list or in a grid. To toggle between these two, use the buttons at the bottom of the window and use the slider to adjust the size of the Label elements. Search for Categories and Labels Categories and Label tabs can be filtered by the search phrase in the search bar in the top-right side of the window. Drag and drop You can quickly populate Categories and Labels by dragging Sprites or PSD Importer supported file types into the Sprite Library Editor window. Create a new Category with one Label for each Sprite Drag and drop Sprites to an empty space in the Categories tab to create a new Category with one Label for each Sprite in the selection. The Category is be named after the first Sprite in the selection and Labels are named after the Sprite's name. If there are any conflicting name, it will be appended with _X suffix for example ConflictingSpriteName_0. Example: Drag and drop multiple Sprites to an empty space in Categories Tab. Result: One Category with Labels for each Sprite in the Selection Create a new Category for each Layer Group with one Label for each Sprite in a Layer To create Categories for each Layer Group with Labels that match Layers in that group simply drag and drop PSD Importer supported file e.g. .psd or .psb. Make sure that Use Layer Group is checked. Result: One Category for each Layer Group and Labels for each Layer. To replace each Label's Sprite reference with Sprites from a different file, simply drag and drop it to an empty space in the Categories Tab. Result: Each Label's Sprite reference is replaced. Replace each Label's Sprite in the Category Drag and drop Sprites to an existing Category. For each Sprite in the selection, a new Label with the same name will be created. If a Label with the same name already exists, its Sprite reference will be replaced with the first Sprite from the selection. Example: Category with several Labels. Result: Labels are replaced after drag and drop. Create a new Label for each Sprite in the Category Drag and drop Sprites to an empty space in the Labels tab. For each Sprite in the selection, a new Label with the same name will be created. If a Label with the same name already exists the _X suffix will be added to the newest Label. Example: Category with before dragging and dropping Sprites. Result: Additional Cateories created with suffix _0, _1 etc. Replace a Label's Sprite Drag and drop a Sprite to an existing Label. Example: Drag and drop a Sprite on a Label. Result: Label's Sprite reference is replaced with the first Sprite in the selection. Main Library Assigning another existing Sprite Library Asset to the Main Library property of the current Sprite Library Asset allows the current Asset to access all Categories and Labels contained in the assigned Sprite Library Asset. Categories retrieved from the Main Library Asset are grouped under the Inherited foldout group, and all new Categories that exist only in the current Asset are grouped under the Local foldout group. The Labels of the Categories retrieved from the Main Library property can't be renamed or removed. However, you can add new Labels to a Category which was retrieved from the Sprite Library Asset assigned to the Main Library property. You can also edit a Label to change the Sprite that it refers to by selecting the object picker and choosing a different Sprite. It's also possible to drag and drop a Sprite to a Label to change its Sprite. To revert changes to a Sprite, select the Label, right-click and select Revert Selected Overrides to restore it to the original Sprite that was retrieved from the Main Library. Use Sprite Library Editor breadcrumbs to navigate between between different Sprite Library Assets that the edited Asset inherits from. After clicking on an Asset in the breadcrums it will be selected in the Project window. Sprite Library component The Sprite Library component defines which Sprite Library Asset a GameObject refers to at runtime. Attach this component to a GameObject or any parent GameObject of a Sprite Resolver component to allow the Sprite Resolver to change the Sprite that is being used by a Sprite Renderer. In the Sprite Library component’s inspector, you can assign the desired Sprite Library Asset to use. By assigning a Sprite Library Asset, the component’s Inspector shows a preview of the content in the Sprite Library Asset Similar to the Sprite Library Editor window, you can add new Categories, change the Sprite a Label refers to, and add a new Sprite Label into the Category in Sprite Library component's Inspector window. Modified Sprites Example: A Sprite retrieved from the Main Library that has been modified. The + icon appears on a Sprite when: A new Label is added to the Sprite Library Asset in a Category retrieved from the Sprite Library Asset property. A Label retrieved from the Sprite Library Asset property has its Sprite reference changed. When assigning a Sprite Library Asset to the Sprite Library Asset property, if the same Category name already exists in the current Sprite Library Asset, then the Labels from both Categories are merged into a single Category. Similarly, any Labels in the same Category that have the same names are merged. The Label uses the Sprite that was referred to in the current Sprite Library Asset instead of the one from the Sprite Library Asset if they are merged. When a Sprite Library Asset is removed from the Sprite Library Asset property, any changes that were made to the current Sprite Library Asset remain. Sprite Resolver component The Sprite Resolver component is attached to each GameObject in the Prefab. The component pulls information from the Sprite Library Asset (assigned to the Sprite Library component at the root of the Prefab). The component contains two properties - Category and Label - and a visual Variant Selector that displays thumbnails of the Sprites contained in the Sprite Library Asset. Inspector view of Sprite Resolver component. Property Function Category Select which Category you want to use a Sprite from for this GameObject. Label Select the Label of the Sprite you want to use for this GameObject. (Visual variant selector) Displays selectable thumbnails of the Sprites contained in this Category. Select the Sprite you want the Sprite Renderer to render by selecting from the Category and Label dropdown menus, or select the Sprite directly in the visual variant selector."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SkinEdToolsShortcuts.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SkinEdToolsShortcuts.html",
    "title": "Editor tools and shortcuts | mmo-rpg-unity",
    "keywords": "Editor tools and shortcuts Labelled 2D Animation Skinning Editor tools The Skinning Editor tools are split-up into the following groups: A. Editor toolbar B. Pose tools C. Bone tools D. Geometry tools E. Weight tools F. Rig tools Editor toolbar This toolbar lets you toggle between Character and Sprite Sheet modes. It also contains the Visibility toggle. Tool Default Shortcut Function Toggle View Mode Shift + 2 Switch between the Character and Sprite Sheet view modes. Visibility Shift + P Toggles the Sprite visibility panel, which controls the visibility of the Sprite meshes and bones in the editor window. Toggle Tool Text Shift + ` Show or hide text on tool buttons. Pose tools This is a toolbar that contains the options to Preview Pose and restore the default pose with Restore Pose. Tool Default Shortcut Function Preview Pose Shift + Q Enable this mode when moving and rotating an actor's model and joints to preview its poses after rigging. Any changes made in this mode are not saved. Reset Pose Shift + 1 Restores an actor's bones and joints to their original positions. Set Pivot Shift + T Enable this tool to edit the pivot point of the actor with the Pivot Panel options. Pivot Panel The Pivot Panel appears when you enable the Set Pivot tool. Property Function Pivot Select the desired location of the Pivot from the dropdown menu. Position Enter a value from 0 to 1 to adjust the X and Y position of the pivot. This is a normalized value from 0 to 1, where (0,0) is lower left of workspace and (1,1) is the upper right of the workspace. Bone tools Use the Bone Tools to create and edit the bones of your character and their hierarchy. Tool Default Shortcut Function Edit Bone Shift + W Reposition the bones into a new position. These changes are automatically saved as the default bind pose for the Restore Bind Pose tool. Sprite geometry does not deform with the bones in this mode, even if the bones are attached as influencers. Create Bone Shift + E Click and drag to create bones. Split Bone Shift + R Splits the selected bone. Bone panel The Bone panel appears at the lower right of the editor window when you select a bone with one of the Bone Tools active. Property Function Name Displays the name of the selected bone. Enter a new name here to rename the selected bone. Position The world position of the bone. Rotation The world rotation value of the bone. Bone Color The color of the bone. Depth Displays the Z-value of the selected bone that determines the render order of the vertices under its influence (refer to the examples below). Enter a new value (which can be negative) to change the render order of the affected vertices. Refer to the bone tab and hierarchy tree documentation for more information on how the Depth value affects the way the Sprite mesh is rendered and deformed. Setting the Depth value The following examples show how the Depth value of a selected bone affects the render order of the mesh vertices it influences. In this example, the selected bone (orange) and has an intitial Depth value of 1. Example 1: With the Depth value of 1, the vertices that are influenced by it (the blue are of the Sprite and mesh) appear in front of the other vertices, which have a lower Depth value. However, by setting the bone's Depth to -1 instead, When the selected bone’s Depth is set to -1 instead, the vertices that are influenced by it appears behind of the other vertices. Geometry tools Use the Geometry tools to generate and edit the meshes of the different Sprites that make up your character. Tool Default Shortcut Function Auto Geometry Shift + A Select to auto-generate meshes for Sprites. When this tool is selected, the Geometry panel becomes available at the lower right of the Skinning Editor. Edit Geometry Shift + S Edit generated meshes by repositioning vertices. Create Vertex Shift + D Create new vertices to create geometry. Create Edge Shift + G Create new edges to create geometry. Split Edge Shift + H Split an existing edge into two. Geometry panel The Geometry panel is only visible when Auto Geometry is enabled. It contains the available settings that affect how the geometry of selected Sprites are generated. Visible only when Auto Geometry is enabled. Property Function Outline Detail Use the slider to adjust the accuracy of the generated geometry’s outline to the outline of the Sprite. Smaller values create simpler outlines, while larger values create denser outlines that fit to the Sprite’s outline more accurately. Alpha Tolerance Use the slider to set the alpha value threshold to consider when generating geometry. Pixels with an alpha value lower than the set tolerance value are considered transparent during outline detection when the geometry is generated. Subdivide Use the slider to adjust the tessellation of the Sprite mesh by adding or decreasing the number of vertices inside the generated mesh. Weights Enable to automatically assign weights between the generated geometry mesh and nearby bones. Generate For Selected/Generate For All Visible Select this button to generate a geometry mesh for selected Sprites based on the property settings above. To generate geometry for all Sprites in the Skinning Editor, do not have any Sprite selected when you select this button. Weight tools Vertices in the generated geometry meshes are influenced by different bones which affect how the meshes deform during animation. The percentage of influences from different bones for each vertex is contained in the weight information assigned to that vertex, which you can control with the following Weight tools. To add weights to your Sprites, you can first ensure that there are bones overlaying the Sprites and geometry has been generated. Tool Default Shortcut Function Auto Weights Shift + Z Auto-generate weights between the geometry and bones. When this tool is selected, the Weights panel becomes available at the lower right of the Skinning Editor that displays the available settings and the option to generate weights for. Weight Slider Shift + X Use the slider to adjust weights. Weight Brush Shift + N Adjust weights by painting with a brush. Bone Influence Shift + V Select which bones influence a Sprite. Sprite Influence Shift + M Select which Sprites are being influenced by a bone. Weights panel The Weights panel appears at the lower right of the Sprite Editor window when Auto Weights under the Weight tools is selected. Property Function Associate Bones Select this box to automatically associate bones to the Sprite geometry they overlay. Generate/Generate All Select this button to generate weights for the currently selected Sprite, or for all Sprites if no Sprite is selected. This does not do anything if geometry has not been generated for the Sprites, or if no bones are associated with the Sprite geometry. Normalize Normalizes the weights of the selected Sprite, or all Sprites if no specific Sprite is selected. Clear Clear the weights of the selected Sprite, or of all Sprites if no specific Sprite is selected. Weight Slider Property Function Mode The current behavior of the Weight Slider tool. Add and Subtract Select this mode to have all sliders influence all vertices around the selected bone (currently displayed in the Bone property). Grow and Shrink Select this mode to have all sliders influence only vertices that are already affected by the selected bone (which is selected in the Bone property). Smooth Averages the weights of all vertices with their neighbors to create an even distribution of weight across all vertices. Bone (unavailable if Mode > Smooth) Displays the currently selected bone. Use the drop-down menu to select a different bone, or select another bone. Normalize Select this to ensure the total normalized weight of all vertices of a selected Sprite mesh is equal to one. Amount Amount of weight applied on selected vertices. Vertex Weight Adjust the bone weights of selected vertices. Weight Brush Property Function Mode The current behavior mode of the weights tool. Add and Subtract Select this mode to have all sliders influence all vertices around the selected bone. Grow and Shrink Select this mode to have all sliders influence only vertices that are already affected by the selected bone. Smooth Averages the weights of vertices with their neighbors to create a smoother distribution of weights. Bone The bone that the Brush is painting influence for. Select a different bone via the drop-down menu. Normalize Enable to ensure the normalized weight of painted vertices will equal to 1. Size Size of the weight brush cursor. Hardness Amount of weight applied by the brush per brushstroke. Higher values increase the weight per brushstroke, up to the maximum of 100 where the full weight is applied at once. Step Number of increments needed to apply the full weight of brush. Bone Influences panel The Bone Influences panel displays a list of bones that are currently influencing the selected Sprite mesh. When the Skinning Editor is set to Character mode, the Bone Influences panel allows you to add a bone to the list which includes its influence in the deformation of the selected Sprite’s mesh, or remove a bone from the list which removes its influence instead. To add a bone to the list, select the bone in the Skinning Editor window and then select Add (+) at the lower right of the panel. To remove a bone from the list, select the bone in the list or in the editor window and then select Remove (-). Rearranging bone order You can rearrange the bone order in the Bone Influences panel by selecting and the dragging the respective bone entries up or down the list. The order of the bones in the Bone Influences panel determines the order of the bones on the Sprite Skin component. This is especially important when replacing the Sprite for deformation in the Sprite Renderer, such as when using Sprite Swap, as you can ensure the bone order remains the same between the Sprites and that the correct Transform drives the correct deformation. Sprite Influences panel The Sprite Influences panel displays a list of Sprite meshes that are currently being influenced by the selected bone. When the Skinning Editor is set to Character mode, the Sprite Influences panel allows you to remove an unwanted Sprite mesh from the list so that it’s not influenced by the selected bone. It’s also possible to add a selected Sprite to the list which will include the selected bone’s influence in its deformation. To add a Sprite mesh to the list, select the bone in the Skinning Editor window as well as the Sprite you want to add, and then select Add (+) at the lower right of the panel. To remove a Sprite from the list, select it in the list or in the editor window and then select Remove (-). Rig tools The Rig tools contain the option to Copy and Paste bones from and into a skeleton rig. Tool Default Shortcut Function Copy Ctrl + C Copies the bone and mesh data from the current selection. Paste Ctrl + V Pastes the copied bone and mesh data to the current selection. Paste Shift + B Use this shortcut to show additional pasting options. Copy and Paste behavior Once you have rigged the skeleton and bone weights of your actor, you can reuse the same rigged skeleton with other Model Prefabs by using the Copy and Paste options on the Rig tools. This is useful if you need to quickly create characters that share the same build and animations. You can only Copy and Paste if the source and destination Model Prefabs have the same number of Sprites and Sprite names. When you Copy and Paste the bone and mesh data, the following occurs: Copied bone data is pasted to the destination. Mesh, weights, and bone association of source Sprite(s) are pasted to destination Sprite(s) with the same names. Copy behavior To copy sprite data, select a sprite and then select Copy. This copies the mesh and bone data associated with that sprite. If no sprite is selected, then this copies the data of all sprites' currently in the Skinning Editor window instead. Paste behavior To paste copied sprite data, select the Paste button. This opens the Paste panel at the lower right of the editor window which contains the following data options. Select which data you want to paste from the copied sprite data. Paste dialog box. Option Function Bones Paste bone data. Mesh Paste mesh data. Flip X Paste the data but mirrored along the X-axis. Flip Y Paste the data but mirrored along the Y-axis. To paste copied sprite data, select a sprite and then select Paste. This pastes the selected data to a selected sprite. If no sprite is selected, then this pastes the data to all sprites’ currently in the Skinning Editor window with the same name as the copied sprite."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SkinningEditor.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SkinningEditor.html",
    "title": "Skinning Editor | mmo-rpg-unity",
    "keywords": "Skinning Editor The Skinning Editor module is added to the Sprite Editor when you install the 2D Animation package. Use the editor's tools to create the bones of your actor's skeleton, generate and edit its mesh geometry, and adjust the weights that bind the bones to the meshes as you rig your actor. The Skinning Editor is found in the modules drop-down menu at the top left of the Sprite Editor. Opening the Skinning Editor To begin working with an actor in the Skinning Editor: Select the actor Prefab that's created when importing your artwork into the Project, and go to its Inspector window. Select the Sprite Editor button in the Inspector window to open the actor in the Sprite Editor. In the Sprite Editor, select the Skinning Editor module from the upper left drop-down menu of the editor window. An actor in the Skinning Editor with the different panels of tools available. Refer to the editor tools and shortcuts documentation for more information about the different tools and functions available in the Skinning Editor. How to select a Sprite in the editor Depending on the actor, there may be multiple Sprites in the Skinning Editor at once. Select specific Sprites in the Skinning Editor window in the following ways: Double-click a Sprite to select it in the editor window. An orange outline and wireframe appears on the selected Sprite. The color of the outline color can be changed in Tool Preferences. If the Sprite you want to select is behind other Sprites, hover the cursor over where the desired Sprite is, and double-click to cycle through all Sprites at the cursor location until you select the desired Sprite. To deselect a selected Sprite, double-click on a blank area in the editor window. How to select bone or Mesh vertices in the editor To select a bone or vertices when using the Bone and Geometry tools: Click a bone or mesh vertex to select it specifically. Draw a rectangle over multiple bones or vertices to make a multiple selection. Right-click to deselect any selected bone or mesh vertices."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteSkin.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteSkin.html",
    "title": "Sprite Skin component | mmo-rpg-unity",
    "keywords": "Sprite Skin component When the Sprite Skin component is added to a GameObject that also contains the Sprite Renderer component with a Sprite assigned, the Sprite Skin deforms that Sprite by using the bones that were rigged and weighted to the Sprite in the Skinning Editor. After preparing and importing your artwork into Unity, bring the generated Prefab into the Scene view and Unity automatically adds the Sprite Skin component to the Prefab. This component is required for the bones to deform the Sprite meshes in the Scene view. The Sprite Skin deforms a Sprite by using GameObject Transforms to represent the bones that were added to the Sprite in the Skinning Editor module. Sprite Skin component settings. Property Function Always Update Enable this to have the Sprite Skin continue to deform the Sprite even when the visual is not in the view of the Camera. Auto Rebind Enable this to have the component attempt to find the correct GameObject Transforms to use as bones for the Sprite by using the GameObject Transform set in the Root Bone property as the starting point. Root Bone Use this property to indicate which GameObject Transform to use as the Root Bone for the Sprite. Bones This shows the list of bones that are being set up for the Sprite in the Skinning Editor module. Each Sprite’s Bone entry must have a GameObject Transform associated with it for correct deformation. Create Bones The button lets you create GameObject Transform(s) to represent the Sprite’s Bone and assign them to the Root Bone property and the individual Bones entry. The Root Bone that is created is placed as a child of the GameObject of the Sprite Skin. The button is only enabled if the Root Bone property isn't assigned. Reset Bind Pose The button resets the GameObject Transforms assigned in the Bones entry to the bind pose value set up for the Sprite in the Skinning Editor module. Auto Rebind When you enable Auto Rebind, Sprite Skin attempts to automatically locate the GameObject Transform that is needed for the current Sprite assigned to the Sprite Renderer. This is triggered when the Sprite in the Sprite Renderer property is changed. When a rebind is required, the Sprite Skin looks for the GameObject Transform name that matches the bone name in the Skinning Editor module. Example: Selecting a Sprite in the Bone Panel shows the bones currently rigged to and influencing the Sprite, along with their names. In the above example, the Sprite is rigged with three connected bones - starting with 'bone_1' as the root bone, 'bone_2' as a child of 'bone_1', and 'bone_3' as a child of 'bone_2'. For the Sprite Skin component to automatically locate the bones successfully, GameObject Transforms with the same name and hierarchy as shown in the above example must be available in the Scene. By setting the Sprite Skin’s Root Bone property to the correct GameObject Transform, Sprite Skin will then map the GameObject Transform to the Sprite’s rigged bone of the same name. For the Auto Rebind to be successful, the name and the hierarchy of the rigged bones and the GameObject Transforms must match. This means that changing the name of the bones in the Skinning Editor will require you to update the names of the GameObject Transforms to match as well."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteSwapIntro.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteSwapIntro.html",
    "title": "Introduction to Sprite Swap | mmo-rpg-unity",
    "keywords": "Introduction to Sprite Swap This page introduces what's Sprite Swap, its different uses and its limitations. Sprite Swap refers to changing the rendered Sprite of a GameObject at runtime, which is useful when animating the Sprites that make up a 2D actor or other GameObjects. For example, you can swap the individual Sprites that make up an animated actor to create multiple actors that share the same skeleton (requires the PSD Importer package; or create animation clips by swapping the Sprites at runtime. You can import sample projects for the 2D Animation package by selecting the option in the 2D Animation package window. Refer to the individual Sprite Swap examples pages for more information about these samples. Required assets and components Sprite Swap requires the following Assets and component, which are available with the 2D Animation package: Sprite Library Asset: The Sprite Library Asset contains a set of selected Sprites which are assigned to different Categories and Labels. Sprite Library component: The Sprite Library component determines which Sprite Library Asset a GameObject refers to. Sprite Resolver component: The Sprite Resolver component requests a Sprite registered to the Sprite Library Asset by referring to the Category and Label value of the desired Sprite. Technical limitations The following are technical limitations which you should keep in mind when using Sprite Swap. Skeletal animation limitations If you want to animate your actor and use Sprite Swap with skeletal animation, both sprites that are swapped must have an identical skeleton. Use the Copy and Paste tools of the Skinning Editor to duplicate the bone and skeleton data from one sprite to another to ensure they will swap correctly. Animator limitations In a single Animator Controller, you can't have one Animation Clip animating the Sprite Renderer’s assigned sprite while another Animation Clip animates the Sprite Resolver’s sprite hash. If these two clips are in the same Animator Controller, they will conflict with each other and cause unwanted playback results. Use the following recommended methods to resolve this issue. The first method is to separate the Animation Clips into separate Animator Controllers that contain only clips that animate either a Sprite Renderer’s sprite or the Sprite Resolver’s sprite hash but not both types in the same Animator Controller. The second method is to update all Animation Clips to the same type so that they can all remain in a single Animator Controller. To do so, convert all clips animating a Sprite Renderer’s sprite to animating a Sprite Resolver’s sprite hash, or vice versa. Additional resources Animation Skinning Editor PSD Importer package"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteSwapLanding.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteSwapLanding.html",
    "title": "Sprite Swap | mmo-rpg-unity",
    "keywords": "Sprite Swap Use Sprite Swap to change a GameObject's rendered Sprite at runtime. You can swap the entire set of Sprites that make up a character (referred to as an 'actor') at once, or swap specific Sprites and 'parts' of an actor to create animation loops or other game-related features. For various examples of how you can use this feature in a Project, import sample Projects for the 2D Animation package and refer to the Sprite Swap examples for examples of the different ways you can use Sprite Swap in your Projects. Topic Description Introduction to Sprite Swap Understand Sprite Swap, its requirements and limitations. Sprite Library Asset in Unity Understand what the Sprite Library Asset is and how to use its features. Sprite Library Editor fundamentals Understand how to use the Sprite Library Editor's main features. Overrides to the Main Library Create overrides are and understand how to use them to make changes. Drag sprites to create or edit Categories and Labels Drag sprites to perform certain functions in the Sprite Library Editor automatically. Sprite Library component in Unity Understand what the Sprite Library component is and how to use its features. Sprite Resolver component in Unity Understand what the Sprite Resolver component is and how to use it. Setting up Sprite Swap Understand how to set up the different components and assets needed to use Sprite Swap. Additional resources PSD Importer package"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteSwapSetup.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteSwapSetup.html",
    "title": "Setting up for Sprite Swap | mmo-rpg-unity",
    "keywords": "Setting up for Sprite Swap The following steps Follow the steps below to create a Sprite Library Asset, and choose which GameObjects refer to the Asset: Select the Sprite Library Asset from the Asset creation menu by going to Asset > Create > 2D > Sprite Library Asset Select the new Sprite Library Asset and open it in the Sprite Library Editor. The editor displays the list of Categories and Labels available in the Asset. Select + at the lower right of the List to add a new Category. Enter a name into Category (the default name is 'New Category'). Each Category in the same Sprite Library Asset must have a unique name. Add new Labels into the Category by either selecting + and then selecting a Sprite from the Object Picker window; or by dragging a Sprite, Texture or PSD Importer supported file type onto an empty space within the Categories tab Create an empty GameObject (menu: Right-click on the Hierarchy window > Create Empty). Select it and then add the Sprite Renderer component. Add the Sprite Library component to the same GameObject. Assign the Sprite Library Asset created in step 3 to Sprite Library Asset. Add the Sprite Resolver component to the same GameObject. Open the Category drop-down menu, and select a Category you created in step 3. The Label drop-down menu will become available and display thumbnails of the Sprites contained in the Category. Select a Sprite in the Sprite Resolver component to replace the current Sprite rendered by the Sprite Renderer component with the one you have selected."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteVis.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/SpriteVis.html",
    "title": "Sprite Visibility panel | mmo-rpg-unity",
    "keywords": "Sprite Visibility panel Use the Sprite Visibility panel to increase or decrease the visibility of bones and sprite meshes. Toggle the Sprite Visibility panel by selecting the Visibility tool button along the upper right of the editor window: The panel appears on the right-side of the editor window. It has two sliders at the top that control the visibility of the bones and Sprite meshes within the editor window. Move either slider further to the left to decrease the visibility of the bones or meshes respectively, and to the right to increase their visibility. The Bone tab displays the Bone hierarchy of the character Prefab. The Sprite tab displays the names of the Sprites and their grouping hierarchy. Bone tab and hierarchy tree The Bone tab selected. Select the Bone tab to view the list of bones in the character Prefab. The list reflects the hierarchy of bones you created with the Bone tools. You can reparent and reorder bones directly from the bone tab by dragging selected bones up and down the list. Toggle the visibility of each bone by selecting the icon next to it. Property Function Toggle the visibility of each bone by selecting this icon next to the bone. +Alt (macOS: +Option) Toggle the visibility of a bone and its children by selecting this icon while holding Alt (macOS: holding Option). Bone The name of the Bone. Depth Displays the Z-value of bones that are influencing the same Sprite Mesh. The parts of the Mesh that is influenced by a bone with higher Depth value will render in front of the Mesh influenced by bones with lower Depth value. A bone’s Depth value is 0 by default. Color The color of the Bone. Sprite tab Select the Sprite tab to see the list of Sprites that make up the character Prefab in the Skinning editor window. The names and order of the Sprites mirror their names, layer and grouping order in the original source file. Toggle the visibility of a Layer by selecting the icon next to it. Hold Alt (macOS: hold Option) to view it in isolation and hide every other Layer."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Introduction to 2D Animation What's new 2D Animation Asset Upgrader Preparing and importing artwork Sprite Skin component Skinning editor Tool Preferences Editor tools and shortcuts Sprite Visibility panel Actor rigging and weighing workflow Animating an actor 2D Inverse Kinematics Sprite Swap Introduction to Sprite Swap Sprite Library Asset in Unity Sprite Library Editor fundamentals Sprite Library Editor reference Overrides to the Main Library Drag sprites to create or edit Categories and Labels Sprite Library component in Unity Sprite Resolver component in Unity Setting up for Sprite Swap How to swap individual Sprites Swapping Sprite Library Assets Importing Samples Simple Single Skinned Sprite Character Sprite Swap sample projects Skeleton Sharing Runtime Swap"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ToolPref.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ToolPref.html",
    "title": "Tool Preferences | mmo-rpg-unity",
    "keywords": "Tool Preferences Adjust the appearance of the 2D Animation tools for the Skinning Editor in the Preferences menu: Edit > Preferences > 2D > Animation. Tool Preferences Setting Function Hide Tool Text Enable this option to hide the tool text to have a compact view. Selected Outline Color Customize the outline color of selected Sprite and bone. Sprite Outline Size Use the slider to adjust the outline thickness of a selected Sprite. Bone Outline Size Use the slider to adjust the outline thickness of a selected bone. Enable Hide Tool Text to only display the tool icons in the Skinning Editor window."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-psd-importer.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-psd-importer.html",
    "title": "Rigging a character imported with the PSD Importer | mmo-rpg-unity",
    "keywords": "Rigging a character imported with the PSD Importer This sample demonstrates how to rig an actor that is made from multiple Sprites, imported with the PSD Importer. Open the Asset Assets/Samples/2D Animation/[X.Y.Z]/Samples/3 Character/Sprites/Fei.psb in the Skinning Editor module to examine how the Sprite is rigged. The _Character sample Scene shows how the Asset is used in a Scene, when it is animated with animation that deforms its Sprite mesh. Follow the steps below to reconstruct the _Character sample Scene: In this sample, the source file Fei.psb is imported into the Editor with the PSD Importer with its Character Rig property enabled. The importer generates a Prefab as a sub-Asset of the imported source file. The importer generates Sprites based on the layers of the source file. In this sample, the actor's bones are already rigged and weighted. Experiment editing the bones and mesh with the Skinning Editor's various tools. Drag the generated Prefab from the Project window into the Scene. This becomes a GameObject named 'Fei'. Add the Animator component to the 'Fei' GameObject. Locate the Fei Animator Controller Asset in Assets/Samples/2D Animation/[X.Y.Z]/Samples/4 Character/Animation/Animators/Fei.controller and assign this Asset to the Animator’s Controller property."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-runtime-swap.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-runtime-swap.html",
    "title": "Runtime Swap | mmo-rpg-unity",
    "keywords": "Runtime Swap This sample demonstrates how you can use the Sprite Library API to override a specific Entry. Note that the sample requires the PSD Importer installed. Open the 6 Runtime Swap Scene to see the sample in action. The graphic Assets are located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprites: Knight.psb Skeleton.psb The Skeleton.psb uses the .skeleton Asset from the Knight.psb for its rigging. It also references the Knight.spriteLib Sprite Library Asset located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprites. Runtime Swap script A custom MonoBehaviour script called the RuntimeSwap is attached to the KnigtboyRig GameObject. The script is located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Scripts/Runtime/RuntimeSwap.cs Pressing a button (in the sample Scene) with a Sprite from the Skeleton.psb causes the script to use the override API from the Sprite Library to override that Sprite Entry. m_SpriteLibraryTarget.AddOverride(entry.sprite, entry.category, entry.entry); Pressing a button with a Sprite from the Knight.psb causes the script to use the override rest API from the Sprite Library to remove the Sprite Entry override. m_SpriteLibraryTarget.RemoveOverride(entry.category, entry.entry);"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-simple.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-simple.html",
    "title": "Simple single Sprite actor and rig | mmo-rpg-unity",
    "keywords": "Simple single Sprite actor and rig This sample shows a simple single Sprite rigged actor, which was imported with the PSD Importer package. The Project and Assets can be found in the following location (the version number folder may differ): Sample project location in the Project window (for 2D Animation 9.0). Open the Asset Assets/Samples/2D Animation/[X.Y.Z]/Samples/1 Simple/Sprites/Boris.psd in the Skinning Editor module to examine how the Sprite is rigged. The _Simple Scene shows how the Asset is used in a Scene when it is animated with animation that deforms its Sprite mesh. Follow the steps below to reconstruct this _Simple sample Scene: Create a new Scene, and create one empty GameObject and name it 'Root'. Drag the 'Boris' psd file into the scene and attach it to the Root GameObject as its child. Add an Animator component to the 'Root' GameObject. Locate the Root Animator Controller Asset in Assets/Samples/2D Animation/[X.Y.Z]/Samples/1 Simple/Animation/Animator/Root.controller. Assign this Asset to the Animator component's Controller property. Add an Animator component to the 'Boris' GameObject. Locate the Boris Animator Controller Asset in Assets/Samples/2D Animation/[X.Y.Z]/Samples/1 Simple/Animation/Animator/Boris.controller and assign this Asset to the Animator’s Controller property."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-single-skinned-sprite.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-single-skinned-sprite.html",
    "title": "Single Sprite rig with bone branching | mmo-rpg-unity",
    "keywords": "Single Sprite rig with bone branching This sample project is a slightly more complex example of a single Sprite rig similar to the Simple project, but with bone branching instead of a single branch rig. The Sprite was imported with the PSD Importer package. The Project and Assets can be found in the following location (the version number folder may differ): Open the Asset Assets/Samples/2D Animation/[X.Y.Z]/Samples/2 Single Skinned Sprite/Sprites/Plunkah.psd in the Skinning Editor module to examine how the Sprite is rigged. The _Single Skinned Sprite sample Scene show how the Asset is used in a Scene when it is animated with animation that deforms its Sprite mesh. Follow the steps below to reconstruct the _Single Skinned Sprite sample Scene: Create a new Scene, and drag the 'Plunkah' psd file into the scene. Add the Animator component to the 'Plunkah' GameObject. Locate the Plunkah Animator Controller Asset in Assets/Samples/2D Animation/[X.Y.Z]/Samples/2 Single Skinned Sprite/Animation/Plunkah.controller and assign this Asset to the Animator’s Controller property."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-skeleton-sharing.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-skeleton-sharing.html",
    "title": "Skeleton Sharing | mmo-rpg-unity",
    "keywords": "Skeleton Sharing This sample demonstrates how Skeleton sharing can be set up and leverages on the other samples before this. Note that the following requires the PSD Importer installed. Open the 5 Skeleton Sharing.unity Scene to see this sample in action. This sample's setup is similar to the one in the Full Skin Swap sample. The visual Assets are located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprites: Knight.psb Wolf.psb The Wolf.psb uses the .skeleton Asset from the Knight.psb, which means that the Wolf.psb is prepared using the same skeleton structure as the Knight.psb. The Wolf actor also uses the following Sprite Library Assets located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprites: Knight.spriteLib Wolf.spriteLib The Knight.spriteLib is assigned to the Main Library property for the Wolf.spriteLib is. The Wolf.spriteLib has been setup so that the torso Category is not overridden, which allows it to use the Sprite from Knight.spriteLib. The Wolf actor uses the same torso Sprite as the Knight actor."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-sprite-swap.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/ex-sprite-swap.html",
    "title": "Sprite Swap examples | mmo-rpg-unity",
    "keywords": "Sprite Swap examples This following sample projects demonstrate the different ways you can use Sprite Swap to achieve different effects and outcomes. The Scenes for the following samples can be all found in Assets/Samples/2D Animation/[X.Y.Z]/Samples/4 SpriteSwap: Animated swap Part swap Full skin swap DLC swap Skeleton Sharing Runtime Swap Animated Swap This sample demonstrates how to use Sprite Swap to create a reusable Animation Clip for animations that include both Sprite swapping and deformation of the Sprites. Note: Install the PSD Importer package to use this sample. Open the Scene file 1 Animated Swap.unity to see the sample in action. Initial frame with the hands in thumbs-up position. This sample uses two different source files located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprites. The Assets used are: dialog.psb dialog gray.psb These Assets are imported with the PSD Importer with its Character Rig property enabled. Both Assets are rigged with the same skeleton, and each Asset has two different Sprites for the hands which are swapped during the animation. Swapped to a frame with the hands open. They are located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 Sprite Swap/Sprite Library and are: dialog.spriteLib dialog gray.spriteLib Follow the steps below to reconstruct the sample Scene: Drag both dialog.psb and dialog gray.psb Prefabs from the Project window into the Scene. Add the Sprite Library component to dialog GameObject, then assign the dialog.spriteLib Asset to its Sprite Library Asset property. Add the Sprite Library component to dialog gray GameObject, then assign the dialog gray.spriteLib Asset to its Sprite Library Asset property. Expand the dialog GameObject's hierarchy and disable the R_arm_2 child GameObject. This Asset is not required as it is swapped in during the animation. Go to the R_arm_1 GameObject, and add the Sprite Resolver component. Select the R_arm_2 graphic from the Label drop-down menu or from its thumbnail. Repeat steps 4 to 5 with the dialog gray GameObject. Add the Animator component to the dialog and dialog gray GameObjects. Locate the Dialog Animator Controller Asset in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 Sprite Swap/Animation/Animators and assign it to the Animator component's Controller property. In this sample, the Sprite Library component is not attached to the same GameObject as the Sprite Resolver component. The Sprite Resolver attempts to locate a Sprite Library component starting from the same GameObject it is on and then traverse up the GameObject hierarchy. This lets a single or multiple Sprite Resolvers use the same Sprite Library component by attaching the Sprite Library component to a common root GameObject that the Sprite Resolver components are attached to. Part Swap This sample demonstrates how to swap Sprite Assets using the API provided by changing the Sprite Resolver data. Open the 2 Part Swap.unity Scene to see the sample in action. In the Scene, each part has three different visual options that can be swapped. The graphic Assets are located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprites: Knight.psb Skeleton.psb Witch.psb A Sprite Library Asset containing Sprites made from all three graphic Assets above is created. A Category is created for each body part of the actor, with three Entries derived from the three different versions of the character. The Asset is located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprite Library/Part Swap.spriteLib. Corresponding parts from each of the three versions of the actor, and named accordingly. Attach the Sprite Library component to the KnightRig GameObject in the Scene. Assign the Part Swap.spriteLib Asset to its Sprite Library Asset property. Add the Sprite Resolver component to all Sprite Renderers under the KnightRig GameObject. Assign a Sprite that matches its corresponding GameObject, depending on the body part that GameObject represents. For example, select one of the Sprites in the 'Body' Category for the Sprite Resolver attached to the KnightRig GameObject and so on. With this setup, you can swap any part of the actor to another Sprite individually. Swap part script A custom MonoBehaviour script called SwapPart is attached to the KnightRig GameObject. This script is located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Scripts/Runtime/SwapPart.cs. The script holds a reference to a Sprite Library component for retrieval of swappable Sprites. It also holds an array of data that describes the Category of Sprites in the Sprite Library that can be changed by a Sprite Resolver component. When the Swap Part script starts up, it attempts to fetch the Sprite Library Asset that is used by a Sprite Library component. var libraryAsset = spriteLibrary.spriteLibraryAsset; From this Sprite Library Asset, it then fetches the Entries and Label names that are in a Category. var labels = libraryAsset.GetCategoryLabelNames(swapOption.category); This is then used to populate the UI Drop Down list. When a value changes in the UI Drop Down List, it then sets the Sprite Resolver component to use the relevant Sprite. swapOption.spriteResolver.SetCategoryAndLabel(swapOption.category, swapOption.dropdown.options[x].text); Full Skin Swap This sample demonstrates how to swap Sprite visuals using the provided API by changing the Sprite Library Asset referenced by the Sprite Library component. Open the 3 Full Swap.unity Scene to see the sample in action. In the Scene, there are three different visual Asset options that you can swap to. The Assets are located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprites: Knight.psb Wolf.psb Witch.psb The Sprite Library Assets have identical Categories, Entries, and Label names but with different Sprites selected. The Assets are located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprite Library. Knight.spriteLib Wolf.spriteLib Witch.spriteLib Attach the Sprite Library component to the KnightRig GameObject. Assign the Knight.spriteLib Asset to its Sprite Library Asset property. Add the Sprite Resolver component to each of the Sprite Renderers under the KnightRig GameObject. Assign a Sprite to each Sprite Resolver that corresponds to the body part they are attached to. For example, the torso Sprite is selected for the Sprite Resolver attached to the torso GameObject. Swap Full Skin Script A custom MonoBehaviour script called SwapFullSkin is attached to the KnightRig GameObject. This script is located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Scripts/Runtime/SwapFullSkin.cs Where a value changes in the UI Drop Down List, the component sets the relevant Sprite Library Asset to be used for the Sprite Library component. spriteLibraryTarget.spriteLibraryAsset = spriteLibraries[value]; DLC Swap This sample demonstrates how to swap Sprite visuals by changing the referenced Sprite Library Asset referenced by the Sprite Library component, using the API provided. This sample builds on the Full Skin Swap sample. This difference from the Full Skin Swap method is that the Sprite Library Asset is loaded from an AssetBundle during runtime and added to the Sprite Library component at a later time. Open the 4 DLC Swap.unity Scene to see the sample in action. To ensure the AssetBundle works correctly, check that the Skeleton.spriteLib Asset in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Sprite Library is labeled with its corresponding AssetBundle tag. The Skeleton.spriteLib Asset labeled with 'skeleton'. Load Swap DLC Script A custom MonoBehaviour script called LoadSwapDLC is attached to the Load DLC GameObject. The script is located in Assets/Samples/2D Animation/[X.Y.Z]/Samples/5 SpriteSwap/Scripts/Runtime/LoadSwapDLC.cs The script starts up when the DLC is loaded, it scan the AssetBundles for any Sprite Library Assets. Once the Sprite Library Assets are loaded, it adds these Entries into the SwapFullSkin script from the Full Skin Swap sample."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/index.html",
    "title": "Introduction to 2D Animation | mmo-rpg-unity",
    "keywords": "Introduction to 2D Animation The 2D Animation package includes features and tools that allow you to quickly rig and animate 2D characters in Unity in a variety of ways. The different versions of the 2D Animation package are supported by the following versions of Unity respectively: Package version Unity Editor version 9.x.x 2022.2 8.x.x 2022.1 7.x.x 2021.2 6.x.x 2021.1 5.x.x 2020.2 or 2020.3 4.x.x 2020.1 3.x.x 2019.3 or 2019.4 2D Animation and PSD Importer package integration Use the 2D Animation package with the PSD Importer package to easily import character artwork created in Photoshop into Unity, and prepare it for animation with the 2D Animation package. The PSD Importer is an Asset importer that supports Adobe Photoshop .psb files, and generates a Prefab made of Sprites based on the source file and its layers. The generated Prefab of a character or prop to be animated with the 2D Animation package is called an 'actor'. The .psb file format has identical functions as the more common Adobe .psd format, with additional support for much larger image sizes. Refer to the PSD Importer package documentation for more information about the importer’s features. Upgrading Sprite Library Assets and Animation Clips The 2D Animation package and its assets are often updated with major and minor tweaks over time. Some asset improvements can be automatically applied when you upgrade to the latest version of the package. However, some of these changes require a manual step in order to have the assets use the latest code path. The 2D Animation Asset Upgrader tool eases the transition and upgrade of older assets to newer ones. Refer to the 2D Animation Asset Upgrader section for more information."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/whats-new.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Documentation~/whats-new.html",
    "title": "What's new in version 9.0 | mmo-rpg-unity",
    "keywords": "What's new in version 9.0 Added Added a new Sprite Library Editor to make authoring and editing of Sprite Libraries easier. Updated 2D Animation now depends on the Collections package, which enables bursted and multithreaded Sprite deformation by default. Sprite Skin's Auto Rebind can now swap between all bones underneath the rootBone."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.animation copyright © 2023 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/README.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/README.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Note: This package is available as a prerelease, so it is not ready for production use. The features and documentation in this package might change before it is verified for release. 2D Character Animation Editor tools and runtime scripts to support the authoring of 2D Animated Characters. Editor Tooling Skinning Editor Available through Sprite Editor Window module Bone tools allow creation of bind poses easily. Supports flexible setup of complex hierarchy. Mesh tools allow auto mesh tesselation or manual tesselation Weight tools allow auto weight calculation and weight painting Runtime Support SpriteSkin deformation 2D IK"
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Samples~/AnimationSamples/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Samples~/AnimationSamples/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.animation Samples © 2022 Unity Technologies Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Samples~/AnimationSamples/README.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Samples~/AnimationSamples/README.html",
    "title": "2D Animation Samples | mmo-rpg-unity",
    "keywords": "2D Animation Samples See the 2D Animation Samples Documentation for more information on the samples."
  },
  "Library/PackageCache/com.unity.2d.animation@9.1.1/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.2d.animation@9.1.1/Third Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This package contains third-party software components governed by the license(s) indicated below: Component Name: Clipper License Type: Boost Software License - Version 1.0 - August 17th, 2003 Copyright (c) 2010-2014 Angus Johnson http://www.angusj.com/delphi/clipper.php Permission is hereby granted, free of charge, to any person or organization obtaining a copy of the software and accompanying documentation covered by this license (the \"Software\") to use, reproduce, display, distribute, execute, and transmit the Software, and to prepare derivative works of the Software, and to permit third-parties to whom the Software is furnished to do so, all subject to the following: The copyright notices in the Software and this entire statement, including the above license grant, this restriction and the following disclaimer, must be included in all copies of the Software, in whole or in part, and all derivative works of the Software, unless such copies or derivative works are solely in the form of machine-executable object code generated by a source language processor. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Eigen License Type: Mozilla Public License Version 2.0 Copyright owner unknown http://eigen.tuxfamily.org/ https://www.mozilla.org/en-US/MPL/2.0/ Component Name: libigl License Type: Mozilla Public License Version 2.0 Copyright (c) 2019 Alec Jacobson, Daniele Panozzo, Christian Schüller, Olga Diamanti, Qingnan Zhou, Sebastian Koch, Jeremie Dumas, Amir Vaxman, Nico Pietroni, Stefan Brugger, Kenshi Takayama, Wenzel Jakob, Nikolas De Giorgis, Luigi Rocca, Leonardo Sacht, Kevin Walliman, Olga Sorkine-Hornung, Teseo Schneider, and others. https://libigl.github.io/ https://www.mozilla.org/en-US/MPL/2.0/"
  },
  "Library/PackageCache/com.unity.2d.aseprite@1.1.5/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.2d.aseprite@1.1.5/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [1.1.5] - 2024-06-19 Fixed Reduced the font size slightly in the importer headers to match other inspector headers in Unity. (DANB-644) Fixed an issue where the Sort Order would not be reset in Animation Clips when making use of the Z-index in Aseprite. [1.1.4] - 2024-05-02 Fixed Fixed an issue where Sprite Renderers would be hidden after transitioning from one Animation Clip to another. Fixed an issue where generated AnimationClips would be 0.01 seconds too long. [1.1.3] - 2024-03-25 Fixed Fixed an issue where the importer would not parse palette data from the \"old palette\" chunks. Fixed an issue where the Physics Shapes would not take the Sprite Rects into account, causing the outline to be wrongly offset. Fixed an issue where .ase/.aseprite files containing z-index data would fail to import. (DANB-608) [1.1.2] - 2024-03-10 Fixed Fixed an issue where the Mosaic padding did not show up in Sprite Sheet import mode. Fixed an issue where using Sprite Padding with individual import mode would misalign the GameObjects in the generated model prefab. Fixed an issue where the Aseprite package would contest with the XR subsystem package over the InternalAPIEditorBridge.005. (UUM-49338) [1.1.1] - 2024-01-03 Fixed Fixed an issue where the Sprite Editor could be opened even though there were no valid texture to open it with. Fixed an issue where the importer would not generate a square power of two texture for compressions which needs it (pvrtc). Fixed an issue where changes to linked cells would not be taken into account when reimporting. [1.1.0] - 2023-11-24 Added Added a mosaic padding option to the importer editor. Added Generate Physics Shape option to the importer editor. Changed Fixed an issue where the background importer would act on files that were not Aseprite files. [1.0.0] - 2023-05-17 Added Added a new event to the Aseprite Importer which is fired at the last import process step. Made the Aseprite file property publicly available. Made the Aseprite file parsing API publicly available. Fixed Fixed an issue where the Animation Window would no longer detect Animation Clips on a prefab. (DANB-458) [1.0.0-pre.4] - 2023-04-16 Added Added a property to set the padding within each generated SpriteRect. Added an option to select import mode for the file, either Animated Sprite or Sprite Sheet. Fixed Fixed an issue where the platform settings could not be modified. (DANB-445) Fixed an issue where the Animation Events would be generated with the wrong time stamp. [1.0.0-pre.3] - 2023-03-23 Added Bursted the texture generation tasks, to speed up importation of Aseprite files. (Note: Only for Unity 2022.2 and newer). Layer blend modes are now supported with Import Mode: Merge Frames. Added ability to generate Animation Events from Cell user data. Added ability to export Animator Controller and/or Animation Clips. Added canvasSize to the Aseprite Importer's public API. Fixed Fixed an issue where the last frame in a generated Animation Clip would receive an incorrect length. (DANB-434) Improved the background importer, so that it only imports modified Aseprite files in the background. [1.0.0-pre.2] - 2023-02-27 Added Added support for individual frame timings in animation clips. Added support for layer groups. Added support for Layer & Cel opacity. Added support for repeating/non repeating tags/clips. Changed The importer UI is now re-written in UI Toolkit. If a Model Prefab only contains one SpriteRenderer, all components will be placed on the root GameObject, rather than generating a single GameObject to house them. A Sorting Group component is added by default to Model Prefabs with more than one Sprite Renderer. Fixed Fixed an issue where renaming an Asperite file in Unity would throw a null reference exception. (DANB-384) Fixed an issue where the background importer would import assets even when Unity Editor has focus. Fixed an issue where the Pixels Per Unit value could be set to invalid values. [1.0.0-pre.1] - 2023-01-06 Added First release of this package."
  },
  "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/AsepriteFeatures.html": {
    "href": "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/AsepriteFeatures.html",
    "title": "Aseprite Features | mmo-rpg-unity",
    "keywords": "Aseprite Features This page highlights which Aseprite feature the Aseprite Importer supports/does not support. Supported features File formats .ase & .aseprite Color modes (All modes are supported) RGBA Grayscale Indexed Layer settings Visible/Hidden layer Hidden layers are by default not imported. This can be changed by checking “Include hidden layers” in the import settings. Layer blend modes All blend modes are supported with Import Mode: Merge frames. Layer & Cel opacity Linked Cels Tags Only Animation Direction: Forward is supported. Values set in the repeating field only has two results on import: ∞ will result in a looping Animation Clip. This value is the default for all Tags in Aseprite. 1 -> N will result in a non looping Animation Clip. Individual frame timings Layer groups The importer respects the visibility mode selected for the group. If a group is hidden, underlying layers will not be imported by default. Layer groups will be generated in the prefab hierarchy if the import mode is set to Individual layers. Unsupported features Slices Tilemaps"
  },
  "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/ImporterFAQ.html": {
    "href": "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/ImporterFAQ.html",
    "title": "Frequently asked questions | mmo-rpg-unity",
    "keywords": "Frequently asked questions How are the layers sorted in Unity? When an Aseprite file is imported using the Import Mode: Individual, every layer from the source file becomes a GameObject inside the generated model prefab. If the layer is a normal layer (and not a group layer), it has a SpriteRenderer compontent added to it. To make sure each SpriteRenderer renders in the same order as inside of Aseprite, Unity automatically assigns a value to the Order in Layer field on the SpriteRenderer component. This value is a combination of two variables, the order of the layer inside of Aseprite, where the bottom layer has the value of 0 and the top layer has the value of Number of layers, e.g. if the source file contains 5 layers, the top layer will have the value of 5. The second value is the z-index, which can be set per cell in Aseprite. The final formula to calculate the Order in Layer value is: Layer count from the bottom + Z-Index of the current cell. Apart from the Order in Layer value, Unity also adds a Sorting Group component onto the root GameObject of the model prefab, to make sure that every SpriteRenderer within the prefab is sorted together. For more information about general 2D sorting in Unity, see the 2D Sorting page in the Unity manual. How to combine multiple sprite sheets into one? You can make use of Sprite Atlases to combine multiple sprite sheets into a single texture. Read more about Sprite Atlas here. Combining multiple sprite sheets into one is a good way to reduce the draw calls in a scene. Why is my trimmed Aseprite file not trimmed in Unity? When modifying the canvas size, make sure the Trim content outside the canvas checkbox is checked. This way, the stored texture will be cropped to the specified size. How to add events to Animation Clips? Animation Events can be generated by adding user data to Cels inside of Aseprite. Follow these steps to add an Animation Event to a frame: In Aseprite, select any cel in the frame you want to add an event to. Right click on the cel and select Cel Properties. Press the User Data-button to the left of the Opacity slider to bring up the User Data-field. Enter the event name in the following format: event:EventName. E.g. event:OnIdle. Save the file and switch over to Unity. Open the Animation Window and inspect the Animation Clip. You can see that the event has been added to the frame. How to make changes to an Animator Controller? The Aseprite Importer generates an Animator Controller if the Aseprite file contains more than one frame and the Animation Clip checkbox is checked in the importer. This Animator Controller is Read Only, meaning that it cannot be changed. The Animator Controller is Read Only. If you like to have an Animator Controller which you can change, follow these steps: Select an Aseprite file in Unity. Press the Export Animation Assets-button. In the popup, make sure the Animator Controller checkbox is checked. Leave the Animation Clips checkbox unchecked if you do not wish to edit any of the clips. Press Export and select a folder to place the Asset(s) into. An Animator Controller should now be located in the selected folder. If the Animation Clip checkbox was left unchecked, all the states within the Animator Controller are linked back to the Aseprite file, meaning that the clips will stay up to date with any changes made in Aseprite. Do note that if you add a new tag in Aseprite, you need to add the resulting Animation Clip to the exported Animator Controller, as this will not happen automatically. How to inject custom assets on import? The Aseprite Importer comes with an event, OnPostAsepriteImport, which is fired at the end of the import process. This event can be used to inject or change the generated assets when importing an Aseprite file. using UnityEditor; using UnityEditor.U2D.Aseprite; using UnityEngine; public class GameObjectInjector : AssetPostprocessor { void OnPreprocessAsset() { if (assetImporter is AsepriteImporter aseImporter) aseImporter.OnPostAsepriteImport += OnPostAsepriteImport; } static void OnPostAsepriteImport(AsepriteImporter.ImportEventArgs args) { var myGo = new GameObject(\"MyGameObject\"); args.context.AddObjectToAsset(myGo.name, myGo); } }"
  },
  "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/ImporterFeatures.html": {
    "href": "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/ImporterFeatures.html",
    "title": "Importer features | mmo-rpg-unity",
    "keywords": "Importer features Default Texture settings The Aseprite Importer sets the following default settings to the generated texture: Texture type: Sprite Sprite mode: Multiple Pixel per unit: 100 Mesh type: Tight Wrap mode: Clamp Filter mode: Point Compression: None Generate Mip Maps: False Aseprite Importer Inspector properties The Aseprite Importer is available after you import a .ase/.aseprite file into your Project. Aseprite Importer Inspector properties General Property Description Import Mode How the file should be imported. This is set to Animated Sprite by default. Sprite Sheet The file is imported as a Sprite Sheet, and can be sliced up in the Sprite Editor. Animated Sprite The file is imported with animation in mind. Animation assets are generated and attached to a model prefab on import. Pixels Per Unit Sets the number of pixels that equals one Unity unit. Mesh Type Sets the Mesh type that Unity generates for the Sprite. This is set to Tight by default. Full Rect Unity maps the Sprite onto a rectangular Mesh. Tight Unity generates a Mesh based on the outline of the Sprite. If the Sprite is smaller than 32 x 32 pixels, Unity always maps it onto a Full Rect quad Mesh, even if you select Tight. Generate Physics Shape Generates a default physics shape from the outline of the Sprite/s when a physics shape has not been set in the Sprite Editor. Layer import Property Description Include Hidden Layers Enable this property to include the hidden layers of the .ase/.asperite file in the import. This property is set to False by default. Import Mode Use this property to specify how the layers from the source file are imported. This property is set to Merge Frame by default. Individual Layers Every layer per frame generates a Sprite. Merge Frame This is the default option. All layers per frame are merged into one Sprite. Pivot Space Select the space pivots should be calculated in. This property is set to Canvas by default. Canvas Calculate the pivot based on where the Sprite is positioned on the source asset's canvas. This is useful if the Sprite is being swapped out in an animation. Local This is the normal pivot space used when importing a standard image in Unity. Pivot Alignment How a Sprite's graphic rectangle is aligned with its pivot point. This property is set Bottom by default. Mosaic Padding External padding between each SpriteRect. This property is set 4 pixels by default. Sprite Padding Internal padding within each SpriteRect. This property is set 0 pixels by default. Generate assets Property Description Model Prefab Enable this property to generate a model prefab setup to look like the first frame in Aseprite. This property is set to True by default. Sorting Group Add a Sorting Group component to the root of the generated model prefab if it has more than one Sprite Renderer. This property is set to True by default. Shadow Casters Enable this property to add Shadow Casters to all GameObjects with a SpriteRenderer. This property is set to False by default. Note that this checkbox is only available in Unity 2023.1 and newer. Animation Clips Enable this property to generate Animation Clips based on the frame data in the file. Every tag in Aseprite generates one Animation Clip. If no tag is present, one Animation Clip is generated which covers all frames in the file. The Animation speed is based on the Constant Frame Rate defined in Aseprite. The length is based on the number of frames included in the tag/file. This property is set to True by default. Export Animation Assets The Animator Controller and the Animation Clips are generated as Read Only assets. This option can be used to export editable versions of these assets. Aseprite Importer Preferences The Aseprite Importer Preferences can be found at Unity > Settings > 2D > Aseprite Importer. Aseprite Importer Preferences Property Description Background import Enable this property to enable asset import when the Unity Editor is in the background. This property is set to True by default."
  },
  "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Introduction to Aseprite Importer What's new Aseprite features Importer features FAQ"
  },
  "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/index.html",
    "title": "Introduction to Aseprite Importer | mmo-rpg-unity",
    "keywords": "Introduction to Aseprite Importer The Aseprite Importer is an Asset importer that imports Aseprite's .ase and .aseprite files into Unity. See Aseprite Features to read more about which features from Aseprite are supported by the importer. See Importer Features to read more about which features the Aseprite Importer provides. Getting Started If you are using any of the following Unity versions or newer, Aseprite Importer package comes preinstalled when creating a new 2D or 2D URP project. Unity 2023.2.0a19 Unity 2023.1.0f1 Unity 2022.3.2f1 Unity 2021.3.28f1 You can also manually add the Aseprite Importer package by: Open Package Manager. Search for Aseprite Importer. Select 2D Aseprite Importer and press the install button. If you see a Burst popup saying that a new version of Burst has been installed, restart the editor. You are now ready to import .ase and .aseprite files into your project. Note: You need to use Unity 2021.3.15f1 or newer."
  },
  "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/whats-new.html": {
    "href": "Library/PackageCache/com.unity.2d.aseprite@1.1.5/Documentation~/whats-new.html",
    "title": "What's new in version 1.1.0 | mmo-rpg-unity",
    "keywords": "What's new in version 1.1.0 Added a mosaic padding option to the importer editor. Added Generate Physics Shape option to the importer editor."
  },
  "Library/PackageCache/com.unity.2d.aseprite@1.1.5/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.aseprite@1.1.5/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.aseprite copyright © 2023 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.aseprite@1.1.5/README.html": {
    "href": "Library/PackageCache/com.unity.2d.aseprite@1.1.5/README.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Aseprite Importer ScriptedImporter to import .ase/.aseprite files into Unity."
  },
  "Library/PackageCache/com.unity.2d.common@8.0.3/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.2d.common@8.0.3/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [8.0.3] - 2024-06-25 Fixed DANB-604 Fix case where Spriteshape vertex array exceeds limit even though it has not reached 64K. [8.0.2] - 2023-10-25 Fixed Fixed an issue where PSDImporter atlas size does not follow PVRTC compression format for the iOS platform [8.0.1] - 2022-10-11 Changed Refactored the internal triangulation and tessellation APIs. [8.0.0] - 2022-08-03 Changed Refactored internal triangulation and tessellation APIs. Update com.unity.burst dependency version to 1.7.3 to support latest PS4 SDK. Added support for different sized texture inputs in ImagePacker. [8.0.0-pre.2] - 2022-05-31 Added Moved internal API from animation to common package. [8.0.0-pre.1] - 2022-03-21 Changed Minimized memory allocated for UTess. [7.0.0] - 2022-01-25 Changed Package release version. Fixed 1382695 Fixed case where control point selection flickers when drag and multi-select points in scene Optimized texture space needed for rect packing [7.0.0-pre.4] - 2021-11-24 Added Added internal method to get build target's group name. Added access to the internal helper method IsUsingDeformableBuffer. Fixed Allow internal TextureGenerator helper consider swizzle data. Fixed 1368956 Deleting certain vertices in sprite mesh leads to mesh resetted to quad incorrectly [7.0.0-pre.3] - 2021-10-21 Fixed Fixed passing in invalid argument to TextureGenerator for swizzling. [7.0.0-pre.2] - 2021-10-11 Fixed 1361541 Fix crash encountered when deleting vertices of sprite mesh in SkinningEditor [7.0.0-pre.1] - 2021-08-06 Changed Update Unity supported version to 2022.1 [6.0.0-pre.4] - 2021-07-05 Added Internal API for applying Sprite Editor Window changes [6.0.0-pre.3] - 2021-05-19 Fixed Fixed issues in tesselation library. [6.0.0-pre.2] - 2021-05-14 Fixed Fixed metafiles conflicts [6.0.0-pre.1] - 2021-05-05 Changed Version bump for Unity 2021.2 [5.0.0] - 2021-03-17 Changed Update version for release [5.0.0-pre.2] - 2021-01-16 Changed Update license file [5.0.0-pre.1] - 2020-10-30 Changed Version bump for Unity 2021.1 [4.0.3] - 2020-10-15 Fixed Allow 2D Packages to access internal constant value for asset creation instance id [4.0.2] - 2020-08-31 Fixed Allow launching Sprite Editor Window to target a specific asset [4.0.1] - 2020-07-07 Fixed Updated to use non-experimental AssetImporter namespace (case 1254381) [4.0.0] - 2020-05-11 Changed Version bump for Unity 2020.2 [3.0.0] - 2019-11-06 Changed Update version number for Unity 2020.1 [2.0.2] - 2019-08-09 Added Add Seconday Texture settings into TextureSettings for TextureGenerator Add related test packages [2.0.1] - 2019-07-13 Changed Mark package to support Unity 2019.3.0a10 onwards. [2.0.0] - 2019-06-17 Added Drop preview tag. Remove experimental namespace [1.2.0-preview.2] - 2019-06-04 Added Remove Image Packer Debug Window Move tests out of package [1.2.0-preview.1] - 2019-02-20 Added Update for Unity 2019.2 support. [1.1.0-preview.2] - 2019-03-18 Added Remove deprecated call to Unity internal API [1.1.0-preview.1] - 2019-01-25 Added Added versioning for CI."
  },
  "Library/PackageCache/com.unity.2d.common@8.0.3/Documentation~/Common.html": {
    "href": "Library/PackageCache/com.unity.2d.common@8.0.3/Documentation~/Common.html",
    "title": "Introduction | mmo-rpg-unity",
    "keywords": "2D Common Introduction This package contains shared code used by various 2D packages such as Sprite Shape and 2D Animation. The package is currently for internal use only, and not meant for public use at this time."
  },
  "Library/PackageCache/com.unity.2d.common@8.0.3/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.common@8.0.3/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.common copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.common@8.0.3/README.html": {
    "href": "Library/PackageCache/com.unity.2d.common@8.0.3/README.html",
    "title": "| mmo-rpg-unity",
    "keywords": "2D Shared Code UTess - a 2D geometry generation toolkit. ImagePacker - fits a list of textures or rects into a bigger rect."
  },
  "Library/PackageCache/com.unity.2d.common@8.0.3/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.2d.common@8.0.3/Third Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This package contains third-party software components governed by the license(s) indicated below: Component Name: cdt2d License Type: The MIT License Copyright (c) 2015 Mikola Lysenko https://github.com/mikolalysenko/cdt2d Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [5.0.3] - 2022-10-20 Added Added editor assembly reference to Unity.RenderPipelines.Universal.2D.Runtime Changed Move internal tests to Pixel Perfect Tests package [5.0.2] - 2022-09-21 Added Added URP Pixel Perfect Camera converter Fixed Removed AudioModule package dependency from sample project Changed Hide duplicate Pixel Perfect menus if URP Package is installed [5.0.1] - 2021-08-06 Fixed Fixed a bug where clear buffer was executed out of order (case 129263) Changed Update compatibility warning text (case 1337165) [5.0.0] - 2021-03-17 Changed Update version for release [5.0.0-pre.2] - 2021-01-16 Changed Update license file [5.0.0-pre.1] - 2020-10-30 Changed Version bump for Unity 2021.1 [4.0.1] - 2020-06-10 Fixed Fixed the broken documentation URL of the Component. [4.0.0] - 2020-05-11 Changed Version bump for Unity 2020.2 [3.0.2] - 2020-03-28 Fixed Fixed an issue where Cinemachine Pixel Perfect Extension didn't work when CinemachineBrain Update Method is anything other than Late Update. [3.0.1] - 2019-11-14 Changed Deploy samples as individual files. Made the editor class internal. Changed License file [3.0.0] - 2019-11-06 Changed Update version number for Unity 2020.1 [2.0.3] - 2019-11-06 Changed Deprecated the CinemachinePixelPerfect extension. Use the one from Cinemachine v2.4 instead. [2.0.2] - 2019-07-13 Changed Mark package to support Unity 2019.3.0a10 onwards. [2.0.1] - 2019-07-12 Changed Deploy Samples as UnityPackage. [2.0.0] - 2019-07-05 Added Added CinemachinePixelPerfect, a Cinemachine Virtual Camera Extension that solves some compatibility issues between Cinemachine and Pixel Perfect Camera. Fixed Fixed an issue where recompiling scripts while a Pixel Perfect Camera is running would cause null reference exeptions. [1.0.1-preview] - 2018-06-19 Changed Disabled \"Run In Edit Mode\" button for presets and inactive game objects. \"Run In Edit Mode\" is now automatically disabled when you enter play mode. Fixed Fixed an issue where some UI text was missing from the preset inspector. Addressed a performance warning you could get when you target mobile platforms. [1.0.0-preview] - 2018-05-03 This is the first preview release of Unity Package <2D Pixel Perfect>. This initial release contains a Pixel Perfect Camera component which ensures your pixel art remains crisp and clear at different resolutions, and stable in motion."
  },
  "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "2D Pixel Perfect"
  },
  "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/Documentation~/index.html",
    "title": "2D Pixel Perfect | mmo-rpg-unity",
    "keywords": "2D Pixel Perfect The 2D Pixel Perfect package contains the Pixel Perfect Camera component, which ensures your pixel art remains crisp and clear at different resolutions, and stable in motion. It is a single component that makes all the calculations Unity needs to scale the viewport with resolution changes, so that you don’t need to do it manually. You can use the component settings to adjust the definition of the rendered pixel art within the camera viewport, and you can use the Run in Edit Mode feature to preview any changes immediately in the Game view. Attach the Pixel Perfect Camera component to the main Camera GameObject in the Scene, it is represented by two green bounding boxes centered on the Camera gizmo in the Scene view. The solid green bounding box shows the visible area in Game view, while the dotted bounding box shows the Reference Resolution. The Reference Resolution is the original resolution your Assets are designed for, its effect on the component's functions is detailed further in the documentation. Before using the component, first ensure your Sprites are prepared correctly for best results with the the following steps. Preparing Your Sprites After importing your textures into the project as Sprites, set all Sprites to the same Pixels Per Unit value. In the Sprites' Inspector window, set their Filter Mode to ‘Point’. Set their Compression to 'None'. Follow the steps below to correctly set the pivot for a Sprite Open the Sprite Editor for the selected Sprite. If __Sprite Mode __is set to ‘Multiple’ and there are multiple Sprite elements, then you need to set a pivot point for each individual Sprite element. Under the Sprite settings, set Pivot to ‘Custom’, then set Pivot Unit Mode to ‘Pixels’. This allows you to set the pivot point's coordinates in pixels, or drag the pivot point around freely in the Sprite Editor and have it automatically snap to pixel corners. Repeat for each Sprite element as necessary. Snap Settings To ensure the pixelated movement of Sprites are consistent with each other, follow the below steps to set the proper snap settings for your project. To open the Snap settings, go to Edit > Snap Settings. Set the Move X/Y/Z properties to 1 divided by the Pixel Perfect Camera’s Asset Pixels Per Unit (PPU) value. For example, if the Asset PPU is 100, you should set the Move X/Y/Z properties to 0.01 (1 / 100 = 0.01). Unity does not apply Snap settings retroactively. If there are any pre-existing GameObjects in the Scene, select each of them and select Snap All Axes to apply the Snap settings. Properties The component's Inspector window Property Function Asset Pixels Per Unit This is the amount of pixels that make up one unit of the Scene. Match this value to the Pixels Per Unit values of all Sprites in the Scene. Reference Resolution This is the original resolution your Assets are designed for. Upscale Render Texture Enable this property to create a temporary rendered texture of the Scene close-to or at the Reference Resolution, which is then upscaled. Pixel Snapping (only available when ‘Upscale Render Texture’ is disabled) Enable this feature to snap Sprite Renderers to a grid in world space at render-time. The grid size is based on the Assets’ Pixels Per Unit value. Crop Frame Crops the viewport with black bars to match the Reference Resolution along the checked axis. Check X to add horizontal black bars, and Y to add vertical black bars. For more information and a visual example, refer to the Property Details below. Stretch Fill (available when both X and Y are checked) Enable to expand the viewport to fit the screen resolution while maintaining the viewport's aspect ratio. Run In Edit Mode Enable this checkbox to preview Camera setting changes in Edit Mode. This causes constant changes to the Scene while active. Current Pixel Ratio (available when ‘Run In Edit Mode’ is enabled) Shows the size ratio of the rendered Sprites compared to their original size. Additional Property Details Reference Resolution This is the original resolution your Assets are designed for. Scaling up Scenes and Assets from this resolution preserves your pixel art cleanly at higher resolutions. Upscale Render Texture By default, the Scene is rendered at the pixel perfect resolution closest to the full screen resolution. Enable this option to have the Scene rendered to a temporary texture set as close as possible to the Reference Resolution, while maintaining the full screen aspect ratio. This temporary texture is then upscaled to fit the entire screen. The result is unaliased and unrotated pixels, which may be a desirable visual style for certain game projects. Pixel Snapping Enable this feature to snap Sprite Renderers to a grid in world space at render-time. The grid size is based on the Assets Pixels Per Unit value. Pixel Snapping prevents subpixel movement and make Sprites appear to move in pixel-by-pixel increments. This does not affect any GameObjects' Transform positions. Crop Frame Crops the viewport along the checked axis with black bars to match the Reference Resolution. Black bars are added to make the Game view fit the full screen resolution. Uncropped Cropped Cinemachine Extension As both the Pixel Perfect Camera and Cinemachine modify a Camera’s orthographic size, using these two systems together in a single Scene would cause them to fight for control over the Camera and likely produce unwanted results. To solve this incompatibility, add the Cinemachine Pixel Perfect extension to your virtual cameras. You can find more information about the extension’s features in the Cinemachine documentation."
  },
  "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.pixel-perfect copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/README.html": {
    "href": "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/README.html",
    "title": "2D Pixel Perfect | mmo-rpg-unity",
    "keywords": "2D Pixel Perfect Quick start guide: Add Pixel Perfect Camera component to your main camera. Set Assets Pixels Per Unit and Reference Resolution. Enter Play Mode and see the result."
  },
  "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/Samples~/Scenes and Extras/Third-Party Notices.html": {
    "href": "Library/PackageCache/com.unity.2d.pixel-perfect@5.0.3/Samples~/Scenes and Extras/Third-Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This asset is governed by the Asset Store EULA; however, the following components are governed by the licenses indicated below: A. Roboto Copyright Google 2004 Apache 2.0 TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2004 Google Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [8.0.5] - 2024-05-06 Fixed Fixed layers are not shown in LayerImportSettings after unselecting all layers and applying. (Case DANB-569) [8.0.4] - 2023-12-14 Fixed Provide custom packing override for users to override to address DANB-526. (Case DANB-526) [8.0.3] - 2023-10-25 Fixed Fixed an issue where PSDImporter atlas size does not follow PVRTC compression format for the iOS platform [8.0.2] - 2022-12-01 Fixed Fixed an issue where the editor would crash when importing .psd/.psb files with their layers outside of the document canvas. (Case DANB-300) Fixed an issue where the amount of alpha removed from layers would not be re-applied as final position offset of the layers. Fixed an issue where the generated GameObjects would be laid out differently from how they appear in the DCC tool. (Case DANB-298) [8.0.1] - 2022-10-11 Fixed Improved import speed and memory allocation for psd/psb files by reducing the intermediate texture buffers. Fixed an editor freeze caused by over allocating intermediate texture buffers. (Case DANB-140) Fixed an issue where some layers would become invisible when merging multiple layers together. (Case DANB-131) [8.0.0] - 2022-08-03 Changed Package release version. Fixed Fixed exception when showing PSDImporter inspector. (DANB-196) [8.0.0-pre.3] - 2022-05-31 Changed Update dependency package version. [8.0.0-pre.2] - 2022-05-20 Fixed Fixed Sprite missing reference on certain source file created by third party tools. (Case DANB-30) [8.0.0-pre.1] - 2022-03-21 Fixed Allow multi editing for PSDImporter Settings tab. (Case 1400534) Fixed import not importing when Apply is clicked on Inspector. Changed SpriteSkins generated by the PSD Importer now have their rootBone assigned to the root object of the model prefab. Added Added drop down list utility in Layer Management tool for quick selection of layers for import. [7.0.0] - 2022-01-25 Changed Package release version. Fixed Fixed null exception when importing files with masks. (Case 1388820) [7.0.0-pre.4] - 2021-11-24 Fixed Fixed per platform settings does not get applied in Windows platform. (Case 1376608) Fixed unable to change mipmap settings in inspector. (Case 1379426) Fixed PSDImporter to able to specify swizzle data. Added Added ability to change swizzle format in inspector. [7.0.0-pre.3] - 2021-10-21 Changed Update to latest com.unity.2d.animation package [7.0.0-pre.2] - 2021-10-11 Fixed Fixed artifacts on images when flatten Fixed exception \"PsdInvalidException: Unrecognized layer section type\" when importing certain files. [7.0.0-pre.1] - 2021-08-06 Changed Update Unity supported version to 2022.1 Fixed Removed memory requirement check since we cannot properly determine if there will be enough memory to import the file (case 1338690) [6.0.0-pre.4] - 2021-07-05 Fixed Fixed changing PSD Importer inspector fields causes UnityEditor.ObjectPreview errors (case 1333823) Fixed 2D PSDImporter always imports .psb files when switching build platforms (case 1327701) Fixed 2D PSDImporter doesn't apply settings from Sprite Editor Window when changes made in Inspector (case 1339799) [6.0.0-pre.3] - 2021-05-17 Changed Update dependency version [6.0.0-pre.2] - 2021-05-14 Changed Update dependency version [6.0.0-pre.1] - 2021-05-05 Changed Version bump for Unity 2021.2 Added Add ability to use Photoshop file's layer name to map to SpriteRect instead of using layer id Provide auto custom Physics shape generation option Add support to collapse layers in a Photoshop file's group Improve PSDImporter Inspector Fixed Fixed Unity hang when importing certain PSD files (case 1312835) [5.0.0] - 2021-03-17 Changed Update version for release [5.0.0-pre.3] - 2021-03-15 Changed Updated documentation [5.0.0-pre.2] - 2021-01-16 Changed Update license file Fixed Fixed case 1291323 where upgrading from PSDImporter v2 causes Sprite to be missing [5.0.0-pre.1] - 2020-11-02 Added Added bone sharing from other PSDImporter file [4.0.2] - 2020-08-31 Fixed Fixed importing files with vector layers generates textures incorrectly (case 1266986) Fixed Sprite Editor Window doesn't show the Sprite when the Inspector is locked and the Sprite is not selected in the Project window [4.0.1] - 2020-07-07 Fixed Fixed ArgumentException thrown when 2D Game Kit is imported for the first time (case 1244287) Updated to use non-experimental AssetImporter (case 1254380) [4.0.0] - 2020-05-11 Changed Version bump for Unity 2020.2 [3.1.4] - 2020-04-09 Fixed Fix PSD import issues with PSD file without unique layer id Fix crash on importing huge PSD files Fix metafile not updated when reimporting Fix error when importing PSB files with 32-bit color Changed Improve PSD file import performance [3.1.3] - 2020-03-20 Changed Update 2D Animation dependency [4.0.0] - 2020-03-11 Changed Version bump for Unity 2020.2 [3.1.2] - 2020-02-27 Fixed Fixed broken documentation links in inspectors Fixed empty GameObjects created in certain cases [3.1.1] - 2020-01-09 Fixed Fix wrong dependency version [3.1.0] - 2019-12-16 Added Expose PSDImporter class to be accessible via scripting Added example in manual to show how to set PSDImporter as default importer for PSD files. [3.0.0] - 2019-11-06 Changed Update version number for Unity 2020.1 Update documentation [2.0.6] - 2019-10-18 Fixed Fixed SpriteRect name clash when Photoshop layer is renamed to the same name as an exisiting user created SpriteRect [2.0.5] - 2019-08-06 Fixed Physics Shape not saved into Sprite when importing with AssetDatabase V2 Added Experimental feature to have Sprites with same name generated from source file Support for providing Layer and Group order to Animation Skinning Module [2.0.4] - 2019-08-09 Added Add related test packages Add support Secondary Texture Module in Sprite Editor Window Fixed Texture and SpriteLibraryAsset subassets in PSDImporter now follows the main asset's name. [2.0.3] - 2019-07-20 Changed Update 2D Animation dependency [2.0.2] - 2019-07-13 Changed Mark package to support Unity 2019.3.0a10 onwards. [2.0.1] - 2019-06-12 Changed Update 2D Animation dependency [2.0.0] - 2019-06-17 Changed Remove preview tag Remove experimental namespace [1.2.0-preview.2] - 2019-06-07 Added Change API to internal access Only generate Sprite Library Asset if there is entry Do not reset Reslice checkbox after Inspector apply [1.2.0-preview.1] - 2019-03-15 Added Update support for 2019.2 Integrate with 2D Animation Sprite Library Integrate with new 2D Animation Character Group Fix asset name conflict [1.1.0-preview.2] - 2019-04-23 Added Fix potential name clashing issues with ScriptedImporter Fix Prefab asset using wrong name. Note this will break Prefab references if upgrading from previous versions. [1.1.0-preview.1] - 2019-02-19 Added Update dependency for 2019.1 support [1.0.0-preview.3] - 2019-02-19 Added Fix compilation error in .NET 3.5 [1.0.0-preview.2] - 2019-01-25 Added Fix unable to rig Sprites created manually Remove legacy packing tag Default Texture Type is changed to 'Sprite (2D and UI)' Default Sprite Mode is changed to 'Multiple' [1.0.0-preview.1] - 2018-11-20 Added New release ScriptedImporter for importing Adobe Photoshop file Supports handling of Adobe Photoshop layers Creates Sprites from individual layers Handles include or exclude hidden layers Supports Prefab generation that reconstruct generated Sprites to original art asset layout Prefab generation supports GameObject grouping based on Adobe Photoshop layer grouping Supports 2D Animation v2 single character with multiple Sprites workflow"
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/PSD-importer-SpriteRect.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/PSD-importer-SpriteRect.html",
    "title": "How the PSD Importer uses SpriteRect data | mmo-rpg-unity",
    "keywords": "How the PSD Importer uses SpriteRect data The PSD Importer can store five separate sets of SpriteRect data, with one set for each of the five combinations of Importer property settings below: When Sprite Mode is set to Single. When Sprite Mode is set to Multiple. When Sprite Mode is set to Multiple, and Individual Sprites (Mosaic) is enabled. When Sprite Mode is set to Multiple, both Individual Sprites (Mosaic) and Use as Rig are enabled, and there is no Skeleton Asset assigned as the Main Skeleton. When Sprite Mode is set to Multiple, both Individual Sprites (Mosaic) and Use as Rig are enabled, and a Skeleton Asset is assigned as the Main Skeleton. Each set of data is persistent, and does not affect or overwrite the data of other sets. This means you can save different SpriteRect data for different importer settings for the same source file. The SpriteRect data persists even if you modify the dimensions and position of images in the source file, as long as the original Layer ID of the source layers remains the same. Modifying SpriteRect data The SpriteRect defines the location of the Sprite on the Texture that Unity generates from the imported source file. You can modify the location and size of each SpriteRect in the Sprite Editor. Moving the SpriteRect Example 1: Original SpriteRect location of the ‘head’ Sprite on the combined Sprite sheet Texture. Example 2: Drag the corners of the SpriteRect to modify its dimensions and location, or enter the coordinates and dimensions in the Sprite panel. A SpriteRect’s modified dimensions and location on the Texture is reflected for its respective Sprite in the Scene view. Original character prefab and its ‘head’ Sprite with unmodified SpriteRect data. Character prefab with its ‘head’ Sprite’s SpriteRect data modified. SpriteRect follows the position of its source layer When you enable the Individual Sprites (Mosaic) importer setting, the PSD Importer arranges the different layers of the source file together to form a single combined Texture when it is imported. The importer generates a SpriteRect for each of these imported layers which follows the position of its associated layer wherever that layer is placed in the combined Mosaic Texture. Before example: The SpriteRect of the ‘head’ layer after moving its SpriteRect from its original position. After example: Some of the layers are hidden in the source file before it is reimported into the Editor. The reimported Texture is different from the original, but the 'head' layer's SpriteRect follows its source layer to its placement in the new Texture. Resizing the source file or image Note that a SpriteRect’s size and position remains the same if you change the image or canvas size of its source layer in the source file. You must manually edit the size and position of the SpriteRect in the Sprite Editor, or select and apply the Automatic Reslice option to regenerate the SpriteRect completely from the source file. Before example: Original position and size of the SpriteRect for the generated ‘head’ Sprite from the 'head' layer. After example: After increasing the size of the 'head' layer, the SpriteRect's position and size remains the same. SpriteRect data persists until you manually delete the SpriteRect, or select the Automatic Reslice option and apply it in the importer settings. When you do this, Unity discards all user modifications for the current set of SpriteRect data and regenerates all the SpriteRects from the current source file. Summary of source file modifications and their effects on SpriteRect data Modification to the source file Effect on SpriteRect data Add a new layer or enable layer visibility The PSD importer automatically generates a new Sprite from the new layer, or newly visible layer, with its associated SpriteRect. Delete a layer or disable layer visibility The PSD Importer deletes the associated Sprite and SpriteRect from the Project file. Rename a layer By default, the SpriteRect copies the new name of its source layer. However if you rename the SpriteRect in the Sprite Editor, then it retains its modified name and does not copy the source layer’s new name. Change a layer or canvas size When a source layer's size changes, the size and position of its related SpriteRect remain the same and do not reflect the changes made to its source layer. To make the SpriteRect reflect the changes made to its source layer, manually edit the SpriteRect’s dimensions in the Sprite Editor, or go to the PSD Importer settings and select and apply the Automatic Reslice option. Name collision errors A name collision error occurs when two or more layers have the same name. This can happen for the following reasons: Two or more layers in the imported source file have the same name. However, Photoshop group layers with the same names do not cause this issue. A new layer that the PSD Importer creates in the source file has the same name as a SpriteRect you have created or modified. A layer is renamed to the same name as a SpriteRect you have modified. A previously hidden layer with the same name as an existing SpriteRect becomes visible and Unity imports it. When a name collision occurs, one SpriteRect retains the original name while the other is appended with a running number to the others (starting with 1). Which SpriteRect retains their original name is based on the following priority: A SpriteRect you have created or modified. The first layer in the source file, starting from the bottom of the layer stack. Currently existing SpriteRects in the Project."
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/PSD-importer-properties.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/PSD-importer-properties.html",
    "title": "| mmo-rpg-unity",
    "keywords": "#PSD Importer Inspector properties The PSD Importer is available after you import a .psb file into your Project. Select the .psb Asset file and set its Texture Type to Sprite (2D and UI). The PSD Importer properties are split between two main tabs, with the following properties available. PSD Importer Inspector properties ##Settings tab The Settings tab allows you to customize how the PSD Importer imports a file. The settings are categorized into individual section fold-outs. ###General Property Description Texture Type Select Sprite (2D and UI) to import the Texture as a Sprite. The is required to begin using the imported Texture with the 2D Animation package. Sprite Mode Use this property to specify how Unity extracts the Sprite graphic from the image. This property is set to Multiple by default. Single Select this option to have Unity treat the imported Texture as a single Sprite Asset without multiple individual parts. This is ideal for characters which are drawn on a single layer in the source file instead of being split onto multiple layers. Multiple This is the default option. Select this option to have Unity create a Sprite for each layer in the source file. This is ideal for complex artwork which has different parts split between multiple layers in the source file, and prepares the imported Textures for animation with the 2D Animation package. Pixels Per Unit Sets the number of pixels that equal to one Unity unit. Mesh Type Sets the Mesh type that Unity generates for the Sprite. This is set to Tight by default. Full Rect Unity maps the Sprite onto a rectangular Mesh. Tight Unity generates a Mesh based on the outline of the Sprite. If the Sprite is smaller than 32 x 32 pixels, Unity always maps it onto a Full Rect quad Mesh, even if you select Tight. Extrude Edges Use the slider to determine how much to extend the Mesh from the edge of the Sprite. Generate Physics Shape Enable this option to generate a default [Physics Shape](https://docs.unity3d.com/2017.4/Documentation/Manual/SpritePhysicsShapeEditor.html) from the outline of the Sprite, if a [Custom Physics Shape](https://docs.unity3d.com/Manual/CustomPhysicsShape.html) has not be defined Automatic Reslice This is available only when the Import Mode is set to Individual Sprites (Mosaic). Enable this setting to regenerate the Sprite from the imported layers and clear any changes you have made to the Sprite and its metadata. ####Automatic Reslice Enable this setting to discard all user modifications for the current set of SpriteRect data and regenerate all SpriteRects based on the current source file. Extra SpriteRect metadata (such as weights and bones data) persist if they remain valid with the regenerated SpriteRects. ###Layer Import The following section is only available if the Texture Type is set to Multiple. Property Description Include Hidden Layers Enable this property to include the hidden layers of the .psb file in the import. This produces the same import result as making all layers visible in the source file unhiding all layers in the source file before you importing it into Unity. Clear this option if you want to only import the visible layers in the .psb file. Keep Duplicate Name Enable this setting to make the PSD Importer generate Sprites from the source files with the exact same name as their source layers, even when there are multiple layers with the same name. Use Layer Group This setting is only available when you enable Character Rig. Enable this setting to make the importer generate a Prefab that follows the layer and grouping hierarchy of the imported .psb. file. Layer Mapping Select this option to use the internal ID provided by the .psb file to map between the .psb file’s layer and the generated Sprite. Use Layer ID Select this to only import the visible layers in the .psb file. Use Layer Name Select this option to use the name of the layer in the .psb file to map between the .psb file’s layer and the generated Sprite. Note that for this option to work correctly, each layer's name needs to be unique. Duplicated names might cause layers to be mapped to the wrong Sprite. Use Layer Name (Case Sensitive) Select this option to use the name of the layer (with case sensitivity) in the .psb file to map between the .psb file’s layer and the generated Sprite. Note that for this option to work correctly, each layer's name needs to be unique. Duplicated names might cause layers to be mapped to the wrong Sprite. Import Mode Use this property to specify how the layers from the source file are imported. This property is set Individual Sprites (Mosaic) by default. Individual Sprites (Mosaic) Select this option to have the PSD Importer generate individual Sprites from the individual layers of the source file, and combines them into a single Texture in a Sprite sheet layout. Merged Select this to have the PSD Importer generate a Texture with all layers merged. Mosaic Padding Settings to control the padding space between each layer in the texture when Import Mode is set to Individual Sprites (Mosaic). Sprite Padding Settings to increase the size of each Sprite's rect in the texture when Import Mode is set to Individual Sprites (Mosaic). ####Individual Sprites (Mosaic) Enable this to have the PSD Importer attempt to create a Texture with each layer from the source file laid out in a mosaic manner. Individual layers are imported as separate Sprites merged into a single Texture in the form of a mosaic. ####Merged Enable this option to have the PSD Importer create a Texture with the layers from the Photoshop source file as if all layers were flattened. ####Keep Duplicate Names Unity's default import behavior when there are duplicate names is to append \"_[number]\" to the Sprites and SpriteRects it generates from source layers with identical names. Enable this feature to instead have Unity give both Sprites and SpriteRects the exact same name as their source layer, even when they are duplicate names. ####Layer Group By default, the importer only generates GameObjects for layers in the source file. This is for performance reasons to minimize the number of GameObjects needed for the Prefab. The generated Prefab with Layer Group set to Ignore Layer Groups. To include and maintain the group and hierarchy structure as per the source file, you can set the Layer Group to As Per Source File, as shown in the example below. The generated Prefab of the same source file with Layer Group set to As Per Source File. ###Character Rig This section is only available if the Texture Type is set to Multiple and Import Mode is set to Individual Sprites (Mosaic). Property Description Use as Rig Enable this property to have the PSD Importer generate a Prefab based on the imported source file. The PSD Importer generates Sprites from the imported layers of the source file, and the Sprites’ hierarchy and positions are based on their layer hierarchy and their positions in the source file. Main Skeleton This is only available when Use as Rig is enabled. Assign the Skeleton Asset that this character Prefab’s bone hierarchy will reference. If no Skeleton Asset is assigned, the importer will automatically generate a Skeleton Asset as a sub-Asset of this character. The Skeleton Asset contains the bone hierarchy of the Asset that was defined in the 2D Animation package's Skinning Editor (refer to Skeleton Sharing for more information). Pivot This is only available when Use as Rig is enabled. Select the pivot point of the Sprite. Custom Define the X and Y coordinates of a custom Pivot location. (All location choices) Select the location where you want to place the pivot on the Sprite from the dropdown menu. ####Use as Rig Enable this property to have the PSD Importer generate a Prefab containing Sprites based on the layers of the imported source file. The PSD Importer also automatically gives the Sprites an Order in Layer value that sorts them according to their positions in the layer hierarchy in the source file. As a result, the generated Prefab recreates the arrangement and appearance of the assets in the original source file as closely as possible. The name of each Sprite in the Prefab is the same as the source layer it is based on, unless a name collision error occurs, which is usually due to duplicate names in the source layers. If the Sprite contains bone or weight data, the PSD Importer automatically adds the Sprite Skin component to it. This happens if the Sprite has been rigged with bones and weights in the Skinning Editor already and the source file is being reimported, or you have manually copied and pasted the bone and weight data onto the Sprites. ####Main Skeleton A skeleton Asset (.skeleton) is an Asset that contains the bone hierarchy structure that can be animated with the 2D Animation package. The Main Skeleton property is only available when you import a .psb file with the Use As Rig importer setting enabled. After importing the .psb file, assign a .skeleton Asset to the Main Skeleton property to have the generated prefab character be automatically rigged with the bone hierarchy structure contained in that .skeleton Asset. If there is no .skeleton Asset assigned to the importer’s Main Skeleton property, then a .skeleton Asset is automatically generated as a of the imported source file and it will be named ‘[Asset File Name] Skeleton’. You can share .skeleton Assets between different generated Prefabs by assigning the same .skeleton as their Main Skeleton property when they're imported. When you open and edit the character in 2D Animation package’s Skinning Editor, the module will display the bone hierarchy provided by the skeleton Asset assigned to Main Skeleton for rigging. ##Layer Management Tab The Layer Management Tab allows you to customize how the Importer imports the layers from the Photoshop file. ###Layer hierarchy tree Group layers in Photoshop are represented with a fold-out folder icon in the hierarchy tree of the Layer Management tab, while regular Photoshop layers in Photoshop represented only by their names. ###Layer visibility Groups or layers that are hidden in the source file are indicated with different color text compared to visible groups or layers. ###Layer Importing The checkbox on each Group/Layer indicates if the Group or Layer from the Photoshop file should be imported. The Group or Layer will be imported when the checkbox is selected. Clear the Include Hidden Layers option in the Layer Management Tab or Settings Tab will only import visible layers from the source file. If a hidden group or layer is mark for import in this state, a warning icon will appear. To import a hidden layer, select the Include Hidden Layers checkbox either in the Settings Tab or in the Layer Management Tab To batch select or deselect layers, you can use the drop down menu located at header of the Layer Importing column. Collapsing Groups The Photoshop layers in a Group can be collapsed into a single Sprite when imported. Hover the cursor over a Group Layer and the Collapse icon appears on its left. Collapse icon with arrow facing down. Click the icon to indicate that the layers in the selected Group should be imported as a single Sprite. Uncollapsing Groups Hovering over a Collapsed Group layer reveals the Uncollapse icon (the arrow faces upwards). Select the icon again to uncollapse the Group layer and to import all Layers in the Group as separate Sprites. Subgroups within Group layers If a Group contains other Group layers and is collapsed, then the layers in the subgroups will also be collapsed into a single Sprite. If a child Group is currently set to be collapsed, then the parent group will have separate icons indicating that are child Groups currently set to collapse."
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/PSD-override.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/PSD-override.html",
    "title": "PSD File Importer Override | mmo-rpg-unity",
    "keywords": "PSD File Importer Override From Unity 2019.30f1 onwards, you can customize the PSD Importer to import files with the .psd extension. To do that you need to create custom scripts that call the AssetDatabaseExperimental.SetImporterOverride method. Example SetImporterOverride scripts PSDImporterOverride.cs using UnityEngine; namespace UnityEditor.U2D.PSD { [ScriptedImporter(1, \"psd\", AutoSelect = false)] internal class PSDImporterOverride : PSDImporter { [MenuItem(\"Assets/2D Importer\", false, 30)] [MenuItem(\"Assets/2D Importer/Change PSD File Importer\", false, 30)] static void ChangeImporter() { foreach (var obj in Selection.objects) { var path = AssetDatabase.GetAssetPath(obj); var ext = System.IO.Path.GetExtension(path); if (ext == \".psd\") { var importer = AssetImporter.GetAtPath(path); if (importer is PSDImporterOverride) { Debug.Log(string.Format(\"{0} is now imported with TextureImporter\", path)); AssetDatabaseExperimental.ClearImporterOverride(path); } else { Debug.Log(string.Format(\"{0} is now imported with PSDImporter\", path)); AssetDatabaseExperimental.SetImporterOverride<PSDImporterOverride>(path); } } } } } } PSDImporterOverrideEditor.cs namespace UnityEditor.U2D.PSD { [CustomEditor(typeof(UnityEditor.U2D.PSD.PSDImporterOverride))] internal class PSDImporterOverrideEditor : PSDImporterEditor { } }"
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "PSD Importer Overview PSD Importer Inspector properties Skeleton sharing How SpriteRect data is used PSD File Importer Override"
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/index.html",
    "title": "Overview | mmo-rpg-unity",
    "keywords": "Overview The PSD Importer is an Asset importer that imports Adobe Photoshop .psb files into Unity, and generates a Prefab of Sprites based on the imported source file. The .psb file format is functionally identical to the more common Adobe .psd format, but supports much larger images than the .psd format (up to 300,000 pixels in any dimension). To convert existing artwork from .psd to .psb format, you can open them in Adobe Photoshop and then save them as .psb files. Importing .psb files with the PSD Importer allows you to use features such as Mosaic (to automatically generate a Sprite sheet from the imported layers) and Character Rig (to reassemble the Sprites of a character as they are arranged in their source files). The PSD Importer currently only supports two Texture Modes: Default and Sprite. Note: The Sprite Library Asset is no longer editable from the Skinning Editor of the 2D Animation from version 6.0 onwards as the Category and Label options have been removed from the Sprite Visibility panel. However, the PSD Importer will continue to automatically generate Sprite Library Assets if relevant data from a previous version is present. Supported and unsupported Photoshop effects When importing a .psb file into Unity with the PSD Importer, the importer generates a prefab of Sprites based on the image and layer data of the imported .psb file. To ensure the importer imports the file correctly, ensure that the Photoshop file is saved with Maximize Compatibility enabled. The PSD Importer does not support all of Photoshop’s layer and visual effects or features. The PSD Importer ignores the following Photoshop layer properties and visual effects when it generates the Sprites and prefab: Channels Blend Modes Layer Opacity Effects If you want to add visual effects to the generated Sprites, you can add additional Textures to the Sprites with the Sprite Editor's Secondary Textures module. Shaders can sample these Secondary Textures to apply additional effects to the Sprite, such as normal mapping. Refer to the Sprite Editor: Secondary Textures documentation for more information."
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/skeleton-sharing.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Documentation~/skeleton-sharing.html",
    "title": "Skeleton sharing | mmo-rpg-unity",
    "keywords": "Skeleton sharing You can share .skeleton Assets between different imported Assets by assigning the .skeleton Asset from one to the other's Main Skeleton property. This feature can be used together with the 2D Animation package to edit the bones of the .skeleton Assets in the 2D Animation package's Skinning Editor. To demonstrate how to skeleton sharing, refer to the following example of two actors (characters or other Assets imported for animation with the 2D Animation package) that were imported into Unity with the PSD Importer called 'Primary' and 'Variant'. The goal is to share the .skeleton Asset of 'Primary' with 'Variant'. | --|-- Primary | Variant The 2D Animation package is required to create and edit the bones of the .skeleton Assets of imported Assets. In this example, the bones of 'Primary' are created and rigged in 2D Animation's Skinning Editor (refer to the 2D Animation package documentation for further information). A bone hierarchy connected together to form the skeleton of 'Primary'. When importing an Asset without anything set in the Main Skeleton property, the PSD Importer generates a .skeleton Asset for the Asset and automatically names it as '[Asset File Name] Skeleton'. Any bones rigged for 'Primary' is saved to the .skeleton Asset 'Primary Skeleton'. To share the 'Primary Skeleton' with 'Variant', select 'Variant' and go to its PSD Importer settings. Assign 'Primary Skeleton' to the Main Skeleton property to have 'Variant' reference that .skeleton Asset as its own bone hierarchy. The Bone tools are greyed out and unavailable when opening 'Variant' in the Skinning Editor. When an actor references another actor's .skeleton Asset instead of its own, the Bone Tools in the Skinning Editor are disabled. To edit the bones, open the original actor (that the .skeleton Asset belongs to) in the Skinning Editor and edit the bones. Any changes to the original .skeleton Asset is reflected in any actor which references it. In this example, changes made to 'Primary Skeleton' are reflected in the 'Variant' actor's bone hierarchy ."
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.psdimporter copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/README.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/README.html",
    "title": "| mmo-rpg-unity",
    "keywords": "PSB Importer ScriptedImporter to import Adobe Photoshop PSB file format Feature Generate texture and sprite by mosaicing layers Option to generate Prefab to reconstuct the image from generated Sprites Option to import hidden layers"
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Samples~/PSDImporterSamples/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Samples~/PSDImporterSamples/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.psdimporter Samples © 2023 Unity Technologies Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Samples~/PSDImporterSamples/PSDImporterCustomPacker/README.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Samples~/PSDImporterSamples/PSDImporterCustomPacker/README.html",
    "title": "PSDImporter Custom Image Packer | mmo-rpg-unity",
    "keywords": "PSDImporter Custom Image Packer This example shows how to override the default image packing algorithm in the PSDImporter. The example utilizes the m_Pipeline SerializedProperty that is defined in the PSDImporter. The m_Pipeline is a ScriptableObject reference and in the PSDImporter it will determine what method is available in the SciptableObject and execute those methods accordingly. Refer to the CustomPackScriptableObject.cs for more details."
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Samples~/PSDImporterSamples/README.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Samples~/PSDImporterSamples/README.html",
    "title": "2D PSDImporter Samples | mmo-rpg-unity",
    "keywords": "2D PSDImporter Samples 2D PSDImporter samples showing various use cases."
  },
  "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.2d.psdimporter@8.0.5/Third Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This package contains third-party software components governed by the license(s) indicated below: Component Name: Photoshop PSD FileType Plugin for Paint.NET License Type: MIT Copyright (c) 2006-2007 Frank Blumenberg Copyright (c) 2010-2016 Tao Yue https://www.psdplugin.com/ Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Yet Another PSD Parser License Type: BSD Copyright (c) 2006, Jonas Beckeman http://www.codeproject.com/KB/graphics/PSDParser.aspx Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Jonas Beckeman nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY JONAS BECKEMAN AND CONTRIBUTORS ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL JONAS BECKEMAN AND CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  "Library/PackageCache/com.unity.2d.sprite@1.0.0/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.2d.sprite@1.0.0/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [1.0.0] - 2020-09-22 ###Added Added confirmation dialog when user pressed on Apply/Revert button on the Sprite Editor Window. This can be enabled/disabled in Preferences [1.0.0] - 2019-01-25 ###Added This is the first release of Sprite Editor, as a Package"
  },
  "Library/PackageCache/com.unity.2d.sprite@1.0.0/Documentation~/DataProvider.html": {
    "href": "Library/PackageCache/com.unity.2d.sprite@1.0.0/Documentation~/DataProvider.html",
    "title": "Sprite Editor Data Provider API | mmo-rpg-unity",
    "keywords": "Sprite Editor Data Provider API By using the Sprite Editor Data Provider API, the user can add, change and remove Sprite data in a custom importer or editor tool. Refer to the code examples below to see how the API is applied. Important: Some of the following examples contains an additional section of code which is needed if you are using Unity 2021.2 or newer. If you are using Unity 2021.1 or older, you should remove the indicated section to ensure the code compiles properly. How to get ISpriteEditorDataProvider instances The following examples show you how to use the API to get each respective instance. Importer using UnityEditor; using UnityEditor.U2D.Sprites; using UnityEngine; public class MyAssetPostProcessor : AssetPostprocessor { private void OnPreprocessTexture() { var factory = new SpriteDataProviderFactories(); factory.Init(); var dataProvider = factory.GetSpriteEditorDataProviderFromObject(assetImporter); dataProvider.InitSpriteEditorDataProvider(); /* Use the data provider */ // Apply the changes made to the data provider dataProvider.Apply(); } } Texture using UnityEditor; using UnityEditor.U2D.Sprites; using UnityEngine; public static class MyCustomTool { [MenuItem(\"Custom/Update Sprite Settings\")] static void UpdateSettings() { foreach (var obj in Selection.objects) { if (obj is Texture2D) { var factory = new SpriteDataProviderFactories(); factory.Init(); var dataProvider = factory.GetSpriteEditorDataProviderFromObject(obj); dataProvider.InitSpriteEditorDataProvider(); /* Use the data provider */ // Apply the changes made to the data provider dataProvider.Apply(); // Reimport the asset to have the changes applied var assetImporter = dataProvider.targetObject as AssetImporter; assetImporter.SaveAndReimport(); } } } } How to add Sprites static void AddSprite(ISpriteEditorDataProvider dataProvider) { // Define the new Sprite Rect var newSprite = new SpriteRect() { name = \"MyNewSprite\", spriteID = GUID.Generate(), rect = new Rect(0, 0, 32, 32) }; // Add the Sprite Rect to the list of existing Sprite Rects var spriteRects = dataProvider.GetSpriteRects().ToList(); spriteRects.Add(newSprite); // Write the updated data back to the data provider dataProvider.SetSpriteRects(spriteRects.ToArray()); // Note: This section is only for Unity 2021.2 and newer // Register the new Sprite Rect's name and GUID with the ISpriteNameFileIdDataProvider var spriteNameFileIdDataProvider = dataProvider.GetDataProvider<ISpriteNameFileIdDataProvider>(); var nameFileIdPairs = spriteNameFileIdDataProvider.GetNameFileIdPairs().ToList(); nameFileIdPairs.Add(new SpriteNameFileIdPair(newSprite.name, newSprite.spriteID)); spriteNameFileIdDataProvider.SetNameFileIdPairs(nameFileIdPairs); // End of Unity 2021.2 and newer section // Apply the changes dataProvider.Apply(); } How to change Sprite data static void SetPivot(ISpriteEditorDataProvider dataProvider) { // Get all the existing Sprites var spriteRects = dataProvider.GetSpriteRects(); // Loop over all Sprites and update the pivots foreach (var rect in spriteRects) { rect.pivot = new Vector2(0.1f, 0.2f); rect.alignment = SpriteAlignment.Custom; } // Write the updated data back to the data provider dataProvider.SetSpriteRects(spriteRects); // Apply the changes dataProvider.Apply(); } How to remove Sprites static void RemoveSprite(ISpriteEditorDataProvider dataProvider, string spriteName) { // Get all the existing Sprites and look for the Sprite with the selected name var spriteRects = dataProvider.GetSpriteRects().ToList(); var index = spriteRects.FindIndex(x => x.name == spriteName); // Remove the entry of the Sprite if found if (index >= 0) spriteRects.RemoveAt(index); // Write the updated data back to the data provider dataProvider.SetSpriteRects(spriteRects.ToArray()); // Note: This section is only for Unity 2021.2 and newer // Get all the existing SpriteName & FileId pairs and look for the Sprite with the selected name var spriteNameFileIdDataProvider = dataProvider.GetDataProvider<ISpriteNameFileIdDataProvider>(); var nameFileIdPairs = spriteNameFileIdDataProvider.GetNameFileIdPairs().ToList(); index = nameFileIdPairs.FindIndex(x => x.name == spriteName); // Remove the entry of the Sprite if found if (index >= 0) nameFileIdPairs.RemoveAt(index); spriteNameFileIdDataProvider.SetNameFileIdPairs(nameFileIdPairs); // End of Unity 2021.2 and newer section // Apply the changes dataProvider.Apply(); } How to update Outline data static void SetOutline(ISpriteEditorDataProvider dataProvider) { // Get the ISpriteOutlineDataProvider var outlineDataProvider = dataProvider.GetDataProvider<ISpriteOutlineDataProvider>(); // Loop over all Sprites and set their outline to a quad var spriteRects = dataProvider.GetSpriteRects(); foreach (var spriteRect in spriteRects) { var halfWidth = spriteRect.rect.width / 2f; var halfHeight = spriteRect.rect.height / 2f; var quadOutline = new Vector2[4] { new Vector2(-halfWidth, -halfHeight), new Vector2(-halfWidth, halfHeight), new Vector2(halfWidth, halfHeight), new Vector2(halfWidth, -halfHeight) }; var outlines = new List<Vector2[]>(); outlines.Add(quadOutline); var spriteGuid = spriteRect.spriteID; outlineDataProvider.SetOutlines(spriteGuid, outlines); } // Apply the changes dataProvider.Apply(); } Additional resources Full list of other available data providers is available in the package's Scripting API section."
  },
  "Library/PackageCache/com.unity.2d.sprite@1.0.0/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.2d.sprite@1.0.0/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "2D Sprite package Sprite Editor Data Provider API"
  },
  "Library/PackageCache/com.unity.2d.sprite@1.0.0/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.2d.sprite@1.0.0/Documentation~/index.html",
    "title": "2D Sprite package | mmo-rpg-unity",
    "keywords": "2D Sprite package Install the 2D Sprite package to install the Sprite Editor, which allows you to create and edit Sprite assets. The Sprite Editor Data Provider API also allow user extensibility to add custom behaviour for editing various Sprite related data. To install the package, search for it in the Package Manager window and install it from the registry. If you created your Project with the 2D Template, this package is automatically installed. This version of Sprite Editor is compatible with the following versions of the Unity Editor: 2019.4 and later (recommended) Topic Description Sprite Editor (User Manual) Understand how to use the main features of the Sprite Editor. Sprite Editor Data Provider APIs Understand how to use the APIs available edit Sprite data. Package contents The following table indicates the folder structure of the Sprite package: Location Description <Editor> Root folder containing the source for the Sprite Editor. <Tests> Root folder containing the source for the tests for Sprite Editpr used the Unity Editor Test Runner. Documentation revision history Date Reason April 13, 2022 Added Sprite Editor Data Provider API samples January 25, 2019 Document created. Matches package version 1.0.0 Additional resources Sprite Editor: Custom Outline Sprite Editor: Custom Physics Shape Sprite Editor: Secondary Textures"
  },
  "Library/PackageCache/com.unity.2d.sprite@1.0.0/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.sprite@1.0.0/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.sprite copyright © 2019 Unity Technologies Licensed under the Unity Package Distribution License (see https://unity3d.com/legal/licenses/Unity_Package_Distribution_License ). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.sprite@1.0.0/README.html": {
    "href": "Library/PackageCache/com.unity.2d.sprite@1.0.0/README.html",
    "title": "About Sprite Editor | mmo-rpg-unity",
    "keywords": "About Sprite Editor Use Unity’s Sprite Editor to create and edit Sprite assets. Sprite Editor provides user extensibility to add custom behaviour for editing various Sprite related data. Installing Sprite Editor To install this package, follow the instructions in the Package Manager documentation. Using Sprite Editor The Sprite Editor Manual can be found [here] (https://docs.unity3d.com/Manual/SpriteEditor.html). Technical details Requirements This version of Sprite Editor is compatible with the following versions of the Unity Editor: 2019.2 and later (recommended) Package contents The following table indicates the folder structure of the Sprite package: Location Description <Editor> Root folder containing the source for the Sprite Editor. <Tests> Root folder containing the source for the tests for Sprite Editpr used the Unity Editor Test Runner. Document revision history Date Reason January 25, 2019 Document created. Matches package version 1.0.0"
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [9.0.4] - 2024-06-25 Fixed DANB-604 Fix case where Spriteshape vertex array exceeds limit even though it has not reached 64K. [9.0.3] - 2024-05-06 Fixed DANB-555 Fix Crash on DynamicHeapAllocator::Deallocate when changing SpriteShapeController splineDetail value through Script to 1 [9.0.2] - 2023-02-27 Fixed DANB-328 Fix case where BezierUtility.BezierPoint function parameters are not in the right order DANB-307 Fix case where Error �A Native Collection has not been disposed, resulting in a memory leak occurs in Play Mode DANB-279 Fix case where Spriteshape with tangents enabled has shadow artifacts after reopening the project [9.0.1] - 2022-10-11 Fixed DANB-177 Fix case where SpriteShapeController does not initialize collider data. DANB-224 Fix case where adding a new element to Custom Geometry Modifier spams errors. [9.0.0] - 2022-08-03 Changed Refactored internal triangulation and tessellation APIs. [9.0.0-pre.1] - 2022-03-21 Added Added versioning for GeometryCreator and GeometryModifier scripts so SpriteShape geoemetry is regenerated when it changes. Fill Tessellation in C# Job is now set as default tessellator. GC allocations are reduced when using this option. Fixed 1394404 Fix case where Tangent Data is always saved even when not in use for SpriteShapeRenderer when GeometryCache is active. 1391968 Fix case where \"Invalid memory pointer was detected in ThreadsafeLinearAllocator::Deallocate!\" error is thrown when Sprite is in Atlas with Tight Packing 1399392 Fix case where SpriteShape with Cache Geometry enabled does not update arrays when saving scene off-screen. 1400229 Fix case where SpriteShape corner does not respect the ControlPoint height. 1387298 Fix case where SpriteShape throws ArgumentException error when checking position validity of a point added to Spline 1401376 Fix case where Shape of PolygonCollider2D doesn't update when Sprite Shape contains vertex at [0,0] and it's Profile doesn't have any Sprites. [8.0.0] - 2022-01-25 Changed Package release version. Fixed 1392653 Fix case where SpriteShapeGeometry Cache does not update when n selecting a different Object when EditTool is active. [8.0.0-pre.5] - 2021-11-24 Fixed 1367509 Fix case where SpriteShapeProfile corner fields disappear when a field above has been deleted in the Inspector. 1363468 Fix case where shortcut keys do not work after editing sprite variant list in SpriteShape Controller. 1382718 Fix Case when setting SpriteShape corners to Disabled, the first corner does not visually change [8.0.0-pre.4] - 2021-10-21 Changed Update to latest com.unity.2d.common package [8.0.0-pre.3] - 2021-10-18 Fixed Fixed package.json to remove com.unity.2d.path dependency. [8.0.0-pre.2] - 2021-10-11 Fixed 1368107 Fix case where Bounds can cause spriteshape not load in when running Player. 1364012 Fix crash when optimizing the geometry of the SpriteShape in certain cases. [8.0.0-pre.1] - 2021-08-06 Added Add actionable console log when encounter vertex count limit exception Improved estimation of vertices required for geometry to minimize memory alloction. Added user preferences for Controlpoint/Tangent/Spline color. Added support for Global Grid Snapping. Changed Remove dependency to path package Moved Control point specific data from Inspector to a Scene Overlay Window. Fixed Fixed Bounds of SpriteShapeRenderer. Update manual to reflect reorganization of menu item. 1346430 Fix case where all open Scenes were dirtied when editing a SpriteShape Spline. 1343836 Fix case where triangular spriteshape with 0 offset collider does not generate collision shape. 1356204 Fix case where Sprite Shapes appear only when their pivot is revealed in the Scene view. 1348701 Fix case where colliders do not extend to the end of the sprite texture when Sprite Borders are enabled. 1362440 Fix case where Edge and Polygon colliders have missing edges on certain open-ended shapes. 1363215 Fix case where enabling Fill Tessellation and setting profile's fill offset to positive causes errors. 1368129 Fix case where Sprite Shape default materials were not initialized correctly. [7.0.0-pre.3] - 2021-05-17 Changed Update dependency version [7.0.0-pre.2] - 2021-05-14 Changed Update dependency version [7.0.0-pre.1] - 2021-05-05 Fixed 1274010 2D light is rendered in half in its Y-axis when two Sprite Shape objects with same Order In Layer are visible on the Screen 1313579 SpriteShape Prefabs does not work properly when GeometryCache is enabled. 1315086 When SpriteShapeController has \"Update Collider\" set to true, it will dirty the scene every time its selected 1306434 PrefabStage is moving out of UnityEditor.SceneManagement.Experimental namepace in 2021.2 1319096 At certain cases, vertex data allocation may not be enough and overflows. 1321978 Edge collider 2D and polygon collider 2D creates different collision shapes during playmode 1317728 On deselecting game object from the Inspector window leads to deselecting Sprite Shape Renderer 1326983 SpriteShape Cache Geometry does not update when changing SpriteShape Profile. Changed Version bump for Unity 2021.2 [6.0.0] - 2021-03-17 Changed Update version for release [6.0.0-pre.3] - 2021-02-28 Fixed 1294930 Exception thrown continuously on creating Range in the preset of Sprite Shape when Undo/Redo operation is performed earlier 1303998 Enabling Fill Tessellation on controller and setting the profile's fill offset to negative causes errors 1293760 Sprite Shape generates Edge Colliders with deformed corners 1305867 Sprite shape edge collider has a gap at end point if optimise collider is disabled 1286378 Sprite Shape incorrect normal generation [6.0.0-pre.2] - 2020-11-25 Changed Update license file Fixed 1273635 Fixed error when adding AngleRange to SpriteShapeProfile Preset that was reset before. 1287237 Fixed ArgumentException when tangents and cache geometry are enabled on SpriteShapeController component. 1240514 Fixed InvalidOperationException thrown continuously on adding SpriteShapeController component to a GameObject with SpriteRenderer. 1284920 Fixed PolygonCollider2D generated with a single vertex when a GameObject has a SpriteShapeController with just 3 vertices. [6.0.0-pre.1] - 2020-10-30 Changed Version bump for Unity 2021.1 Height is interpolated linearly between control points that are both linear and smoothly if otherwise. [5.1.0] - 2020-09-24 Added Added C# Job Tessellation support for Fill Area of SpriteShape. Fixed 1274400 SpriteShape Bounding Box does not take into account certain vertices 1273705 Assertion failed exception is thrown on undoing after clicking on Create Range button 1273635 Errors occurs when adding range on Reset-ed Preset of the SpriteShapeProfile 1271817 Icon is missing on creating SpriteShapeProfile at the time of creating 1280016 Unable to create Sprite Shape Profile along with ArgumentNullException thrown in the Project window 1274776 NullReferenceException thrown on performing Redo operation after creating Range property in the SpriteShape profiler preset [5.0.2] - 2020-08-31 Fixed 1267542 Sprite Variant Window does not appear in Sprite Shape Controller Component when selecting a Spline pivot point. 1265846 Dragging Sprite Shape Profile to Hierarchy creates a Game Object in main Scene when being in Prefab Mode [5.0.1] - 2020-07-17 Changed If Geometry is baked using SpriteShapeGeometryCache, do not check for dirty once data is updated to prevent GC. Updated Help Section to point to the correct URLs. Fixed 1242910 Unable to add item on Resetting the Preset of the SpriteShapeProfile 1256914 Exception thrown continuously when Undo operation is performed with sprites are assigned earlier 1263266 BakeCollider requires GC every frame even when there are no changes in SpriteShape [5.0.0] - 2020-05-28 Added Sample script GenerateSpriteShapes.cs to demonstrate force generating invisible SpriteShapes on runtime scene load. Changed Version bump for Unity 2020.2 Fixed 1246133 Error occurs when unselecting Cache Geometry for Sprite Shape prefab 1240380 OnGUI in SpriteShapeController creates GC allocs. 1235972 \"A Native Collection has not been disposed, resulting in a memory leak\" is thrown when 2D Sprite Shape Controller is disabled 1240514 InvalidOperationException thrown continuously on adding \"Sprite Shape Controller\" Component to a Sprite object 1241841 Disabled corner option does not work on existing spriteshape upgraded from a previous version [4.1.1] - 2020-04-20 Added Added BakeMesh to save generated geometry data. Added warning when a valid SpriteShape profile is not set. [4.1.0] - 2020-03-16 Added Stretched Corners. Fixed 1226841 Fix when Collider generation allocation. 1226856 SpriteShape Edge Collider does not extend to End-point even if Edges dont overlap. 1226847 SpriteShape Corner Threshold does not work. [4.0.3] - 2020-03-09 Fixed 1220091 SpriteShapeController leaks memory when zero control points are used 1216990 Colliders should also respect Pivot property of Edge Sprites. 1225366 Ensure SpriteShape are generated when not in view on Runtime. [4.0.2] - 2020-02-11 Changed Improved Memory Allocations. Fixed Fixed OnDrawGizmos to Get/Release RenderTexture through CommandBuffer. [4.0.1] - 2019-11-26 Changed Updated License file Updated Third Party Notices file Changed how Samples are installed into user's project Fixed Fixed where the last point of the Sprite Shape does not behave correctly when using Continuous Points in a closed shape (case 1184721) [4.0.0] - 2019-11-06 Changed Update version number for Unity 2020.1 [3.0.7] - 2019-10-27 Fixed Added missing meta file Changed Update com.unity.2d.path package dependency [3.0.6] - 2019-09-27 Added Added support to set CornerAngleThreshold. Burst is now enabled for performance boost. Fixed Fix (Case 1041062) Inputting Point Position manually causes mesh to not conform to the spline Fix GC in confirming Spline Extras sample. Fix hash Validation errors. Removed resources from Packages. [3.0.5] - 2019-09-05 Fixed Fix (Case 1159767) Error generated when using a default sprite for Corner sprite or Angle Range sprite in Sprite Shape Profile Fix (Case 1178579) \"ArgumentOutofRangeException\" is thrown and SpriteShapeProfile freezes on reset [3.0.4] - 2019-08-09 Added Added tangent channel support for proper 2D lighting in URP. [3.0.3] - 2019-07-24 Added Add related test packages [3.0.2] - 2019-07-13 Changed Update to latest Mathematics package version [3.0.1] - 2019-07-13 Changed Mark package to support Unity 2019.3.0a10 onwards. [3.0.0] - 2019-06-19 Changed Stable Version. Remove experimental namespace. [2.1.0-preview.8] - 2019-06-12 Changed Fix (Case 1152342) The first point of the Sprite Shape does not behave correctly when using Continuous Points Fix (Case 1160009) Edge and Polygon Collider does not seem to follow the spriteshape for some broken mirrored tangent points Fix (Case 1157201) Edge Sprite Material changed when using a fill texture that is already an edge sprite on spriteshape Fix (Case 1162134) Open ended Spriteshape renders the fill texture instead of the range sprite [2.1.0-preview.7] - 2019-06-02 Changed Fix Variant Selection. [2.1.0-preview.6] - 2019-06-02 Changed Fix Null reference exception caused by SplineEditorCache changes. Fill Inspector changes due to Path integration. [2.1.0-preview.4] - 2019-05-28 Changed Upgrade Mathematics package. Use path editor. [2.1.0-preview.2] - 2019-05-13 Changed Initial version for 2019.2 Update for common package. [2.0.0-preview.8] - 2019-05-16 Fixed Fixed issue when sprites are re-ordered in Angle Range. Updated Samples. [2.0.0-preview.7] - 2019-05-10 Fixed Version Update and fixes. [2.0.0-preview.6] - 2019-05-08 Fixed Added Sprite Variant Selector. Fix Variant Bug (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-6#post-4480936) Fix (Case 1146747) SpriteShape generating significant GC allocations every frame (OnWillRenderObject) [2.0.0-preview.5] - 2019-04-18 Fixed Shape angle does not show the accurate sprite on certain parts of the shape. SpriteShape - Unable to use the Depth buffer (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-6#post-4413142) [2.0.0-preview.4] - 2019-03-28 Changed Disable burst for now until we have a final release. [2.0.0-preview.3] - 2019-03-25 Fixed Update Common version. [2.0.0-preview.2] - 2019-03-08 Fixed Fix Edge Case Scenario where Vertices along Continuous segment could be duplicated.. Ensure that Collider uses a valid Sprite on Generation. [2.0.0-preview.1] - 2019-02-27 Changed Updated version. [1.1.0-preview.1] - 2019-02-10 Added Spriteshape tessellation code is re-implemented in C# Jobs and utilizes Burst for Performance. Added Mirrored and Non-Mirrored continous Tangent mode. Simplified Collider Generation support and is part of C# Job/Burst for performance. Added Shortcut Keys (for setting Tangentmode, Sprite Variant and Mirror Tangent). Ability to drag Spriteshape Profile form Project view to Hierarchy to create Sprite Shape in Scene. Simplified Corner mode for Points and is now enabled by default. Added Stretch UV support for Fill Area. Added Color property to SpriteShapeRenderer. Fixed SpriteShapeController shows wrong Sprites after deleting a sprite from the top angle range. Empty SpriteShapeController still seem to show the previous Spriteshape drawcalls Streched Sprites are generated in between non Linked Points Corners sprites are no longer usable if user only sets the corners for the bottom Sprites in SpriteShape still shows even after user deletes the SpriteShape Profile SpriteShape doesn't update Point Positions visually at runtime for Builds Spriteshape Colliders does not update in scene immediately Fixed constant Mesh baking (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-4#post-3925789) Fixed Bounds generation issue (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-5#post-4079857) Sprite Shape Profile component breaks when creating range Fixed when sprite is updated in the sprite editor, the spriteshape is not updated. Fixed cases where Spline Edit is disabled even when points are selected. (https://forum.unity.com/threads/spriteshape-preview-package.522575/#post-3436940) Sprite with SpriteShapeBody Shader gets graphical artifacts when rotating the camera. When multiple SpriteShapes are selected, Edit Spline button is now disabled. (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-3#post-3764413) Fixed texelSize property (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-4#post-3877081) Fixed Collider generation for different quality levels. (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-4#post-3956062) Fixed Framing Issues (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-5#post-4137214) Fixed Collider generation for Offsets (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-5#post-4149841) Fixed Collider generation for different Heights (https://forum.unity.com/threads/spriteshape-preview-package.522575/page-5#post-4190116) Changed SpriteShape Asset parameters WorldSpace UV, PixelPerUnit have been moved to SpriteShapeController properties. Collider generation has been simplified and aligns well with the generated geometry (different height, corners etc.) Removed Remove redundant parameters BevelCutoff and BevelSize that can be done by simply modifying source spline. [1.0.12-preview.1] - 2018-08-03 Added Fix issue where Point Positions do not update visually at runtime for Builds [1.0.11-preview] - 2018-06-20 Added Fix Spriteshape does not update when Sprites are reimported. Fix SpriteShapeController in Scene view shows a different sprite when user reapplies a Sprite import settings Fix Editor Crashed when user adjusts the \"Bevel Cutoff\" value Fix Crash when changing Spline Control Points for a Sprite Shape Controller in debug Inspector Fix SpriteShape generation when End-points are Broken. Fix cases where the UV continuity is broken even when the Control point is continous. [1.0.10-preview] - 2018-04-12 Added Version number format changed to -preview [0.1.0] - 2017-11-20 Added Bezier Spline Shape Corner Sprites Edge variations Point scale SpriteShapeRenderer with support for masking Auto update collision shape"
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/CustomGeometry.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/CustomGeometry.html",
    "title": "Generating Custom Geometry | mmo-rpg-unity",
    "keywords": "Generating Custom Geometry The Custom Geometry feature is found in the Sprite Shape Controller. It allows you to use a custom script to generate or modify Sprite Shape geometry. The custom script is written as a ScriptableObject and is reusable. API Examples ###Generating new geometry To generate new geometry, refer to the following example code. public abstract class SpriteShapeGeometryCreator : ScriptableObject { public abstract int GetVertexArrayCount(SpriteShapeController spriteShapeController); public abstract JobHandle MakeCreatorJob(SpriteShapeController spriteShapeController, NativeArray<ushort> indices, NativeSlice<Vector3> positions, NativeSlice<Vector2> texCoords, NativeSlice<Vector4> tangents, NativeArray<SpriteShapeSegment> segments, NativeArray<float2> colliderData); } Note: The default generator script that ships with the Sprite Shape package is itself written as a SpriteShapeGeometryCreator (refer to Runtime/SpriteShapeDefaultCreator.cs). Any custom SpriteShapeGeometryCreator set through the script or Inspector will override this default Object. ###Modifying existing geometry To modify generated geometry, refer to the following example code. public abstract class SpriteShapeGeometryModifier : ScriptableObject { public abstract JobHandle MakeModifierJob(JobHandle generator, SpriteShapeController spriteShapeController, NativeArray<ushort> indices, NativeSlice<Vector3> positions, NativeSlice<Vector2> texCoords, NativeSlice<Vector4> tangents, NativeArray<SpriteShapeSegment> segments, NativeArray<float2> colliderData); } Note: SpriteShapeGeometryModifier is only applicable when either: SpriteShapeDefaultCreator is used and the vertex data only needs modification. Or a custom SpriteShapeGeometryCreator is used with default channels accepted in MakeCreatorJob. SpriteShapeGeometryModifier cannot be used when MakeCreatorJob creates a Job with custom Channel data. Examples by usage Creating a simple quad with the size of the Bounds with SpriteShapeGeometryCreator: // A simple C# job to generate a quad. public struct CreatorJob : IJob { // Indices of the generated triangles. public NativeArray<ushort> indices; // Vertex positions. public NativeSlice<Vector3> positions; // Texture Coordinates. public NativeSlice<Vector2> texCoords; // Sub-meshes of generated geometry. public NativeArray<UnityEngine.U2D.SpriteShapeSegment> segments; // Input Bounds. public Bounds bounds; public void Execute() { // Generate Positions/TexCoords/Indices for the Quad. positions[0] = bounds.min; texCoords[0] = Vector2.zero; positions[1] = bounds.max; texCoords[1] = Vector2.one; positions[2] = new Vector3(bounds.min.x, bounds.max.y, 0); texCoords[2] = new Vector2(0, 1); positions[3] = new Vector3(bounds.max.x, bounds.min.y, 0); texCoords[3] = new Vector2(1, 0); indices[0] = indices[3] = 0; indices[1] = indices[4] = 1; indices[2] = 2; indices[5] = 3; // Set the only sub-mesh (quad) var seg = segments[0]; seg.geomIndex = seg.spriteIndex = 0; seg.indexCount = 6; seg.vertexCount = 4; segments[0] = seg; // Reset other sub-meshes. seg.geomIndex = seg.indexCount = seg.spriteIndex = seg.vertexCount = 0; for (int i = 1; i < segments.Length; ++i) segments[i] = seg; } } [CreateAssetMenu(fileName = \"SpriteShapeQuad\", menuName = \"ScriptableObjects/SpriteShapeQuad\", order = 1)] public class SpriteShapeQuad : SpriteShapeGeometryCreator { public override int GetVertexArrayCount(SpriteShapeController sc) { // Set the maximum size required for the Vertices. return 64; } public override JobHandle MakeCreatorJob(SpriteShapeController sc, NativeArray<ushort> indices, NativeSlice<Vector3> positions, NativeSlice<Vector2> texCoords, NativeSlice<Vector4> tangents, NativeArray<UnityEngine.U2D.SpriteShapeSegment> segments, NativeArray<float2> colliderData) { NativeArray<Bounds> bounds = sc.spriteShapeRenderer.GetBounds(); var spline = sc.spline; int pointCount = spline.GetPointCount(); Bounds bds = new Bounds(spline.GetPosition(0), spline.GetPosition(0)); for (int i = 0; i < pointCount; ++i) bds.Encapsulate(spline.GetPosition(i)); bounds[0] = bds; var cj = new CreatorJob() {indices = indices, positions = positions, texCoords = texCoords, segments = segments, bounds = bds}; var jh = cj.Schedule(); return jh; } } Changing UV data with SpriteShapeGeometryModifier: // A simple C# job to move the UV along the x-axis. If this is called repeatedly each frame it creates UV Animation effect. To get this called each frame, use RefreshSpriteShape API of SpriteShapeController. public struct UVAnimatorJob : IJob { // We are only modifying UV data. public NativeSlice<Vector2> uvs; // Offset to move x coordinates of UV. public float offset; public void Execute() { // Move x coordinates of UV data. for (int i = 0; i < uvs.Length; ++i) { var uv = uvs[i]; uv.x = (uv.x + offset) % 1.0f; uvs[i] = uv; } } } [CreateAssetMenu(fileName = \"SpriteShapeUVAnimator\", menuName = \"ScriptableObjects/SpriteShapeUVAnimator\", order = 1)] public class SpriteShapeUVAnimator : SpriteShapeGeometryModifier { public override JobHandle MakeModifierJob(JobHandle generator, SpriteShapeController spriteShapeController, NativeArray<ushort> indices, NativeSlice<Vector3> positions, NativeSlice<Vector2> texCoords, NativeSlice<Vector4> tangents, NativeArray<SpriteShapeSegment> segments, NativeArray<float2> colliderData) { var mj = new UVAnimatorJob(){ uvs = texCoords, offset = UnityEngine.Time.time}; var jh = mj.Schedule(generator); return jh; } } Advanced usage The following is an example of advanced usage of the API by creating geometry with vertex colors. In the function MakeCreatorJob below, GetChannels is invoked to get additional colors other than the default. The input parameters for MakeCreatorJob are overwritten by the GetChannels function. Note: Only SpriteShapeGeometryCreator can be used when updating any other channels that are not part of the MakeCreatorJob parameters. public struct ColorCreatorJob : IJob { // Indices of the generated triangles. public NativeArray<ushort> indices; // Vertex positions. public NativeSlice<Vector3> positions; // Texture Coordinates. public NativeSlice<Vector2> texCoords; // Color of Vertces. public NativeSlice<Color32> colors; // Sub-meshes of generated geometry. public NativeArray<UnityEngine.U2D.SpriteShapeSegment> segments; // Input Bounds. public Bounds bounds; public void Execute() { // Generate Positions/TexCoords/Indices for the Quad. positions[0] = bounds.min; texCoords[0] = Vector2.zero; colors[0] = Color.red; positions[1] = bounds.max; texCoords[1] = Vector2.one; colors[1] = Color.blue; positions[2] = new Vector3(bounds.min.x, bounds.max.y, 0); texCoords[2] = new Vector2(0, 1); colors[2] = Color.green; positions[3] = new Vector3(bounds.max.x, bounds.min.y, 0); texCoords[3] = new Vector2(1, 0); colors[3] = Color.yellow; indices[0] = indices[3] = 0; indices[1] = indices[4] = 1; indices[2] = 2; indices[5] = 3; // Set the only sub-mesh (quad) var seg = segments[0]; seg.geomIndex = seg.spriteIndex = 0; seg.indexCount = 6; seg.vertexCount = 4; segments[0] = seg; // Reset other sub-meshes. seg.geomIndex = seg.indexCount = seg.spriteIndex = seg.vertexCount = 0; for (int i = 1; i < segments.Length; ++i) segments[i] = seg; } } [CreateAssetMenu(fileName = \"SpriteShapeColorQuad\", menuName = \"ScriptableObjects/SpriteShapeColorQuad\", order = 1)] public class SpriteShapeColorQuad : SpriteShapeGeometryCreator { public override int GetVertexArrayCount(SpriteShapeController sc) { return 64; } public override JobHandle MakeCreatorJob(SpriteShapeController sc, NativeArray<ushort> indices, NativeSlice<Vector3> positions, NativeSlice<Vector2> texCoords, NativeSlice<Vector4> tangents, NativeArray<UnityEngine.U2D.SpriteShapeSegment> segments, NativeArray<float2> colliderData) { NativeArray<Bounds> bounds = sc.spriteShapeRenderer.GetBounds(); var spline = sc.spline; int pointCount = spline.GetPointCount(); Bounds bds = new Bounds(spline.GetPosition(0), spline.GetPosition(0)); for (int i = 0; i < pointCount; ++i) bds.Encapsulate(spline.GetPosition(i)); NativeSlice<Color32> colors = default(NativeSlice<Color32>); sc.spriteShapeRenderer.GetChannels(32000, out indices, out positions, out texCoords, out colors); var cj = new ColorCreatorJob() {indices = indices, positions = positions, texCoords = texCoords, colors = colors, segments = segments, bounds = bds}; var jh = cj.Schedule(); return jh; } }"
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/FillTessellation.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/FillTessellation.html",
    "title": "Fill Tessellation (C# Job) | mmo-rpg-unity",
    "keywords": "Fill Tessellation (C# Job) Example of a Sprite Shape: the blue area is the inner fill geometry, while the green area is the edge geometry. The geometry of a Sprite Shape is made up of its outer edge (for both Open and Closed Shapes and its inner fill (only for Closed Shapes). Both edge and fill geometry are always generated in a C# Job which provides performance benefits and avoids potential performance loss from garbage collection (refer to Understanding Automatic Memory Management for more information). Running C# Job also gains additional performance if the Burst package is installed in the same Project. If Fill Tessellation (C# Job) is disabled, the fill geometry is generated in the main thread using LibNess.NET instead (see What is multithreading? for more information). Requirements The Fill Tessellation (C# Job) option in the Sprite Shape Controller Inspector window To enable Fill Tessellation (C# Job), select a Sprite Shape and then select the Fill Tessellation (C# Job) checkbox in its Inspector window; clear the checkbox to disable the feature. The Sprite Shape must also fulfill the following requirements for this feature to work: The Sprite Shape must not have any duplicate points or points that are too close to each other. Duplicate points can occur if you drag a point over another point. The Sprite Shape’s edges cannot intersect or overlap each other. Note: If Fill Tessellation (C# Job) is enabled but the Sprite Shape does not fulfill these requirements, then the Sprite Shape’s Fill geometry will not be generated. Disable Fill Tessellation (C# Job) to enable the default tessellation method to generate the geometry. Enabling or disabling this option does not affect the edge geometry tessellation method which is always in a C# Job. Recommended tessellation method The following are examples and reasons for when either method of tessellation is recommended, depending on the requirements of your project. When Fill Tessellation (C# Job) is recommended Enabling Fill Tessellation (C# Job) is ideal for situations where you want to reduce memory usage for improved CPU performance. For example, when you have dynamic Sprite Shape objects generated at runtime, or are animating Sprite Shape objects at runtime. Both scenarios feature CPU intensive processes, and enabling Fill Tessellation (C# Job) helps to reduce the memory usage of these processes and improve performance overall. In general, enabling Fill Tessellation (C# Job) is also recommended whenever size and memory usage are important constraints to consider for your application or game. When default LibTess.NET is recommended It is recommended to disable the Fill Tessellation (C# Job) option and use the default LibTess.NET generation method whenever the Sprite Shape cannot meet the requirements that allow it to be generated in a C# Job. This could be because the Sprite Shape has a complex spline shape, with overlapping edges or duplicate points. If the Sprite Shape is being generated with non-deterministic and random input points for the shape of its spline, then it is recommended to use LibTess.NET as it is not guaranteed that the Sprite Shape fulfils the Fill Tessellation requirements. If you enabled Cache Geometry under the Sprite Shape Controller properties, then it is recommended that you use LibTess.NET instead of Fill Tessellation. The Sprite Shape’s geometry is cached as it is generated in the Editor, and this stored data is used at runtime instead of being generated at runtime. Both the LibTess.NET and Fill Tessellation options use this stored data instead of recalculating and regenerating the geometry if it is available. As LibTess.NET is more flexible and is able to accept a wider range of inputs when generating the Sprite Shape, it is recommended to disable Fill Tessellation if Cache Geometry is used."
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/SSCollision.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/SSCollision.html",
    "title": "Enabling Collision | mmo-rpg-unity",
    "keywords": "Enabling Collision Attach a Collider 2D component to your Sprite Shape to enable the Collider properties in the Sprite Shape Controller. However, note that only the Edge and Polygon Collider 2D components can be used with Sprite Shapes. The Collider mesh automatically updates itself to the shape of the Sprite Shape when attached. See the Collider section of the Sprite Shape Controller page for more details about the various Sprite Shape Collider options. Manually editing the Collider mesh By default, the Collider mesh is automatically reshaped to match the Sprite Shape every time it is edited. To make manual edits to the Collider mesh directly, disable both Update Collider in the Sprite Shape Controller's Collider settings by clearing their respective checkboxes. This prevents the Sprite Shape Controller from updating the Collider mesh automatically and overriding your manual edits."
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/SSController.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/SSController.html",
    "title": "Sprite Shape Controller | mmo-rpg-unity",
    "keywords": "Sprite Shape Controller The Sprite Shape Controller component is automatically attached to the GameObject created when a Sprite Shape Profile is dragged into the Scene. You edit the shape of the Sprite Shape's outline through the Controller's settings. The Controller displays different settings depending on different conditions. Property Settings - Default The default component settings below are displayed when Edit Spline is not enabled. Property Function Profile Select the Sprite Shape Profile used by this Sprite Shape. Edit Spline Enable to make the Control Points of the Sprite Shape visible and editable. Spline - Detail Select the tessellation quality of the rendered Sprite Shape mesh. High/Medium/Low Quality options available. Open Ended Disable to connect both ends of the Sprite Shape together to form an enclosed Shape. Enable to leave both ends of the Sprite Shape unconnected. Adaptive UV Enabled by default. When enabled, Unity attempts to seamlessly tile the Sprites along the Sprite Shape path by deforming the Sprites to between Control Points. Disable this property to tile Sprites with no deformation and at their exact width. Sprites may appear cutoff if the space between Control Points is shorter than the width of the Sprite. Enable Tangents Enable this property if there are features which require tangent calculations, such as when utilizing the Shaders with the 2D Universal Render Pipeline. Corner Threshold Use this slider to set the threshold of when a point is considered a corner of the Sprite Shape, where the value is the angle between adjacent edges and angles at the. A point is considered a corner at the threshold value and lower. The default value is 30 degrees. Set a custom value to override this default value. Fill - Fill Tessellation (C# Job) Generate fill geometry in C# Job. Stretch UV Enable this setting to have Unity stretch the UV of the Fill texture across the Full Rect of the Sprite Shape. Custom Geometry Creator Set the Scriptable Object that generates custom geometry. By default a built-in generator is set when created. Custom Geometry Modifier Set a list of Scriptable Objects that modifies generated geometry. Pixels Per Unit (only available when Stretch UV is disabled) This values affect the appearance of the Fill texture of the Sprite Shape. This value affects the scale of the Fill texture, with higher values reducing the size of the texture. The default value is 100. World Space UV (only available when Stretch UV is disabled) Enable to apply the Fill texture according to the World Space UV, instead of per GameObject UV. With Edit Spline enabled and a Control Point selected Enable Edit Spline in the Controller settings to make Control Points on the Sprite Shape visible and editable. Selecting a Control Point enables the following additional Controller settings. A: Global snap toggle Point - Tangent Mode Select one of three Point Modes to change the way tangents on Control Points are edited. Linear No curve is formed between the Control Point and its neighboring points. Continuous Mirrored Two tangents appear on opposite sides of the Control Point, and the spline between the Control Point and its neighbors becomes curved. Adjust the tangents to change the shape of the curve. The angle between the two tangents is always 180 degrees in this mode. Broken Mirrored Two tangents appear on opposite sides of the Control Point, and the spline between the Control Point and its neighbors becomes curved. Adjust the tangents to change the shape of the curve. The length and angle of the tangents can be adjusted independently in this mood. Position The local x and y coordinates of a selected Control Point. Height Increase or decrease the height of Sprites at the Control Point by a factor of 0.1 to 4. Corner Sets whether Corner Sprites are rendered at Control Points. Set to Automatic by default. Disabled A Sprite is not rendered at the selected Control Point. Automatic The Control Point displays the assigned Corner Sprite, if both it and its neighbors are in Linear Point Mode. Stretched The Corner Sprite at the selected Control Point is connected to its adjacent neighbors, stretching the Sprite. See the list of required criteria below to use this feature. Sprite Variant Select the Sprite Variant from the visual Variant selector. Press N to cycle through all available Variants for the Control Point. Global snapping When Edit Spline is enabled, select the Global Snap icon (see A in screenshot above) to toggle Grid Snapping on or off. Stretched Corners This feature allows the Sprite Shape to form corners with stretched Sprites between adjacent edges between the corner point and its neighbors. Select the Stretched option from the Corner dropdown menu, and ensure the following criteria are met: Both the selected and adjacent points have the same Height. Sprites rendered at the Corner point and its neighboring points must have the same Sprite pivot position. Additional Collider settings Add either the Polygon Collider 2D or Edge Collider 2D component to the Sprite Shape to enable additional Collider settings in the Sprite Shape Controller. Refer to Enabling Collision for more details about enabling Colliders with Sprite Shapes. Colliders are always optimized by cleaning up extra control points that are colinear. Collider - Update Collider Enabled by Default. Enable this option to have the Collider mesh be updated to the Sprite Shape's current shape as the Sprite Shape is edited. Disable if you are editing the Collider mesh separately from the Sprite Shape and to use a custom Collider mesh. Offset Select the amount to extrude the Collider mesh towards the edge of the Sprite Shape. The range is from -0.5 to 0.5, starting at 0 by default. Detail Sets the tessellation quality of the rendered Collider. High/Medium/Low Quality options available. Editing the Spline To edit the mesh outline of the Sprite Shape, click the Edit Spline button to make the Shape's spline and its Control Points become visible and editable. When Edit Spline is enabled, move the Control Points of the Sprite Shape to adjust its overall shape and size. Add additional Control Points by clicking on the spline in between Control Points. Press the Del/Delete key to remove the currently selected Control Point. With a Control Point selected, cycle through the __Point Modes __by pressing the M key. To change the Mode of multiple Control Points at once, ensure that all selected Control Points are the same Mode first before cycling or selecting another Mode. To change the Sprite Variant currently displayed at a selected Control Point, press the N key to cycle through all available Variants. All shortcut keys can be rebound under the Shortcut menu (menu: Edit > Shortcuts... > SpriteShape Editing). Point Modes When a Control Point is selected, its Point Mode can be one of three modes- Linear, Mirrored, and Non-Mirrored. The Point Mode determines the behavior of the tangents that are used to adjust the spline between Control Points. Each Control Point can be set to a specific Point Mode and contain its own settings. Linear Point Mode In Linear Point Mode, there are no tangents to control the curve between the Control Point and its neighbors, curves are not formed between Control Points and Sprites may overlap if they intersect. Adjust which Sprite is displayed when two or more intersect by adjusting their Order value in the Sprite Shape Profile's Angle Range settings. Continuous Mirrored Point Mode In Continuous Mirrored Point Mode, tangents appear on both sides of the selected Control Point to create a curve between the Control Point and its neighbors. Adjust the shape of the curve with the tangents. In this mode, the angle between the tangents is always maintained at 180 degrees although their lengths from the can vary. Press B to mirror the length of the last edited tangent onto the opposite tangent. Broken Mirrored Point Mode In Broken Mirrored Point Mode, tangents appear on both sides of the selected Control Point to create a curve between the Control Point and its neighbors. Adjust the shape of the curve with the tangents. In this mode, the length and angle of each tangent can be adjusted independently. Press B to mirror the length of the last edited tangent onto the opposite tangent. In this mode, pressing B also causes the angle of the opposite tangent to become exactly 180 degrees from the last edited tangent."
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/SSPreferences.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/SSPreferences.html",
    "title": "Sprite Shape Preferences | mmo-rpg-unity",
    "keywords": "Sprite Shape Preferences You can select the colors used by a Sprite Shape's spline and control points through the Sprite Shape Preferences window (menu: Edit > Preferences > 2D > Sprite Shape). These colors are displayed when you enable Edit Spline in the Sprite Shape Controller properties and edit the Sprite Shape."
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/SSProfile.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/SSProfile.html",
    "title": "Sprite Shape Profile | mmo-rpg-unity",
    "keywords": "Sprite Shape Profile The Sprite Shape Profile contains the settings that determine which Sprites that appear on a Sprite Shape at specific Angle Ranges, as well as other display settings. You can use the same Profile for multiple Sprite Shapes in a Scene. Create a Sprite Shape Profile from the Editor main menu (menu: Assets > Create > Sprite Shape Profile), and select from the two available options: Open Shape and Closed Shape. Property Function Control Points - Use Sprite Borders Enable to draw the Sprite Borders of a Sprite at the Control Point. Define the Sprite Borders in the Sprite Editor. Fill - Texture Set the Texture to be used as a Fill to this field. Has no effect if the Open Ended property in the Sprite Shape Controller settings is enabled. Offset Determines the border offset at the edges of the Fill texture. Angle Ranges (tool) Use this tool to create Angle Ranges and assign Sprites to those ranges. Start (degrees) Enter the starting angle for the selected Angle Range in degrees. End (degrees) Enter the ending angle for the selected Angle Range in degrees. Order Determines the display priority when Sprites intersect. Sprites with higher values are rendered above lower ones. Sprites List of Sprites assigned to the selected Angle Range. Displays a list of all Sprites assigned to the selected Angle Range. The order of Sprites in the list determines their Sprite Variant number, starting from zero at the top of the list. The first Sprite at the top of the list is the Sprite displayed by default at a Control Point. Corners - (All Corner options) Assign specific Sprites to be displayed on the Sprite Shape at the respective corners. Open Shape Use the Open Shape preset Profile to create Shapes made from a single edge outline with tiled Sprites along its edge. This preset is ideal for creating level elements such as platforms. Drag the Open Shape Profile into the Scene view to automatically generate a Sprite Shape with Open Ended enabled in its Sprite Shape Controller settings. Closed Shape Use the Closed Shape preset Profile to create Shapes that encompass an enclosed area. The Closed Sprite Shape can display and tile a Fill texture in the enclosed area, if a Fill texture is set in its Profile settings. Use this preset to create large solid filled Shapes that are ideal for backgrounds or large platforms. Drag the Closed Shape Profile into the Scene view to automatically generate a Sprite Shape with Open Ended disabled in its Sprite Shape Controller settings. The Closed Shape Profile's preset Angle Ranges create a square Sprite Shape by default. A key feature of the Sprite Shape Profile is the Angle Ranges tool. Assigning an Angle Range determines what Sprite is displayed at specific angles, as the Sprite Shape is deformed in the Scene. Creating Angle Ranges Method 1: To create an Angle Range, click the Create Range button at the bottom of the Angle Ranges tool: The Create Range button is only visible if the Preview Handle is over an area without an Angle Range (see the example image below). Method 2: Another way is to hover your cursor over an empty area of the Angle Range circle. An outline appears to show the possible default angle range. Click to create this Angle Range. Editing the Angle Range degrees The range covered by the currently selected Angle Range is displayed at the bottom of the tool. You can edit a range by entering new values into Start and End, or drag either endpoint of the tool to the desired angles. A range cannot be extended into an existing neighboring range. To delete an Angle Range, select the range and then press the Del/Delete key. Assigning Sprites After creating the Angle Ranges, the next step is to assign Sprites to those ranges. The Sprites list is found beneath the Angle Ranges tool. It lists all the Sprites assigned to the selected range. To add Sprites to the list, click the + icon to insert a new row to the list. Click the circle icon next to the empty row to open the Object Picker window, which displays all available Sprites in the project. You can also drag a Sprite directly onto a row to add it to the list. The Sprite at the top of the list is the default Sprite displayed on the Sprite Shape. Refer to the other Sprites in the list by their Sprite Variant number. See the Sprite Shape Controller page for more details. Drag the leftmost ends of the rows up or down to reorder the list, which changes the Sprite Variant numbers of the Sprites accordingly. Previewing Sprites of multiple Angle Ranges After assigning Sprites to multiple Angle Ranges, rotate the Preview Handle around the Angle Range tool to preview the Sprites assigned those ranges."
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Overview Sprite Shape Profile Sprite Shape Controller Fill Tessellation in a C# Job Generating Custom Geometry Enabling Collision Preferences"
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Documentation~/index.html",
    "title": "2D Sprite Shape | mmo-rpg-unity",
    "keywords": "2D Sprite Shape Overview The Sprite Shape is a flexible and powerful world building Asset that features Sprite tiling along a shape's outline that automatically deforms and swaps Sprites based on the angle of the outline. Additionally, you can assign a Fill texture to a Sprite Shape to create filled shapes with tiled textures as backgrounds or other large level-building props. The following are examples of Sprite Shapes used to construct different parts of various levels. Sprite Shapes comprise of two parts - the Sprite Shape Profile Asset, and the Sprite Shape Controller component. The Sprite Shape Profile contains the angle settings and Sprites used by the Sprite Shape, and you edit the Sprite Shape's outline with the Sprite Shape Controller component. Importing Sprites for Sprite Shapes When importing Sprites, use the following property settings to ensure that the Sprites are compatible for use with Sprite Shape: Texture Type - Set this to ‘Sprite (2D and UI)’. Other Texture types are not supported for Sprite Shapes. Sprite Mode - Set this to ‘Single’ if the Texture contains only a single Sprite. Mesh Type - This must be set to Full Rect for the Sprite to be used with Sprite Shape. In addition, if the Sprites used for the Sprite Shape are part of a Sprite Atlas, disable both Allow Rotation and Tight Packing options under the Sprite Atlas’ properties so that the Sprites can be used by the Sprite Shape. Creating a Sprite Shape general workflow Create Sprite Shapes with the following steps: Create a Sprite Shape GameObject from the main GameObject menu (menu: GameObject > 2D Object > Sprite Shape) and select from the two available options: Open Shape Closed Shape Edit the outline of the Sprite Shape with the Sprite Shape Controller component settings. Enable Physics 2D interactions for your Sprite Shapes by attaching a Collider component. To further customize the shape and outline of a Sprite Shape: Create a Sprite Shape Profile from the main menu (menu: Assets > Create > 2D > Sprite Shape Profile). Create Angle Ranges and assign Sprites in the Sprite Shape Profile. Assign the Sprite Shape Profile to a Sprite Shape Controller's Profile settings. The same Profile can be used by multiple Sprite Shapes."
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.spriteshape copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/README.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/README.html",
    "title": "About 2D SpriteShape | mmo-rpg-unity",
    "keywords": "About 2D SpriteShape Use the 2D SpriteShape package as a powerful worldbuilding tool that allows you to tile Sprites along the path of a shape, with the Sprites automatically deforming in response to different angles according to their settings. For example, use 2D SpriteShapes to quickly build various 2D platforms by editing their spline paths into different shapes. Installing 2D SpriteShape To install this package, please follow the instructions in the Package Manager documentation. Links to Feature Documentation and Useful Resources 2D SpriteShape Online Documentation 2D SpriteShape Samples 2D SpriteShape Discussion Forums Requirements This version of 2D SpriteShape is compatible with the following versions of the Unity Editor: 2018.1 and later (recommended)"
  },
  "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.2d.spriteshape@9.0.4/Third Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This package contains third-party software components governed by the license(s) indicated below: Component Name: LibTessDotNet License Type: SGI FREE SOFTWARE LICENSE B (Version 2.0, Sept. 18, 2008) Copyright (C) 2011 Silicon Graphics, Inc. https://github.com/speps/LibTessDotNet All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice including the dates of first publication and either this permission notice or a reference to http://oss.sgi.com/projects/FreeB/ shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL SILICON GRAPHICS, INC. BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Except as contained in this notice, the name of Silicon Graphics, Inc. shall not be used in advertising or otherwise to promote the sale, use or other dealings in this Software without prior written authorization from Silicon Graphics, Inc."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog [3.1.2] - 2023-08-21 Fixed [GameObjectBrush] Use cell offset to determine location of GameObject when painting and erasing [3.1.1] - 2023-05-01 Fixed [GameObjectBrush] Set HideFlags of instantiated GameObject to HideFlags.None when painting [GridInformation] Fix serialization of GridInformationKey/Value [3.1.0] - 2023-01-16 Added [AnimatedTileEditor] -Add field to change TileAnimationFlags (For 2022.2.x) [RuleTile] -Add RotatedMirror rule which checks neighbors using both the mirror and rotation Rule in addition to the standard rotation Rule Fixed [GameObjectBrush] Fix placement of GameObjects for Hexagon Layouts with Anchor [GameObjectBrush] Align rotation and flip to 2D View in Editor [RandomBrush] Use default color and transform when painting over with RandomBrush Changed [AnimatedTileEditor] Moved to Unity.2d.Tilemap.Extras.Editor [3.0.3] - 2022-11-03 Fixed [GridInformation] Implement IEquatable for GridInformationKey [PrefabRandomBrush] Fix possible NullReferenceException in PrefabRandomBrush [GameObjectBrush] Fix placement of GameObjects when Cell Gap is set [3.0.2] - 2022-04-01 Fixed [RuleOverrideTile] -Mark RuleOverrideTile InstanceTile as dirty when overriding RuleTile for the RuleOverrideTile changes [RuleOverrideTile] -Fix undo for RuleOverrideTile when overriding RuleTile has changed [RuleTileEditor] -Fix height for ReorderableList when extending the view for marking Rules [3.0.1] - 2022-03-03 Fixed [AnimatedTileEditor] -Fix undo when setting number of Sprites for Animated Tile [RuleTile] -Fix data for custom container fields not being transferred in RuleOverrideTiles overriding a Custom Rule Tile [RuleTileEditor] -Fix undo when setting number of Rules for Rule Tile [RuleTileEditor] -Use different text color for Extend Neighbors with dark and light skin [3.0.0] - 2021-08-06 Update version to 3.0.0 for Unity 2022.1 Changed [GameObjectBrush] Add canChangePosition [GameObjectBrush] Use GridLayout from BrushTarget if it has one [HexagonalRuleTile] Fix GetOffsetPositionReverse [RuleOverrideTile] Create instance Tile on override [RuleTile] Add scripting documentation [RuleTileEditor] Add drag and drop rect for Sprites to create initial TilingRules [RuleTileEditor] Add field to change number of TilingRules [RuleTileEditor] Add blank space to the end of the Rule list [RuleTileEditor] Add undo for changes [AnimatedTileEditor] Add undo for changes [TintBrush] Convert cell positions to world positions based on the Grid used [TintBrush] Add k_ScaleFactor for better precision when painting on non-rectangular Tilemaps Fixed [RuleTile] Fixed error in RuleTileEditor when removing all Rules and adding a new Rule [2.2.0] - 2021-06-01 Changed [RuleTileEditor] Add tooltips to fields Add required package dependencies [2.1.0] - 2021-05-06 Changed [RuleTile] Improve performance of RuleTile caching [RuleTileEditor] Allow non-public fields with the SerializeField attribute as custom fields for RuleTile Make U2DExtrasPlaceholder internal Fixed [RuleTileEditor] Fix exception when adding a new Rule when no Rule is selected [2.0.0] - 2021-03-17 Update version to 2.0.0 [2.0.0-pre.3] - 2021-02-19 [HexagonalRuleTile] Fix issue with mirror rule [RuleTile] Add min and max animation speedup [RuleOverrideTile] Fix import issue when upgrading from a previous version of RuleOverrideTile [RuleTileEditor] Add new rule below selected rule in RuleTileEditor [RuleTileEditor] Add dropdown to duplicate Rule [2.0.0-pre.2] - 2020-11-26 Changed Update documentation Add contribution notice in README.md Update Third Party Notices.md [PrefabBush] Add pick [PrefabBush] Add tooltip for \"Erase Any Objects\" field [PrefabBrush][GameObjectBrush] Account for Anchor when using GetObjectsInCell in PrefabBrush and GameObjectBrush [CustomRuleTileScript] Allow Custom Rule Tile template script to be created regardless of where template script is installed (from a package or in the project) [2.0.0-pre.1] - 2020-10-14 Update version to 2.0.0-pre.1 [1.6.2-preview] - 2020-09-25 Changed [RuleTile/RuleOverrideTile/AdvancedRuleOverrideTile] Renamed Game Object to GameObject [RuleTile] Fix menu order for RuleOverrideTile [RuleOverrideTile] Fix menu order for RuleOverrideTile [AdvancedRuleOverrideTile] Fix Rule toggle for AdvancedRuleOverrideTile [GameObjectBrush] Use correct position when ClearSceneCell [GameObjectBrush] Update cells when size changes [GameObjectBrush] Clear cell for Prefabs [LineBrush] Clear previews from base.OnPaintSceneGUI [PrefabBrush] Fix box erase [1.6.1-preview] - 2020-08-11 Changed Update samples [1.6.0-preview] - 2020-05-27 Changed Updated for Unity 2020.1 [GameObjectBrush] Allow painting, erasing and picking on Tile Palette [GameObjectBrush] Add Paint on Scene view to GameObjectBrush [PrefabBush] Add BoxFill to PrefabBrush [PrefabBush] Add Rotation to PrefabBrush Consolidated menu items [1.5.0-preview] - 2020-02-14 Added Added CONTRIBUTING.md Updated LICENSE.md Added [PrefabRandomBrush] Split functionality of PrefabBrush to PrefabBrush and PrefabRandomBrush [PrefabBrush/PrefabRandomBrush] Add Erase Any Objects toggle to choose between erasing any Objects or Objects in the Brush Changed Consolidated menu items Fixed [WeightedRandomTile] Fixed WeightedRandomTile messing up Random.seed! [1.4.0] - 2020-01-07 Added [RuleTile / HexagonalRuleTile / IsometricRuleTile / RuleOverrideTile] Added Asset Preview for TilingRules [RuleTile] Hidden Rule field [CustomRuleTile] Support custom field of Object type [CustomRuleTile] Support HideInInspector, DontOverride attributes [RuleOverrideTile] Move advanced mode to AdvancedRuleOverrideTile [RuleOverrideTile] Add GameObject overrides [RuleOverrideTile] List height lessen [RuleOverrideTile] Don't override null sprite [RuleOverrideTile] Add static preview [AdvancedRuleOverrideTile] List GUI simplify [RuleOverrideTile / AdvancedRuleOverrideTile] Show unused overrides [RuleOverrideTile / AdvancedRuleOverrideTile] Support multiple inheritance [RuleOverrideTile / AdvancedRuleOverrideTile] Prevent circular reference [AnimatedTile] Added Animation Start Frame which helps to calculate the Animation Start Time for a given Tilemap Fixed [RuleTile] Fixed RuleTile InstantiatedGameObject rotation/scale [RuleTile] Fixed override tiles have not update when default properties changed [AdvancedRuleOverrideTile] Fix override rule lost reference when source rule reorder [PrefabBrush] Use WorldToCell comparison when getting GameObjects using PrefabBrush [1.3.1] - 2019-11-06 Changed [RuleTile] Simplified [RuleTile] Caching all RuleTile neighbor positions for Tilemap to speedup refresh affected tiles Fixed [RuleTile] Fix remote positions missing of MirrorXY (#148) [HexagonalRuleTile] Fix ApplyRandomTransform() of HexagonalRuleTile missing MirrorXY case [RuleOverrideTile] Fix RuleOverrideTile does not refresh when add/remove rule [RuleTile] Fix random rotation calculation mistake [RuleTile] Fix cache data will not update when rule change [1.3.0] - 2019-11-01 Changed [RuleTile] changed from using index to using position. [RuleTile] Additional storage rule position. [RuleTile] Delete DontCare rule. [RuleTile] Rule list increased Extend Neighbor toggle. When selected, it will increase the rule range that can be set. [RuleTile] No longer fixed to checking around 8 rules. [RuleTile] RefreshTile() will refresh affected remote Tiles. [RuleTile] Delete GetMatchingNeighboringTiles(), no longer get nearby Tiles in advance, the performance is affected. (may be changed to cache later) [IsometricRuleTile] Rewrite. [HexagonalRuleTile] Rewrite. [LineBrush] Fix for Tiles disappear after selection and drag with LineBrush [RuleTile] Add MirrorXY Transform Rule [1.2.0] - 2019-10-17 Changed [PrefabBrush] Erase GameObjects at target position before painting [RuleTileEditor] Made RuleTileEditor and children public [RuleTile] Roll back m_Self to this. [RuleOverrideTile] Remove m_OverrideSelf property. [RuleOverrideTile] Inherit custom properties from custom RuleTile. [RuleOverrideTile] Change m_RuntimeTile to m_InstanceTile. [1.1.0] - 2019-08-23 Changed Validate Gap and Limit for GroupBrush Fix z iterator for RandomBrush Check randomTileSets on addToRandomTiles Add Anchor to GameObjectBrush and PrefabBrush [1.1.0] - 2019-03-22 Changed Copy GameObject when copying TilingRule in RuleOverrideTile [1.1.0] - 2019-03-08 Added Added com.unity.2d.tilemap as a dependency of com.unity.2d.tilemap.extras Changed Custom Grid Brushes have been updated to the UnityEditor.Tilemaps namespace [1.0.0] - 2019-01-02 This is the first release of Tilemap Extras, as a Package"
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/CONTRIBUTING.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/CONTRIBUTING.html",
    "title": "Contributing | mmo-rpg-unity",
    "keywords": "Contributing All contributions are subject to the Unity Contribution Agreement(UCA) By making a pull request, you are confirming agreement to the terms and conditions of the UCA, including that your Contributions are your original creation and that you have complete right and authority to make your Contributions. Once you have a change ready following these ground rules. Simply make a pull request!"
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/AdvancedRuleOverrideTile.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/AdvancedRuleOverrideTile.html",
    "title": "Advanced Rule Override Tile | mmo-rpg-unity",
    "keywords": "Advanced Rule Override Tile Contributions by: johnsoncodehk, Autofire Advanced Rule Override Tiles are Tiles which can override a subset of Rules for a given Rule Tile while maintaining most of the other set Rules of the Rule Tile. This allows you to create Tiles that provide specialized behavior in specific scenarios. Properties Property Function Tile The Rule Tile to override. Depending on the Rule Tile that is overridden, there may be further properties which you can override here. Any public property in the Rule Tile that does not have a RuleTile.DontOverride attribute will be shown here and can be overridden. Usage First select the Rule Tile to be overridden in the Tile property. The Rule Override Tile editor then displays the different rules in the selected Rule Tile which you can override. Select the Rule which you want to override by toggling the Rule. This will allow you to modify the output of the Rule, such as the Sprite, the GameObject or the Collider Type. The outputs are the same as the original Rule Tile and are detailed there. The matching Rule itself cannot be changed here and is displayed here to help identify it. Paint with the Advanced Rule Override Tile using the Tile Palette tools."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/AnimatedTile.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/AnimatedTile.html",
    "title": "Animated Tile | mmo-rpg-unity",
    "keywords": "Animated Tile Contribution by: MahdiMahzuni An Animated Tile runs through and displays a list of Sprites in sequence to create a frame-by-frame animation. Animated Tile editor window Properties Property Function Number of Animated Sprites Number of Animated Sprites in the Animated Tile. Sprite list The list displaying the current order of Sprites for this Animated Tile’s animation which plays in sequence. Set a Sprite by selecting the Select button at the bottom right of the Sprite preview, then choosing the Sprite from the dialog box. Select and hold the = next to each Sprite to reorder their place in the animation sequence. Minimum Speed The minimum possible speed at which the Animation of the Tile is played. A speed value will be randomly chosen between the minimum and maximum speed. Maximum Speed The maximum possible speed at which the Animation of the Tile is played. A speed value will be randomly chosen between the minimum and maximum speed. Start Time The starting time of this Animated Tile. This allows you to start the Animation from a particular time. Start Frame The starting frame of this Animated Tile. This allows you to start the Animation from a particular Sprite in the list of Animated Sprites. Collider Type The Collider shape generated by the Tile. Flags The Flags which control the Tile Animation. Loop Once The Tile Animation will loop through once and stop at the last Sprite of the animation. Pause Animation The Tile Animation will pause and not run. Update Physics The Tile Animation will update the Physics Shape in the TilemapCollider2D whenever it switches to the next Sprite in the animation. Usage Create the Animated Tile by selecting and ordering the Sprites that makes up its animation sequence in the Animated Tile editor, then paint the Animated Tile with the Tile Palette tools. Game view, painted with the Group Brush."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/Brushes.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/Brushes.html",
    "title": "Scriptable Brushes | mmo-rpg-unity",
    "keywords": "Scriptable Brushes You can script Brushes to paint items based on the position and conditions of the cell it targets on the Grid Layout. Brush paint behavior can be further modified by the selected editing Tool, such as Erase or Floodfill. Here are some implementations of Scriptable Brushes which can help save time when designing your Tilemap: GameObject Brush Random Brush Line Brush Group Brush Refer to the Scriptable Brushes documentation for more information."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/Contributors.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/Contributors.html",
    "title": "Contributors | mmo-rpg-unity",
    "keywords": "Contributors Thank you to all who have contributed to this repository! johnsoncodehk nicovain superkerokero pmurph0305 janissimsons distantcam Pepperized MahdiMahzuni DreadBoy DoctorShinobi CraigGraff Autofire AVChemodanov ream88 Quickz capnslipp TrentSterling vladderb trobol HyagoOliveira RyotaMurohoshi ManickYoj n4n0lix If anybody has been missed, please do let us know!"
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/CustomRulesForRuleTile.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/CustomRulesForRuleTile.html",
    "title": "Custom Rules for Rule Tile | mmo-rpg-unity",
    "keywords": "Custom Rules for Rule Tile Contribution by: johnsoncodehk Use this template script to create new custom Rule Tiles with matching options that differ from the Rule Tile’s default options (namely This and Not This). This creates selectable options for each Rule in your custom Rule Tile. Template features Inheritable Rule Tile. Customizable properties. Expand or rewrite both neighbor Rules and the GUI display of the Rules. Usable with by RuleOverrideTile Create from a template script. Neighbor Rules tooltips. Backward compatible. Creating a custom Rule Tile script Create a Custom Rule Tile script by going to Assets > Create > Custom Rule Tile Script. Name the newly created file when prompted. After creating the file, you can edit it to add new matching options and custom algorithms for testing matches. Examples Custom properties: public class MyTile : RuleTile { public string tileId; public bool isWater; } Custom rules: public class MyTile : RuleTile<MyTile.Neighbor> { public class Neighbor { public const int MyRule1 = 0; public const int MyRule2 = 1; } public override bool RuleMatch(int neighbor, TileBase tile) { switch (neighbor) { case Neighbor.MyRule1: return false; case Neighbor.MyRule2: return true; } return true; } } Expansion rules public class MyTile : RuleTile<MyTile.Neighbor> { public class Neighbor : RuleTile.TilingRule.Neighbor { // 0, 1, 2 is using in RuleTile.TilingRule.Neighbor public const int MyRule1 = 3; public const int MyRule2 = 4; } public override bool RuleMatch(int neighbor, TileBase tile) { switch (neighbor) { case Neighbor.MyRule1: return false; case Neighbor.MyRule2: return true; } return base.RuleMatch(neighbor, tile); } } Siblings Tile 1 public class MyTile : RuleTile<MyTile.Neighbor> { public List<TileBase> sibings = new List<TileBase>(); public class Neighbor : RuleTile.TilingRule.Neighbor { public const int Sibing = 3; } public override bool RuleMatch(int neighbor, TileBase tile) { switch (neighbor) { case Neighbor.Sibing: return sibings.Contains(tile); } return base.RuleMatch(neighbor, tile); } } Siblings Tile 2 public class MyTile : RuleTile<MyTile.Neighbor> { public int siblingGroup; public class Neighbor : RuleTile.TilingRule.Neighbor { public const int Sibing = 3; } public override bool RuleMatch(int neighbor, TileBase tile) { MyTile myTile = tile as MyTile; switch (neighbor) { case Neighbor.Sibing: return myTile && myTile.siblingGroup == siblingGroup; } return base.RuleMatch(neighbor, tile); } }"
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/GameObjectBrush.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/GameObjectBrush.html",
    "title": "GameObject Brush | mmo-rpg-unity",
    "keywords": "GameObject Brush This Brush instances, places and manipulates GameObjects onto the Scene. Use this Brush as an example for creating custom Brushes which can target and manipulate other GameObjects beside Tiles. Usage First select the GameObject Brush from the Brush drop-down menu. With the Brush selected, then select the Picker Tool from the Tile Palette toolbar. Use the Select Tool to select GameObjects from the Scene that you want the GameObject Brush to paint with. Note that these GameObjects must be a child of the active Grid to be selectable with this Brush. When painting with the GameObject Brush, the Brush will instantiate GameObjects picked onto the Scene. Implementation The GameObjectBrush inherits from the GridBrush and overrides several methods when implemented. The following methods are overridden: It overrides the Paint method to paint a GameObject. It overrides the Erase method to erase the GameObjects from the Scene. It overrides the BoxFill method to paint a GameObject in each cell defined by the Box Tool. It overrides the Move methods to move GameObjects in the Scene. It overrides the Flip methods to flip GameObjects in the picked selection."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/GridInformation.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/GridInformation.html",
    "title": "Grid Information | mmo-rpg-unity",
    "keywords": "Grid Information This is a simple component that stores and provides information based on Grid positions and keywords. Usage Add this Component to a GameObject with a Grid component. To store information on to the Grid Information component, use the following APIs: public bool SetPositionProperty(Vector3Int position, String name, int positionProperty) public bool SetPositionProperty(Vector3Int position, String name, string positionProperty) public bool SetPositionProperty(Vector3Int position, String name, float positionProperty) public bool SetPositionProperty(Vector3Int position, String name, double positionProperty) public bool SetPositionProperty(Vector3Int position, String name, UnityEngine.Object positionProperty) public bool SetPositionProperty(Vector3Int position, String name, Color positionProperty) To retrieve information from the Grid Information component, use the following APIs: public T GetPositionProperty<T>(Vector3Int position, String name, T defaultValue) where T : UnityEngine.Object public int GetPositionProperty(Vector3Int position, String name, int defaultValue) public string GetPositionProperty(Vector3Int position, String name, string defaultValue) public float GetPositionProperty(Vector3Int position, String name, float defaultValue) public double GetPositionProperty(Vector3Int position, String name, double defaultValue) public Color GetPositionProperty(Vector3Int position, String name, Color defaultValue) You can use this in combination with Scriptable Tiles to get the right TileData when creating the layout of your Tilemap."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/GroupBrush.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/GroupBrush.html",
    "title": "Group Brush | mmo-rpg-unity",
    "keywords": "Group Brush This Brush picks Tiles which are grouped together according to their position and its set properties. Set the Gap value to identify which Tiles belong to the group, and set the Limit value to ensure that the picked group remains within the desired size. Use this Brush as an example to create your own Brushes that can choose and pick specific Tiles Properties Property Function Gap This value represents the minimum number of cells that must be in between picked Tiles. Only Tiles that are at least this many cells apart are picked by the Brush and placed in the group. Set this value to 0 to pick up all Tiles that are directly adjacent to each other in the group. Limit This value represents the maximum number of cells around the initial picked position. Only Tiles within this range of cells are picked by the Brush and placed in the group. Usage Select the Group Brush, and use the Picker Tool and pick a position on the Tilemap. The Group Brush selects a group of Tiles based on its set properties and creates a Group. Implementation The Group Brush inherits from the Grid Brush. It overrides the Pick method when picking a group of Tiles based on their position and its set properties."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/LineBrush.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/LineBrush.html",
    "title": "Line Brush | mmo-rpg-unity",
    "keywords": "Line Brush Contribution by : CraigGraff This Brush draws a line of Tiles onto a Tilemap. With this Brush selected, click once to set the starting point of the line and click again at another position to set the ending point of the line. This Brush then draws a line of Tiles between the two points. Use this as an example to create custom Brush behavior to make painting more efficient. Properties Property Function Line Start Active Indicates whether the Line Brush has started drawing a line. Fill Gaps Ensures that there are orthogonal connections between all Tiles that connect the start and end of the line. Line Start The current starting point of the line. Usage Select the Line Brush, then click once on a cell of the Tilemap to set the starting point of the line, then click on a second cell to set the ending point of the line. The Brush then draws the line of Tiles between the two set points. When the Line Brush is active, a blue outline will indicate the starting point of the line. To have Tiles which are orthogonally connected from start to end, enable the Fill Gaps property in the Brush Editor. Implementation The Line Brush inherits from the Grid Brush and overrides the Paint method to implement the line painting functionality."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/Other.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/Other.html",
    "title": "Other | mmo-rpg-unity",
    "keywords": "Other This section will contain other useful scripts which you can use and other details in the future."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/RandomBrush.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/RandomBrush.html",
    "title": "Random Brush | mmo-rpg-unity",
    "keywords": "Random Brush This Brush places random Tiles onto a Tilemap by selecting from defined Tile Sets while painting onto the the Tilemap. Use this as an example to create custom Brushes which store specific data per Brush, and to make Brushes with randomized painting behavior. Properties Property Function Pick Random Tiles Enable this property to pick the Tiles from the current selection as a random Tile Set. Add To Random Tiles Enable this property to add the picked Tile Sets to existing Tile Sets instead of replacing them. Tile Set Size Set the size of the Tile Set that is painted by this Brush. Number of Tiles The number of Tile Sets. Tile Set The Tile Set to randomize from Tiles The Tiles in the Tile Set. Usage To create a Tile Set, first define the size of the Tile Set you want to paint by setting its size values in the Tile Set Size property. Then you can add Tile Sets manually with the Brush Editor or select them from an existing Tile Palette. To select Tile Sets from an existing Tile Palette, enable the Pick Random Tiles property and select the Tile Sets using the Picker Tool. This will create a Tile Set, or multiple Sets if the picked size is larger than the size set in the Tile Set Size property. Enable the Add To Random Tiles property to add a picked selection of Tiles onto new or existing Tile Sets instead of replacing them. In this example, 3 Tile Sets of 1x2 are created. When painting with the Random Brush, the Random Brush will randomly pick from the available Tile Sets while painting the Tiles. Implementation The Random Brush inherits from the Grid Brush and implements the following overrides: It overrides the Paint method to paint random selections of Tiles from chosen Tile Sets. It overrides the Pick method to be able to pick selections of Tiles for the random Tile Sets."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/RuleOverrideTile.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/RuleOverrideTile.html",
    "title": "Rule Override Tile | mmo-rpg-unity",
    "keywords": "Rule Override Tile Contributions by: johnsoncodehk, Autofire Rule Override Tiles are Tiles which can override the Sprites and GameObjects for a given Rule Tile while maintaining the Rule set of the Rule Tile. This allows you to create Tiles that provide variations of a Rule Tile without setting new Rules. Properties Property Function Tile The Rule Tile to override. Depending on the Rule Tile that is overridden, there may be further properties which you can override here. Any public property in the Rule Tile that does not have a RuleTile.DontOverride attribute will be shown here and can be overridden. Usage First select the Rule Tile to be overridden in the Tile property. The Editor then displays the different Sprites and GameObjects in the selected Rule Tile which you can override. The editor displays the original Sprites that are used in the Rule Tile in the left column. Select the Sprites that override each of the respective original Sprites on the right ‘Override’ column. When the Rule Tile has a match that would usually output the original Sprite, it will instead output the override Sprite. Below that, the editor displays the original GameObjects that are used in the Rule Tile in the left column. Select the GameObjects that override each of the respective original GameObjects on the right ‘Override’ column. When the Rule Tile has a match that would usually output the original GameObject, it will instead output the override GameObject. If you have modified the original Rule Tile and changed the Sprites there, the Rule Override Tile will note that the original Sprites are missing. You can check the original Rule Tile to see if it is set up correctly or set the Override Sprites to None to remove the override. Paint with the Rule Override Tile using the Tile Palette tools."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/RuleTile.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/RuleTile.html",
    "title": "Rule Tile | mmo-rpg-unity",
    "keywords": "Rule Tile Contributions by: johnsoncodehk, DreadBoy, AVChemodanov, DoctorShinobi, n4n0lix This is a generic visual Tile that other Tiles such as the Terrain Tiles, Pipeline Tile, Random Tile or Animated Tiles are based on. There are specific types of Rule Tiles for each of the Tilemap grid types. The default Rule Tile is for the default Rectangle Grid type; the Hexagonal Rule Tile is for the Hexagonal Grid type; and the Isometric Rule Tile is for the Isometric Grid types. The different types of Rule Tiles all possess the same properties. Properties The Rule Tile editor of a Terrain Tile. Property Function Default Sprite The default Sprite set when creating a new Rule. Default GameObject The default GameObject set when creating a new Rule. Default Collider The default Collider Type set when creating a new Rule. Tiling Rules Tiling Rules properties Property Function Rule The Rule Type for this Rule. GameObject The GameObject for the Tile which fits this Rule. Collider The Collider Type for the Tile which fits this Rule Output The Output for the Tile which fits this Rule. Each Output type has its own properties. Output: Fixed Property Function Sprite Display this Sprite for Tiles which fit this Rule. Output: Random Property Function Noise The Perlin noise factor when placing the Tile. Shuffle The randomized transform given to the Tile when placing it. Size The number of Sprites to randomize from. Sprite The Sprite for the Tile which fits this Rule. A random Sprite will be chosen out of this when placing the Tile. Output: Animation Property Function MinSpeed The minimum speed at which the animation is played. MaxSpeed The maximum speed at which the animation is played. Size The number of Sprites in the animation. Sprite The Sprite for the Tile which fits this Rule. Sprites will be shown in sequence based on the order of the list. Editor Properties Property Function Extend Neighbor Enabling this allows you to increase the range of neighbors beyond the 3x3 box. Setting up a Rule Tile Set up the Rule Tile with the required rules with the Rule Tile editor. In the Rule Tile editor, you can change, add, duplicate or remove Rules in the Tiling Rules list. Click on the + or - buttons to add or remove Rules. If you have a Rule selected, clicking on the + button will allow you to choose between adding a new Rule or duplicating the selected Rule. The newly created Rule will be placed after the current selected Rule. Select and hold the top left corner of each row to drag them up or down to change the order of the Rules in the list. Rule Tile Editor When you add a new Rule, the Rule editor displays the following: the list of Rule properties, a 3x3 box that visualizes the behavior of the set Rules, and a Sprite selector that displays a preview of the selected Sprite. The 3x3 box represents the neighbors a Tile can have, where the center represents the Tile itself, and the eight bordering cells are its neighboring Tiles in their relative positions to the Tile. Each of the neighboring cells can be set with one of three options: Don't Care, This and Not This. These define the behavior of the Rule Tile towards these Tiles. Edit the 3x3 box to set up the Rule the Tile must match. Options Rule Tile behavior Don't Care The Rule Tile ignores the contents in this cell. This The Rule Tile checks if the contents of this cell is an instance of this Rule Tile. If it is an instance, the rule passes. If it is not an instance, the rule fails. Not This The Rule Tile checks if the contents of this cell is not an instance of this Rule Tile. If it is not an instance, the rule passes. If it is an instance, the rule fails. If all of the neighbors of the Rule Tile match the options set for their respective directions, then the Rule is considered matched and the rest of the Rule properties are applied. When the Rule is set to Fixed, the Rule will only match exactly the conditions set for its neighbors. The example below will only match if there are the same Rule Tiles to the left and right of it. When the Rule is set to ‘Rotated’, the 3x3 box will be rotated 90 degrees each time the Rule fails to match and it will try to match again with this rotated 3x3 box. If the Rule now matches, the contents of this Rule will be applied as well as the rotation required to match the Rule. Use this if you want the Rule to match for the four 90 degree rotations if rotation is possible. When the Rule is set to Mirror X, Mirror Y or Mirror XY, the 3x3 box will be mirrored in that axis each time the Rule fails to match and it will try to match again with this mirrored 3x3 box. If the Rule now matches, the contents of this Rule will be applied as well as the mirroring required to match the Rule. Use this if you want the Rule to match for the mirrored locations if mirroring is possible. If you want the Rule Tile to have a Random output, you can set the Output to Random. This will allow you to specify a number of input Sprites to randomize from. The rotation of the Sprites can be randomized as well by changing the Shuffle property. If you want the Rule Tile to output a Sprite Animation, you can set the Output to Animation. This will allow you to specify a number of Sprites to animate sequentially. The speed of the Animation can be randomized as well by changing the Speed property. When Extend Neighbors is enabled, the 3x3 box can be extended to allow for more specific neighbor matching. The Transform rule matching (eg. Rotated, Mirror) will apply for the extended neighbors set. Paint with the Rule Tile in the same way as other Tiles by using the Tile Palette tools. For optimization, please set the most common Rule at the top of the list of Rules and follow with next most common Rule and so on. When matching Rules during the placement of the Tile, the Rule Tile algorithm will check the first Rule first, before proceeding with the next Rules."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Overview Scriptable Brushes GameObject Brush Group Brush Line Brush Random Brush Scriptable Tiles Animated Tile Rule Tile Rule Override Tile Other Grid Information Custom Rules for Rule Tile Contributors"
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/Tiles.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/Tiles.html",
    "title": "Scriptable Tiles | mmo-rpg-unity",
    "keywords": "Scriptable Tiles You can script Tiles to adapt to different criteria and conditions, such as its position on the Tilemap. It then displays the Sprite which meets its scripted requirements. This allows you to create different Tiles that can help you save time and be more efficient when creating Tilemaps. Refer to the Scriptable Tiles page for more information. The following Scriptable Tiles are included in this package, with examples of how they are implemented. You can use these Tiles as the base for your own custom Tiles as well. Animated Tile Rule Tile Rule Override Tile"
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Documentation~/index.html",
    "title": "2D Tilemap Extras | mmo-rpg-unity",
    "keywords": "2D Tilemap Extras The 2D Tilemap Extras package contains reusable 2D and Tilemap editor scripts which you can use for your own Projects, and as the basis for your own custom Brushes and Tiles. You can freely customize the behavior of the scripts to create new Brushes that suit different uses or scenarios. To find these additional Brushes, open the Tile Palette window (menu: Window > 2D > Tile Palette) and open the Brush drop-down menu near the bottom of the editor. Select from the available Brush options for different effects. The source code for these scripts can be found in the repository 2d-extras, and examples of the implemented scripts can be found in the sister repository 2d-techdemos. Scriptable Brushes GameObject: This Brush instances, places and manipulates GameObjects onto the Scene. Use this as an example to create Brushes which targets GameObjects, other than Tiles, for instancing and manipulation. Group: This Brush picks groups of Tiles based on their positions relative to each other. Adjust the size of groups the Brush picks by setting the Gap and Limit properties. Use this Brush as an example to create Brushes that pick Tiles based on specific criteria. Line: This Brush draws a line of Tiles between two points onto a Tilemap. Use this as an example to modify Brush painting behavior to make painting more efficient. Random: This Brush places random Tiles onto a Tilemap. Use this as an example to create Brushes which store specific data per Brush and to make Brushes which randomize behavior. Scriptable Tiles The following are the Scriptable Tiles included in this package. You can create (menu: Create > Tiles ) the following additional Tile types that are included with this package. Animated: This Tile runs through and displays a list of Sprites in sequence to create a frame-by-frame animation. Rule Tile: This is a generic visual Tile that accepts rules you create with the Tiling Rules editor to create different Tilesets. Rule Tiles are the basis of the Terrain, Pipeline, Random or Animated Tiles. There are different types of Rule Tiles for each of the Tilemap grid types. The default Rule Tile is only used with the Rectangle Grid type Tilemap, while the Hexagonal and Isometric Rule Tiles are used with their respective Grid types. Hexagonal Rule Tile: A Rule Tile for Hexagonal Grids. Enable the Flat Top property for a Flat Top Hexagonal Grid, or clear it for a Pointed Top Hexagonal Grid. Isometric Rule Tile: A Rule Tile for use with Isometric Grids. Rule Override Tile: This Tile can override Sprites and GameObjects for a given Rule Tile to provide different behaviour without changing the original Rules. Advanced Rule Override Tile: This Tile can override a subset of Rules for a given Rule Tile to provide specialized behavior, while keeping the rest of the original Rules intact. Other GridInformation: A simple MonoBehavior that stores and provides information based on Grid positions and keywords. Custom Rules for RuleTile: This helps to create new custom Rules for the Rule Tile with more options."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "2D Tilemap Extras copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/README.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/README.html",
    "title": "2d-extras | mmo-rpg-unity",
    "keywords": "2d-extras 2d-extras is a repository containing helpful reusable scripts which you can use to make your games, with a slant towards 2D. Feel free to customise the behavior of the scripts to create new tools for your use case! Implemented examples using these scripts can be found in the sister repository 2d-techdemos. All items in the repository are grouped by use for a feature and are listed below. How to use this You can use this in two different ways: downloading this repository or adding it to your project's Package Manager manifest. Alternatively, you can pick and choose the scripts that you want by placing only these scripts in your project's Assets folder. Download Setup Download or clone this repository into your project in the folder Packages/com.unity.2d.tilemap.extras. Package Manager Manifest Requirements Git must be installed and added to your path. Setup The following line needs to be added to your Packages/manifest.json file in your Unity Project under the dependencies section: \"com.unity.2d.tilemap.extras\": \"https://github.com/Unity-Technologies/2d-extras.git#master\" Tilemap For use with Unity 2021.1.0f1 onwards. Please use the 2020.3 branch for Unity 2020.1-2020.3 versions. Please use the 1.5.0-preview tag for Unity 2019.2-2019.4 versions. Please use the 2019.1 tag for Unity 2019.1 versions. Please use the 2018.3 branch or the 2018.3 tag for Unity 2018.3-2018.4 versions. Please use the 2018.2 branch or the 2018.2 tag for Unity 2018.2 versions. Please use the 2017 branch or the 2017 tag for earlier versions of Unity (from 2017.2 and up). Brushes Coordinate: This Brush displays the cell coordinates it is targeting in the SceneView. Use this as an example to create brushes which have extra visualization features when painting onto a Tilemap. Line: This Brush helps draw lines of Tiles onto a Tilemap. The first click of the mouse sets the starting point of the line and the second click sets the ending point of the line and draws the lines of Tiles. Use this as an example to modify brush painting behaviour to making painting quicker with less actions. Random: This Brush helps to place random Tiles onto a Tilemap. Use this as an example to create brushes which store specific data per brush and to make brushes which randomize behaviour. Prefab: This Brush instances and places the containing Prefab onto the targeted location and parents the instanced object to the paint target. Use this as an example to quickly place an assorted type of GameObjects onto structured locations. PrefabRandom: This Brush instances and places a randomly selected Prefabs onto the targeted location and parents the instanced object to the paint target. Use this as an example to quickly place an assorted type of GameObjects onto structured locations. GameObject: This Brush instances, places and manipulates GameObjects onto the scene. Use this as an example to create brushes which targets objects other than tiles for manipulation. TintBrush: Brush to edit Tilemap per-cell tint colors. TintBrushSmooth: Advanced tint brush for interpolated tint color per-cell. Requires the use of custom shader (see TintedTilemap.shader) and helper component TileTextureGenerator. Group: This Brush helps to pick Tiles which are grouped together by position. Gaps can be set to identify if Tiles belong to a Group. Limits can be set to ensure that an over-sized Group will not be picked. Use this as an example to create brushes that have the ability to choose and pick whichever Tiles it is interested in. Tiles Animated: Animated Tiles are tiles which run through and display a list of sprites in sequence. Pipeline: Pipeline Tiles are tiles which take into consideration its orthogonal neighboring tiles and displays a sprite depending on whether the neighboring tile is the same tile. Random: Random Tiles are tiles which pseudo-randomly pick a sprite from a given list of sprites and a target location, and displays that sprite. Terrain: Terrain Tiles, similar to Pipeline Tiles, are tiles which take into consideration its orthogonal and diagonal neighboring tiles and displays a sprite depending on whether the neighboring tile is the same tile. RuleTile: Generic visual tile for creating different tilesets like terrain, pipeline, random or animated tiles. Hexagonal Rule Tile: A Rule Tile for use with Hexagonal Grids. Enable Flat Top for Flat Top Hexagonal Grids and disable for Pointed Top Hexagonal Grids. Isometric Rule Tile: A Rule Tile for use with Isometric Grids. RuleOverrideTile: Rule Override Tiles are Tiles which can override a subset of Rules for a given Rule Tile to provide specialised behaviour while keeping most of the Rules originally set in the Rule Tile. Weighted Random: Weighted Random Tiles are tiles which randomly pick a sprite from a given list of sprites and a target location, and displays that sprite. The sprites can be weighted with a value to change its probability of appearing. Other GridInformation: A simple MonoBehaviour that stores and provides information based on Grid positions and keywords. Custom Rules for RuleTile: This helps to create new custom Rules for the Rule Tile. Check the Wiki or this great video for more information on how to use this! Contribution Notice From 7 January 2019 until 12 February 2020, all contributions are licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license)."
  },
  "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap.extras@3.1.2/Third Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This package contains third-party software components governed by the license(s) indicated below: Component Name: Line Brush public static IEnumerable GetPointsOnLine(Vector2Int p1, Vector2Int p2) License Type: MIT Copyright (c) 2020 Eric Woroshow http://ericw.ca/notes/bresenhams-line-algorithm-in-csharp.html Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ericw.ca / Content © 2009-2020 Eric Woroshow. All rights reserved. Code under MIT license unless otherwise noted. Component Name: Line Brush License Type: MIT Copyright © 2017 CraigGraff (https://github.com/CraigGraff) https://github.com/Unity-Technologies/2d-extras/pull/6 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Animation Tile License Type: MIT Copyright © 2017 MahdiMahzouni (https://github.com/MahdiMahzouni) https://github.com/Unity-Technologies/2d-extras/pull/12 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Coordinate Brush License Type: MIT Copyright © 2018 nicovain (https://github.com/nicovain) https://github.com/Unity-Technologies/2d-extras/pull/20 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Weighted Random Tile License Type: MIT Copyright © 2018 nicovain (https://github.com/nicovain) https://github.com/Unity-Technologies/2d-extras/pull/20 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Rule Tile Editor License Type: MIT Copyright © 2018 DreadBoy (https://github.com/DreadBoy) https://github.com/Unity-Technologies/2d-extras/pull/22 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Weighted Random Tile License Type: MIT Copyright © 2018 distantcam (https://github.com/distantcam) https://github.com/Unity-Technologies/2d-extras/pull/26 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Rule Override Tile License Type: MIT Copyright © 2018 johnsoncodehk (https://github.com/johnsoncodehk) https://github.com/Unity-Technologies/2d-extras/pull/29 and https://github.com/Unity-Technologies/2d-extras/pull/36 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Rule Override Tile Editor License Type: MIT Copyright © 2018 johnsoncodehk (https://github.com/johnsoncodehk) https://github.com/Unity-Technologies/2d-extras/pull/29 and https://github.com/Unity-Technologies/2d-extras/pull/36 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Rule Tile License Type: MIT Copyright © 2018 johnsoncodehk (https://github.com/johnsoncodehk) https://github.com/Unity-Technologies/2d-extras/pull/36 and https://github.com/Unity-Technologies/2d-extras/pull/38 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Rule Tile Editor License Type: MIT Copyright © 2018 johnsoncodehk (https://github.com/johnsoncodehk) https://github.com/Unity-Technologies/2d-extras/pull/36 and https://github.com/Unity-Technologies/2d-extras/pull/38 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Custom Rule Tile License Type: MIT Copyright © 2018 johnsoncodehk (https://github.com/johnsoncodehk) https://github.com/Unity-Technologies/2d-extras/pull/38 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Create Asset Menus License Type: MIT Copyright © 2018 janissimsons (https://github.com/janissimsons) https://github.com/Unity-Technologies/2d-extras/pull/49 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Rule Tile License Type: MIT Copyright © 2018 DoctorShinobi (https://github.com/DoctorShinobi) https://github.com/Unity-Technologies/2d-extras/pull/51 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Rule Tile Editor License Type: MIT Copyright © 2018 DoctorShinobi (https://github.com/DoctorShinobi) https://github.com/Unity-Technologies/2d-extras/pull/51 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE."
  },
  "Library/PackageCache/com.unity.2d.tilemap@1.0.0/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap@1.0.0/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog [1.0.0] - 2019-09-18 Added Allow child GameObjects in the Palette Asset to be shown in the Tile Palette Add toggle to allow rendering of Gizmos in the Tile Palette Add OnSceneGUI API to GridBrushEditorBase for GUI calls for the active Brush (OnPaintSceneGUI is called only when the appropriate EditorTool is active) Add GridPaletteUtility to create Palette Assets through scripting [1.0.0] - 2019-06-06 Added Rename package to 2D Tilemap Editor Switch to a Paintable tool after picking from a Picking Is Default Paintable Grid if the previous tool was a tool that did not allow painting Store last used brush per session to persist when going into and out of PlayMode [1.0.0] - 2019-03-22 Added Allow users to convert Prefabs to Tile Palettes by dragging and dropping a valid Prefab onto the Tile Palette Window Add toggle to allow changing of Z Position with GridBrush Expose GridPaintingState.scenePaintTarget to allow users to change currently active target for Tile Palette Window Expose GridPaintingState.validTargets to allow users to get currently valid targets for Tile Palette Window Expose GridPaintingState.gridBrush to allow users to change currently active GridBrush for Tile Palette Window Expose GridPaintingState.palette to allow users to change currently active Palette for Tile Palette Window Expose TileUtility to allow users to create default Tiles through scripts Add CreateTileFromPaletteAttribute to allow users to specify how Tiles are created when dragging and dropping assets to the Tile Palette Window Changed Convert TilePalette to use EditorTools API [1.0.0] - 2019-01-02 This is the first release of Tilemap Editor, as a Package"
  },
  "Library/PackageCache/com.unity.2d.tilemap@1.0.0/Documentation~/TilemapEditor.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap@1.0.0/Documentation~/TilemapEditor.html",
    "title": "About Tilemap Editor | mmo-rpg-unity",
    "keywords": "About Tilemap Editor Use Unity’s Tilemap Editor to create and edit a variety of 2D levels using Tile Assets arranged on the Grid and Tilemap GameObjects. This also supports specialized types of Tilemaps, such as Hexagonal and Isometric Tilemaps. Installing Tilemap Editor To install this package, follow the instructions in the Package Manager documentation. Using Tilemap Editor The Tilemap Manual can be found [here] (http://docs.unity3d.com/Documentation/Manual/class-Tilemap.html). The Tile Palette Manual can be found [here] (https://docs.unity3d.com/Manual/Tilemap-Palette.html). Technical details Requirements This version of Tilemap Editor is compatible with the following versions of the Unity Editor: 2019.2 and later (recommended) Package contents The following table indicates the folder structure of the Tilemap Editor package: Location Description <Editor> Root folder containing the source for the Tilemap Editor used to edit Tilemaps inside the Unity Editor. <Tests> Root folder containing the source for the tests for Tilemap Editor used the Unity Editor Test Runner. Document revision history Date Reason January 2, 2019 Document created. Matches package version 1.0.0"
  },
  "Library/PackageCache/com.unity.2d.tilemap@1.0.0/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap@1.0.0/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.2d.tilemap copyright © 2019 Unity Technologies ApS Licensed under the Unity Package Distribution License (see https://unity3d.com/legal/licenses/Unity_Package_Distribution_License ). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.2d.tilemap@1.0.0/README.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap@1.0.0/README.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Tilemap Editor."
  },
  "Library/PackageCache/com.unity.2d.tilemap@1.0.0/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.2d.tilemap@1.0.0/Third Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Component Name: Bresenham's Line Algorithm in C# License Type: MIT Copyright © 2009-2020 Eric Woroshow http://ericw.ca/notes/bresenhams-line-algorithm-in-csharp.html Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [1.8.17] - 2024-07-01 Added Removed Changed Improved performance of Burst-compiled code in the Windows x64 Editor by only emitting context-saving code when the code being compiled contains a throw Improved error message for pointer-like types in non-readonly static fields Fixed Fixed another compiler crash caused by faulty alias analysis BurstAotSettings files are no longer written to disk unless default settings are changed Fixed the BurstDebugInformation_DoNotShip folder not being saved outside the player build folder for Embedded Linux and QNX platforms Fixed direct negation of enums was not correctly promoting the underlying type, causing wrong results. Fixed that Mathf.Approximately would return the wrong result approximately all of the time Fixed an issue with default interface methods which would result in compiler errors due to IL corruption. Creating a project with a space in the path would cause burst to fail on windows arm64. Known Issues [1.8.16] - 2024-05-29 Fixed Fixed compiler crash caused by faulty alias analysis [1.8.15] - 2024-05-10 Added Removed Changed Fixed An issue with auto promotion from bool to float that can occur with newer Roslyn. Fixed compilation error when trying to use MemoryMarshal.GetReference on Spans Fixed crash caused by faulty no-alias analysis Fix build error when Product Name contains illegal path characters. Improved the compilation time for projects with many assemblies/assembly-define symbols Known Issues [1.8.14] - 2024-04-04 Fixed Fixed burst sometimes throwing FileNotFoundException Fixed incorrect handling of [Conditional] attributes in some circumstances Fixed that some or all scripting symbol defines wouldn't be known by Burst in player builds Added Removed Changed [1.8.13] - 2024-02-29 Added Added clearer diagnostic error for certain bad usages of IsSupportedXXX intrinsics. Added support for Burst with the visionOS Simulator SDK. Added support for Windows Arm64. Fixed Fixed InvalidCompilerException when usage of IsSupportedXXX intrinsic results in no branches being generated. Fixed information in documentation regarding scheduling generic jobs through generic methods. Fixed a crash caused by arithmetic or bitwise negation on native integers followed by a cast to a pointer. Fixed that the burst debug information folder would sometimes be saved in project root folder. Fixed System.ArgumentNullException exception in ILPostProcessing when encountering a library using mscorlib Fixed an issue where if two modules were referencing the same external method (dllImport) an internal compiler error could occur - \"Burst internal compiler error: Burst.Compiler.IL.CompilerException: Error while verifying module: DISubprogram attached to more than one function\" Fixed \"Failed to find entry-points: ... An item with the same key has already been added\" error that could occur in the presence of precompiled (usually obfuscated) assemblies that contained methods overloaded only by return type Removed Changed Known Issues [1.8.12] - 2024-01-02 Fixed Fixed the managed fallback for bursts intrinsic functions cvt_ss2si, cvtss_si32, and cvtss_si64 to follow midpoint rounding standard of nearest even. Fixed an issue where use of certain intrinsics could cause a compile error even if properly guarded by the appropriate IsXXXSupported property. If an exception is thrown from burst compiled code in the Editor on Windows there was potential for certain callee saved registers to be corrupted. In order to fix this ( editor only - player builds are unaffected), we now save some additional context on each entry point. Fixed burst not differentiating between overloaded generic functions such as T foo(int val) and T foo(T val) when the function calls are foo(1); foo (1). Burst would previously only compile the T foo(T val) function. Fixed android builds throwing a NullReferenceException. Fixed arithmetic and bitwise negation on native integers. Fixed an issue where underflows of nint and nuint at compile time would lead to incorrect code. Burst recompiles assemblies due to hashes mismatching because of the way assembly defines are combined into the hash. Fixed constant SHUFFLE function not seen as a constant when called indirectly through a FunctionPointer Added Removed Changed Update default LLVM to version 16 Known Issues [1.8.11] - 2023-11-16 Added Burst support for Apple visionOS [1.8.10] - 2023-11-02 Fixed Fixed the Burst Inspector not displaying target methods if namespace/class contained the method name. Linking libstdc++/libc++ statically on HMI platforms Fixed an issue that caused an empty variable to be returned if it is between a zero initializer Native debug information would fail to reflect the contents of parameters to functions. For native debug information, type symbols can now be referenced using :: separator between namespaces (C++ style) - E.g. Example.Type becomes Example::Type. Fixed that changing certain player build platform settings (like SDK version) would not trigger Burst to recompile Fixed invalid burst string formats leading to internal compiler error. Fixed QNX player builds on 32-bit ARM Fixed an error thrown by the Burst Inspector when opening a non-static job with special characters in its name Fixed an issue that caused alignments for global values to be wrong, which could lead to a rare AVX2 specific crash. Added Added support for System.Math functions Acosh, Asinh, Atanh, Cbrt, CopySign, Log2, SinCos, FusedMultiplyAdd, and ILogB Removed Remove all code specific to DOTS Runtime Changed Use mimalloc as our native allocator on Windows to speed up concurrently executing LLVM work Known Issues [1.8.9] - 2023-09-22 Changed Minor behind-the-scenes changes that should not affect users. [1.8.8] - 2023-07-24 Fixed Fixed error when trying to use direct call to a nested protected class Fixed that converting a negated unsigned type to a float would produce a mismatching value in Burst versus .Net/Mono Fixed that the Burst Inspector handled negation of unsigned types differently than .Net for static readonly fields or static constructors Fixed Burst sometimes returning wrong value for static readonly fields or static constructors. Fixed a possible source of invalid alignment, avx2 storing to stack was given a slot with the wrong alignment. Fixed System.NotImplementedException: Unimplemented Instruction Extension Tail_ error when the code contained tail-calls Fixed wrong alignment for v128 when doing an indirect access. Fix compiler crash when compiling different assemblies that define methods or types with the exact same name and namespace Fixed using Armv9 target in the Burst Inspector not formatting the assembly. Fixed that jobs wouldn't be Burst compiled for player builds with high stripping Fixed burst not being able to find external function leading to crashing the Editor Prevented Burst emitting errors even when Burst was disabled via the --burst-disable-compilation command line option Under some conditions (if the error in compilation occurred in a location that didn't have valid debug information), building a player might not generate any files, and not display any errors. Fixed uint to float conversion edge-case Fixed syntax highlight missing for some ARM instructions. Added Added support for default interface methods Added ability to support hashing against different target frameworks. Added support for string interpolation in exception messages Removed Changed Fixed a compile-time performance regression in 1.8.7 that could result in slower Burst compilation and increased memory usage during compilation Direct call is now correctly disabled for methods that are decorated with both [BurstCompile] and [UnmanagedCallersOnly] attributes (such methods shouldn't be called directly from managed code) Add support for Math.Clamp (this API is available when Api Compatibility Level is set to .NET Standard 2.1) Known Issues [1.8.7] - 2023-06-07 Added Add proper license attribution for MUSL and SLEEF libraries. Removed Changed Changed focus for initial Burst Inspector focus to actually get the search hit in focus. Fixed Fix QNX builds using the qnxInstallationPath editor build setting Fixed an issue causing source file handles to be left open (preventing saving in an ide, if in debug scripting mode and the file is used in the burst path). Fixed an issue when targeting multiple cpu architectures (e.g. SSE2 & AVX2) that under some circumstances would lead to code attempting to execute paths not designed for that cpu. Fixed an issue that caused builds to fail due to the System.Diagnostics.Tracing assembly not being found Fixed a warning that occurred when opening Burst AOT Settings while in Play Mode Fixed a hashing error that could occur when an operator overload method is used as a Burst entry point Fixed crash on linux if debug logging was enabled. Fixed \"The specified path is not of a legal form (empty)\" error Calls to methods with multiple [Conditional] attributes are now kept if any one of the conditions are met Fixed Burst implementation of IntPtr.GetHashCode() being different than .Net Fixed an issue that caused the digits and MidpointRounding parameters of Math.Round be ignored Known Issues [1.8.4] - 2023-03-20 Fixed Fixed possible deadlock when compiling after domain reload Fixed incorrect codegen when having multiple try-finally blocks inside another try-finally block (for example from foreach loops) Domain completed stall when switching between debug/release scripting modes when burst compilation is needed for items in the new domain. Fixed \"An item with the same key has already been added\" compiler error that could occur when duplicate field names were present in obfuscated assemblies Fixed \"Failed to find entry-points: Mono.Cecil.AssemblyResolutionException: Failed to resolve assembly\" error that was displayed when Burst tried to compile an assembly that had C# compilation errors Fixed code-gen issue where side-effects before a conditional throw would be ignored Burst managed breakpoints might fail to work, after a domain reload. Fixed that some changes made to versioned assemblies wouldn't get picked up and compiled by Burst Fixed line highlight and register highlight not clearing when Burst Inspector settings change. Fixed Burst compilation error relating to UnityEngine.Assertions.Assert.Fail when doing player builds with high stripping settings Fixed a BadImageFormatException error that could occur in some player builds Neon intrinsics: fixed default target CPU for Arm Mac Standalone builds Fixed MethodDecoderException when trying to call CompileFunctionPointer on a nested static method Fixed incorrect pdb path for AoT dll libraries Fixed inaccurate stacktraces when throwing an exception from Burst in specific cases Fixed \"An item with the same key has already been added\" hashing error that could occur if obfuscators changed nested type names to have the same name and different namespaces Added Add support for ChromeOS in Unity versions 2020.3 and 2019.4. Windows/ARM64 targeting support Removed Changed Changed Burst Inspector input handling so that arrow-keys can be used to select in search boxes. Made Burst Inspector's target job load asynchronous. Known Issues [1.8.3] - 2023-01-30 Added Added selection of line and highlight of selected line and selected lines register usage. FunctionPointer ()::Invoke usage is now checked and patched to ensure the calling convention is compatible with burst. Added SIMD smell test to the Burst Inspector, highlighting ARM or x86-64 SIMD instruction differently depending on whether they work for packed or scalar inputs. Added a toggle for filtering out \".Generated\" jobs from the Burst Inspector target job list. Added a Burst AOT setting for the kind of debug information generated for player builds Fixed Fixed AoT linking error on Windows Link based linkers when file paths (typically user names/home folders) contain non-ASCII characters. Fixed ARM vector registers not being highlighted. Fixed Burst Inspector sometimes throwing ArugmentOutOfRangeException when copying without color-tags from assembly that is colored. Fixes error when calling direct call method from background thread without having previously called a BurstCompiler API from the main thread Fixes \"Plain Without Debug Information\" outputting assembly with debug information. Fixed a hashing error that could occur when a struct implements a generic interface multiple times with different generic parameters An issue that could cause function pointers to point to the wrong burst function, if a domain reload occurs and a compilation started before the reload, completes soon after. Fixed bug in a small set of managed fallback versions of intrinsics, where the bitwise representation of float values would not be maintained Fixed player build error that could occur if the project contains an assembly whose name doesn't match the assembly filename Crashes on 32bit cpus when an entry point with byvalue paramaters was called, when using dispatch (multiple supported cpu targets). Fixed module verification errors when using overloaded functions as function pointers Fixed an issue the definition order of overloaded methods with function pointer parameters would decide which overload was actually being used Fixed compiler AccessViolationException that could occur when compiling two or more types with the same name but different source assemblies Burst now updates its list of assembly paths if they change, for instance - adding packages that contain precompiled assemblies. Fixed a stall that could occur at Editor shutdown Fixed BC1361 error when trying to compile large static readonly arrays. Fixed compilation error when using CompileFunctionPointer from Burst in code compiled with Roslyn on .NET 7+ Fixed a BadImageFormatException error that could occur in DOTS Runtime builds Fixed the inspector job tree view splitting jobs, with '.' in their parameters. Fixed internal compiler error when implcitly converting an array to a Span Fixed managed fallback implementation of Sse4_2.cmpestrs \"LLVM IR Optimisation Diagnostics\" tab in Burst Inspector was blank if \"Native Debug Mode Compilation\" was enabled; this is now fixed Fixed burst tree view items leading to wrong job if some jobs where hidden from view by filter or similar. Fixed \"Callee/caller attribute ABI did not match!\" error that could occur in certain player builds when calling an entry point that had at least one struct-by-value parameter Fixed namespace collision that could occur between Unity.Burst.Cecil.dll and the com.unity.nuget.mono-cecil package Enum values cast to integers in a format string previously output the enum type name; now the integer value is correctly output Fix Burst compilation on QNX Arm Fixed visual artifact in Burst Inspector, where block of enhanced code was cut at the bottom. Fixed compiler crash when invoking FunctionPointers based on a generic delegate in DOTS Runtime Fixed internal compiler error that occurred when creating debug metadata from certain obfuscated dlls Fixed \"Assertion failed on expression: \"exception == SCRIPTING_NULL\" errors and editor crash when the project path contained multi-byte Unicode characters Changed Changed burst inspector source location comments from \"===\" to either \";\" or \"#\" depending on the given assembly kind. Changed horizontal code focus in the Burst Inspector to only scroll when branches fill more than half the space Changes so target job list in the Burst Inspector is a fold-able/expandable tree view, instead of a simple list. Improved how optimisation remarks are displayed in the \"LLVM IR Optimisation Diagnostics\" tab in Burst Inspector to make them more useful Burst now only generates full debug information when \"Native Debug Mode Compilation\" and script debug information is enabled Removed Known Issues [1.8.2] - 2022-11-18 Added Changed Fixed Fixed an issue where sometimes the wrong body of an overloaded entrypoint would be used Failing to link if ; in path Fixed Burst being disabled in the Editor after changing script optimization mode (i.e. from Release to Debug or vica-versa) C# Debug information was incorrectly ignored for methods that had multiple source files. This caused native debug information to be dropped for code generated methods, and prevented the disabling of burst for such methods when a managed break point was set in Unity 2022.2 or greater (see https://docs.unity3d.com/Packages/com.unity.burst@1.8/manual/debugging-profiling-tools.html). Pointer addition of byte would incorrectly sign extend the byte, instead of zero extend. lib_burst_generated.txt was not being output. Player stripping levels higher than minimal would fail to build with burst if they used String.Formatters, String Copy, or BurstDiscard. Fixed error when building player caused by calling an entrypoint method from within other Burst-compiled code iOS/tvOS burst libraries are now using explicit min os version, as configured in player settings. Fixed Burst AOT setting \"Enable Optimizations\" not being applied in player builds Fixed player builds not being recompiled when changing only Burst AOT settings (and changing nothing else) in Unity 2022.2+ Error caused by the MonoDebuggerHandling.dll requiring VCRuntime to be installed. Removed Known Issues [1.8.1] - 2022-10-12 Added Added a custom lld wrapper, to save package space in transit and on disk. Added hover box information for assembly instructions. Changed Upgraded Burst to use LLVM Version 14.0.6 by default, bringing the latest optimization improvements from the LLVM project. Ensured our executables and libraries on macOS and Linux are stripped to reduce package size. Changed how we handle domain reloads within Burst to avoid paying a 250ms cost on each domain reload when using Burst. With the relaxation in Unity 2022.2 or newer that we can call CompileFunctionPointer from a background thread, we now use this mechanism in Burst to handle Direct Call methods, resulting in a cost saving during Domain Reload. Added a categorized index of Neon intrinsics supported in Burst to the Manual Changed the documentation so that it is super clear that exceptions in player builds cause the application to abort. Fixed Fixed a compiler crash that could occur with code that followed the pattern Debug.Log($\"{variable}\") Compiling with line only debug information could cause a compiler crash on certain platforms PDB path associated with windows player dll had the wrong filename, resulting in broken symbols. Fixed documentation issues with Neon intrinsics where the comparison operation would not match the actual one Fixed bug that could occur when swapping large structs by value Fixed \"Unable to resolve type T. Reason: Unknown.\" error when accessing a field of a struct referenced via a pointer behind a reference. Fixed some arm64 instructions not being labelled as instructions. If burst is disabled, and an assembly is changed, burst won't recompile that assembly once burst is re-enabled. Removed Known Issues [1.8.0] - 2022-09-13 Added Added experimental atomic and/or operations to Burst. Changed math.fmod in combination with a Burst job compiled with FloatPrecision.Low will now generate a more optimized low-precision version of the function. Burst now respects the checkbox \"Enable Armv9 Security Features for Arm64\" in the Player settings, making Android builds generate PAC/BTI instructions if enabled. In Burst AOT Settings, only the relevant CPU Architectures dropdowns for the current build target and architecture are now displayed The callstack of the invalid external call is now included when reporting BC1091 Changed so code is focused when branch arrows are present. Changed so Burst reported errors are not collapsible. Removed Fixed An Internal Compiler Error that could occur if a function that requires a struct ret (due to ABI) has been discarded by other logic. Fixed a bug with locally declared array variables in functions where storing null into them could cause invalid codegen. Fixed a bug in Burst player builds where sufficiently complicated Bursted code could cause a deadlock deep within LLVM. Fixed that UWP builds wouldn't respect the specified \"Target SDK Version\" and \"Visual Studio Version\" settings Fixed Burst inspector sometimes freezing when selecting between blocks. Fixed the Burst Inspector sometimes becoming unresponsive when selecting text. Fixed a race condition with the Burst log timings such that previously reported results could be included in subsequently reported timings. Fixed the managed fallbacks for bzhi and bextr to match what the native hardware instructions do. Fixed a bug in the static readonly constant expression evaluation (what we call the IL interpreter) whereby it would not truncate unsigned integers correctly. Fixed that compilation would have full debug info forced on Fixed incorrect code-gen when a function is both used normally and as a function-pointer Known Issues The PDB path associated with the Windows Player dll is incorrect, resulting in broken symbols. [1.8.0-pre.2] - 2022-08-03 Fixed Fixed hashing bug that could occur when a function pointer type is used in a method parameter Fix selection and copying of folded blocks Fixed hashing error that could occur in the presence of multiple synthesized explicit interface implementations with the same name and signature Fixed a compiler crash if users used __refvalue or __arglist in Burst. Neither of these are supported, but now we will nicely tell you via a compiler error that they aren't supported. Fixed a compiler error when trying to acquire the function pointer of a generic function from Bursted code. Fix some ARM branch instructions not being processed as such. Using a function only through a C# function pointer could cause a crash Whitespace changes in ILPP'd assemblies would not be detected. Issue where a warning could be generated about the debug information version mismatching warning: ignoring debug info with an invalid version (0) during link. Interface methods where not being hashed correctly for constrained types, which would result in burst failing to recompile code that had changed in an implementation class. Fixed a safety check bug with Span/ReadOnlySpan and Slice(start, length) where if start + length was equal to the Length of the original span, the safety check would incorrectly report an out-of-bounds access. Linking issue when exports differ only by module. Disabling Burst from the command line via --burst-disable-compilation no longer results in Burst errors when building a player for Android Corrupted binary could be produced on M1 if there was not enough space for UUID+codesign injection. ;'s in paths would cause burst to fail. Note - Also requires a fix in the Editor, so if your project has ;'s in its path, the workaround is to remove the ; from the folder name for now. Fixed error when compiling assemblies with spaces in their names Fixed access violation race condition bug Fixed a bug where static fields in generic types could in some situations be initialized with the incorrect value Fixed last line in Burst Inspector not being select-able using the mouse cursor. Fix error that occurs with a specific formulation of IL, using xx with an early out escape and unbalanced calculation stack. (Object reference not set to an instance of ... in CollectBlock.ToVisitOrder) Changed Changed burst inspector toggles to popup menus. Removed label from burst inspector popup menu into the menu itself. Used explicit namespace for UnityEditor.PackageManager.Events to avoid conflicts. Improved \"hashing\" performance. This is the part of Burst that determines whether anything significant has changed in .NET assemblies, and therefore whether that assembly to be compiled. Entry point function names weren't always included in crash callstacks; now they are Search pattern from previous job is not carried over to the new. Changed so block of 1 line cannot be folded in the Burst Inspector Added Setting a breakpoint in an attached managed debugger (Rider/VS Unity Debugger...) on a method that is burst compiled, will switch off the burst code path for that method, allowing it to be debugged as normal. Added toggle to filter Unity tests on and off. Assembly is now searchable either through CTRL + f or the contex menu associated with the inspector view. Search options include case sensitivity, whole word match, and regex. Intrinsic support for UnsafeUtility.IsNativeContainerType Added an actual definition for HPC# in the package docs. Check that calling convention is correctly set to Cdecl for functions whose addresses are taken via ldftn. Added focus on current job in the burst inspector. Added copy to burst inspector, which ignores underlying color tags. Removed Known Issues [1.8.0-pre.1] - 2022-05-06 Changed Always preserve frame pointers in Burst. This results in a neglible performance hit (less than 0.5% in benchmarks), but ensures that stack recovery for stack traces is always possible. Class libraries are now built with netstandard 2.0 The minimum Xcode version to build for iOS, iPadOS, and tvOS with Burst is now 12.0.0. Upgraded Burst to use LLVM Version 13.0.1 by default, bringing the latest optimization improvements from the LLVM project. Fixed \"error while hashing\" message that could appear during compilation Made Burst explicitly check for any compilation requests that came from AssemblyBuilder, and do not compile these with Burst. These exist outside the normal compilation pipeline, and Burst could not support them (but we now explicitly check for that case). Made Burst's ILPP 22% faster by caching dependent assemblies that the being-processed assembly uses. Changed how we process static readonly fields in static constructors such that we'll allow more computational budget per static field. This fixes the case where having too many static readonly variables in a single static constructor could fail to compile, while they would work if each was in their own static constructors. Collapsed block of code in burst inspector now shows the blocks first line of code. Upgraded Burst to use LLVM Version 14.0.0 by default, bringing the latest optimization improvements from the LLVM project. Changed the default alignment for SharedStatic's from 4 to 16. Added Branches now highlights when you hover them. Branches are clickable; directing the view to the other end of the branch when clicked. Added support for the System.Runtime.CompilerServices.IsExternalInit workaround documented here into Burst when used in 2022.1+. Enabled keyboard navigation in the right pane of the burst inspector. Added version number to debug metadata for llvm Experimental support for Armv9 SVE2 CPU target for Android Added a Target Arm64 CPU setting in Burst AOT Settings for Android Removed Removed the requirement that BurstLoader has to initialize BurstReflection during a domain reload, making BurstLoader setup 2x faster during domain reloads. Fixed Error if install in build folder is used without ever using a regular build. Fixed a performance regression with IJobParallelFor where vectorization didn't happen for cases where it previously would have. Fixed a compiler miscompile if you loaded a static readonly v128 and passed it straight to a function as an argument. Removed implicit dependencies to pre-compile binaries in CodeGen which would otherwise cause assembly resolution conflicts. Fixed a Unity 2021.2 and newer bug that manifested with UWP builds - we were using the wrong unityaot folder in the Unity editor distribution with Burst. Fixed a really subtle caching bug in the compiler where if you had a job that compiled successfully at least once, then it failed (you used managed state for instance), then you closed the editor and restarted, if the compiler threads started in precisely a strange combination then Burst might accidentally never recompile the job which failed previously. Fixed potential hang in Editor when compiling a Burst entry point method that is defined in a generic class Fix for the X.pdb: The process cannot access the file because it is being used by another process issue our users were seeing. We were taking a FileShare.Read lock, when we needed to take FileShare.ReadWrite. Fixed a bug where the compiler would reject a try/finally statement if it was the first thing in a method Fixed a performance regression affecting some vectorization in Burst 1.7+ (LLVM 12+). Inspector performance regression. Improved UWP linker error message to clarify which VS components need to be installed for UWP Fixed a bug that meant Burst was accidentally enabled in secondary Unity processes, including the asset import worker and out-of-process profiler (see changelog entry for 1.6.0-pre.1 for more context around this) Keybindings for copy and selection did not depend on OS. Right pane vertical scrollbar not always showing correctly. Inspector font style changing when entering and exiting play mode. Fixed access violation error that could occur when reading from a static readonly variable Made --burst-force-sync-compilation command-line option actually work Fixed a bug that was exposed by a Script Updater running against the Entities tests, whereby if some sort of pre-domain-reload code (some sort of teardown like thing) called into Burst, the script updater could have caused Burst to purge valid function pointers, resulting in us trying to execute a DLL location that we had already unloaded. Fixed a super rare bug whereby if you kicked off two compilations very close together (most likely when running Unity in some sort of headless build-a-player mode), Burst could throw an exception on a burst hash cache file being locked by the process. Fix a bug where if you had a long running compilation and a new compilation came in, some threads in the thread pool could (if unlucky) block trying to dirty the assembly in our Burst caching infrastructure while waiting for the compilation to complete. Fix a bug where codegen differences could occur when using a local vector variable that was being captured by reference and passed to a called function, versus when it wasn't. Fixed an exception that could occur if you had the Burst AOT Settings menu docked in the Editor, and then did a player build. Trying to change any of the Burst AOT Settings would throw an exception (unless you closed and reopened the Burst AOT Settings). Fixed a bug where we could leave background tasks around forever when we had actually completed them (could only happen if two re-compilation requests arrived close together, meaning we'd cancel the first but never report to the background tasks that we had cancelled them!). Fix the Burst link.xml output to preserve C# methods we rely on, alongside the static constructors that we preserved previously. Fixed errors when working with paths containing special characters Fixed a bug where if you used FloatMode.Fast with math.pow, where the y argument to math.pow was actually sourced from an integer, illegal codegen would be generated (LLVM would try and call out to powf from the cstdlib). Worked around an ordering issue with post-processing in 2020.3 and earlier by deferring the early compilation of script assemblies in the editor until the entire pipeline has completed. Fixed a bug in 2022.1+ where calling Debug.Log in a static constructor would result in a Burst failure. Fixed another rare case of the file-is-locked bug where the Burst IL Post Processor could incorrectly hold a file lock on a pdb. Fixed a bug when calling profiling CreateMarker on iOS, Burst could fail at runtime saying it was unable to find CreateMarker__Unmanaged. Fixed that the crc32_u64 second parameter should have been a ulong. Added a new ulong variant and marked the old long variant as [Obsolete]. Fixed a bug where using ReinterpretStore(someIndex, (ushort)someValue) could cause an internal compiler error in Burst. Fixed a potential deadlock whereby if Burst was compiling in the background (the background tasks window showed Burst in it) and a user switched from release to debug in the editor, Burst could cause a deadlock. A potential issue with the debug info mover pass, that meant it only affected the first entry point in a module Fixed hashing error that could occur with unbound generic type Fixed a bug where if you had synchronous compilation on a job, disabled Burst compilation and entered playmode, then exited playmode, and finally re-enabled Burst compilation, a hang could occur. Fixed a bug where toggling Burst enable <-> disable during a playmode execution using Burst, and then attaching the managed debugger, could cause an editor crash. Fixed a memory leak where during hashing we'd pin a GC object and never unpin and free it. Fix burst inspector sometimes stalling during loading for script reloads. Fixed a super rare bug where Burst could hit an internal error with System.InvalidOperationException: Nullable object must have a value. Fixed a regression where out parameters of C# 9.0 function pointers weren't working in Burst. Fixed internal compiler error when encountering a calli with closed generics Fixed bug in static constructor ordering in the presence of indirect dependencies between static constructors (i.e. static constructor -> static method -> static constructor) that could result in a runtime crash Added workaround for \"cannot dlopen until fork() handlers have completed\" issue seen in macOS 12.3 Fixed compiler crash when trying to dynamically call BurstCompiler.CompileFunctionPointer in Burst-compiled code Fix compiler crash when the only usage of a static field was in a formatted exception string Fixed burst inspector sometimes not rendering text or rendering text on top of other text. Fixed selection rendering off-by-one error at last line of each block. Fixed a bug with Span and ReadOnlySpan types where if the indices used were not already 32-bit signed integers, an internal compiler error would occur if running with safety checks enabled. Fixed a really convoluted bug that could manifest in Burst returning out of date cached libraries, which would manifest as random exceptions in Burst jobs/function-pointers (users deleting the BurstCache would workaround the bug). Known Issues [1.7.0-pre.2] - 2021-12-06 Changed Improved the compiler performance when doing large struct copies by detecting more cases where a load/store can be safely converted to a move-memory operation. Used BuildReport::summary::subtarget to detect headless (server) player builds on 2022.1+. Don't move pdbs out of build folder for UWP builds. Changed how we display the timings when a user has the Show Timings option enabled in the Burst menu, by cleaning up and presenting the information in a (hopefully!) clearer way. Fixed Fixed constant folding when using Hint.Likely or Hint.Unlikely intrinsics - the compiler is now able to fold these calls away entirely if the input value is constant. Fixed an internal compiler error when casting a void* to a pointer-to-vector and then access the element. One Definition Rule optimisation would break if multiple modules shared static constructors due to an issue with sharing code but not data. Fixed type initialization error, and invalid log messages about needing to add [MonoPInvokeCallback] to be compatible with IL2CPP, that could occur in a player build with Burst disabled ILPP issue for dots runtime whereby a calli patch could generate bad IL if the first instruction replaced was the target of a branch. Fixed a bug where fixed used in conjunction with Span or ReadOnlySpan would cause a compiler error. Fixed a codegen issue with Unity 2021.2 and System.Buffer.MemoryCopy. Fixed compiler crash when trying to load a generic static field Fixed \"UnityException: CompileAsyncDelegateMethod can only be called from the main thread.\" error that was logged in standalone players when the first invocation of a direct-call method was from a background thread Fix the very rare bug whereby the Burst Hash Cache files (*.bhc) will sometimes cause an exception in the editor log. Fixed the documentation to note that the System.Runtime.CompilerServices attributes [CallerLineNumber], [CallerMemberName], and [CallerFilePath] work with Burst, with the restriction that you cannot format the [CallerMemberName], and [CallerFilePath] strings yet. Fixed an issue where with optimizations disabled, using half conversions on platforms that did not natively support half could cause linker errors. Fix error when trying to Direct Call a method belonging to a private nested type Fixed some memory leaks between the C# and C++ parts of the Burst compiler, and added some CI tooling to ensure this doesn't happen again. Fixed a bug where our [BurstCompile] job finding code would not find methods in generic base classes in places where we knew the concrete-generic type (for instance struct Foo<T> { [BurstCompile] struct MyJob : IJob { void Execute() {} } }, struct Bar<T> : Foo<T> {}, and struct Haz : Bar<int> {} - we wouldn't find the concrete Foo<int>::MyJob in Burst). Fixed editor crash when trying to debug a DirectCalled method Fixed a bug whereby complicated try/finally nesting could trip up the compiler. Fixed a bug in the fixed string processing whereby we'd miscompile a fixed string that was within a struct inside a SharedStatic (depending on how it was used). Fixed a bug in the entry-point finding code whereby we wouldn't correctly resolve a nested generic struct's job if it was within a concrete generic class that was outwith the root assembly set. Added Ability to partially select and copy text in the burst inspector. Right clicking the inspector view reveals a context menu, allowing selecting all text and copying selection. Removed The button \"Copy to Clipboard\". Removed Newtonsoft.Json as a dependency Known Issues [1.7.0-pre.1] - 2021-10-21 Fixed Fixed an issue where dsym folders would be not be copied across to the DoNotShip folder when building a multi architecture build for mac os. Fixed bug that could lead to \"Failed to resolve method with name hash X and signature hash Y\" compiler error Fixed compiler error that occurred when calling BurstCompiler.CompileFunctionPointer with a delegate type that was decorated with a custom attribute Linking would fail on non-Windows platforms if the project folder contained a single-quote Fixed the \"could not find path tempburstlibs\" error message popping up when building for Android and Burst is disabled Fixed bug that could lead to incorrect compiler errors for calls to GetHashCode from a generic type Incorrect conversions between signed and unsigned vector types Detects if the simulator is the target of a player build for iOS/tvOS and disables burst, as at present this configuration is not supported by burst. [SkipLocalsInit] now correctly doesn't zero-initialize variables in a function (previously it only avoided zero-initialization of stackalloc created variables). Fixed a bug whereby sometimes some LLVM intrinsics could be incorrectly marked as unused causing invalid codegen with calls to math.acos. The cache for pdbs was becoming stale. This caused issues with wrong source information being shown in the inspector, and potentially wrong debug information being generated for bursted code in editor sessions. Missing output messages from some tools when a failure occurred. Fixed a bug with sqrt_ps for 128-bit types where it would crash the compiler. ArgumentOutOfRangeException due to _renderBlockStart and _renderBlockEnd not being probably initialized when all blocks were above the scroll position. Arrows were rendered even though they were not within the current view. Made it save the actual line numbers for code blocks in _blockLine even when the block is below the view. Removed the starting newline character when copying, and when rendering plain assembly kind. Fixed a bug where a player build that had multiple assemblies that had structs declared with the same name and same contents but different [BurstCompile] methods in them, would wrongly only pick a single struct to Burst-compile. Crash in burst module initialization if multiple modules are compiled and then linked in a different order. Fixed our platform documentation to accurately reflect the current supported platforms with Burst. Inspector menu buttons were seen as available, even though they were not supported, when viewing i.e. .NET IL code. Burst will now handle projects special characters in their project-name Static constructor sorting didn't account for dependencies within calls' IL Static constructor cyclic checks also included method calls when this is not necessary and fails on burst runtime logging code Fixed the bug @tertle found when loading a vector from a struct pointer that is marked as in. Fixed that implicitly casting a scalar half to a vector type would cause the compiler to crash Fixed a crash that could occur when loading legacy Burst AOT settings and then entering play mode Stack overflow caused by placement of alloca under certain function transforms. linker errors on macOS due to long command lines, swapped to using filelists for inputs. Fixed issue that could cause bcl.exe to fail with an exit code of 1 but not output any compilation errors Added Added support for DOTS Runtime running / loading .Net Core assemblies. Added support for System.Span<T> and System.ReadOnlySpan<T> within Bursted code. These types are not allowed as entry-point arguments. Folding/collapsing code in inspector Branch arrows (can be switched off) Automatically collapses less important blocks of disasssembly (focuses on code). Burst now generates a link.xml automatically to avoid issues with stripping causing missing symbols at runtime from static constructor usage. Removed Removed the Use Platform SDK Linker option from Burst AOT Settings for desktop platforms. Removed the player build BC1370 exception warnings as users only found them annoying. Changed Made the cost of initializing Direct Call methods for execution 33x faster during domain reload. Upgraded Burst to use LLVM Version 12.0.0 by default, bringing the latest optimization improvements from the LLVM project. Change the optimization pipeline to run the loop unroller exclusively after the loop vectorizer. This improves codegen in a lot of cases (mostly because the SLP vectorizer is unable to vectorize all the code that the loop unroller could have). Intrinsics: Neon vst1 APIs are now fully supported Made fmod and floating-point modulus use a faster algorithm to improve performance. Made the SharedStatic initialization cost during static constructor initialization time 13.3x faster. Improved iteration time by triggering Burst compilation immediately after .NET assemblies have been compiled Upgraded the minimum supported PS4 SDK to 8.00. Updated the minimum Xcode required for Burst to compile for the Apple iOS/tvOS plaforms to 12.0. Burst now waits for all threads to complete on shutdown, rather than performing a thread abort, as that could lead to a race condition with Dispose. Known Issues Burst does not work correctly when a project has a semi-colon in its name [1.6.0-pre.3] - 2021-07-27 Fixed Fixed a bug where methods with the same name and namespace, but in different assemblies, could resolve to the wrong method. Burst no longer logs a warning when opening the standalone Profiler Fixed an UnauthorizedAccessException that could occur when using Burst in players built for the macOS App Sandbox Fixed a bug that could cause an incorrect compilation error when using a primitive type as a generic argument in a static method entry point Crash due to member function debug information on tvOS. Fix documentation to make clear that ref / out parameters are supported on [BurstDiscard] methods. Fixed a NullReferenceException in the Burst compiler when multi-dimensional arrays were used. The compiler now produces a correct error message telling users that multi-dimensional arrays are not supported by Burst. Fixed DOTS Runtime Job Marshalling behaviour to properly handle marshalling generic Job types when not all closed forms of the generic type require marshalling. Fixed a Burst package warning in our editor compiler integration with respect to BuildOptions.EnableHeadlessMode. Fixed small race which could cause an unexpected exception when finishing a standalone compilation task. Building for Apple Silicon architecture on macOS would produce a universal binary, now it behaves correctly. tvOS/iOS and other statically linked platforms would fail to burst compile if the burst compiled code contained references to functions that were [DllImport(\"__Internal\")], due to a mismatch in calling convention. Fixed a bug whereby if you had $\"{too} {many} {fixed} {string} {formatted} {arguments}\" in a string formatter, Burst wouldn't be able to correctly understand how to transform this for the purposes of logging or fixed-string construction. Fixed where Unity.Burst.CompilerServices.Constant.IsConstantExpression is evaluated to be later in the compilation pipeline, to let it catch more constant expressions (for instance post-inlining). Rare non zero return code from bcl after successfully building.. Only check assembly cache when the main-thread is requesting some Burst code - meaning that kicking off eager compilation is 1.6x faster than before. stackalloc byte[] with an array initializer was previously only supported when the stackalloc size was 8 or less. Sizes greater than 8 are now supported. Fixed an error that could occur with the form \"System.InvalidOperationException: Could not find burst.initialize function in library 'SomeLibrary'\" Fixed incorrect runtime behavior that could occur when casting a pointer to a generic type Fixed a bug where stackalloc's could be wrongly hoisted out of loops. Added [Preserve] attribute to prevent stripping a compiler service call Fixed incorrect compiler error that could occur when casting a pointer to a generic type and then calling a method with generic parameters Fixed incorrect compiler error that could occur with explicit-layout structs when setting a Size smaller than the natural struct size Added Universal (Apple Silicon + X64) versions of extra build tools Add Android x86_64 and re-enable x86 support Added support for having [MarshalAs(UnmanagedType.U1)] or [MarshalAs(UnmanagedType.I1)] on a bool external function parameter. Neon intrinsics: Added vst1* experimental APIs Added a global player build setting to let users specify the default optimization choice for Burst. Native support for Apple Silicon. Added support for StructLayoutAttribute.Pack Additional notes about BurstCompiler.CompileFunctionPointer<T> regarding; avoid wrapping in another open generic method, and interoperability with IL2CPP. Removed Removed the Enable Safety Checks option for player builds, since it didn't actually enable safety checks in containers, which are editor only in Unity. Changed Changed how we link object files for iOS and tvOS platforms such that Burst will now create the object file and hand it off to XCode for linking only. Assembly-level attributes (such as [assembly: RegisterGenericJobType]) are now scanned for generic job types to compile Fixed a regression that caused eager-compilation at Editor startup to be slower than it should have been math.f16tof32 now uses hardware intrinsics where available (AVX2 / NEON). half to float or double vector conversions now produce more optimal codegen. Burst Inspector now remembers scroll position between domain reloads Changed how we schedule Burst eager compilation threads. Previously we'd spawn at most 8 of the threads, and only allow 2 to make progress while in the Editor (to ensure the editor UX/UI was as responsive as possible). Instead we now spawn number_of_cores - 1 threads at a lower thread priority, ensuring that any computing power slack can be consumed to speed up Burst compilation. On a 24 core machine this resulted in 2.5x reduction in time taken for Burst to fully compile a large project. Fixed a potential error related to duplicate symbols when calling BurstCompiler.CompileFunctionPointer from inside Burst code Improved performance of checking the cache to see if methods have already been compiled For player builds : lib_burst_generated.txt, pdbs (in non development mode) and dysm folders are now placed into a xxx_BurstDebugInformation_DoNotShip folder alongside the data folder, this is to ensure it is easy to remove the files that you should not ship with your player. Known Issues Code that previously mixed managed or non-readonly static fields with Burst compiled code will now fail to compile. [1.6.0-pre.2] - 2021-04-15 Fixed Fixed obsolete API in package code. [1.6.0-pre.1] - 2021-04-14 Changed Start 1.6 release cycle Changed how we resolve function references in the compiler to improve resolving an existing function reference by 3x. Improve how we handle generic resolution in Cecil to cache the strictly resolved generic types and save a bunch of time in the compiler. Exception strings no longer contain the entry-point name of the job/function-pointer that caused the throw. This change was required because the Burst compiler has to produce deterministic results from any given compile, which is fundamentally opposed to per-entry-point function derivations. Changed how SLEEF global variables for trig functions are pulled into Burst to reduce duplications. Changed how exceptions throw types and messages are stored in our Burst binaries to reduce binary size. Constant array data is now named after the static field it belongs to in assembly Upgraded Burst to use LLVM Version 11.0.1 by default, bringing the latest optimization improvements from the LLVM project. The Unity.Burst.Intrinsics.Common.Pause intrinsic is no longer experimental. DOTS Runtime shares the logging code path with the general case Armv8.2 Neon intrinsics are now fully supported Disable threading within the lld linker instances we use for in-editor and desktop cross compilation, because we're already threading seperate process instances of lld and it results in lot of OS context switching. Tweaked how the IL Post Processed 'direct call' Burst function pointers are compiled so that the compilation is deferred until they are needed (previously we'd enqueue them all for compilation on a domain reload). Changed Burst minimum editor version to 2019.4 Use rpmalloc as our native allocator on Windows to speed up concurrently executing LLVM work. When Burst has previously compiled a method, and neither the assembly containing that method nor any of that assembly's dependencies have changed, it was possible after a domain reload for the Mono version of the method to be used for a short time before being replaced by the Burst version. This has now been improved such that the Burst version will be used immediately. Improved iteration speed by reducing the time it takes for Burst to check if any Burst-compilable code has changed Change our link step to not use response files if the command line was smaller enough, saving the cost of the round-trip to the disk. Made half <-> float / double conversions use native hardware where possible (Arm or AVX2 targets). In order to prevent conflicts with the main Unity process, Burst is now inactive in secondary Unity processes, including the asset import worker and out-of-process profiler. This means that in those secondary processes, code that would normally be Burst-compiled will now run under Mono. In a future release of Burst, we hope to lift this restriction and allow Burst-compiled code to run in secondary Unity processes. Fixed Fixed a bug in LLVM that it would incorrectly convert some memset -> memcpy if both pointers derived from the same memory address, and where one indexed into the 0th element of the pointer. Fixed namespace issue triggering a warning in the editor. Made math.shuffle compile correctly when non-constant ShuffleComponent's are used. Fixed alignment issues associated with xxHash3 on ArmV7 (case 1288992) Fixed managed implementation of sub_ss intrinsic Fixed a bug that occurred when an explicitly laid out struct was used by a dup instruction, which caused an internal compiler error. Fixes DOTS Runtime JobProducer Bursting code to support JobProducers with multiple generic arguments, complex job wrapper and generic jobs. Fixed a bug where if a user had defined multiple implicit or explicit casts, the compiler could resolve to the wrong cast. Fixed a bug where explicitly casting from an int to IntPtr would not sign extend the value. String interpolation issues when using Dots / Tiny runtime. Fixed managed implementations of blend_epi32 and mm256_blend_epi32 intrinsics on Mono Fixed a bug where loading from a vector within a struct, that was got from a NativeArray using an indexer, would cause the compiler to crash. Fixed an issue where Burst would erroneously error on BurstCompile.CompileFunctionPointer calls when building for the DOTS Runtime. clang segmentation fault on iOS when member function debug information was emitted, it is disabled for this platform now. Intrinsics: Neon - fixed vget_low and vget_high producing suboptimal code Private [BurstCompile] methods no longer throw MethodAccessException Fixed a bug where the Burst post-processing for direct call would cause duplicate function pointers to be compiled, wasting compile time in the editor and caused an Editor launch stall. Corrected 'Enable safety checks tooltip`. Fixed a minor debug information bug where built-in types with methods (like System.Int32) would generate incorrect debug information. Fixed a very obscure bug where if you had a function-pointer that was called from another function-pointer of job, and that function-pointer happened to be compiled in a player build in the same bucket as the caller, and the no-alias cloning analysis identified that it could clone the original function-pointer to enable more aliasing optimizations, it could create a duplicate symbol error. Revert to internal linkage for Android X86 (32bit) to ensure ABI compliance. Fixed compilation errors when targeting Arm CPUs and using some of the Intel intrinsics Added PreserveAttribute to prevent the internal log from being stripped in il2cpp builds. IL Function Pointer Invoke Transformation updated to handle transforms that affect instructions that are the destination of a branch. IL Function Pointer Invoke Transformation now uses correct runtime library for dots runtime. Fixed compilation errors when targeting Intel CPUs and using some of the Arm Neon intrinsics Fixed a bug where eager-compilation could pick up out-of-date global Burst menu options for compiling. Fixed a bug where the progress bar would report double the amount of pending compile jobs if a user changed the Burst options while background compilation was going on. Fixed some intrinsics not checking target CPU against required CPU, so it was possible to use some intrinsics without an IsXXXSupported check Fixed a bug where having any [DllImport] in a class that used the Direct Call mechanism could result in an illegal CompileFunctionPointer call being produced by our post processor. Fixed an issue where if a user used a math function (like cos, sin, etc) then LLVM would preserve both the scalar and vector implementations even if they were trivially dead, causing us to inject otherwise dead functions into the resulting binary. PDB debug information for instance methods that also used struct return were incorrect. When generating Line Table only debug information, an unreachable could occur due to a missing check. Fixed the 1.5 restriction that Direct Call methods can only be called from the main thread, now they work when called from any thread. Internal Compiler Error if a call was discarded (via BurstDiscard for example), but the callsites required an ABI transform e.g. struct return. Fixed a bug with using multiple IsXXXSupported intrinsics in the same boolean condition would fail. Broken link restored for known issues with debugging and profiling. The Direct Call injected delegate now has a unique suffix to avoid type-name clashes. Dots runtime function pointer transform has been simplified, making it less brittle and fixing some bad IL generation. Fixed crashes on 32 bit windows when calling function pointers from managed code and using IL2CPP. Fixed a possible DivideByZeroException due to race condition in TermInfoDriver initialization code. Fixed a bug where the multi-CPU dispatcher (used for player builds targetting multiple CPU architectures) could end up generating invalid instructions. Gracefully handle failing to find a particular assembly in the ILPP to prevent an ICE. function calls using in modifiers on blittable structs where being treated as non blittable. crash when extracting sequence point information for error reporting/debug information generation. Direct Call extension methods that only differ on argument types are now supported (previously Burst's AssemblyLoader would complain about multiple matches). Fixed a regression where managed static fields, in static constructors that would also be compiled with Burst, could cause a compile time failure for mixing managed and unmanaged state. Added Added links to blog posts from the burst team to the Burst documentation. Intrinsics: Neon - Added support for basic vld1 APIs Can now call BurstCompiler.CompileFunctionPointer() in Burst code Add support for the C# 8.0 construct default(T) is null to Burst by transforming the generated Box + 'is the box non-null?' at compile time. Make it possible to get a pointer to UTF-8 encoded string literal data in HPC# code via StringLiteral.UTF8() Add an OptimizeFor option to [BurstCompile], allowing users to say they want fast code, small code, or fastly compiled code. Known issue with Windows Native Debuggers and Dll numbers + workarounds. Assemblies are now allowed to have an [assembly: BurstCompile()] attribute to let users specify compile options that should apply assembly wide (for instance [assembly: BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)]). Automatically add [UnmanagedFunctionPointer(CallingConvention.Cdecl)] to any delegates that are used for BurstCompiler.CompileFunctionPointer<>() or error if the delegate has the attribute and it is not Cdecl. Source location metadata into hash cache. Added support for having [return: MarshalAs(UnmanagedType.U1)] or [return: MarshalAs(UnmanagedType.I1)] on a bool return external function. An additional warning about delegates being used by BurstCompiler.CompileFunctionPointer that are not decorated as expected. In most cases, Burst will automatically add the C-declaration attribute in IL Post Processing, but if the usage of CompileFunctionPointer is abstracted away behind an open generic implementation, then Burst will not be able to automatically correct the delegate declaration, and thus this warning will fire. new burst_TargetPlatform_EmbeddedLinux new AotNativeLinkEmbeddedLinux for EmbeddedLinux Added a new OptimizeFor mode Balanced. This becomes the default optimization mode, and trades off slightly lower maximum performance for much faster compile times. Added experimental half precision floating point type f16 Added experimental support for half precision floating point Arm Neon intrinsics Removed Known Issues Direct Call methods only execute using Burst after an initial execution of them on the main-thread. Notes BurstAotCompiler integration done using reflection and raw values, since the platform will only be officially available for 2021.2+ and we special customer versions (shadow branches) for 2019.4 & 2020.3. AotNativeLinkEmbeddedLinux implementation gets the toolchain from environment vars. [1.5.0-pre.2] - 2020-12-01 Added Removed Changed Fixed Fixed a failure on linux builds where libdl.so cannot be found. Known Issues [1.5.0-pre.1] - 2020-11-26 Added New intrinsics Hint.Likely, Hint.Unlikely, and Hint.Assume to let our users tell the compiler some additional information which could aid optimization. New Bmi1 and Bmi2 x86 intrinsics. These are gated on AVX2 being supported to keep the feature sets that Burst has to support small. You can now select explicit x86/x64 architecture SIMD target for Universal Windows Platform. Added Apple silicon and macOS universal binaries support to Burst. An extra alloca hoisting step to ensure that allocas that occur deep within functions are correctly allocated in the function entry block (which LLVM requires for optimization purposes). Added the missing clflush intrinsic to the SSE2 intrinsics. An optimize-for-size option to bcl to let select users focus the optimization passes to create smaller executables. Added a Unity.Burst.CompilerServices.SkipLocalsInitAttribute attribute that lets developers tell the compiler that stack-allocations do not need to be zero initialized for a given function. Added a new attribute [IgnoreWarnings] that can be specified per method, for users that really want the compiler to be quiet. Support for RDMA, crypto, dotprod Armv8.2-A Neon intrinsics An error message if attempting to BurstCompiler.CompileFunctionPointer() on a multicast delegate, since this is not supported in Burst. Burst detects removal of the burst package in 2020.2 editors and beyond, and displays a dialog asking the user to restart the editor. Added a pass that will classify and remove dead loops for improved code generation. Add support for using ValueTuple types like (int, float) from within Burst code, as long as the types do not enter or escape the Burst function boundaries. Added a new intrinsic Unity.Burst.CompilerServices.Constant.IsConstantExpression that will return true if an expression is known to be a compile-time constant in Bursted code. Added support for PlayMode / Desktop Standalone Players to load additional burst compiled libraries for use in Modding. Add support for calling Burst code directly from C# without using function pointers. In Unity 2020.2 and above, you can now call new ProfilerMarker(\"MarkerName\") from Burst code Add a compiler error if a ldobj tries to source its address to load from a non-pointer/non-reference. C# frontends should never generate this pattern, but we did see it with code generation. Fixed Fixed an issue where a function with a [return: AssumeRange(13, 42)] could lose this information during inlining. Storing into Lo64 or Hi64 would cause a compiler exception. Hitting a ldobj of a pointer-to-vector would incorrectly load the vector rather than the pointer.Burst only generates unaligned stores. Fix that the parameter to mm256_set1_epi8 should be a byte instead of a char. Fix sqrt_ss would fail because LLVM version later than 6 changed the encoding. Fixed the comi*_ss intrinsics which would generate invalid code. Pdb location for player builds is now linked relative to the final lib_burst_generated.dll, this allows the crashdump utility to access the symbols and provide better callstacks. Support negative intrinsics features checks to enable usage like if (!IsSse41Supported) return;. Clean up linker temp response files on successful build Wasm ABI issue with pointers Pause intrinsic in wasm (ignored) fmod expansion to sleef for wasm The AOT option for disabling optimizations now actually disables optimizations in player builds. Fix a bug where a static readonly variable that was a System.Guid would result in an internal compiler error. bitmask intrinsic was broken on non intel platforms When \"Enable Compilation\" was unchecked in the Burst menu, Burst was incorrectly enabled after an Editor restart. This is now fixed. Fixed a bug where a cloned function (say through no-aliasing propagation cloning) would re-create any global variables used rather than use the original variable. If the only reference to an external function was discarded, don't attempt to add it to the burst initialisation block (which caused on ICE on prior versions). Fixed a case where extracting a FixedString4096 from a parent struct could cause very slow compile times. Fixed a poor error message when a generic unsupported type (like a class or an auto-layout struct) combined with an unsupported managed array (like (int, float)[]) wouldn't give the user any context on where the code went wrong. Fixed a bug where if you used an enum argument to a function to index into a fixed array, a codegen error would occur. If targeting multiple iOS architectures, produce a combined burst library containing all architectures, this fixes \"New Build System\" on xcode version 12. Static method parameters are now validated correctly during eager-compilation Fixed permissions error when running lipo tool to combine libraries. Fixed compiler error that could occur when calling a [BurstDiscard] method with an argument that is also used elsewhere in the method Fixed an issue that could prevent the Editor from shutting down Fixed an internal compiler error when nested managed static readonly arrays were used (produces a proper Burst error instead now). Fixed a bug whereby for platforms that require us to write intermediate LLVM bitcode files, UTF paths would be incorrectly handled. Correctly marked Neon intrinsics vmovn_high_* as ArmV7 and not ArmV8 On windows, the pdb location for burst cached dll's now points to the correct path. Native debuggers attached to the Editor should now locate the symbols without requiring adding the Library/Burst/JitCache folder to the symbol search. Re-enabled BC1370 exception warnings but only for player builds. Fixed a bug whereby if you had an assembly that was guarded by UNITY_SERVER, Burst would be unable to find the assembly when Server Build was ticked. When \"Enable Compilation\" was unchecked in the Burst menu, Burst was incorrectly enabled after an Editor restart. This is now actually fixed. static readonly array with enum elements would cause the compiler to crash. Fixed managed (reference) implementation of mm256_cvttps_epi32 (case 1288563) Debug information for instance methods is now correctly scoped. This means instance variables can now be inspected correctly. Removed Removed support for XCode SDKs less than version 11.0.0. Removed support for platform SDKs that used the older LLVM 6 and 7 in the codebase to significantly simply our code and reduce the package size. Changed Minimum SDK version for iOS/tvOS increased to 13. See https://developer.apple.com/news/?id=03042020b for details. When using \"Executable Only\" build type on Universal Windows Platform, Burst will now only generate code for a single CPU architecture that you're building for. The inliner heuristics have been modified to inline less functions, but improve compile times and reduce executable size. The minimum XCode SDK required to compile for iOS/iPadOS/tvOS is now 11.0.0. We now copy the lib_burst_generated.pdb into the root of the player build (in addition to being alongside the lib_burst_generated.dll), this allows the unity crash handler to resolve the callstacks from burst code. Made Arm Neon intrinsics fully supported (removed the guarding define) Improved eager-compilation performance Improved Burst Inspector loading time Improved Burst initialization time If an argument to a BurstDiscard method is discarded, and that argument is a method call, then a warning is now generated to indicate the function call no longer happens. Changed how struct-return and indirect arguments use stack allocations to significantly reduce stack usage and improve performance in these cases. Improved the compilers ability to deduce dead memory operations (memcpy, memset, etc) to improve performance. Improved error message seen when scheduling Burst compilation during domain reload Open-generic static methods are not supported by Burst, but they were previously visible in Burst Inspector - they are now hidden In Burst Inspector, the \"Safety Checks\" checkbox now defaults to unchecked Burst Inspector no longer loses the search filter and \"Safety Checks\" option after domain reload Changed exception throws to allow more vectorization chances surrounding them. Upgraded Burst to use LLVM Version 11.0.0 by default, bringing the latest optimization improvements from the LLVM project. Eager-compilation is now cancelled when script compilation starts, to prevent spurious errors related to recompiled assemblies Strings can now be passed between methods within Burst code. Previously, string literals used for e.g. Debug.Log calls could only appear in the same method where they were used; now the string literal can be in one method, and passed to another method via a string parameter. Transitioning from burst disabled to burst enabled in editor, will perform a re-initialise of some internal state in use by Direct Call methods. Improved the performance of in-compiler hashing by 1.2x. Improved our hashing performance some more by re-using fixed-sized buffers in the compiler to improve eager-compilation / warm-cache costs by 1.25x. Improved compile time by ~37% on big projects by reworking some core compiler infrastructure. Known Issues In player builds, exceptions can report the wrong job that they were thrown from. [1.4.0-preview.4] - 2020-08-17 Fixed Fixed a bug introduced in 1.4.0-preview.3 that prevented some UnityEngine.Debug methods (such as DrawLine) from being called Fixed compiler error when explicit-layout struct contains a field which is itself an empty struct Fixed a bug that if you used more than four arguments in a function declared within another function, and then implicitly captured a few variables, Burst would map the variables wrongly. Changed Bump com.unity.mathematics to 1.2.1 version [1.4.0-preview.3] - 2020-08-06 Added VS 2017 support for platform that needs it. Added first batch of Arm Neon intrinsics. Currently, only ArmV8 (AArch64) targets are supported. The supported intrinsics include all ArmV7 and ArmV8 ones. Removed Changed In versions of Unity older than 2019.3, changing the following options in the Burst menu now requires the Editor to be restarted: Enable Compilation, Safety Checks, and Native Debug Mode Compilation. In versions of Unity older than 2019.3, previously-compiled methods will not be recompiled after changing those options, which could lead to undefined behavior where methods may or may not be compiled with the correct options. This change removes that possibility. Improved performance of \"eager-compilation\" (scheduling compilation immediately after assemblies are changed) by cancelling queued eager-compilation when entering play mode with Synchronous Compilation unchecked Improved performance of eager-compilation by not eager-compiling test assemblies Asserts that are currently discarded no longer discard arguments with potential side effects. Fixed We no longer attempt to replace the debug metadata multiple times for a given export. Fixed a subtle codegen bug that could occur when the target is an Arm or AArch64 CPU with vectors of 3 elements. Inspector slow down when scrolling/moving the window on large listings. Fixed a bug where a stfld into an element of a vector could deduce the wrong type for the underlying vector. Fixed a potential error when running the linker with a failure on lld command. If path to the package contained spaces, then native command execution could fail. This would manifiest as weird errors with 'lld' or 'vswhere' or other native tools. Fixed Debug.Log by re-enabling it when used in function pointers or jobs. Fixed errors when opening Inspector with a non-public Execute method on a job producer type Known Issues [1.4.0-preview.2] - 2020-07-01 Added Removed Changed The Burst Inspector no longer uses JIT compilation. The code it shows is now compiled the same way as for editor / player usage. Warnings are hidden in the inspector view Fixed Fixed potential error that could occur when unloading cached libraries Known Issues [1.4.0-preview.1] - 2020-06-26 Added Experimental support for tvOS Add intrinsics support for AtomicSafetyHandle.NewStaticSafetyId<T> A new option [BurstCompile(DisableSafetyChecks = true)] that allows per job or function-pointer disabling of safety checks. This allows users to have blessed code run fast always. Improve Editor experience by scheduling compilation immediately after assemblies are changed, instead of waiting until Play Mode is entered. Improved our aliasing detection to allow DynamicBuffer structs to be easily vectorizable. Added a compiler warning for any use of throwing an exception from a method not guarded by [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")]. Since exceptions in Burst are only supported in the editor, this provides a useful warning to users who may be relying on try/catch behaviors for control-flow which is not supported in final game builds. Burst compilation status is now displayed in the Background Tasks window in Unity 2020.1 and above (click the spinner in the bottom-right of the Editor to open this window). Upgraded Burst to use LLVM Version 10.0.0 by default, bringing the latest optimization improvements from the LLVM project. Add support for try/finally and using/foreach for IDisposable patterns. Add BurstCompiler.IsEnabled API. Add syntax colouring for LLVM IR and Optimized IR panels in the inspector Removed Changed Made the compiler better at constant-folding complex static readonly constructors. Bursted DOTS Runtime Jobs are now decorated with [NativePInvokeCallback] instead of [MonoPInvokeCallback] which could generate callback wrappers which could cause native code to inadvertently interop with the managed VM. The Burst menu-item Safety Checks has been changed to a modal choice of Off, On, and Force On. Force On will overwrite any user job or function-pointer with DisableSafetyChecks = true. To avoid users falling into the consistent trap of having Safety Checks set to Off, any reload of the Editor will issue a warning telling the user that Safety Checks have been reset to On. Use platform provided memory intrinsics for iOS, tvOS, WASM, and console platforms. Updated Cross Compilation Tooling To LLVM 10 The command line option --burst-disable-compilation is now disabling entirely Burst, including the AppDomain. Fixed Fixed incorrect struct layout for certain configurations of explicit-layout structs with overlapping fields Fixes a caching issue where stale cached libraries may have been used if a project was copied to a different folder, or Unity was upgraded to a newer version Burst will now error if a cpblk was used to copy into a [ReadOnly] parameter or field. Fixed a bug where the mm256_cvtepi32_ps intrinsic would crash the compiler. Fixed a bug with constant expressions that could cause a compile-time hang. Debug symbols are now output when using the native toolchain on mac. Sleef fallback to scalar float for WASM. ABI struct ret/by val for trivial aggregates for WASM is now respected. Fixed a bug with float/double vector constructors of Unity.Mathematics that take half or half vector parameters. Debug information for anonymous structs could be created partially multiple times for the same type. Filter symbol warnings to prevent them reaching logs. Fixed an issue where UNITY_DOTSPLAYER builds not building for NET_DOTS would be unable to compile do to references to UnityEngine. Fixed handling of conversion from signed integer to pointer which caused issues as discovered by Zuntatos on the forums. Allow to call [BurstCompile] functions from other [BurstCompile] functions IntPtr.Size now correctly returns int32 size (rather than UInt64) - fixes an assert. Burst package has been upgraded popup could fire erroneously under shutdown conditions. Fixed an issue preventing player builds to succeed when burst compilation is disabled. Debug symbols for function names on some platforms are no longer hashes. Job Entry point symbols should now reflect the job name and type rather than a hash in callstacks/native profilers Job entry points without symbols now use the Execute location rather than pointing to unknown/unknown Dwarf symbols from multiple modules (e.g. multithreaded AOT compilation) now have correct compilation unit information. Known Issues Output of Debug.Log is temporarily disabled in Burst Function Pointers/Jobs to avoid a deadlock on a domain reload. A fix for the Unity editor is being developed. [1.3.0-preview.12] - 2020-05-05 Fixed Fix an issue when changing the base type of an enum that would not trigger a new compilation and would keep code previously compiled, leading to potential memory corruptions or crashes. Fixed a subtle AArch64 ABI bug with struct-return's (structs that are returned via a pointer argument) that was found by our partners at Arm. Fix an issue that was preventing Debug.Log to be used from a Job in Unity 2020.1 Changed JIT cache is now cleared when changing Burst version [1.3.0-preview.11] - 2020-04-30 Fixed Fix potentially different hashes returned from BurstRuntime.GetHashCode32/64 if called from different assemblies. Fixed an issue where Burst was misidentifying F16C supporting CPUs as AVX2. SDK level bumped for MacOS to ensure notarization requests are compatable. Fixed a typo m256_cvtsi256_si32 -> mm256_cvtsi256_si32 and m256_cvtsi256_si64 -> mm256_cvtsi256_si64. The compiler is now generating a proper compiler error if a managed type used directly or indirectly with SharedStatic . Fixed a bug where implicitly stack allocated variables (var foo = new Foo();) in Burst were not being zero initialized, so any field of the variable that was not initialized during construction would have undefined values. Fix potential race condition when accessing on-disk library cache Fixed a bug where Burst was sometimes producing invalid code for iOS 11.0.3+. Added Added support for System.Threading.Volatile methods Read and Write, and for the System.Threading.Thread.MemoryBarrier method. New FMA X86 intrinsics. These are gated on AVX2 support, as our AVX2 detection requires the AVX2, FMA, and F16C features. UnsafeUtility.MemCmp now maps to a Burst optimal memory comparison path that uses vectorization. Removed Changed Known Issues [1.3.0-preview.10] - 2020-04-21 Fixed Fix negation of integer types smaller than 32 bits. Fixed a bug where optimizer generated calls to ldexp would be incorrectly deduced when deterministic floating-point was enabled. Swapped private linkage for internal linkage on functions, this fixes duplicate symbol issues on some targets. variable scopes should now encompass the whole scope. variables in parent scopes should now be present in locals windows. Native plugin location for windows has changed in 2019.3.9f1. If you are on an older version of 2019.3 you will need to upgrade for burst to work in windows standalone players. Added an error if Assert.AreEqual or Assert.AreNotEqual were called with different typed arguments. Fixed a bug where doing an explicit cast to a Unity.Mathematics vector type where the source was a scalar would fail to compile. Fix issue when converting large unsigned integer values to double or float. Fix an invalid value returned from a conditional where one type is an int32 and the other type would be a byte extended to an int32. Button layout of disassembly toolbar tweaked. Copy to clipboard now copies exactly what is shown in the inspector window (including enhancements and colours if shown) AVX2 now generates the correct AVX2 256-bit wide SLEEF functions instead of the FMA-optimized 128-bit variants. Added Anonymous types are now named in debug information. XCode/LLDB debugging of burst compiled code is now possible on macOS. Added some extra documentation about how to enable AVX/AVX2 in AOT builds, and how we gate some functionality on multiple instruction sets to reduce the combinations exposed underneath. Optimized external functions (like UnsafeUtility.Malloc) such that if they are called multiple times the function-pointer address is cached. Add support for string interpolation (e.g $\"This is a string with an {arg1} and {arg2}\"). Add support for Debug.Log(object) (e.g Debug.Log(\"Hello Log!\");). Add support for string assignment to Unity.Collections.FixedString (e.g \"FixedString128 test = \"Hello FixedString!\"). If burst detects a package update, it now prompts a restart of Unity (via dialog). The restart was always required, but could be missed/forgotten. Better error message for unsupported static readonly arrays. Link to native debugging video to Presentations section of docs. Fixes a bug where in parameters of interfaces could sometimes confuse the Burst inspector. Removed Changed iOS builds for latest xcode versions will now use LLVM version 9. Burst AOT Settings now lets you specify the exact targets you want to compile for - so you could create a player with SSE2, AVX, and AVX2 (EG. without SSE4 support if you choose to). Improve speed of opening Burst Inspector by up to 2x. Provided a better error message when structs with static readonly fields were a mix of managed/unmanaged which Burst doesn't support. Tidied up the known issues section in the docs a little. Enhanced disassembly option has been expanded to allow better control of what is shown, and allow a reduction in the amount of debug metadata shown. Load Burst Inspector asynchronously to avoid locking-up Editor. Documented restrictions on argument and return types for DllImport, internal calls, and function pointers. Known Issues [1.3.0-preview.9] - 2020-04-01 Changed Improved the compile time performance when doing UnsafeUtility.ReadArrayElement or UnsafeUtility.WriteArrayElement with large structs. Made some compile-time improvements when indirect arguments (those whose types are too big that they have to be passed by reference) that reduced our compile time by 3.61% on average. Fixed Fixed a bug where storing a default to a pointer that was generic would cause an LLVM verifier error. Fixed an obscure bug in how struct layouts that had dependencies on each other were resolved. Fixed a bug as found by @iamarugin where LLVM would introduce ldexp/ldexpf during optimizations that LLD would not be able to resolve. Fixed a bug where the compiler would not promote sub-integer types to integers when doing scalar-by-vector math (like multiplies). Added Variable scopes are now constructed for debug information. A new setting to Burst AOT Settings that allows debug symbols to be generated even in a non development standalone build. Removed Known Issues [1.3.0-preview.8] - 2020-03-24 Added Double math builtins in Unity.Mathematics now use double vector implementations from SLEEF. Fixed a bug with lzcnt, tzcnt, and countbits which when called with long types could produce invalid codegen. New F16C X86 intrinsics. These are gated on AVX2 support, as our AVX2 detection requires the AVX2, FMA, and F16C features. Add user documentation about generic jobs and restrictions. Add new experimental compiler intrinsics Loop.ExpectVectorized() and Loop.ExpectNotVectorized() that let users express assumptions about loop vectorization, and have those assumptions validated at compile-time.Enabled with UNITY_BURST_EXPERIMENTAL_LOOP_INTRINSICS. Changed Changed how Unity.Mathematics functions behave during loop vectorization and constant folding to substantially improve code generation. Our SSE4.2 support was implicitly dependent on the POPCNT extended instruction set, but this was not reflected in our CPU identification code. This is now fixed so that SSE4.2 is gated on SSE4.2 and POPCNT support. The popcnt intrinsics now live in their own static class Unity.Burst.Intrinsics.Popcnt to match the new F16C intrinsics. Deferred when we load the SLEEF builtins to where they are actually used, decreasing compile time with Burst by 4.29% on average. Fixed Fix an issue where a generic job instance (e.g MyGenericJob<int>) when used through a generic argument of a method or type would not be detected by the Burst compiler when building a standalone player. [DlIimport(\"__Internal\")] for iOS now handled correctly. Fixes crashes when using native plugins on iOS. Removed Known Issues [1.3.0-preview.7] - 2020-03-16 Added Added additional diagnostic for tracking Visual Studio location failures. Added an override to bypass link.exe discovery under certain conditions. Added a ldloc -> stloc optimization which improves compile times. More documentation on function pointers, specifically some performance considerations to be aware of when using them. Removed Changed Updated tools used for determining Visual Studio locations. Fixed Embedded Portable PDB handling improved. Fixed a case where our load/store optimizer would inadvertently combine a load/store into a cpblk where there were intermediate memory operations that should have been considered. Fixed a bug where the no-alias analysis would, through chains of complicated pointer math, deduce that a no-alias return (like from UnsafeUtility.Malloc) would not alias with itself. No longer log missing MonoPInvokeCallbackAttribute when running tests. Known Issues [1.3.0-preview.6] - 2020-03-12 Added Experimental support for Prefetch, allowing users to request from the memory subsystem pointer addresses they intend to hit next. This functionality is guarded by the UNITY_BURST_EXPERIMENTAL_PREFETCH_INTRINSIC preprocessor define. Fixed Fix SSE maxps intrinsic would emit maxss [1.3.0-preview.5] - 2020-03-11 Fixed MemCpy and MemSet performance regression in Burst 1.3.0.preview.4 (as was spotted by @tertle) has been fixed. Fix a crash when loading assembly with PublicKeyToken starting with a digit. Better handling of MonoPInvokeCallbackAttribute: no check for the namespace, don't print message on Mono builds. Changed Improved error message for typeof usage. [1.3.0-preview.4] - 2020-03-02 Added Debug information for types. Debug information for local variables. Debug information for function parameters. Support for fixed statements. These are useful when interacting with fixed buffers in structs, to get at the pointer data underneath. A fast-math optimization for comparisons that benefits the BurstBenchmarks that nxrightthere has put together. DOTS Runtime Jobs will now generate both MarshalToBurst and MarshalFromBurst functions when job structs in .Net builds are not blittable. DOTS Runtime Job Marshalling generation is now controllable via the commandline switch --generate-job-marshalling-methods. Removed Changed Made it clear that the Burst aliasing intrinsics are tied to optimizations being enabled for a compilation. Restore unwind information for all builds. Print a info message if compiling a function pointer with missing MonoPInvokeCallback attribute (this can lead to runtime issues on IL2CPP with Burst disabled). The message will be converted to a warning in future releases. Fixed Fixed an issue where DOTS Runtime generated job marshalling functiosn may throw a FieldAccessException when scheduling private and internal job structs. Fix a bug that prevented entry point method names (and their declaring type names) from having a leading underscore. vector/array/pointer debug data now utilizes the correct size information. DOTS Runtime will now only generate job marshaling functions on Windows, as all other platforms rely on Mono which does not require job marshalling. ldobj / stobj of large structs being copied to stack-allocated variables could cause compile-time explosions that appeared to the user like the compiler had hung. Worked around these by turning them into memcpy's underneath in LLVM. Don't always use latest tool chain on certain platforms. Fix a crash when compiling job or function pointer that was previously cached, then unloaded, then reloaded. Fixed compiler error in array element access when index type is not Int32. Fix set1_xxx style x86 intrinsics generated compile time errors. Known Issues Native debugger feature is only available on windows host platform at the moment. [1.3.0-preview.3] - 2020-02-12 Changed Changed how the inliner chooses to inline functions to give the compiler much more say over inlining decisions based on heuristics. Updated AOT requirements to be clearer about cross platform support. Added 1.3.0-preview.1 added support for desktop cross compilation, but the changelog forgot to mention it. Removed Fixed Documentation for the command line options to unity contained extra - Burst now exclusively uses the <project>/Temp/Burst folder for any temporary files it requires during compilation. Fix a regression that could break usage of native plugins. Known Issues [1.3.0-preview.2] - 2020-02-10 Fixed Fix the error Burst failed to compile the function pointer Int32 DoGetCSRTrampoline() that could happen when loading a project using Burst with Burst disabled. [1.3.0-preview.1] - 2020-02-04 Added Enabled lower precision variants for pow, sin, cos, log, log2, log10, exp, exp2, and exp10 when BurstPrecision.Low is specified. Add CPU minimum and maximum target for desktop platforms Standalone Player builds. Append a newline between IRPassDiagnostic messages, fixes pass diagnostics readability in the inspector. Add a new attribute [AssumeRange] that lets users tag function parameters and returns of an integer type with a constrained range that the value is allowed to inhabit. NativeArray.Length and NativeSlice.Length have automatic detection that the property is always positive. This assumption feeds into the optimizer and can produce better codegen. Enabled support for DOTS Runtime SharedStatics. Due to the nature of DOTS Runtime, only the generic versions of SharedStatic.GetOrCreate<TContext> are supported. Add a new intrinsic Unity.Burst.Intrinsics.Common.Pause() which causes a thread pause to occur for the current thread. This is useful for spin-locks to stop over contention on the lock. Add some new Burst aliasing deductions to substantially improve the aliasing detection in the compiler, resulting in better codegen. Add syntax colouring to WASM. Add IsCreated to the FunctionPointer class to allow checks on whether a given function pointer has a valid (non null) pointer within it. Add AVX2 intrinsics Add some missing intrinsics from SSE, SSE2 and AVX Added explicit X86 intrinsics from SSE-AVX2. AVX and AVX2 CPU targets are now available for x64 AOT builds. Allow handle structs (structs with a single pointer/integer in them) to be inside another struct as long as they are the single member, as these require no ABI pain. Added support for Interlocked.Read. Added a new intrinsic Common.umul128 which lets you get the low and high components of a 64-bit multiplication. This is especially useful for things like large hash creation. Menu option to allow all burst jobs to be more easily debugged in a native debugger. Removed Changed Upgraded Burst to use LLVM Version 9.0.1 by default, bringing the latest optimization improvements from the LLVM project. Upgraded Burst to use SLEEF 3.4.1, bringing the latest performance improvements to mathematics functions as used in Burst. Improved Burst performance in the Editor by caching compiled libraries on-disk, meaning that in subsequent runs of the Editor, assemblies that haven't changed won't be recompiled. Update the documentation of CompileSynchronously to advise against any general use of setting CompileSynchronously = true. Take the Unity.Burst.CompilerServices.Aliasing intrinsics out of experimental. These intrinsics form part of our strategy to give users more insight into how the compiler understands their code, by producing compiler errors when user expectations are not met. Questions like 'Does A alias with B?' can now be definitively answered for developers. See the Aliasing Checks section of the Burst documentation for information. Align disassembly instruction output in Inspector (x86/x64 only). Renamed m128 to v128. Renamed m256 to v256. BurstCompile(Debug=true), now modifies the burst code generator (reducing some optimisations) in order to allow a better experience in debugging in a native debugger. Fixed Fix a bug where floating-point != comparisons were using a stricter NaN-aware comparison than was required. Fix inspector for ARMV7_NEON target. Fix some issues with Burst AOT Settings, including changing the settings to be Enable rather than Disable. Fix an issue where WASM was being incorrectly shown in the disassembly view. Fixed an issue where if the Unity.Entities.StaticTypeRegistry assembly wasn't present in a build, Burst would throw a NullReferenceException. Fix issue with type conversion in m128/m256 table initializers. Fix inspector source line information (and source debug information) from being lost depending on inlining. Fix occasional poor code generation for on stack AVX2 variables. Fix xor_ps was incorrectly downcoded. Fix reference version of AVX2 64-bit variable shifts intrinsics. Fix reference version of SSE4.2 cmpestrz. Fix bitwise correctness issue with SSE4.2/AVX explicit rounding in CEIL mode for negative numbers that round to zero (was not correctly computing negative zero like the h/w). Fix calls to SHUFFLE, SHUFFLE_PS and similar macro-like functions would not work in non-entrypoint functions. Source location information was offset by one on occasions. Debug metadata is now tracked on branch/switch instructions. Fix poor error reporting when intrinsic immediates were not specified as literals. Fix basic loads and stores (using explicit calls) were not unaligned and sometimes non-temporal when they shouldn't be. Removed the <>c__DisplayClass_ infix that was inserted into every Entities.ForEach in the Burst inspector to clean up the user experience when searching for Entities.ForEach jobs. Fix background compile errors accessing X86 MXCSR from job threads. Fix possible ExecutionEngineException when resolving external functions. Fix linker output not being propagated through to the Editor console. Known Issues [1.2.0-preview.9] - 2019-11-06 Fix compilation requests being lost when using asynchronous compilation. Prevent Burst compilation being toggled on while in play mode, either via \"Enable Compilation\" menu item or programmatically - was previously technically possible but produced unpredictable results. [1.2.0-preview.8] - 2019-11-01 Fix a NullReferenceException happening in a call stack involving CecilExtensions.IsDelegate(...). [1.2.0-preview.7] - 2019-10-30 Many improvements to the Inspector: New assembly syntax colorization! Fix issue with menu settings being modified when opening the Inspector. Make compile targets left pane resizable. Fix vertical scrollbar size. Add automatic refresh when selecting a target to compile. Fix an issue where ref readonly of a struct type, returned from a function, would cause a compiler crash. Add support for Interlocked.Exchange and Interlocked.CompareExchange for float and double arguments. Fix bug preventing iOS builds from working, if burst is disabled in AOT Settings. [1.2.0-preview.6] - 2019-10-16 New multi-threaded compilation support when building a standalone player. Improve BurstCompiler.CompileFunctionPointer to compile asynchronously function pointers in the Editor. Improve of error codes and messages infrastructure. Upgraded Burst to use LLVM Version 8.0.1 by default, bringing the latest optimization improvements from the LLVM project. Fix issue with libtinfo5 missing on Linux. Fix possible NullReferenceException when an entry point function is calling another empty function. Fix an exception occurring while calculating the size of a struct with indirect dependencies to itself. Fix potential failure when loading MDB debugging file. Fix linker issue with folder containing spaces. Fix issue with package validation by removing ifdef around namespaces. Fix issue with an internal compiler exception related to an empty stack. [1.2.0-preview.5] - 2019-09-23 Fix crashing issue during the shutdown of the editor. [1.2.0-preview.4] - 2019-09-20 Fix a logging issue on shutdown. [1.2.0-preview.3] - 2019-09-20 Fix potential logging of an error while shutting down the editor. [1.2.0-preview.2] - 2019-09-20 New multi-threaded compilation of jobs/function pointers in the editor. Improve caching of compiled jobs/function pointers. Fix a caching issue where some jobs/function pointers would not be updated in the editor when updating their code. Fix an issue where type initializers with interdependencies were not executed in the correct order. Fix an issue with Failed to resolve assembly Windows, Version=255.255.255.255... when building for Xbox One. Fix compilation error on ARM32 when calling an external function. Fix an issue with function pointers that would generate invalid code if a non-blittable type is used in a struct passed by ref. Fix an issue with function pointers that would generate invalid code in case containers/pointers passed to the function are memory aliased. Report a compiler error if a function pointer is trying to be compiled without having the [BurstCompile] attribute on the method and owning type. [1.2.0-preview.1] - 2019-09-09 Fix assembly caching issue, cache usage now conservative (Deals with methods that require resolving multiple assemblies prior to starting the compilation - generics). Fix Mac OS compatibility of Burst (10.10 and up) - fixes undefined symbol futimens. [1.1.3-preview.3] - 2019-09-02 Query android API target level from player settings when building android standalone players. Add calli opcode support to support bindings to native code. [1.1.3-preview.2] - 2019-08-29 Fix to allow calling [BurstDiscard] functions from static constructors. Correctly error if a DLLImport function uses a struct passed by value, but allow handle structs (structs with a single pointer/integer in them) as these require no ABI pain. Upgraded Burst to use LLVM Version 8 by default, bringing the latest optimisation improvements from the LLVM project. Added support for multiple LLVM versions, this does increase the package size, however it allows us to retain compatability with platforms that still require older versions of LLVM. Fix bug in assembly caching, subsequent runs should now correctly use cached jit code as appropriate. Add support for Lumin platform [1.1.3-preview.1] - 2019-08-26 Add support for use of the MethodImpl(MethodImplOptions.NoOptimization) on functions. Fix an issue whereby static readonly vector variables could not be constructed unless using the constructor whose number of elements matched the width of the vector. Fix an issue whereby static readonly vector variables could not be struct initialized. Improve codegen for structs with explicit layout and overlapping fields. Fix a bug causing SSE4 instructions to be run on unsupported processors. Fix an issue where storing a pointer would fail as our type normalizer would cast the pointer to an i8. Begin to add Burst-specific aliasing information by instructing LLVM on our stack-allocation and global variables rules. [1.1.2] - 2019-07-26 Fix an issue where non-readonly static variable would not fail in Burst while they are not supported. Fix issue with char comparison against an integer. Add partial support for C# char type. Improve codegen for struct layout with simple explicit layout. Fix NullReferenceException when using a static variable with a generic declaring type. Fix issue with stackalloc not clearing the allocated stack memory as it is done in .NET CLR. [1.1.1] - 2019-07-11 Fix a compiler error when using a vector type as a generic argument of a NativeHashMap container. Disable temporarily SharedStatic/Execution mode for current 2019.3 alpha8 and before. Fix detection of Android NDK for Unity 2019.3. Update documentation for known issues. [1.1.0] - 2019-07-09 Fix detection of Android NDK for Unity 2019.3. Update documentation for known issues. [1.1.0-preview.4] - 2019-07-05 Burst will now report a compilation error when writing to a [ReadOnly] container/variable. Fix regression with nested generics resolution for interface calls. Fix issue for UWP with Burst generating non appcert compliant binaries. Fix issue when reading/writing vector types to a field of an explicit layout. Fix build issue on iOS, use only hash names for platforms with clang toolchain to mitigate issues with long names in LLVM IR. Allow calls to intrinsic functions (e.g System.Math.Log) inside static constructors. Improve performance when detecting if a method needs to be recompiled at JIT time. Fix an issue with explicit struct layout and vector types. [1.1.0-preview.3] - 2019-06-28 Fix issue with generic resolution that could fail. Add support for readonly static data through generic instances. Add internal support for SharedStatic<T> for TypeManager. Add intrinsic support for math.bitmask. [1.1.0-preview.2] - 2019-06-20 Fix issue where uninitialized values would be loaded instead for native containers containing big structs. Fix issue where noalias analysis would fail for native containers containing big structs. Fix issue when calling \"internal\" methods that take bool parameters. Add support for MethodImplOptions.AggressiveInlining to force inlining. Fix issue in ABITransform that would cause compilation errors with certain explicit struct layouts. Disable debug information generation for PS4 due to IR compatability issue with latest SDK. Implemented an assembly level cache for JIT compilation to improve iteration times in the Editor. Implement a hard cap on the length of symbols to avoid problems for platforms that ingest IR for AOT. Add support for FunctionPointer<T> usable from Burst Jobs via BurstCompiler.CompileFunctionPointer<T>. Add BurstCompiler.Options to allow to control/enable/disable Burst jobs compilation/run at runtime. Add BurstRuntime.GetHashCode32<T> and GetHashCode64<T> to allow to generate a hash code for a specified time from a Burst job. [1.0.0] - 2019-04-16 Release stable version. [1.0.0-preview.14] - 2019-04-15 Bump to mathematics 1.0.1 Fix android ndk check on windows when using the builtin toolchain. Fix crash when accessing a field of a struct with an explicit layout through an embedded struct. Fix null pointer exception on building for android if editor version is less than 2019.1. Workaround IR compatibility issue with AOT builds on IOS. [1.0.0-preview.13] - 2019-04-12 Fix linker error on symbol $___check_bounds already defined. Fix StructLayout Explicit size calculation and backing storage. [1.0.0-preview.12] - 2019-04-09 Fix crash when accessing a NativeArray and performing in-place operations (e.g nativeArray[i] += 121;). [1.0.0-preview.11] - 2019-04-08 Improve error logging for builder player with Burst. Fix NullReferenceException when storing to a field which is a generic type. [1.0.0-preview.10] - 2019-04-05 Update known issues in the user manual. Improve user manual documentation about debugging, [BurstDiscard] attribute, CPU architectures supported... Fix an issue where Burst callbacks could be sent to the editor during shutdowns, causing an editor crash. Improve error messages for external tool chains when building for AOT. [1.0.0-preview.9] - 2019-04-03 Fix an auto-vectorizer issue not correctly detecting the safe usage of NativeArray access when performing in-place operations (e.g nativeArray[i] += 121;). Add support for dynamic dispatch of functions based on CPU features available at runtime. Fix issue when running SSE4 instructions on a pre-SSE4 CPU. Fix write access to NativeArray<bool>. Remove dependencies to C runtime for Windows/Linux build players (for lib_burst_generated.so/.dll). Updated API documentation. Update User manual. Static link some libraries into the Burst llvm wrapper to allow better support for some linux distros. [1.0.0-preview.8] - 2019-03-28 Fix for iOS symbol names growing too long, reduced footprint of function names via pretty printer and a hash. [1.0.0-preview.7] - 2019-03-28 Burst will now only generate debug information for AOT when targeting a Development Build. Added support for locating the build tools (standalone) for generating AOT builds on windows, without having to install Visual Studio complete. Fix Log Timings was incorrectly being passed along to AOT builds, causing them to fail. Fix editor crash if Burst aborted compilation half way through (because editor was being closed). Fix issue with job compilation that could be disabled when using the Burst inspector. Fix issue with spaces in certain paths (e.g. ANDROID_NDK_ROOT) when building for AOT. Restore behavior of compiling ios projects from windows with Burst, (Burst does not support cross compiling for ios) - we still generate a valid output project, but with no Burst code. Add support for Android embedded NDK. Fix issue where certain control flow involving object construction would crash the compiler in release mode. [1.0.0-preview.6] - 2019-03-17 Fix invalid codegen with deep nested conditionals. Fix issue with Burst menu \"Enable Compilation\" to also disable cache jobs. Improve handling of PS4 toolchain detection. [1.0.0-preview.5] - 2019-03-16 Fix regression with JIT caching that was not properly recompiling changed methods. Remove NativeDumpFlags from public API. Remove usage of PropertyChangingEventHandler to avoid conflicts with custom Newtonsoft.Json. Fix issue when a job could implement multiple job interfaces (IJob, IJobParallelFor...) but only the first one would be compiled. [1.0.0-preview.4] - 2019-03-15 Fix \"Error while verifying module: Invalid bitcast\" that could happen with return value in the context of deep nested conditionals. Fix support for AOT compilation with float precision/mode. Fix fast math for iOS/PS4. Fix issue with double not using optimized intrinsics for scalars. Fix issue when loading a MDB file was failing when building a standalone player. Fix no-alias analysis that would be disabled in a standalone player if only one of the method was failing. Fix bug with explicit layout struct returned as a pointer by a property but creating an invalid store. Change FloatPrecision.Standard defaulting from FloatPrecision.High (ULP1) to FloatPrecision.Medium (ULP3.5). [1.0.0-preview.3] - 2019-03-14 Fix compilation issue with uTiny builds. [1.0.0-preview.2] - 2019-03-13 Fix no-alias warning spamming when building a standalone player. Improve the layout of the options/buttons for the inspector so that they at least attempt to layout better when the width is too small for all the buttons. Fix formatting of error messages so the Unity Console can correctly parse the location as a clickable item (Note however it does not appear to allow double clicking on absolute paths). Change Burst menu to Jobs/Burst. Improve order of menu items. Fix for AOTSettings bug related to StandaloneWindows vs StandaloneWindows64. [1.0.0-preview.1] - 2019-03-11 Fix regression when resolving the type of generic used in a field. Fix linker for XboxOne, UWP. Fix performance codegen when using large structs. Fix codegen when a recursive function is involved with platform dependent ABI transformations. [0.2.4-preview.50] - 2019-02-27 Fix meta file conflict. Fix changelog format. [0.2.4-preview.49] - 2019-02-27 Move back com.unity.burst.experimental for function pointers support, but use internal modifier for this API. Restructure package for validation. [0.2.4-preview.48] - 2019-02-26 Move back com.unity.burst.experimental for function pointers support, but use internal modifier for this API. [0.2.4-preview.47] - 2019-02-26 Fix an issue during publish stage which was preventing to release the binaries. [0.2.4-preview.46] - 2019-02-26 iOS player builds now use static linkage (to support TestFlight) - Minimum supported Unity versions are 2018.3.6f1 or 2019.1.0b4. Fix a warning in Burst AOT settings. Enable forcing synchronous job compilation from menu. [0.2.4-preview.45] - 2019-02-07 Disable Burst AOT settings support for unity versions before 2019.1. [0.2.4-preview.44] - 2019-02-06 Fix incorrect conversions when performing subtraction with enums and floats. Fix compatability issue with future unity versions. Fix bug with ldfld bitcast on structs with explicit layouts. Guard against an issue resolving debug locations if the scope is global. [0.2.4-preview.43] - 2019-02-01 Add preliminary support for Burst AOT settings in the player settings. Move BurstCompile (delegate/function pointers support) from com.unity.burst package to com.unity.burst.experimental package. Fix issue with stackalloc allocating a pointer size for the element type resulting in possible StackOverflowException. Add support for disabling Burst compilation from Unity editor with the command line argument --burst-disable-compilation . Add support for forcing synchronous compilation from Unity editor with the command line argument --burst-force-sync-compilation. Fix a compiler crash when generating debugging information. Fix invalid codegen involving ternary operator [0.2.4-preview.42] - 2019-01-22 Fix a compilation error when implicit/explicit operators are used returning different type for the same input type. [0.2.4-preview.41] - 2019-01-17 Fix codegen issue with Interlocked.Decrement that was instead performing an increment. Fix codegen issue for an invalid layout of struct with nested recursive pointer references. Fix for Fogbugz case : https://fogbugz.unity3d.com/f/cases/1109514/. Fix codegen issue with ref bool on a method argument creating a compiler exception. [0.2.4-preview.40] - 2018-12-19 Fix bug when a write to a pointer type of an argument of a generic function. Breaking change of API: Accuracy -> FloatPrecision, and Support => FloatMode. Add FloatMode.Deterministic mode with early preview of deterministic mathematical functions. Fix bug with fonts in inspector being incorrectly reloaded. [0.2.4-preview.39] - 2018-12-06 Add preview support for readonly static arrays typically used for LUT. Fix an issue with generics incorrectly being resolved in certain situations. Fix ARM32/ARM64 compilation issues for some instructions. Fix ARM compilation issues on UWP. Fix issue with math.compress. Add support for ldnull for storing a managed null reference to a ref field (e.g for DisposeSentinel). [0.2.4-preview.38] - 2018-11-17 Fix issue when converting an unsigned integer constant to a larger unsigned integer (e.g (ulong)uint.MaxValue). Fix crash in editor when IRAnalysis can return an empty string . Fix potential crash of Cecil when reading symbols from assembly definition. [0.2.4-preview.37] - 2018-11-08 Fix a crash on Linux and MacOS in the editor with dlopen crashing when trying to load burst-llvm (linux). [0.2.4-preview.36] - 2018-11-08 Fix a crash on Linux and MacOS in the editor with dlopen crashing when trying to load burst-llvm (mac). [0.2.4-preview.35] - 2018-10-31 Try to fix a crash on macosx in the editor when a job is being compiled by Burst at startup time. Fix Burst accidentally resolving reference assemblies. Add support for Burst for ARM64 when building UWP player. [0.2.4-preview.34] - 2018-10-12 Fix compiler exception with an invalid cast that could occur when using pinned variables (e.g int32& resolved to int32** instead of int32*). [0.2.4-preview.33] - 2018-10-10 Fix a compiler crash with methods incorrectly being marked as external and throwing an exception related to ABI. [0.2.4-preview.32] - 2018-10-04 Fix codegen and linking errors for ARM when using mathematical functions on plain floats. Add support for vector types GetHashCode. Add support for DllImport (only compatible with Unity 2018.2.12f1+ and 2018.3.0b5+). Fix codegen when converting uint to int when used in a binary operation. [0.2.4-preview.31] - 2018-09-24 Fix codegen for fmodf to use inline functions instead. Add extended disassembly output to the Burst inspector. Fix generic resolution through de-virtualize methods. Fix bug when accessing float3.zero. Prevents static constructors being considered intrinsics. Fix NoAlias attribute checking when generics are used. [0.2.4-preview.30] - 2018-09-11 Fix IsValueType throwing a NullReferenceException in case of using generics. Fix discovery for Burst inspector/AOT methods inheriting from IJobProcessComponentData or interfaces with generics. Add [NoAlias] attribute. Improved codegen for csum. Improved codegen for abs(int). Improved codegen for abs on floatN/doubleN. [0.2.4-preview.29] - 2018-09-07 Fix issue when calling an explicit interface method not being matched through a generic constraint. Fix issue with or/and binary operation on a bool returned by a function. [0.2.4-preview.28] - 2018-09-05 Fix a compilation issue when storing a bool returned from a function to a component of a bool vector. Fix AOT compilation issue with a duplicated dictionary key. Fix settings of ANDROID_NDK_ROOT if it is not setup in Unity Editor. [0.2.4-preview.27] - 2018-09-03 Improve detection of jobs within nested generics for AOT/Burst inspector. Fix compiler bug of comparison of a pointer to null pointer. Fix crash compilation of sincos on ARM (neon/AARCH64). Fix issue when using a pointer to a VectorType resulting in an incorrect access of a vector type. Add support for doubles (preview). Improve AOT compiler error message/details if the compiler is failing before the linker. [0.2.4-preview.26] - 2018-08-21 Added support for cosh, sinh and tanh. [0.2.4-preview.25] - 2018-08-16 Fix warning in unity editor. [0.2.4-preview.24] - 2018-08-15 Improve codegen of math.compress. Improve codegen of math.asfloat/asint/asuint. Improve codegen of math.csum for int4. Improve codegen of math.count_bits. Support for lzcnt and tzcnt intrinsics. Fix AOT compilation errors for PS4 and XboxOne. Fix an issue that could cause wrong code generation for some unsafe ptr operations. [0.2.4-preview.23] - 2018-07-31 Fix bug with switch case to support not only int32. [0.2.4-preview.22] - 2018-07-31 Fix issue with pointers comparison not supported. Fix a StackOverflow exception when calling an interface method through a generic constraint on a nested type where the declaring type is a generic. Fix an issue with EntityCommandBuffer.CreateEntity/AddComponent that could lead to ArgumentException/IndexOutOfRangeException. [0.2.4-preview.21] - 2018-07-25 Correct issue with Android AOT compilation being unable to find the NDK. [0.2.4-preview.20] - 2018-07-05 Prepare the user documentation for a public release. [0.2.4-preview.19] - 2018-07-02 Fix compilation error with generics when types are coming from different assemblies. [0.2.4-preview.18] - 2018-06-26 Add support for subtracting pointers. [0.2.4-preview.17] - 2018-06-25 Bump only to force a new version pushed. [0.2.4-preview.16] - 2018-06-25 Fix AOT compilation errors. [0.2.4-preview.15] - 2018-06-25 Fix crash for certain access to readonly static variable. Fix StackOverflowException when using a generic parameter type into an interface method. [0.2.4-preview.14] - 2018-06-23 Fix an issue with package structure that was preventing Burst to work in Unity. [0.2.4-preview.13] - 2018-06-22 Add support for Burst timings menu. Improve codegen for sin/cos. Improve codegen when using swizzles on vector types. Add support for sincos intrinsic. Fix AOT deployment. [0.2.4-preview.12] - 2018-06-13 Fix a bug in codegen that was collapsing methods overload of System.Threading.Interlocked to the same method. [0.2.4-preview.11] - 2018-06-05 Fix exception in codegen when accessing readonly static fields from different control flow paths. [0.2.4-preview.10] - 2018-06-04 Fix a potential stack overflow issue when a generic parameter constraint on a type is also referencing another generic parameter through a generic interface constraint Update to latest Unity.Mathematics: Fix order of parameters and codegen for step functions. [0.2.4-preview.9] - 2018-05-29 Fix bug when casting an IntPtr to an enum pointer that was causing an invalid codegen exception. [0.2.4-preview.8] - 2018-05-24 Breaking change: Move Unity.Jobs.Accuracy/Support to Unity.Burst. Deprecate ComputeJobOptimizationAttribute in favor of BurstCompileAttribute. Fix bug when using enum with a different type than int. Fix bug with IL stind that could lead to a memory corruption. [0.2.4-preview.7] - 2018-05-22 Add support for nested structs in SOA native arrays. Add support for arbitrary sized elements in full SOA native arrays. Fix bug with conversion from signed/unsigned integers to signed numbers (integers & floats). Add support for substracting pointers at IL level. Improve codegen with pointers arithmetic to avoid checking for overflows. [0.2.4-preview.6] - 2018-05-11 Remove bool1 from mathematics and add proper support in Burst. Add support for ARM platforms in the Burst inspector UI. [0.2.4-preview.5] - 2018-05-09 Add support for readonly static fields. Add support for stackalloc. Fix potential crash on MacOSX when using memset is used indirectly. Fix crash when trying to write to a bool1*. Fix bug with EnableBurstCompilation checkbox not working in Unity Editor. [0.2.4-preview.4] - 2018-05-03 Fix an issue on Windows with DllNotFoundException occurring when trying to load burst-llvm.dll from a user profile containing unicode characters in the folder path. Fix an internal compiler error occurring with IL dup instruction. [0.2.4-preview.3] - 2018-05-03 Add support for struct with an explicit layout. Fix noalias regression (that was preventing the auto-vectorizer to work correctly on basic loops). [0.2.3] - 2018-03-21 Improve error messages for static field access. Improve collecting of compilable job by trying to collect concrete job type instances (issue #23). [0.2.2] - 2018-03-19 Improve error messages in case using is or as cast in C#. Improve error messages if a static delegate instance is used. Fix codegen error when converting a byte/ushort to a float."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "About Burst Getting started C# language support HPC# overview Static read-only fields and static constructor support String support Calling Burst compiled code Function pointers C#/.NET type support C#/.NET System namespace support DllImport and internal calls SharedStatic struct Burst instrinsics Burst intrinsics Common class Processor specific SIMD extensions Arm Neon intrinsics reference Editor reference Burst menu Burst Inspector Burst compilation Compilation overview Synchronous compilation BurstCompile attribute Assembly level BurstCompile BurstDiscard attribute Generic jobs Compilation warnings Building your project Burst AOT Player Settings reference Optimization Debugging and profiling tools Loop vectorization optimization Memory aliasing NoAlias attribute Aliasing and the job system AssumeRange attribute Hint intrinsic Constant intrinsic SkipLocalsInit attribute Modding support"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/aliasing-job-system.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/aliasing-job-system.html",
    "title": "Aliasing and the job system | mmo-rpg-unity",
    "keywords": "Aliasing and the job system Unity's job system infrastructure has some limitations on what can alias within a job struct: Structs attributed with [NativeContainer] (for example, NativeArray and NativeSlice) that are members of a job struct don't alias. Job struct members with the [NativeDisableContainerSafetyRestriction] attribute can alias with other members. This is because this attribute explicitly opts in to this kind of aliasing. Pointers to structs attributed with [NativeContainer] can't appear in other structs attributed with [NativeContainer]. For example, you can't have a NativeArray<NativeSlice<T>>. The following example job shows how these limitations work in practice: [BurstCompile] private struct MyJob : IJob { public NativeArray<float> a; public NativeArray<float> b; public NativeSlice<int> c; [NativeDisableContainerSafetyRestriction] public NativeArray<byte> d; public void Execute() { ... } } a, b, and c don't alias with each other. d can alias with a, b, or c. Tip If you're used to working with C/C++'s Type Based Alias Analysis (TBAA), then you might assume that because d has a different type from a, b, or c, it shouldn't alias. However, in C#, pointers don't have any assumptions that pointing to a different type results in no aliasing. This is why d is assumed to alias with a, b, or c."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/aliasing-noalias.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/aliasing-noalias.html",
    "title": "NoAlias attribute | mmo-rpg-unity",
    "keywords": "NoAlias attribute Use the [NoAlias] attribute to give Burst additional information on the aliasing of pointers and structs. In most use cases, you won't need to use the [NoAlias] attribute. You don't need to use it with [NativeContainer] attributed structs, or with fields in job structs. This is because the Burst compiler infers the no-alias information. The [NoAlias] attribute is exposed so that you can construct complex data structures where Burst can't infer the aliasing. If you use the [NoAlias] attribute on a pointer that could alias with another, it might result in undefined behavior and make it hard to track down bugs. You can use this attribute in the following ways: On a function parameter it signifies that the parameter doesn't alias with any other parameter to the function. On a struct field it signifies that the field doesn't alias with any other [NoAlias] field of the struct. On a struct it signifies that the address of the struct can't appear within the struct itself. On a function return value it signifies that the returned pointer doesn't alias with any other pointer returned from the same function. NoAlias function parameter The following is an example of aliasing: int Foo(ref int a, ref int b) { b = 13; a = 42; return b; } For this, Burst produces the following assembly: mov dword ptr [rdx], 13 mov dword ptr [rcx], 42 mov eax, dword ptr [rdx] ret This means that Burst does the following: Stores 13 into b. Stores 42 into a. Reloads the value from b to return it. Burst has to reload b because it doesn't know whether a and b are backed by the same memory or not. Add the [NoAlias] attribute to the code to change this: int Foo([NoAlias] ref int a, ref int b) { b = 13; a = 42; return b; } For this, Burst produces the following assembly: mov dword ptr [rdx], 13 mov dword ptr [rcx], 42 mov eax, 13 ret In this case, the load from b has been replaced with moving the constant 13 into the return register. NoAlias struct field The following example is the same as the previous, but applied to a struct: struct Bar { public NativeArray<int> a; public NativeArray<float> b; } int Foo(ref Bar bar) { bar.b[0] = 42.0f; bar.a[0] = 13; return (int)bar.b[0]; } For this, Burst produces the following assembly: mov rax, qword ptr [rcx + 16] mov dword ptr [rax], 1109917696 mov rcx, qword ptr [rcx] mov dword ptr [rcx], 13 cvttss2si eax, dword ptr [rax] ret In this case, Burst does the following: Loads the address of the data in b into rax. Stores 42 into it (1109917696 is 0x42280000, which is 42.0f). Loads the address of the data in a into rcx. Stores 13 into it. Reloads the data in b and converts it to an integer for returning. If you know that the two NativeArrays aren't backed by the same memory, you can change the code to the following: struct Bar { [NoAlias] public NativeArray<int> a; [NoAlias] public NativeArray<float> b; } int Foo(ref Bar bar) { bar.b[0] = 42.0f; bar.a[0] = 13; return (int)bar.b[0]; } If you attribute both a and b with [NoAlias] it tells Burst that they don't alias with each other within the struct, which produces the following assembly: mov rax, qword ptr [rcx + 16] mov dword ptr [rax], 1109917696 mov rax, qword ptr [rcx] mov dword ptr [rax], 13 mov eax, 42 ret This means that Burst can return the integer constant 42. NoAlias struct Burst assumes that the pointer to a struct doesn't appear within the struct itself. However, there are cases where this isn't true: unsafe struct CircularList { public CircularList* next; public CircularList() { // The 'empty' list just points to itself. next = this; } } Lists are one of the few structures where it's normal to have the pointer to the struct accessible from somewhere within the struct itself. The following example indicates where [NoAlias] on a struct can help: unsafe struct Bar { public int i; public void* p; } float Foo(ref Bar bar) { *(int*)bar.p = 42; return ((float*)bar.p)[bar.i]; } This produces the following assembly: mov rax, qword ptr [rcx + 8] mov dword ptr [rax], 42 mov rax, qword ptr [rcx + 8] mov ecx, dword ptr [rcx] movss xmm0, dword ptr [rax + 4*rcx] ret In this case, Burst: Loads p into rax. Stores 42 into p. Loads p into rax again. Loads i into ecx. Returns the index into p by i. In this situation, Burst loads p twice. This is because it doesn't know if p points to the address of the struct bar. Once it stores 42 into p it has to reload the address of p from bar, which is a costly operation. Add [NoAlias] to prevent this: [NoAlias] unsafe struct Bar { public int i; public void* p; } float Foo(ref Bar bar) { *(int*)bar.p = 42; return ((float*)bar.p)[bar.i]; } This produces the following assembly: mov rax, qword ptr [rcx + 8] mov dword ptr [rax], 42 mov ecx, dword ptr [rcx] movss xmm0, dword ptr [rax + 4*rcx] ret In this situation, Burst only loads the address of p once, because [NoAlias] tells it that p can't be the pointer to bar. NoAlias function return Some functions can only return a unique pointer. For instance, malloc only returns a unique pointer. In this case, [return:NoAlias] gives some useful information to Burst. Important Only use [return: NoAlias] on functions that are guaranteed to produce a unique pointer. For example, with bump-allocations, or with things like malloc. Burst aggressively inlines functions for performance considerations, so with small functions, Burst inlines them into their parents to produce the same result without the attribute. The following example uses a bump allocator backed with a stack allocation: // Only ever returns a unique address into the stackalloc'ed memory. // We've made this no-inline because Burst will always try and inline // small functions like these, which would defeat the purpose of this // example [MethodImpl(MethodImplOptions.NoInlining)] unsafe int* BumpAlloc(int* alloca) { int location = alloca[0]++; return alloca + location; } unsafe int Func() { int* alloca = stackalloc int[128]; // Store our size at the start of the alloca. alloca[0] = 1; int* ptr1 = BumpAlloc(alloca); int* ptr2 = BumpAlloc(alloca); *ptr1 = 42; *ptr2 = 13; return *ptr1; } This produces the following assembly: push rsi push rdi push rbx sub rsp, 544 lea rcx, [rsp + 36] movabs rax, offset memset mov r8d, 508 xor edx, edx call rax mov dword ptr [rsp + 32], 1 movabs rbx, offset \"BumpAlloc(int* alloca)\" lea rsi, [rsp + 32] mov rcx, rsi call rbx mov rdi, rax mov rcx, rsi call rbx mov dword ptr [rdi], 42 mov dword ptr [rax], 13 mov eax, dword ptr [rdi] add rsp, 544 pop rbx pop rdi pop rsi ret The key things that Burst does: Has ptr1 in rdi. Has ptr2 in rax. Stores 42 into ptr1. Stores 13 into ptr2. Loads ptr1 again to return it. If you add the [return: NoAlias] attribute: [MethodImpl(MethodImplOptions.NoInlining)] [return: NoAlias] unsafe int* BumpAlloc(int* alloca) { int location = alloca[0]++; return alloca + location; } unsafe int Func() { int* alloca = stackalloc int[128]; // Store our size at the start of the alloca. alloca[0] = 1; int* ptr1 = BumpAlloc(alloca); int* ptr2 = BumpAlloc(alloca); *ptr1 = 42; *ptr2 = 13; return *ptr1; } It produces the following assembly: push rsi push rdi push rbx sub rsp, 544 lea rcx, [rsp + 36] movabs rax, offset memset mov r8d, 508 xor edx, edx call rax mov dword ptr [rsp + 32], 1 movabs rbx, offset \"BumpAlloc(int* alloca)\" lea rsi, [rsp + 32] mov rcx, rsi call rbx mov rdi, rax mov rcx, rsi call rbx mov dword ptr [rdi], 42 mov dword ptr [rax], 13 mov eax, 42 add rsp, 544 pop rbx pop rdi pop rsi ret In this case, Burst doesn't reload ptr2, and moves 42 into the return register."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/aliasing.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/aliasing.html",
    "title": "Memory aliasing | mmo-rpg-unity",
    "keywords": "Memory aliasing Memory aliasing is a way to tell Burst how your code uses data. This can improve and optimize the performance of your application. Memory aliasing happens when locations in the memory overlap each other. The following documentation outlines the difference between memory aliasing, and no memory aliasing. The following example shows a job that copies data from an input array to an output array: [BurstCompile] private struct CopyJob : IJob { [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public void Execute() { for (int i = 0; i < Input.Length; i++) { Output[i] = Input[i]; } } } No memory aliasing If the arrays Input and Output don't overlap, which means that their respective memory location doesn't overlap, the code returns the following result after running this job on a sample input/output: Memory with no aliasing If Burst is noalias aware, it can work at the scalar level to optimize the previous scalar loop. It does this through a process called vectorizing, where it rewrites the loop to process elements in a small batch. For example, Burst could work at vector level in 4 by 4 elements: Memory with no aliasing vectorized Memory aliasing If the Output array overlaps the Input array by one element (for example Output[0] points to Input[1]), then this means that the memory is aliasing. This gives the following result when you run CopyJob without the auto vectorizer: Memory with aliasing If Burst isn't aware of the memory aliasing, it tries to auto vectorize the loop, which results in the following: Memory with aliasing and invalid vectorized code The result of this code is invalid and might lead to bugs if Burst can't identify them. Generated code In the CopyJob example, there is an x64 assembly targeted at AVX2 in its loop. The instruction vmovups moves 8 floats, so a single auto vectorized loop moves 4 × 8 floats, which equals 32 floats copied per loop iteration, instead of just one: .LBB0_4: vmovups ymm0, ymmword ptr [rcx - 96] vmovups ymm1, ymmword ptr [rcx - 64] vmovups ymm2, ymmword ptr [rcx - 32] vmovups ymm3, ymmword ptr [rcx] vmovups ymmword ptr [rdx - 96], ymm0 vmovups ymmword ptr [rdx - 64], ymm1 vmovups ymmword ptr [rdx - 32], ymm2 vmovups ymmword ptr [rdx], ymm3 sub rdx, -128 sub rcx, -128 add rsi, -32 jne .LBB0_4 test r10d, r10d je .LBB0_8 The following example shows the same Burst compiled loop, but Burst's aliasing is artificially disabled: .LBB0_2: mov r8, qword ptr [rcx] mov rdx, qword ptr [rcx + 16] cdqe mov edx, dword ptr [rdx + 4*rax] mov dword ptr [r8 + 4*rax], edx inc eax cmp eax, dword ptr [rcx + 8] jl .LBB0_2 The result is entirely scalar and runs approximately 32 times slower than the highly optimized, vectorized variant that the original alias analysis produces. Function cloning For function calls where Burst knows about the aliasing between parameters to the function, Burst can infer the aliasing. It can then propagate this onto the called function to improve optimization: [MethodImpl(MethodImplOptions.NoInlining)] int Bar(ref int a, ref int b) { a = 42; b = 13; return a; } int Foo() { var a = 53; var b = -2; return Bar(ref a, ref b); } The assembly for Bar would be: mov dword ptr [rcx], 42 mov dword ptr [rdx], 13 mov eax, dword ptr [rcx] ret This is because Burst doesn't know the aliasing of a and b within the Bar function. This is in line with what other compiler technologies do with this code snippet. Burst is smarter than this though. Through a process of function cloning, Burst creates a copy of Bar where it knows that the aliasing properties of a and b don't alias. It then replaces the original call to Bar with a call to the copy. This results in the following assembly: mov dword ptr [rcx], 42 mov dword ptr [rdx], 13 mov eax, 42 ret In this scenario, Burst doesn't perform the second load from a. Aliasing checks Because aliasing is key to Burst's ability to optimize for performance, there are some aliasing intrinsics: Unity.Burst.CompilerServices.Aliasing.ExpectAliased expects that the two pointers do alias, and generates a compiler error if not. Unity.Burst.CompilerServices.Aliasing.ExpectNotAliased expects that the two pointers don't alias, and generates a compiler error if not. An example: using static Unity.Burst.CompilerServices.Aliasing; [BurstCompile] private struct CopyJob : IJob { [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public unsafe void Execute() { // NativeContainer attributed structs (like NativeArray) cannot alias with each other in a job struct! ExpectNotAliased(Input.getUnsafePtr(), Output.getUnsafePtr()); // NativeContainer structs cannot appear in other NativeContainer structs. ExpectNotAliased(in Input, in Output); ExpectNotAliased(in Input, Input.getUnsafePtr()); ExpectNotAliased(in Input, Output.getUnsafePtr()); ExpectNotAliased(in Output, Input.getUnsafePtr()); ExpectNotAliased(in Output, Output.getUnsafePtr()); // But things definitely alias with themselves! ExpectAliased(in Input, in Input); ExpectAliased(Input.getUnsafePtr(), Input.getUnsafePtr()); ExpectAliased(in Output, in Output); ExpectAliased(Output.getUnsafePtr(), Output.getUnsafePtr()); } } These checks only run when optimizations are enabled, because proper aliasing deduction is intrinsically linked to the optimizer's ability to see through functions via inlining."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/building-aot-settings.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/building-aot-settings.html",
    "title": "Burst AOT Player Settings reference | mmo-rpg-unity",
    "keywords": "Burst AOT Player Settings reference To control Burst's AOT compilation, use the Player Settings window (Edit > Player Settings > Burst AOT Settings). These settings override the Burst settings in the Jobs menu when you make a build of your project. Setting Function Target Platform Displays the current platform. To change the platform, go to File > Build Settings. You can set these Player Settings per platform. Enable Burst Compilation Enable this setting to turn Burst compilation on. Disable this setting to deactivate Burst compilation for the selected platform. Enable Optimizations Enable this setting to activate Burst optimizations. Force Debug Information Enable this setting to make Burst generate debug information. This adds debug symbols to your project, even in release builds of your project, so that when you load it in a debugger you can see file and line information. Use Platform SDK Linker (Windows, macOS, and Linux builds only) Disables cross compilation support. When you enable this setting, you must use platform-specific tools for your target platform. Only enable this setting for debugging purposes. For more information, see Platforms with cross compilation disabled. Target 32Bit CPU Architectures (Displayed if the architecture is supported) Select the CPU architectures that you want to use for 32 bit builds. By default, SSE2 and SSE4 are selected. Target 64Bit CPU Architectures (Displayed if the architecture is supported) Select the CPU architectures that you want to use for 64-bit builds. By default, SSE2 and SSE4 are selected. Target Arm 64Bit CPU Architectures (Displayed if the architecture is supported) Select the CPU architectures that you want to use for Arm 64-bit builds. By default, ARMV8A is selected. Optimize For Select which optimization settings to compile Burst code for. For more information see OptimizeFor. Performance Optimizes the job to run as fast as possible. Size Optimizes to make the code generation as small as possible. Fast Compilation Compiles code as fast as possible, with minimal optimization. Burst doesn't perform any vectorization, inlining, or loop optimizations. Balanced (Default) Optimizes for code that runs fast but keeps compile time as low as possible. Disabled Warnings Specify a semi-colon separated list of Burst warning numbers to disable the warnings for a player build. Unity shares this setting across all platforms. This can be useful if you want to ignore specific compilation warnings while testing your application. The CPU Architecture setting is only supported for Windows, macOS, Linux and Android. Unity builds a Player that supports the CPU architectures you've selected. Burst generates a special dispatch into the module, so that the code generated detects the CPU the target platform uses and selects the appropriate CPU architecture at runtime. Optimize For setting Note Any OptimizeFor setting is the global default optimization setting for any Burst job or function-pointer. If any assembly level BurstCompile, or a specific Burst job or function-pointer has an OptimizeFor setting, it overrides the global optimization setting for those jobs. To control how Burst optimizes your code, use the Optimize For setting in the Editor, or use the OptimizeFor field: [BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)] public struct MyJob : IJob { // ... }"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/building-projects.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/building-projects.html",
    "title": "Building your project | mmo-rpg-unity",
    "keywords": "Building your project When you build your project, Burst compiles your code, then creates a single dynamic library, and puts it into the Plugins folder for the platform you're targeting. For example, on Windows, the path is Data/Plugins/lib_burst_generated.dll. Note This is different if your target platform is iOS. Instead, Unity generates a static library because of Apple's submission requirements for TestFlight. The job system runtime loads the generated library the first time a Burst compiled method is invoked. To control Burst's AOT compilation, use the settings in the Burst AOT Settings section of the Player Settings window (Edit > Player Settings > Burst AOT Settings). For more information, see Burst AOT Settings reference. Platforms without cross compilation If you're compiling for a non-desktop platform, then Burst compilation requires specific platform compilation tools (similar to IL2CPP). By default, desktop platforms (macOS, Linux, Windows) don't need external toolchain support, unless you enable the Use Platform SDK Linker setting in the Burst AOT Settings. The table below lists the level of support for AOT compilation on each platform. If you select an invalid target (one with missing tools, or unsupported), Unity doesn't use Burst compilation, which might lead it to fail, but Unity still builds the target without Burst optimizations. Note Burst supports cross-compilation between desktop platforms (macOS/Linux/Windows) by default. Host Editor platform Target Player platform Supported CPU architectures External toolchain requirements Windows Windows x86 (SSE2, SSE4) x64 (SSE2, SSE4, AVX, AVX2) None Windows Universal Windows Platform x86 (SSE2, SSE4) x64 (SSE2, SSE4, AVX, AVX2) ARM32 (Thumb2, Neon32) ARMV8 AARCH64 Note: A UWP build always compiles all four targets. Visual Studio 2017 Universal Windows Platform Development Workflow C++ Universal Platform Tools Windows Android x86 SSE2 ARMV7 (Thumb2, Neon32) ARMV8 AARCH64 (ARMV8A, ARMV8A_HALFFP, ARMV9A) Android NDK Important: Use the Android NDK that you install through Unity Hub (via Add Component). Burst falls back to the one that the ANDROID_NDK_ROOT environment variable specifies if the Unity external tools settings aren't configured. Windows Magic Leap ARMV8 AARCH64 You must install the Lumin SDK via the Magic Leap Package Manager and configured in the Unity Editor's External Tools Preferences. Windows Xbox One x64 SSE4 Microsoft GDK Windows Xbox Series x64 AVX2 Microsoft GDK Windows PlayStation 4 x64 SSE4 Minimum PS4 SDK version 8.00 Windows PlayStation 5 x64 AVX2 Minimum PS5 SDK version 2.00 Windows Nintendo Switch ARMV8 AARCH64 None macOS macOS x64 (SSE2, SSE4, AVX, AVX2), Apple Silicon None macOS iOS ARM32 Thumb2/Neon32, ARMV8 AARCH64 Xcode with command line tools installed (xcode-select --install) macOS Android x86 SSE2 ARMV7 (Thumb2, Neon32) ARMV8 AARCH64 (ARMV8A, ARMV8A_HALFFP, ARMV9A) Android NDK Important: Use the Android NDK that you install through Unity Hub (via Add Component). Burst falls back to the one that the ANDROID_NDK_ROOT environment variable specifies if the Unity external tools settings aren't configured. macOS Magic Leap ARMV8 AARCH64 You must install the Lumin SDK via the Magic Leap Package Manager and configured in the Unity Editor's External Tools Preferences. Linux Linux x64 (SSE2, SSE4, AVX, AVX2) None The maximum target CPU is hardcoded per platform. For standalone builds that target desktop platforms (Windows/Linux/macOS) you can choose the supported targets via the Burst AOT Settings Projects that don't use Burst Some projects can't use Burst as the compiler: iOS projects from the Windows Editor Android projects from the Linux Editor Xcode projects generated from the Create Xcode Project option Multiple Burst targets When Burst compiles multiple target platforms during a build, it has to perform separate compilations. For example, if you want to compile X64_SSE2 and X64_SSE4, the Burst has to do two separate compilations to generate code for each of the targets you choose. To keep the combinations of targets to a minimum, Burst target platforms require multiple processor instruction sets underneath: SSE4.2 is gated on having SSE4.2 and POPCNT instruction sets. AVX2 is gated on having AVX2, FMA, F16C, BMI1, and BMI2 instruction sets. ARMV8A is a basic Armv8-A CPU target ARMV8A_HALFFP is ARMV8A plus the following extensions: fullfp16, dotprod, crypto, crc, rdm, lse. In practice, this means Cortex A75/A55 and later cores. ARMV9A is ARMV8A_HALFFP plus SVE2 support. In practice, this means Cortex X2/A710/A510 and later cores. Important: this target is currently experimental. Dynamic dispatch based on runtime CPU features For all x86/x64 CPU desktop platforms, as well as for 64-bit Arm on Android, Burst takes into account the CPU features available at runtime to dispatch jobs to different versions it compiles. For x86 and x64 CPUs, Burst supports SSE2 and SSE4 instruction sets at runtime only. For example, with dynamic CPU dispatch, if your CPU supports SSE3 and below, Burst selects SSE2 automatically."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-burstcompile-assembly.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-burstcompile-assembly.html",
    "title": "Assembly level BurstCompile | mmo-rpg-unity",
    "keywords": "Assembly level BurstCompile Use the BurstCompile attribute on an assembly to set options for all Burst jobs and function-pointers within the assembly: [assembly: BurstCompile(CompileSynchronously = true)] For example, if an assembly just contains game code which needs to run quickly, you can use: [assembly: BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)] This means that Burst compiles the code as fast as it possibly can, which means that you can iterate on the game code much more quickly. It also means that other assemblies compile as they did before, which gives you more control on how Burst works with your code. Assembly-level BurstCompile attributes iterate with any job or function-pointer attribute, and also with any globally set options from the Burst Editor menu. Burst prioritizes assembly level attributes in the following order: Editor menu settings take precedence. For example, if you enable Native Debug Compilation from the Burst menu, Burst always compiles your code ready for debugging. Burst checks any BurstCompile attribute on a job or function-pointer. If you have CompileSynchronously = true in BurstCompile, then Burst compiles synchronously Otherwise, Burst sources any remaining settings from any assembly level attribute. For example: [assembly: BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)] // This job will be optimized for fast-compilation, because the per-assembly BurstCompile asked for it [BurstCompile] struct AJob : IJob { // ... } // This job will be optimized for size, because the per-job BurstCompile asked for it [BurstCompile(OptimizeFor = OptimizeFor.Size)] struct BJob : IJob { // ... }"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-burstcompile.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-burstcompile.html",
    "title": "BurstCompile attribute | mmo-rpg-unity",
    "keywords": "BurstCompile attribute To improve the performance of Burst, you can change how it behaves when it compiles a job with the [BurstCompile] attribute. Use it do the following: Use a different accuracy for math functions (for example, sin, cos). Relax the order of math computations so that Burst can rearrange the floating point calculations. Force a synchronous compilation of a job (only for just-in-time compilation). For example, you can use the [BurstCompile] attribute to change the floating precision and float mode of Burst like so: [BurstCompile(FloatPrecision.Med, FloatMode.Fast)] FloatPrecision Use the FloatPrecision enumeration to define Burst's floating precision accuracy. Float precision is measured in ulp (unit in the last place or unit of least precision). This is the space between floating-point numbers: the value the least significant digit represents if it's 1. Unity.Burst.FloatPrecision provides the following accuracy: FloatPrecision.Standard: Default value, which is the same as FloatPrecision.Medium. This provides an accuracy of 3.5 ulp. FloatPrecision.High: Provides an accuracy of 1.0 ulp. FloatPrecision.Medium: Provides an accuracy of 3.5 ulp. FloatPrecision.Low: Has an accuracy defined per function, and functions might specify a restricted range of valid inputs. Note: In previous versions of the Burst API, the FloatPrecision enum was named Accuracy. FloatPrecision.Low If you use the FloatPrecision.Low mode, the following functions have a precision of 350.0 ulp. All other functions inherit the ulp from FloatPrecision.Medium. Unity.Mathematics.math.sin(x) Unity.Mathematics.math.cos(x) Unity.Mathematics.math.exp(x) Unity.Mathematics.math.exp2(x) Unity.Mathematics.math.exp10(x) Unity.Mathematics.math.log(x) Unity.Mathematics.math.log2(x) Unity.Mathematics.math.log10(x) Unity.Mathematics.math.pow(x, y) Negative x to the power of a fractional y aren't supported. Unity.Mathematics.math.fmod(x, y) FloatMode Use the FloatMode enumeration to define Burst's floating point math mode. It provides the following modes: FloatMode.Default: Defaults to FloatMode.Strict mode. FloatMode.Strict: Burst doesn't perform any re-arrangement of the calculation and respects special floating point values (such as denormals, NaN). This is the default value. FloatMode.Fast: Burst can perform instruction re-arrangement and use dedicated or less precise hardware SIMD instructions. FloatMode.Deterministic: Unsupported. Deterministic mode is reserved for a future iteration of Burst. For hardware that can support Multiply and Add (e.g mad a * b + c) into a single instruction, you can use FloatMode.Fast to enable this optimization. However, the reordering of these instructions might lead to a lower accuracy. Use FloatMode.Fast for scenarios where the exact order of the calculation and the uniform handling of NaN values aren't required."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-burstdiscard.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-burstdiscard.html",
    "title": "BurstDiscard attribute | mmo-rpg-unity",
    "keywords": "BurstDiscard attribute If you're running C# code not inside Burst-compiled code, you might want to use managed objects, but not compile these portions of code within Burst. To do this, use the [BurstDiscard] attribute on a method: [BurstCompile] public struct MyJob : IJob { public void Execute() { // Only executed when running from a full .NET runtime // this method call will be discard when compiling this job with // [BurstCompile] attribute MethodToDiscard(); } [BurstDiscard] private static void MethodToDiscard(int arg) { Debug.Log($\"This is a test: {arg}\"); } } Note A method with [BurstDiscard] can't have a return value. You can use a ref or out parameter, which indicates whether the code is running on Burst or managed: [BurstDiscard] private static void SetIfManaged(ref bool b) => b = false; private static bool IsBurst() { var b = true; SetIfManaged(ref b); return b; }"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-generic-jobs.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-generic-jobs.html",
    "title": "Generic jobs | mmo-rpg-unity",
    "keywords": "Generic jobs Burst compiles a job in two ways: In the Editor, it compiles the job when it's scheduled, known as just-in-time (JIT) compilation. In a player build, it compiles the job as part of the built player, known as ahead-of-time (AOT) compilation. For more information, see the documentation on Compilation. If the job is a concrete type (doesn't use generics), Burst compiles it in both modes (AOT and JIT). However, a generic job might behave in an unexpected way. While Burst supports generics, it has limited support for generic jobs or function pointers. If you notice that a job scheduled in the Editor is running at full speed, but not in a built player, it's might be a problem related to generic jobs. The following example defines a generic job: // Direct generic job [BurstCompile] struct MyGenericJob<TData> : IJob where TData : struct { public void Execute() { ... } } You can also nest generic jobs: // Nested generic job public class MyGenericSystem<TData> where TData : struct { [BurstCompile] struct MyGenericJob : IJob { public void Execute() { ... } } public void Run() { var myJob = new MyGenericJob(); // implicitly MyGenericSystem<TData>.MyGenericJob myJob.Schedule(); } } Jobs that aren't Burst compiled look like this: // Direct Generic Job var myJob = new MyGenericJob<int>(); myJob.Schedule(); // Nested Generic Job var myJobSystem = new MyGenericSystem<float>(); myJobSystem.Run(); In both cases, in a player build, the Burst compiler detects that it has to compile MyGenericJob<int> and MyGenericJob<float>. This is because the generic jobs (or the type surrounding it for the nested job) are used with fully resolved generic arguments (int and float). However, if these jobs are used indirectly through a generic parameter, the Burst compiler can't detect the jobs it has to compile at player build time: public static void GenericJobSchedule<TData>() where TData: struct { // Generic argument: Generic Parameter TData // This Job won't be detected by the Burst Compiler at standalone-player build time. var job = new MyGenericJob<TData>(); job.Schedule(); } // The implicit MyGenericJob<int> will run at Editor time in full Burst speed // but won't be detected at standalone-player build time. GenericJobSchedule<int>(); The same restriction applies if you declare the job in the context of generic parameter that comes from a type: // Generic Parameter TData public class SuperJobSystem<TData> { // Generic argument: Generic Parameter TData // This Job won't be detected by the Burst Compiler at standalone-player build time. public MyGenericJob<TData> MyJob; } If you want to use generic jobs, you must use them directly with fully resolved generic arguments (for example, int, MyOtherStruct). You can't use them with a generic parameter indirection (for example, MyGenericJob<TContext>). Important Burst doesn't support scheduling generic Jobs through generic methods. Function pointers Function pointers are restricted because you can't use a generic delegate through a function pointer with Burst: public delegate void MyGenericDelegate<T>(ref TData data) where TData: struct; var myGenericDelegate = new MyGenericDelegate<int>(MyIntDelegateImpl); // Will fail to compile this function pointer. var myGenericFunctionPointer = BurstCompiler.CompileFunctionPointer<MyGenericDelegate<int>>(myGenericDelegate); This limitation is because of a limitation of the .NET runtime to interop with such delegates. For more information, see the documentation on Function pointers."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-overview.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-overview.html",
    "title": "Compilation overview | mmo-rpg-unity",
    "keywords": "Compilation overview Burst compiles your code in different ways depending on its context. In Play mode, Burst compiles your code just-in-time (JIT). When you build and run your application to a player, Burst compiles ahead-of-time (AOT). Just-in-time compilation While your application is in Play mode in the Editor, Burst compiles your code asynchronously at the point that Unity uses it. This means that your code runs under the default Mono compiler until Burst completes its work in the background. To force Unity to compile your code synchronously while in the Editor, see Synchronous compilation Ahead-of-time compilation When you build your project, Burst compiles all the supported code ahead-of-time (AOT) into a native library which Unity ships with your application. To control how Burst compiles AOT, use the Player Settings window. Depending on the platform you want to build for, AOT compilation might require access to linker tools. For more information, see Building your project. Further resources Synchronous compilation BurstCompile attribute"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-synchronous.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-synchronous.html",
    "title": "Synchronous compilation | mmo-rpg-unity",
    "keywords": "Synchronous compilation By default, when in Play mode, the Burst compiler compiles jobs asynchronously. To force synchronous compilation, set the CompileSynchronously property to true, which compiles your method on the first schedule. [BurstCompile(CompileSynchronously = true)] public struct MyJob : IJob { // ... } If you don't set this property, on the first call of a job, Burst compiles it asynchronously in the background, and runs a managed C# job in the mean time. This minimizes any frame hitching and keeps the experience responsive. However, when you set CompileSynchronously = true, no asynchronous compilation can happen. This means that it might take longer for Burst to compile. This pause for compilation affects the current running frame, which means that hitches can happen and it might provide an unresponsive experience for users. In general, only use CompileSynchronously = true in the following situations: If you have a long running job that only runs once. The performance of the compiled code might outweigh the downsides doing the compilation synchronously. If you're profiling a Burst job and want to test the code from the Burst compiler. When you do this, perform a warmup to discard any timing measurements from the first call to the job. This is because the profiling data includes the compilation time and skews the result. To aid with debugging the difference between managed and Burst compiled code."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-warnings.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation-warnings.html",
    "title": "Compilation warnings | mmo-rpg-unity",
    "keywords": "Compilation warnings This page describes common compilation warnings, and how to fix them. IgnoreWarning attribute The Unity.Burst.CompilerServices.IgnoreWarningAttribute attribute lets you suppress warnings for a specific function that is being compiled from Burst. However, the warnings that the Burst compiler generates are very important to pay attention to, so this attribute should be used sparingly and only when necessary. The sections below describe the specific situations in which you might want to suppress warnings. BC1370 Warning BC1370 produces the message: An exception was thrown from a function without the correct [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")] guard... This warning happens if Unity encounters a throw in code that [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")] doesn't guard. In the Editor, thrown exceptions will be caught and logged to the Console, but in a Player build, a throw becomes an abort, which crashes your application. Burst warns you about these exceptions, and advises you to place them in functions guarded with [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")], because functions guarded with that attribute will not be included in Player builds. However, if you want to purposely throw an exception to crash your application, use the IgnoreWarningAttribute to suppress the warnings that Burst provides on the throw: [IgnoreWarning(1370)] int DoSomethingMaybe(int x) { if (x < 0) throw new Exception(\"Dang - sorry I crashed your game!\"); return x * x; } Note This warning is only produced for exceptions that persist into Player builds. Editor-only or debug-only exception throws that aren't compiled into Player builds will not trigger this warning. BC1371 Warning BC1371 produces the message: A call to the method 'xxx' has been discarded, due to its use as an argument to a discarded method... To understand this warning, consider the following example: [BurstDiscard] static void DoSomeManagedStuff(int x) { ///.. only run when Burst compilation is disabled } // A function that computes some result which we need to pass to managed code int BurstCompiledCode(int x,int y) { return y+2*x; } [BurstCompile] void BurstMethod() { var myValue = BurstCompiledCode(1,3); DoSomeManagedStuff(myValue); } When Unity compiles your C# code in release mode, it optimizes and removes the local variable myValue. This means that Burst receives something like the following code : [BurstCompile] void BurstedMethod() { DoSomeManagedStuff(BurstCompiledCode(1,3)); } This makes Burst generate the warning, because Burst discards DoSomeManagedStuff, along with the BurstCompiledCode argument. This means that the BurstCompiledCode function is no longer executed, which generates the warning. If this isn't what you intended then ensure the variable has multiple uses. For example: void IsUsed(ref int x) { // Dummy function to prevent removal } [BurstCompile] void BurstedMethod() { var myValue = BurstCompiledCode(1,3); DoSomeManagedStuff(myValue); IsUsed(ref myValue); } Alternatively, if you're happy that the code is being discarded correctly, ignore the warning on the BurstedMethod like so: [IgnoreWarning(1371)] [BurstCompile] void BurstMethod() { var myValue = BurstCompiledCode(1,3); DoSomeManagedStuff(myValue); }"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/compilation.html",
    "title": "Compilation | mmo-rpg-unity",
    "keywords": "Compilation Burst compiles your code in different ways, depending on its context. You can also change the way that the compiler behaves when compiling code. Topic Description Compilation overview Understand the different compilation types. Synchronous compilation Understand synchronous compilation. BurstCompile attribute Customize the BurstCompile attribute to improve performance. BurstDiscard attribute Use the BurstDiscard attribute to select which portions of code to compile. Generic jobs Understand how Burst compiles jobs. Compilation warnings Fix common compilation warnings. Additional resources C# language support"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics-common.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics-common.html",
    "title": "Burst Intrinsics Common class | mmo-rpg-unity",
    "keywords": "Burst Intrinsics Common class The Unity.Burst.Intrinsics.Common intrinsics are for functionality shared across the hardware targets that Burst supports. Pause Unity.Burst.Intrinsics.Common.Pause is an intrinsic that requests that the CPU pause the current thread. It maps to pause on x86, and yield on ARM. Use it to stop spin locks over contending on an atomic access, which reduces contention and power on that section of code. Prefetch The Unity.Burst.Intrinsics.Common.Prefetch is an experimental intrinsic that provides a hint that Burst should prefetch the memory location into the cache. Because the intrinsic is experimental, you must use the UNITY_BURST_EXPERIMENTAL_PREFETCH_INTRINSIC preprocessor define to get access to it. umul128 Use the Unity.Burst.Intrinsics.Common.umul128 intrinsic to access 128-bit unsigned multiplication. These multiplies are useful for hashing functions. It maps 1:1 with hardware instructions on x86 and ARM targets. InterlockedAnd & InterlockedOr The Unity.Burst.Intrinsics.Common.InterlockedAnd and Unity.Burst.Intrinsics.Common.InterlockedOr are experimental intrinsics that provides atomic and/or operations on int, uint, long, and ulong types. Because these intrinsics are experimental, you must use the UNITY_BURST_EXPERIMENTAL_ATOMIC_INTRINSICS preprocessor define to get access to them."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics-dllimport.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics-dllimport.html",
    "title": "| mmo-rpg-unity",
    "keywords": "DllImport and internal calls To call native functions, use [DllImport]: [DllImport(\"MyNativeLibrary\")] public static extern int Foo(int arg); Burst also supports internal calls implemented inside Unity: // In UnityEngine.Mathf [MethodImpl(MethodImplOptions.InternalCall)] public static extern int ClosestPowerOfTwo(int value); DllImport is only supported for native plug-ins, not platform-dependent libraries like kernel32.dll. For all DllImport and internal calls, you can only use the following types as parameter or return types: Type Supported type Built-in and intrinsic types byte / sbyte short / ushort int / uint long / ulong float double System.IntPtr / System.UIntPtr Unity.Burst.Intrinsics.v64 / Unity.Burst.Intrinsics.v128 / Unity.Burst.Intrinsics.v256 Pointers and references sometype* : Pointer to any of the other types in this list ref sometype : Reference to any of the other types in this list Handle structs unsafe struct MyStruct { void* Ptr; } : Struct containing a single pointer field unsafe struct MyStruct { int Value; } : Struct containing a single integer field Note Passing structs by value isn't supported; you need to pass them through a pointer or reference. The only exception is that handle structs are supported. These are structs that contain a single field of pointer or integer type."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics-neon.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics-neon.html",
    "title": "Burst Arm Neon intrinsics reference | mmo-rpg-unity",
    "keywords": "Burst Arm Neon intrinsics reference This page contains an ordered reference for the APIs in Unity.Burst.Intrinsics.Arm.Neon. For information on how to use these, see the documentation on Processor specific SIMD extensions. Intrinsics type creation and conversion Operation Description APIs vcreate Create vector Click here to expand the API list vcreate_f16 vcreate_f32 vcreate_f64 vcreate_s16 vcreate_s32 vcreate_s64 vcreate_s8 vcreate_u16 vcreate_u32 vcreate_u64 vcreate_u8 vdup_n Duplicate (splat) value Click here to expand the API list vdup_n_f32 vdup_n_f64 vdup_n_s16 vdup_n_s32 vdup_n_s64 vdup_n_s8 vdup_n_u16 vdup_n_u32 vdup_n_u64 vdup_n_u8 vdupq_n_f32 vdupq_n_f64 vdupq_n_s16 vdupq_n_s32 vdupq_n_s64 vdupq_n_s8 vdupq_n_u16 vdupq_n_u32 vdupq_n_u64 vdupq_n_u8 vdup_lane Duplicate (splat) vector element Click here to expand the API list vdup_lane_f32 vdup_lane_f64 vdup_lane_s16 vdup_lane_s32 vdup_lane_s64 vdup_lane_s8 vdup_lane_u16 vdup_lane_u32 vdup_lane_u64 vdup_lane_u8 vdup_laneq_f32 vdup_laneq_f64 vdup_laneq_s16 vdup_laneq_s32 vdup_laneq_s64 vdup_laneq_s8 vdup_laneq_u16 vdup_laneq_u32 vdup_laneq_u64 vdup_laneq_u8 vdupq_lane_f32 vdupq_lane_f64 vdupq_lane_s16 vdupq_lane_s32 vdupq_lane_s64 vdupq_lane_s8 vdupq_lane_u16 vdupq_lane_u32 vdupq_lane_u64 vdupq_lane_u8 vdupq_laneq_f32 vdupq_laneq_f64 vdupq_laneq_s16 vdupq_laneq_s32 vdupq_laneq_s64 vdupq_laneq_s8 vdupq_laneq_u16 vdupq_laneq_u32 vdupq_laneq_u64 vdupq_laneq_u8 vdups_lane_f32 vdups_lane_s32 vdups_lane_u32 vdups_laneq_f32 vdups_laneq_s32 vdups_laneq_u32 vdupb_lane_s8 vdupb_lane_u8 vdupb_laneq_s8 vdupb_laneq_u8 vdupd_lane_f64 vdupd_lane_s64 vdupd_lane_u64 vdupd_laneq_f64 vdupd_laneq_s64 vdupd_laneq_u64 vduph_lane_s16 vduph_lane_u16 vduph_laneq_s16 vduph_laneq_u16 vmov_n Duplicate (splat) value Click here to expand the API list vmov_n_f32 vmov_n_f64 vmov_n_s16 vmov_n_s32 vmov_n_s64 vmov_n_s8 vmov_n_u16 vmov_n_u32 vmov_n_u64 vmov_n_u8 vmovq_n_f32 vmovq_n_f64 vmovq_n_s16 vmovq_n_s32 vmovq_n_s64 vmovq_n_s8 vmovq_n_u16 vmovq_n_u32 vmovq_n_u64 vmovq_n_u8 vcopy_lane Insert vector element from another vector element Click here to expand the API list vcopy_lane_f32 vcopy_lane_f64 vcopy_lane_s16 vcopy_lane_s32 vcopy_lane_s64 vcopy_lane_s8 vcopy_lane_u16 vcopy_lane_u32 vcopy_lane_u64 vcopy_lane_u8 vcopy_laneq_f32 vcopy_laneq_f64 vcopy_laneq_s16 vcopy_laneq_s32 vcopy_laneq_s64 vcopy_laneq_s8 vcopy_laneq_u16 vcopy_laneq_u32 vcopy_laneq_u64 vcopy_laneq_u8 vcopyq_lane_f32 vcopyq_lane_f64 vcopyq_lane_s16 vcopyq_lane_s32 vcopyq_lane_s64 vcopyq_lane_s8 vcopyq_lane_u16 vcopyq_lane_u32 vcopyq_lane_u64 vcopyq_lane_u8 vcopyq_laneq_f32 vcopyq_laneq_f64 vcopyq_laneq_s16 vcopyq_laneq_s32 vcopyq_laneq_s64 vcopyq_laneq_s8 vcopyq_laneq_u16 vcopyq_laneq_u32 vcopyq_laneq_u64 vcopyq_laneq_u8 vcombine Join two vectors into a larger vector Click here to expand the API list vcombine_f16 vcombine_f32 vcombine_f64 vcombine_s16 vcombine_s32 vcombine_s64 vcombine_s8 vcombine_u16 vcombine_u32 vcombine_u64 vcombine_u8 vget_high Get the higher half of the vector Click here to expand the API list vget_high_f32 vget_high_f64 vget_high_s16 vget_high_s32 vget_high_s64 vget_high_s8 vget_high_u16 vget_high_u32 vget_high_u64 vget_high_u8 vget_low Get the lower half of the vector Click here to expand the API list vget_low_f32 vget_low_f64 vget_low_s16 vget_low_s32 vget_low_s64 vget_low_s8 vget_low_u16 vget_low_u32 vget_low_u64 vget_low_u8 Arithmetic Operation Description APIs vadd Add Click here to expand the API list vadd_f32 vadd_f64 vadd_s16 vadd_s32 vadd_s64 vadd_s8 vadd_u16 vadd_u32 vadd_u64 vadd_u8 vaddq_f32 vaddq_f64 vaddq_s16 vaddq_s32 vaddq_s64 vaddq_s8 vaddq_u16 vaddq_u32 vaddq_u64 vaddq_u8 vaddd_s64 vaddd_u64 vaddv Add across vector Click here to expand the API list vaddv_f32 vaddv_s16 vaddv_s32 vaddv_s8 vaddv_u16 vaddv_u32 vaddv_u8 vaddvq_f32 vaddvq_f64 vaddvq_s16 vaddvq_s32 vaddvq_s64 vaddvq_s8 vaddvq_u16 vaddvq_u32 vaddvq_u64 vaddvq_u8 vaddl Add long Click here to expand the API list vaddl_s16 vaddl_s32 vaddl_s8 vaddl_u16 vaddl_u32 vaddl_u8 vaddl_high_s16 vaddl_high_s32 vaddl_high_s8 vaddl_high_u16 vaddl_high_u32 vaddl_high_u8 vaddlv Add long across Vector Click here to expand the API list vaddlv_s16 vaddlv_s32 vaddlv_s8 vaddlv_u16 vaddlv_u32 vaddlv_u8 vaddlvq_s16 vaddlvq_s32 vaddlvq_s8 vaddlvq_u16 vaddlvq_u32 vaddlvq_u8 vaddw Add wide Click here to expand the API list vaddw_s16 vaddw_s32 vaddw_s8 vaddw_u16 vaddw_u32 vaddw_u8 vaddw_high_s16 vaddw_high_s32 vaddw_high_s8 vaddw_high_u16 vaddw_high_u32 vaddw_high_u8 vhadd Halving add Click here to expand the API list vhadd_s16 vhadd_s32 vhadd_s8 vhadd_u16 vhadd_u32 vhadd_u8 vhaddq_s16 vhaddq_s32 vhaddq_s8 vhaddq_u16 vhaddq_u32 vhaddq_u8 vrhadd Rounding halving add Click here to expand the API list vrhadd_s16 vrhadd_s32 vrhadd_s8 vrhadd_u16 vrhadd_u32 vrhadd_u8 vrhaddq_s16 vrhaddq_s32 vrhaddq_s8 vrhaddq_u16 vrhaddq_u32 vrhaddq_u8 vqadd Saturating add Click here to expand the API list vqadd_s16 vqadd_s32 vqadd_s64 vqadd_s8 vqadd_u16 vqadd_u32 vqadd_u64 vqadd_u8 vqaddq_s16 vqaddq_s32 vqaddq_s64 vqaddq_s8 vqaddq_u16 vqaddq_u32 vqaddq_u64 vqaddq_u8 vqaddb_s8 vqaddb_u8 vqaddh_s16 vqaddh_u16 vqadds_s32 vqadds_u32 vqaddd_s64 vqaddd_u64 vsqadd Unsigned saturating Accumulate of signed value Click here to expand the API list vsqadd_u16 vsqadd_u32 vsqadd_u64 vsqadd_u8 vsqaddq_u16 vsqaddq_u32 vsqaddq_u64 vsqaddq_u8 vsqaddb_u8 vsqaddh_u16 vsqadds_u32 vsqaddd_u64 vuqadd Signed saturating Accumulate of unsigned value Click here to expand the API list vuqadd_s16 vuqadd_s32 vuqadd_s64 vuqadd_s8 vuqaddq_s16 vuqaddq_s32 vuqaddq_s64 vuqaddq_s8 vuqaddb_s8 vuqaddh_s16 vuqadds_s32 vuqaddd_s64 vaddhn Add returning high narrow Click here to expand the API list vaddhn_s16 vaddhn_s32 vaddhn_s64 vaddhn_u16 vaddhn_u32 vaddhn_u64 vaddhn_high_s16 vaddhn_high_s32 vaddhn_high_s64 vaddhn_high_u16 vaddhn_high_u32 vaddhn_high_u64 vraddhn Rounding add returning high narrow Click here to expand the API list vraddhn_s16 vraddhn_s32 vraddhn_s64 vraddhn_u16 vraddhn_u32 vraddhn_u64 vraddhn_high_s16 vraddhn_high_s32 vraddhn_high_s64 vraddhn_high_u16 vraddhn_high_u32 vraddhn_high_u64 vpadd Add pairwise (vector) Click here to expand the API list vpadd_f32 vpadd_s16 vpadd_s32 vpadd_s8 vpadd_u16 vpadd_u32 vpadd_u8 vpaddq_f32 vpaddq_f64 vpaddq_s16 vpaddq_s32 vpaddq_s64 vpaddq_s8 vpaddq_u16 vpaddq_u32 vpaddq_u64 vpaddq_u8 vpadds_f32 vpaddd_f64 vpaddd_s64 vpaddd_u64 vpaddl Signed add long pairwise Click here to expand the API list vpaddl_s16 vpaddl_s32 vpaddl_s8 vpaddl_u16 vpaddl_u32 vpaddl_u8 vpaddlq_s16 vpaddlq_s32 vpaddlq_s8 vpaddlq_u16 vpaddlq_u32 vpaddlq_u8 vpadal Signed add and accumulate long pairwise Click here to expand the API list vpadal_s16 vpadal_s32 vpadal_s8 vpadal_u16 vpadal_u32 vpadal_u8 vpadalq_s16 vpadalq_s32 vpadalq_s8 vpadalq_u16 vpadalq_u32 vpadalq_u8 vsub Subtract Click here to expand the API list vsub_f32 vsub_f64 vsub_s16 vsub_s32 vsub_s64 vsub_s8 vsub_u16 vsub_u32 vsub_u64 vsub_u8 vsubq_f32 vsubq_f64 vsubq_s16 vsubq_s32 vsubq_s64 vsubq_s8 vsubq_u16 vsubq_u32 vsubq_u64 vsubq_u8 vsubd_s64 vsubd_u64 vsubl Subtract long Click here to expand the API list vsubl_s16 vsubl_s32 vsubl_s8 vsubl_u16 vsubl_u32 vsubl_u8 vsubl_high_s16 vsubl_high_s32 vsubl_high_s8 vsubl_high_u16 vsubl_high_u32 vsubl_high_u8 vsubw Subtract wide Click here to expand the API list vsubw_s16 vsubw_s32 vsubw_s8 vsubw_u16 vsubw_u32 vsubw_u8 vsubw_high_s16 vsubw_high_s32 vsubw_high_s8 vsubw_high_u16 vsubw_high_u32 vsubw_high_u8 vhsub Halving subtract Click here to expand the API list vhsub_s16 vhsub_s32 vhsub_s8 vhsub_u16 vhsub_u32 vhsub_u8 vhsubq_s16 vhsubq_s32 vhsubq_s8 vhsubq_u16 vhsubq_u32 vhsubq_u8 vqsub Saturating subtract Click here to expand the API list vqsub_s16 vqsub_s32 vqsub_s64 vqsub_s8 vqsub_u16 vqsub_u32 vqsub_u64 vqsub_u8 vqsubq_s16 vqsubq_s32 vqsubq_s64 vqsubq_s8 vqsubq_u16 vqsubq_u32 vqsubq_u64 vqsubq_u8 vqsubb_s8 vqsubb_u8 vqsubh_s16 vqsubh_u16 vqsubs_s32 vqsubs_u32 vqsubd_s64 vqsubd_u64 vsubhn Subtract returning high narrow Click here to expand the API list vsubhn_s16 vsubhn_s32 vsubhn_s64 vsubhn_u16 vsubhn_u32 vsubhn_u64 vsubhn_high_s16 vsubhn_high_s32 vsubhn_high_s64 vsubhn_high_u16 vsubhn_high_u32 vsubhn_high_u64 vrsubhn Rounding subtract returning high narrow Click here to expand the API list vrsubhn_s16 vrsubhn_s32 vrsubhn_s64 vrsubhn_u16 vrsubhn_u32 vrsubhn_u64 vrsubhn_high_s16 vrsubhn_high_s32 vrsubhn_high_s64 vrsubhn_high_u16 vrsubhn_high_u32 vrsubhn_high_u64 Multiply Operation Description APIs vmul Multiply (vector) Click here to expand the API list vmul_f32 vmul_f64 vmul_s16 vmul_s32 vmul_s8 vmul_u16 vmul_u32 vmul_u8 vmulq_f32 vmulq_f64 vmulq_s16 vmulq_s32 vmulq_s8 vmulq_u16 vmulq_u32 vmulq_u8 vmul_n Vector multiply by scalar Click here to expand the API list vmul_n_f32 vmul_n_f64 vmul_n_s16 vmul_n_s32 vmul_n_u16 vmul_n_u32 vmulq_n_f32 vmulq_n_f64 vmulq_n_s16 vmulq_n_s32 vmulq_n_u16 vmulq_n_u32 vmul_lane Multiply (vector) Click here to expand the API list vmul_lane_f32 vmul_lane_f64 vmul_lane_s16 vmul_lane_s32 vmul_lane_u16 vmul_lane_u32 vmul_laneq_f32 vmul_laneq_f64 vmul_laneq_s16 vmul_laneq_s32 vmul_laneq_u16 vmul_laneq_u32 vmulq_lane_f32 vmulq_lane_f64 vmulq_lane_s16 vmulq_lane_s32 vmulq_lane_u16 vmulq_lane_u32 vmulq_laneq_f32 vmulq_laneq_f64 vmulq_laneq_s16 vmulq_laneq_s32 vmulq_laneq_u16 vmulq_laneq_u32 vmuls_lane_f32 vmuls_laneq_f32 vmuld_lane_f64 vmuld_laneq_f64 vmull Multiply long (vector) Click here to expand the API list vmull_s16 vmull_s32 vmull_s8 vmull_u16 vmull_u32 vmull_u8 vmull_high_s16 vmull_high_s32 vmull_high_s8 vmull_high_u16 vmull_high_u32 vmull_high_u8 vmull_n Vector long multiply by scalar Click here to expand the API list vmull_n_s16 vmull_n_s32 vmull_n_u16 vmull_n_u32 vmull_high_n_s16 vmull_high_n_s32 vmull_high_n_u16 vmull_high_n_u32 vmull_lane Multiply long (vector) Click here to expand the API list vmull_lane_s16 vmull_lane_s32 vmull_lane_u16 vmull_lane_u32 vmull_laneq_s16 vmull_laneq_s32 vmull_laneq_u16 vmull_laneq_u32 vmull_high_lane_s16 vmull_high_lane_s32 vmull_high_lane_u16 vmull_high_lane_u32 vmull_high_laneq_s16 vmull_high_laneq_s32 vmull_high_laneq_u16 vmull_high_laneq_u32 vmulx Floating-point multiply extended Click here to expand the API list vmulx_f32 vmulx_f64 vmulx_lane_f32 vmulx_lane_f64 vmulx_laneq_f32 vmulx_laneq_f64 vmulxq_f32 vmulxq_f64 vmulxq_lane_f32 vmulxq_lane_f64 vmulxq_laneq_f32 vmulxq_laneq_f64 vmulxs_f32 vmulxs_lane_f32 vmulxs_laneq_f32 vmulxd_f64 vmulxd_lane_f64 vmulxd_laneq_f64 vmla Multiply-add to accumulator (vector) Click here to expand the API list vmla_f32 vmla_f64 vmla_s16 vmla_s32 vmla_s8 vmla_u16 vmla_u32 vmla_u8 vmlaq_f32 vmlaq_f64 vmlaq_s16 vmlaq_s32 vmlaq_s8 vmlaq_u16 vmlaq_u32 vmlaq_u8 vmla_lane Vector multiply accumulate with scalar Click here to expand the API list vmla_lane_f32 vmla_lane_s16 vmla_lane_s32 vmla_lane_u16 vmla_lane_u32 vmla_laneq_f32 vmla_laneq_s16 vmla_laneq_s32 vmla_laneq_u16 vmla_laneq_u32 vmlaq_lane_f32 vmlaq_lane_s16 vmlaq_lane_s32 vmlaq_lane_u16 vmlaq_lane_u32 vmlaq_laneq_f32 vmlaq_laneq_s16 vmlaq_laneq_s32 vmlaq_laneq_u16 vmlaq_laneq_u32 vmla_n Vector multiply accumulate with scalar Click here to expand the API list vmla_n_f32 vmla_n_s16 vmla_n_s32 vmla_n_u16 vmla_n_u32 vmlaq_n_f32 vmlaq_n_s16 vmlaq_n_s32 vmlaq_n_u16 vmlaq_n_u32 vmlal Multiply-accumulate long (vector) Click here to expand the API list vmlal_s16 vmlal_s32 vmlal_s8 vmlal_u16 vmlal_u32 vmlal_u8 vmlal_high_s16 vmlal_high_s32 vmlal_high_s8 vmlal_high_u16 vmlal_high_u32 vmlal_high_u8 vmlal_lane Multiply-accumulate long with scalar Click here to expand the API list vmlal_lane_s16 vmlal_lane_s32 vmlal_lane_u16 vmlal_lane_u32 vmlal_laneq_s16 vmlal_laneq_s32 vmlal_laneq_u16 vmlal_laneq_u32 vmlal_high_lane_s16 vmlal_high_lane_s32 vmlal_high_lane_u16 vmlal_high_lane_u32 vmlal_high_laneq_s16 vmlal_high_laneq_s32 vmlal_high_laneq_u16 vmlal_high_laneq_u32 vmlal_n Multiply-accumulate long with scalar Click here to expand the API list vmlal_n_s16 vmlal_n_s32 vmlal_n_u16 vmlal_n_u32 vmlal_high_n_s16 vmlal_high_n_s32 vmlal_high_n_u16 vmlal_high_n_u32 vmls Multiply-subtract from accumulator (vector) Click here to expand the API list vmls_f32 vmls_f64 vmls_s16 vmls_s32 vmls_s8 vmls_u16 vmls_u32 vmls_u8 vmlsq_f32 vmlsq_f64 vmlsq_s16 vmlsq_s32 vmlsq_s8 vmlsq_u16 vmlsq_u32 vmlsq_u8 vmls_lane Vector multiply subtract with scalar Click here to expand the API list vmls_lane_f32 vmls_lane_s16 vmls_lane_s32 vmls_lane_u16 vmls_lane_u32 vmls_laneq_f32 vmls_laneq_s16 vmls_laneq_s32 vmls_laneq_u16 vmls_laneq_u32 vmlsq_lane_f32 vmlsq_lane_s16 vmlsq_lane_s32 vmlsq_lane_u16 vmlsq_lane_u32 vmlsq_laneq_f32 vmlsq_laneq_s16 vmlsq_laneq_s32 vmlsq_laneq_u16 vmlsq_laneq_u32 vmls_n Vector multiply subtract with scalar Click here to expand the API list vmls_n_f32 vmls_n_s16 vmls_n_s32 vmls_n_u16 vmls_n_u32 vmlsq_n_f32 vmlsq_n_s16 vmlsq_n_s32 vmlsq_n_u16 vmlsq_n_u32 vmlsl Multiply-subtract long (vector) Click here to expand the API list vmlsl_s16 vmlsl_s32 vmlsl_s8 vmlsl_u16 vmlsl_u32 vmlsl_u8 vmlsl_high_s16 vmlsl_high_s32 vmlsl_high_s8 vmlsl_high_u16 vmlsl_high_u32 vmlsl_high_u8 vmlsl_lane Vector multiply-subtract long with scalar Click here to expand the API list vmlsl_lane_s16 vmlsl_lane_s32 vmlsl_lane_u16 vmlsl_lane_u32 vmlsl_laneq_s16 vmlsl_laneq_s32 vmlsl_laneq_u16 vmlsl_laneq_u32 vmlsl_high_lane_s16 vmlsl_high_lane_s32 vmlsl_high_lane_u16 vmlsl_high_lane_u32 vmlsl_high_laneq_s16 vmlsl_high_laneq_s32 vmlsl_high_laneq_u16 vmlsl_high_laneq_u32 vmlsl_n Vector multiply-subtract long with scalar Click here to expand the API list vmlsl_n_s16 vmlsl_n_s32 vmlsl_n_u16 vmlsl_n_u32 vmlsl_high_n_s16 vmlsl_high_n_s32 vmlsl_high_n_u16 vmlsl_high_n_u32 vqdmull Signed saturating doubling multiply long Click here to expand the API list vqdmull_s16 vqdmull_s32 vqdmullh_s16 vqdmulls_s32 vqdmull_high_s16 vqdmull_high_s32 vqdmull_lane Vector saturating doubling multiply long with scalar Click here to expand the API list vqdmull_lane_s16 vqdmull_lane_s32 vqdmull_laneq_s16 vqdmull_laneq_s32 vqdmullh_lane_s16 vqdmullh_laneq_s16 vqdmulls_lane_s32 vqdmulls_laneq_s32 vqdmull_high_lane_s16 vqdmull_high_lane_s32 vqdmull_high_laneq_s16 vqdmull_high_laneq_s32 vqdmull_n Vector saturating doubling multiply long with scalar Click here to expand the API list vqdmull_n_s16 vqdmull_n_s32 vqdmull_high_n_s16 vqdmull_high_n_s32 vqdmulh Saturating doubling multiply returning high half Click here to expand the API list vqdmulh_s16 vqdmulh_s32 vqdmulhq_s16 vqdmulhq_s32 vqdmulhh_s16 vqdmulhs_s32 vqdmulh_lane Vector saturating doubling multiply high by scalar Click here to expand the API list vqdmulh_lane_s16 vqdmulh_lane_s32 vqdmulh_laneq_s16 vqdmulh_laneq_s32 vqdmulhq_lane_s16 vqdmulhq_lane_s32 vqdmulhq_laneq_s16 vqdmulhq_laneq_s32 vqdmulhh_lane_s16 vqdmulhh_laneq_s16 vqdmulhs_lane_s32 vqdmulhs_laneq_s32 vqdmulh_n Vector saturating doubling multiply high by scalar Click here to expand the API list vqdmulh_n_s16 vqdmulh_n_s32 vqdmulhq_n_s16 vqdmulhq_n_s32 vqrdmulh Saturating rounding doubling multiply returning high half Click here to expand the API list vqrdmulh_s16 vqrdmulh_s32 vqrdmulhq_s16 vqrdmulhq_s32 vqrdmulhh_s16 vqrdmulhs_s32 vqrdmulh_lane Vector saturating rounding doubling multiply high with scalar Click here to expand the API list vqrdmulh_lane_s16 vqrdmulh_lane_s32 vqrdmulh_laneq_s16 vqrdmulh_laneq_s32 vqrdmulhq_lane_s16 vqrdmulhq_lane_s32 vqrdmulhq_laneq_s16 vqrdmulhq_laneq_s32 vqrdmulhh_lane_s16 vqrdmulhh_laneq_s16 vqrdmulhs_lane_s32 vqrdmulhs_laneq_s32 vqrdmulh_n Vector saturating rounding doubling multiply high with scalar Click here to expand the API list vqrdmulh_n_s16 vqrdmulh_n_s32 vqrdmulhq_n_s16 vqrdmulhq_n_s32 vqdmlal Saturating doubling multiply-add long Click here to expand the API list vqdmlal_s16 vqdmlal_s32 vqdmlalh_s16 vqdmlals_s32 vqdmlal_high_s16 vqdmlal_high_s32 vqdmlal_lane Vector saturating doubling multiply-accumulate long with scalar Click here to expand the API list vqdmlal_lane_s16 vqdmlal_lane_s32 vqdmlal_laneq_s16 vqdmlal_laneq_s32 vqdmlalh_lane_s16 vqdmlalh_laneq_s16 vqdmlals_lane_s32 vqdmlals_laneq_s32 vqdmlal_high_lane_s16 vqdmlal_high_lane_s32 vqdmlal_high_laneq_s16 vqdmlal_high_laneq_s32 vqdmlal_n Vector saturating doubling multiply-accumulate long with scalar Click here to expand the API list vqdmlal_n_s16 vqdmlal_n_s32 vqdmlal_high_n_s16 vqdmlal_high_n_s32 vqdmlsl Signed saturating doubling multiply-subtract long Click here to expand the API list vqdmlsl_s16 vqdmlsl_s32 vqdmlslh_s16 vqdmlsls_s32 vqdmlsl_high_s16 vqdmlsl_high_s32 vqdmlsl_lane Vector saturating doubling multiply-subtract long with scalar Click here to expand the API list vqdmlsl_lane_s16 vqdmlsl_lane_s32 vqdmlsl_laneq_s16 vqdmlsl_laneq_s32 vqdmlslh_lane_s16 vqdmlslh_laneq_s16 vqdmlsls_lane_s32 vqdmlsls_laneq_s32 vqdmlsl_high_lane_s16 vqdmlsl_high_lane_s32 vqdmlsl_high_laneq_s16 vqdmlsl_high_laneq_s32 vqdmlsl_n Vector saturating doubling multiply-subtract long with scalar Click here to expand the API list vqdmlsl_n_s16 vqdmlsl_n_s32 vqdmlsl_high_n_s16 vqdmlsl_high_n_s32 vqrdmlah Saturating rounding doubling multiply accumulate returning high half (vector) Click here to expand the API list vqrdmlah_s16 vqrdmlah_s32 vqrdmlahq_s16 vqrdmlahq_s32 vqrdmlahh_s16 vqrdmlahs_s32 vqrdmlah_lane Saturating rounding doubling multiply accumulate returning high half (vector) Click here to expand the API list vqrdmlah_lane_s16 vqrdmlah_lane_s32 vqrdmlah_laneq_s16 vqrdmlah_laneq_s32 vqrdmlahq_lane_s16 vqrdmlahq_lane_s32 vqrdmlahq_laneq_s16 vqrdmlahq_laneq_s32 vqrdmlahh_lane_s16 vqrdmlahh_laneq_s16 vqrdmlahs_lane_s32 vqrdmlsh Saturating rounding doubling multiply subtract returning high half (vector) Click here to expand the API list vqrdmlsh_s16 vqrdmlsh_s32 vqrdmlshq_s16 vqrdmlshq_s32 vqrdmlshh_s16 vqrdmlshs_s32 vqrdmlsh_lane Saturating rounding doubling multiply subtract returning high half (vector) Click here to expand the API list vqrdmlsh_lane_s16 vqrdmlsh_lane_s32 vqrdmlsh_laneq_s16 vqrdmlsh_laneq_s32 vqrdmlshq_lane_s16 vqrdmlshq_lane_s32 vqrdmlshq_laneq_s16 vqrdmlshq_laneq_s32 vqrdmlshh_lane_s16 vqrdmlshh_laneq_s16 vqrdmlshs_lane_s32 vfma Floating-point fused multiply-add to accumulator (vector) Click here to expand the API list vfma_f32 vfma_f64 vfmaq_f32 vfmaq_f64 vfma_n Floating-point fused multiply-add to accumulator (vector) Click here to expand the API list vfma_n_f32 vfma_n_f64 vfmaq_n_f32 vfmaq_n_f64 vfma_lane Floating-point fused multiply-add to accumulator (vector) Click here to expand the API list vfma_lane_f32 vfma_lane_f64 vfma_laneq_f32 vfma_laneq_f64 vfmaq_lane_f32 vfmaq_lane_f64 vfmaq_laneq_f32 vfmaq_laneq_f64 vfmas_lane_f32 vfmas_laneq_f32 vfmad_lane_f64 vfmad_laneq_f64 vfms Floating-point fused multiply-subtract from accumulator (vector) Click here to expand the API list vfms_f32 vfms_f64 vfmsq_f32 vfmsq_f64 vfms_n Floating-point fused multiply-subtract from accumulator (vector) Click here to expand the API list vfms_n_f32 vfms_n_f64 vfmsq_n_f32 vfmsq_n_f64 vfms_lane Floating-point fused multiply-subtract from accumulator (vector) Click here to expand the API list vfms_lane_f32 vfms_lane_f64 vfms_laneq_f32 vfms_laneq_f64 vfmsd_lane_f64 vfmsd_laneq_f64 vfmsq_lane_f32 vfmsq_lane_f64 vfmsq_laneq_f32 vfmsq_laneq_f64 vfmss_lane_f32 vfmss_laneq_f32 vdiv Floating-point divide (vector) Click here to expand the API list vdiv_f32 vdiv_f64 vdivq_f32 vdivq_f64 Data processing Operation Description APIs vpmax Maximum pairwise Click here to expand the API list vpmax_f32 vpmax_s16 vpmax_s32 vpmax_s8 vpmax_u16 vpmax_u32 vpmax_u8 vpmaxq_f32 vpmaxq_f64 vpmaxq_s16 vpmaxq_s32 vpmaxq_s8 vpmaxq_u16 vpmaxq_u32 vpmaxq_u8 vpmaxs_f32 vpmaxqd_f64 vpmaxnm Floating-point maximum number pairwise (vector) Click here to expand the API list vpmaxnm_f32 vpmaxnmq_f32 vpmaxnmq_f64 vpmaxnms_f32 vpmaxnmqd_f64 vpmin Minimum pairwise Click here to expand the API list vpmin_f32 vpmin_s16 vpmin_s32 vpmin_s8 vpmin_u16 vpmin_u32 vpmin_u8 vpminq_f32 vpminq_f64 vpminq_s16 vpminq_s32 vpminq_s8 vpminq_u16 vpminq_u32 vpminq_u8 vpmins_f32 vpminqd_f64 vpminnm Floating-point minimum number pairwise (vector) Click here to expand the API list vpminnm_f32 vpminnmq_f32 vpminnmq_f64 vpminnms_f32 vpminnmqd_f64 vabd Absolute difference Click here to expand the API list vabd_f32 vabd_f64 vabd_s16 vabd_s32 vabd_s8 vabd_u16 vabd_u32 vabd_u8 vabdq_f32 vabdq_f64 vabdq_s16 vabdq_s32 vabdq_s8 vabdq_u16 vabdq_u32 vabdq_u8 vabds_f32 vabdd_f64 vabdl Absolute difference long Click here to expand the API list vabdl_s16 vabdl_s32 vabdl_s8 vabdl_u16 vabdl_u32 vabdl_u8 vabdl_high_s16 vabdl_high_s32 vabdl_high_s8 vabdl_high_u16 vabdl_high_u32 vabdl_high_u8 vaba Absolute difference and accumulate Click here to expand the API list vaba_s16 vaba_s32 vaba_s8 vaba_u16 vaba_u32 vaba_u8 vabaq_s16 vabaq_s32 vabaq_s8 vabaq_u16 vabaq_u32 vabaq_u8 vabal Absolute difference and accumulate long Click here to expand the API list vabal_s16 vabal_s32 vabal_s8 vabal_u16 vabal_u32 vabal_u8 vabal_high_s16 vabal_high_s32 vabal_high_s8 vabal_high_u16 vabal_high_u32 vabal_high_u8 vmax Maximum Click here to expand the API list vmax_f32 vmax_f64 vmax_s16 vmax_s32 vmax_s8 vmax_u16 vmax_u32 vmax_u8 vmaxq_f32 vmaxq_f64 vmaxq_s16 vmaxq_s32 vmaxq_s8 vmaxq_u16 vmaxq_u32 vmaxq_u8 vmaxnm Floating-point maximum number Click here to expand the API list vmaxnm_f32 vmaxnm_f64 vmaxnmq_f32 vmaxnmq_f64 vmaxnmv_f32 vmaxnmvq_f32 vmaxnmvq_f64 vmaxv Maximum across vector Click here to expand the API list vmaxv_f32 vmaxv_s16 vmaxv_s32 vmaxv_s8 vmaxv_u16 vmaxv_u32 vmaxv_u8 vmaxvq_f32 vmaxvq_f64 vmaxvq_s16 vmaxvq_s32 vmaxvq_s8 vmaxvq_u16 vmaxvq_u32 vmaxvq_u8 vmin Minimum Click here to expand the API list vmin_f32 vmin_f64 vmin_s16 vmin_s32 vmin_s8 vmin_u16 vmin_u32 vmin_u8 vminq_f32 vminq_f64 vminq_s16 vminq_s32 vminq_s8 vminq_u16 vminq_u32 vminq_u8 vminnm Floating-point minimum number Click here to expand the API list vminnm_f32 vminnm_f64 vminnmq_f32 vminnmq_f64 vminnmv_f32 vminnmvq_f32 vminnmvq_f64 vminv Minimum across vector Click here to expand the API list vminv_f32 vminv_s16 vminv_s32 vminv_s8 vminv_u16 vminv_u32 vminv_u8 vminvq_f32 vminvq_f64 vminvq_s16 vminvq_s32 vminvq_s8 vminvq_u16 vminvq_u32 vminvq_u8 vabs Absolute value Click here to expand the API list vabs_f32 vabs_f64 vabs_s16 vabs_s32 vabs_s64 vabs_s8 vabsq_f32 vabsq_f64 vabsq_s16 vabsq_s32 vabsq_s64 vabsq_s8 vabsd_s64 vqabs Saturating absolute value Click here to expand the API list vqabs_s16 vqabs_s32 vqabs_s64 vqabs_s8 vqabsq_s16 vqabsq_s32 vqabsq_s64 vqabsq_s8 vqabsb_s8 vqabsh_s16 vqabss_s32 vqabsd_s64 vneg Negate Click here to expand the API list vneg_f32 vneg_f64 vneg_s16 vneg_s32 vneg_s64 vneg_s8 vnegd_s64 vnegq_f32 vnegq_f64 vnegq_s16 vnegq_s32 vnegq_s64 vnegq_s8 vqneg Saturating negate Click here to expand the API list vqneg_s16 vqneg_s32 vqneg_s64 vqneg_s8 vqnegq_s16 vqnegq_s32 vqnegq_s64 vqnegq_s8 vqnegb_s8 vqnegh_s16 vqnegs_s32 vqnegd_s64 vcls Count leading sign bits Click here to expand the API list vcls_s16 vcls_s32 vcls_s8 vclsq_s16 vclsq_s32 vclsq_s8 vclz Count leading zero bits Click here to expand the API list vclz_s16 vclz_s32 vclz_s8 vclz_u16 vclz_u32 vclz_u8 vclzq_s16 vclzq_s32 vclzq_s8 vclzq_u16 vclzq_u32 vclzq_u8 vcnt Population count per byte Click here to expand the API list vcnt_s8 vcnt_u8 vcntq_s8 vcntq_u8 vrecpe Reciprocal estimate Click here to expand the API list vrecpe_f32 vrecpe_f64 vrecpe_u32 vrecpeq_f32 vrecpeq_f64 vrecpeq_u32 vrecpes_f32 vrecped_f64 vrecps Reciprocal step Click here to expand the API list vrecps_f32 vrecps_f64 vrecpsq_f32 vrecpsq_f64 vrecpss_f32 vrecpsd_f64 vrecpx Floating-point reciprocal exponent Click here to expand the API list vrecpxd_f64 vrecpxs_f32 vrsqrte Reciprocal square root estimate Click here to expand the API list vrsqrte_f32 vrsqrte_f64 vrsqrte_u32 vrsqrteq_f32 vrsqrteq_f64 vrsqrteq_u32 vrsqrtes_f32 vrsqrted_f64 vrsqrts Reciprocal square root step Click here to expand the API list vrsqrts_f32 vrsqrts_f64 vrsqrtsq_f32 vrsqrtsq_f64 vrsqrtss_f32 vrsqrtsd_f64 vmovn Extract narrow Click here to expand the API list vmovn_s16 vmovn_s32 vmovn_s64 vmovn_u16 vmovn_u32 vmovn_u64 vmovn_high_s16 vmovn_high_s32 vmovn_high_s64 vmovn_high_u16 vmovn_high_u32 vmovn_high_u64 vmovl Extract long Click here to expand the API list vmovl_s16 vmovl_s32 vmovl_s8 vmovl_u16 vmovl_u32 vmovl_u8 vmovl_high_s16 vmovl_high_s32 vmovl_high_s8 vmovl_high_u16 vmovl_high_u32 vmovl_high_u8 vqmovn Saturating extract narrow Click here to expand the API list vqmovn_s16 vqmovn_s32 vqmovn_s64 vqmovn_u16 vqmovn_u32 vqmovn_u64 vqmovn_high_s16 vqmovn_high_s32 vqmovn_high_s64 vqmovn_high_u16 vqmovn_high_u32 vqmovn_high_u64 vqmovnh_s16 vqmovnh_u16 vqmovns_s32 vqmovns_u32 vqmovnd_s64 vqmovnd_u64 vqmovun Signed saturating extract unsigned narrow Click here to expand the API list vqmovun_s16 vqmovun_s32 vqmovun_s64 vqmovun_high_s16 vqmovun_high_s32 vqmovun_high_s64 vqmovunh_s16 vqmovuns_s32 vqmovund_s64 Comparison Operation Description APIs vceq Compare bitwise equal Click here to expand the API list vceq_f32 vceq_f64 vceq_s16 vceq_s32 vceq_s64 vceq_s8 vceq_u16 vceq_u32 vceq_u64 vceq_u8 vceqq_f32 vceqq_f64 vceqq_s16 vceqq_s32 vceqq_s64 vceqq_s8 vceqq_u16 vceqq_u32 vceqq_u64 vceqq_u8 vceqs_f32 vceqd_f64 vceqd_s64 vceqd_u64 vceqz Compare bitwise equal to zero Click here to expand the API list vceqz_f32 vceqz_f64 vceqz_s16 vceqz_s32 vceqz_s64 vceqz_s8 vceqz_u16 vceqz_u32 vceqz_u64 vceqz_u8 vceqzq_f32 vceqzq_f64 vceqzq_s16 vceqzq_s32 vceqzq_s64 vceqzq_s8 vceqzq_u16 vceqzq_u32 vceqzq_u64 vceqzq_u8 vceqzs_f32 vceqzd_f64 vceqzd_s64 vceqzd_u64 vcge Compare greater than or equal Click here to expand the API list vcge_f32 vcge_f64 vcge_s16 vcge_s32 vcge_s64 vcge_s8 vcge_u16 vcge_u32 vcge_u64 vcge_u8 vcgeq_f32 vcgeq_f64 vcgeq_s16 vcgeq_s32 vcgeq_s64 vcgeq_s8 vcgeq_u16 vcgeq_u32 vcgeq_u64 vcgeq_u8 vcges_f32 vcged_f64 vcged_s64 vcged_u64 vcgez Compare greater than or equal to zero Click here to expand the API list vcgez_f32 vcgez_f64 vcgez_s16 vcgez_s32 vcgez_s64 vcgez_s8 vcgezq_f32 vcgezq_f64 vcgezq_s16 vcgezq_s32 vcgezq_s64 vcgezq_s8 vcgezs_f32 vcgezd_f64 vcgezd_s64 vcle Compare less than or equal Click here to expand the API list vcle_f32 vcle_f64 vcle_s16 vcle_s32 vcle_s64 vcle_s8 vcle_u16 vcle_u32 vcle_u64 vcle_u8 vcleq_f32 vcleq_f64 vcleq_s16 vcleq_s32 vcleq_s64 vcleq_s8 vcleq_u16 vcleq_u32 vcleq_u64 vcleq_u8 vcles_f32 vcled_f64 vcled_s64 vcled_u64 vclez Compare less than or equal to zero Click here to expand the API list vclez_f32 vclez_f64 vclez_s16 vclez_s32 vclez_s64 vclez_s8 vclezq_f32 vclezq_f64 vclezq_s16 vclezq_s32 vclezq_s64 vclezq_s8 vclezs_f32 vclezd_f64 vclezd_s64 vcgt Compare greater than Click here to expand the API list vcgt_f32 vcgt_f64 vcgt_s16 vcgt_s32 vcgt_s64 vcgt_s8 vcgt_u16 vcgt_u32 vcgt_u64 vcgt_u8 vcgtq_f32 vcgtq_f64 vcgtq_s16 vcgtq_s32 vcgtq_s64 vcgtq_s8 vcgtq_u16 vcgtq_u32 vcgtq_u64 vcgtq_u8 vcgts_f32 vcgtd_f64 vcgtd_s64 vcgtd_u64 vcgtz Compare greater than zero Click here to expand the API list vcgtz_f32 vcgtz_f64 vcgtz_s16 vcgtz_s32 vcgtz_s64 vcgtz_s8 vcgtzq_f32 vcgtzq_f64 vcgtzq_s16 vcgtzq_s32 vcgtzq_s64 vcgtzq_s8 vcgtzs_f32 vcgtzd_f64 vcgtzd_s64 vclt Compare less than Click here to expand the API list vclt_f32 vclt_f64 vclt_s16 vclt_s32 vclt_s64 vclt_s8 vclt_u16 vclt_u32 vclt_u64 vclt_u8 vcltq_f32 vcltq_f64 vcltq_s16 vcltq_s32 vcltq_s64 vcltq_s8 vcltq_u16 vcltq_u32 vcltq_u64 vcltq_u8 vclts_f32 vcltd_f64 vcltd_s64 vcltd_u64 vcltz Compare less than zero Click here to expand the API list vcltz_f32 vcltz_f64 vcltz_s16 vcltz_s32 vcltz_s64 vcltz_s8 vcltzq_f32 vcltzq_f64 vcltzq_s16 vcltzq_s32 vcltzq_s64 vcltzq_s8 vcltzs_f32 vcltzd_f64 vcltzd_s64 vcage Floating-point absolute compare greater than or equal Click here to expand the API list vcage_f32 vcage_f64 vcageq_f32 vcageq_f64 vcages_f32 vcaged_f64 vcagt Floating-point absolute compare greater than Click here to expand the API list vcagt_f32 vcagt_f64 vcagtq_f32 vcagtq_f64 vcagts_f32 vcagtd_f64 vcale Floating-point absolute compare less than or equal Click here to expand the API list vcale_f32 vcale_f64 vcaleq_f32 vcaleq_f64 vcales_f32 vcaled_f64 vcalt Floating-point absolute compare less than Click here to expand the API list vcalt_f32 vcalt_f64 vcaltq_f32 vcaltq_f64 vcalts_f32 vcaltd_f64 Bitwise Operation Description APIs vtst Test bits nonzero Click here to expand the API list vtst_s16 vtst_s32 vtst_s64 vtst_s8 vtst_u16 vtst_u32 vtst_u64 vtst_u8 vtstd_s64 vtstd_u64 vtstq_s16 vtstq_s32 vtstq_s64 vtstq_s8 vtstq_u16 vtstq_u32 vtstq_u64 vtstq_u8 vmvn Bitwise NOT Click here to expand the API list vmvn_s16 vmvn_s32 vmvn_s8 vmvn_u16 vmvn_u32 vmvn_u8 vmvnq_s16 vmvnq_s32 vmvnq_s8 vmvnq_u16 vmvnq_u32 vmvnq_u8 vand Bitwise AND Click here to expand the API list vand_s16 vand_s32 vand_s64 vand_s8 vand_u16 vand_u32 vand_u64 vand_u8 vandq_s16 vandq_s32 vandq_s64 vandq_s8 vandq_u16 vandq_u32 vandq_u64 vandq_u8 vorr Bitwise OR Click here to expand the API list vorr_s16 vorr_s32 vorr_s64 vorr_s8 vorr_u16 vorr_u32 vorr_u64 vorr_u8 vorrq_s16 vorrq_s32 vorrq_s64 vorrq_s8 vorrq_u16 vorrq_u32 vorrq_u64 vorrq_u8 vorn Bitwise OR NOT Click here to expand the API list vorn_s16 vorn_s32 vorn_s64 vorn_s8 vorn_u16 vorn_u32 vorn_u64 vorn_u8 vornq_s16 vornq_s32 vornq_s64 vornq_s8 vornq_u16 vornq_u32 vornq_u64 vornq_u8 veor Bitwise exclusive OR Click here to expand the API list veor_s16 veor_s32 veor_s64 veor_s8 veor_u16 veor_u32 veor_u64 veor_u8 veorq_s16 veorq_s32 veorq_s64 veorq_s8 veorq_u16 veorq_u32 veorq_u64 veorq_u8 vbic Bitwise bit clear Click here to expand the API list vbic_s16 vbic_s32 vbic_s64 vbic_s8 vbic_u16 vbic_u32 vbic_u64 vbic_u8 vbicq_s16 vbicq_s32 vbicq_s64 vbicq_s8 vbicq_u16 vbicq_u32 vbicq_u64 vbicq_u8 vbsl Bitwise select Click here to expand the API list vbsl_f32 vbsl_f64 vbsl_s16 vbsl_s32 vbsl_s64 vbsl_s8 vbsl_u16 vbsl_u32 vbsl_u64 vbsl_u8 vbslq_f32 vbslq_f64 vbslq_s16 vbslq_s32 vbslq_s64 vbslq_s8 vbslq_u16 vbslq_u32 vbslq_u64 vbslq_u8 Shift Operation Description APIs vshl Shift left (register) Click here to expand the API list vshl_s16 vshl_s32 vshl_s64 vshl_s8 vshl_u16 vshl_u32 vshl_u64 vshl_u8 vshlq_s16 vshlq_s32 vshlq_s64 vshlq_s8 vshlq_u16 vshlq_u32 vshlq_u64 vshlq_u8 vshld_s64 vshld_u64 vqshl Saturating shift left (register) Click here to expand the API list vqshl_s16 vqshl_s32 vqshl_s64 vqshl_s8 vqshl_u16 vqshl_u32 vqshl_u64 vqshl_u8 vqshlq_s16 vqshlq_s32 vqshlq_s64 vqshlq_s8 vqshlq_u16 vqshlq_u32 vqshlq_u64 vqshlq_u8 vqshlb_s8 vqshlb_u8 vqshlh_s16 vqshlh_u16 vqshls_s32 vqshls_u32 vqshld_s64 vqshld_u64 vqshl_n Saturating shift left (immediate) Click here to expand the API list vqshl_n_s16 vqshl_n_s32 vqshl_n_s64 vqshl_n_s8 vqshl_n_u16 vqshl_n_u32 vqshl_n_u64 vqshl_n_u8 vqshlq_n_s16 vqshlq_n_s32 vqshlq_n_s64 vqshlq_n_s8 vqshlq_n_u16 vqshlq_n_u32 vqshlq_n_u64 vqshlq_n_u8 vqshlb_n_s8 vqshlb_n_u8 vqshlh_n_s16 vqshlh_n_u16 vqshls_n_s32 vqshls_n_u32 vqshld_n_s64 vqshld_n_u64 vqshlu_n Saturating shift left unsigned (immediate) Click here to expand the API list vqshlu_n_s16 vqshlu_n_s32 vqshlu_n_s64 vqshlu_n_s8 vqshlub_n_s8 vqshlud_n_s64 vqshluh_n_s16 vqshluq_n_s16 vqshluq_n_s32 vqshluq_n_s64 vqshluq_n_s8 vqshlus_n_s32 vrshl Rounding shift left (register) Click here to expand the API list vrshl_s16 vrshl_s32 vrshl_s64 vrshl_s8 vrshl_u16 vrshl_u32 vrshl_u64 vrshl_u8 vrshlq_s16 vrshlq_s32 vrshlq_s64 vrshlq_s8 vrshlq_u16 vrshlq_u32 vrshlq_u64 vrshlq_u8 vrshld_s64 vrshld_u64 vqrshl Saturating rounding shift left (register) Click here to expand the API list vqrshl_s16 vqrshl_s32 vqrshl_s64 vqrshl_s8 vqrshl_u16 vqrshl_u32 vqrshl_u64 vqrshl_u8 vqrshlq_s16 vqrshlq_s32 vqrshlq_s64 vqrshlq_s8 vqrshlq_u16 vqrshlq_u32 vqrshlq_u64 vqrshlq_u8 vqrshlb_s8 vqrshlb_u8 vqrshlh_s16 vqrshlh_u16 vqrshls_s32 vqrshls_u32 vqrshld_s64 vqrshld_u64 vshl_n Shift left (immediate) Click here to expand the API list vshl_n_s16 vshl_n_s32 vshl_n_s64 vshl_n_s8 vshl_n_u16 vshl_n_u32 vshl_n_u64 vshl_n_u8 vshlq_n_s16 vshlq_n_s32 vshlq_n_s64 vshlq_n_s8 vshlq_n_u16 vshlq_n_u32 vshlq_n_u64 vshlq_n_u8 vshld_n_s64 vshld_n_u64 vshll_n Shift left long (immediate) Click here to expand the API list vshll_n_s16 vshll_n_s32 vshll_n_s8 vshll_n_u16 vshll_n_u32 vshll_n_u8 vshll_high_n_s16 vshll_high_n_s32 vshll_high_n_s8 vshll_high_n_u16 vshll_high_n_u32 vshll_high_n_u8 vshr_n Shift right (immediate) Click here to expand the API list vshr_n_s16 vshr_n_s32 vshr_n_s64 vshr_n_s8 vshr_n_u16 vshr_n_u32 vshr_n_u64 vshr_n_u8 vshrq_n_s16 vshrq_n_s32 vshrq_n_s64 vshrq_n_s8 vshrq_n_u16 vshrq_n_u32 vshrq_n_u64 vshrq_n_u8 vshrd_n_s64 vshrd_n_u64 vrshr_n Rounding right left (register) Click here to expand the API list vrshr_n_s16 vrshr_n_s32 vrshr_n_s64 vrshr_n_s8 vrshr_n_u16 vrshr_n_u32 vrshr_n_u64 vrshr_n_u8 vrshrq_n_s16 vrshrq_n_s32 vrshrq_n_s64 vrshrq_n_s8 vrshrq_n_u16 vrshrq_n_u32 vrshrq_n_u64 vrshrq_n_u8 vrshrd_n_s64 vrshrd_n_u64 vshrn_n Shift right narrow (immediate) Click here to expand the API list vshrn_n_s16 vshrn_n_s32 vshrn_n_s64 vshrn_n_u16 vshrn_n_u32 vshrn_n_u64 vshrn_high_n_s16 vshrn_high_n_s32 vshrn_high_n_s64 vshrn_high_n_u16 vshrn_high_n_u32 vshrn_high_n_u64 vqshrun_n Signed saturating shift right unsigned narrow (immediate) Click here to expand the API list vqshrun_n_s16 vqshrun_n_s32 vqshrun_n_s64 vqshrunh_n_s16 vqshruns_n_s32 vqshrund_n_s64 vqshrun_high_n_s16 vqshrun_high_n_s32 vqshrun_high_n_s64 vqrshrun_n Signed saturating rounded shift right unsigned narrow (immediate) Click here to expand the API list vqrshrun_n_s16 vqrshrun_n_s32 vqrshrun_n_s64 vqrshrunh_n_s16 vqrshruns_n_s32 vqrshrund_n_s64 vqrshrun_high_n_s16 vqrshrun_high_n_s32 vqrshrun_high_n_s64 vqshrn_n Signed saturating shift right narrow (immediate) Click here to expand the API list vqshrn_n_s16 vqshrn_n_s32 vqshrn_n_s64 vqshrn_n_u16 vqshrn_n_u32 vqshrn_n_u64 vqshrnh_n_s16 vqshrnh_n_u16 vqshrns_n_s32 vqshrns_n_u32 vqshrnd_n_s64 vqshrnd_n_u64 vqshrn_high_n_s16 vqshrn_high_n_s32 vqshrn_high_n_s64 vqshrn_high_n_u16 vqshrn_high_n_u32 vqshrn_high_n_u64 vrshrn_n Rounding shift right narrow (immediate) Click here to expand the API list vrshrn_n_s16 vrshrn_n_s32 vrshrn_n_s64 vrshrn_n_u16 vrshrn_n_u32 vrshrn_n_u64 vrshrn_high_n_s16 vrshrn_high_n_s32 vrshrn_high_n_s64 vrshrn_high_n_u16 vrshrn_high_n_u32 vrshrn_high_n_u64 vqrshrn_n Signed saturating rounded shift right narrow (immediate) Click here to expand the API list vqrshrn_n_s16 vqrshrn_n_s32 vqrshrn_n_s64 vqrshrn_n_u16 vqrshrn_n_u32 vqrshrn_n_u64 vqrshrnh_n_s16 vqrshrnh_n_u16 vqrshrns_n_s32 vqrshrns_n_u32 vqrshrnd_n_s64 vqrshrnd_n_u64 vqrshrn_high_n_s16 vqrshrn_high_n_s32 vqrshrn_high_n_s64 vqrshrn_high_n_u16 vqrshrn_high_n_u32 vqrshrn_high_n_u64 vsra_n Signed shift right and accumulate (immediate) Click here to expand the API list vsra_n_s16 vsra_n_s32 vsra_n_s64 vsra_n_s8 vsra_n_u16 vsra_n_u32 vsra_n_u64 vsra_n_u8 vsraq_n_s16 vsraq_n_s32 vsraq_n_s64 vsraq_n_s8 vsraq_n_u16 vsraq_n_u32 vsraq_n_u64 vsraq_n_u8 vsrad_n_s64 vsrad_n_u64 vrsra_n Signed rounding shift right and accumulate (immediate) Click here to expand the API list vrsra_n_s16 vrsra_n_s32 vrsra_n_s64 vrsra_n_s8 vrsra_n_u16 vrsra_n_u32 vrsra_n_u64 vrsra_n_u8 vrsraq_n_s16 vrsraq_n_s32 vrsraq_n_s64 vrsraq_n_s8 vrsraq_n_u16 vrsraq_n_u32 vrsraq_n_u64 vrsraq_n_u8 vrsrad_n_s64 vrsrad_n_u64 vsri_n Shift right and insert (immediate) Click here to expand the API list vsri_n_s16 vsri_n_s32 vsri_n_s64 vsri_n_s8 vsri_n_u16 vsri_n_u32 vsri_n_u64 vsri_n_u8 vsriq_n_s16 vsriq_n_s32 vsriq_n_s64 vsriq_n_s8 vsriq_n_u16 vsriq_n_u32 vsriq_n_u64 vsriq_n_u8 vsrid_n_s64 vsrid_n_u64 vsli_n Shift left and insert (immediate) Click here to expand the API list vsli_n_s16 vsli_n_s32 vsli_n_s64 vsli_n_s8 vsli_n_u16 vsli_n_u32 vsli_n_u64 vsli_n_u8 vsliq_n_s16 vsliq_n_s32 vsliq_n_s64 vsliq_n_s8 vsliq_n_u16 vsliq_n_u32 vsliq_n_u64 vsliq_n_u8 vslid_n_s64 vslid_n_u64 Floating-point Operation Description APIs vcvt Convert to/from another precision or fixed point, rounding towards zero Click here to expand the API list vcvt_f32_f64 vcvt_f32_s32 vcvt_f32_u32 vcvt_f64_f32 vcvt_f64_s64 vcvt_f64_u64 vcvt_s32_f32 vcvt_s64_f64 vcvt_u32_f32 vcvt_u64_f64 vcvtq_f32_s32 vcvtq_f32_u32 vcvtq_f64_s64 vcvtq_f64_u64 vcvtq_s32_f32 vcvtq_s64_f64 vcvtq_u32_f32 vcvtq_u64_f64 vcvts_f32_s32 vcvts_f32_u32 vcvts_s32_f32 vcvts_u32_f32 vcvtd_f64_s64 vcvtd_f64_u64 vcvtd_s64_f64 vcvtd_u64_f64 vcvt_high_f32_f64 vcvt_high_f64_f32 vcvta Convert to integer, rounding to nearest with ties to away Click here to expand the API list vcvta_s32_f32 vcvta_s64_f64 vcvta_u32_f32 vcvta_u64_f64 vcvtad_s64_f64 vcvtad_u64_f64 vcvtaq_s32_f32 vcvtaq_s64_f64 vcvtaq_u32_f32 vcvtaq_u64_f64 vcvtas_s32_f32 vcvtas_u32_f32 vcvtm Convert to integer, rounding towards minus infinity Click here to expand the API list vcvtm_s32_f32 vcvtm_s64_f64 vcvtm_u32_f32 vcvtm_u64_f64 vcvtmq_s32_f32 vcvtmq_s64_f64 vcvtmq_u32_f32 vcvtmq_u64_f64 vcvtms_s32_f32 vcvtms_u32_f32 vcvtmd_s64_f64 vcvtmd_u64_f64 vcvtn Convert to integer, rounding to nearest with ties to even Click here to expand the API list vcvtn_s32_f32 vcvtn_s64_f64 vcvtn_u32_f32 vcvtn_u64_f64 vcvtnq_s32_f32 vcvtnq_s64_f64 vcvtnq_u32_f32 vcvtnq_u64_f64 vcvtns_s32_f32 vcvtns_u32_f32 vcvtnd_s64_f64 vcvtnd_u64_f64 vcvtp Convert to integer, rounding towards plus infinity Click here to expand the API list vcvtp_s32_f32 vcvtp_s64_f64 vcvtp_u32_f32 vcvtp_u64_f64 vcvtpq_s32_f32 vcvtpq_s64_f64 vcvtpq_u32_f32 vcvtpq_u64_f64 vcvtps_s32_f32 vcvtps_u32_f32 vcvtpd_s64_f64 vcvtpd_u64_f64 vcvtx Convert to lower precision, rounding to nearest with ties to odd Click here to expand the API list vcvtx_f32_f64 vcvtx_high_f32_f64 vcvtxd_f32_f64 vcvt_n Convert to/from fixed point, rounding towards zero Click here to expand the API list vcvt_n_f32_s32 vcvt_n_f32_u32 vcvt_n_f64_s64 vcvt_n_f64_u64 vcvt_n_s32_f32 vcvt_n_s64_f64 vcvt_n_u32_f32 vcvt_n_u64_f64 vcvtq_n_f32_s32 vcvtq_n_f32_u32 vcvtq_n_f64_s64 vcvtq_n_f64_u64 vcvtq_n_s32_f32 vcvtq_n_s64_f64 vcvtq_n_u32_f32 vcvtq_n_u64_f64 vcvts_n_f32_s32 vcvts_n_f32_u32 vcvts_n_s32_f32 vcvts_n_u32_f32 vcvtd_n_f64_s64 vcvtd_n_f64_u64 vcvtd_n_s64_f64 vcvtd_n_u64_f64 vrnd Round to Integral, toward zero Click here to expand the API list vrnd_f32 vrnd_f64 vrndq_f32 vrndq_f64 vrnda Round to Integral, with ties to away Click here to expand the API list vrnda_f32 vrnda_f64 vrndaq_f32 vrndaq_f64 vrndi Round to Integral, using current rounding mode Click here to expand the API list vrndi_f32 vrndi_f64 vrndiq_f32 vrndiq_f64 vrndm Round to Integral, towards minus infinity Click here to expand the API list vrndm_f32 vrndm_f64 vrndmq_f32 vrndmq_f64 vrndn Round to Integral, with ties to even Click here to expand the API list vrndn_f32 vrndn_f64 vrndnq_f32 vrndnq_f64 vrndns_f32 vrndp Round to Integral, towards plus infinity Click here to expand the API list vrndp_f32 vrndp_f64 vrndpq_f32 vrndpq_f64 vrndx Round to Integral exact Click here to expand the API list vrndx_f32 vrndx_f64 vrndxq_f32 vrndxq_f64 Load and store Operation Description APIs vld1 Load vector from memory Click here to expand the API list vld1_f32 vld1_f64 vld1_s16 vld1_s32 vld1_s64 vld1_s8 vld1_u16 vld1_u32 vld1_u64 vld1_u8 vld1q_f32 vld1q_f64 vld1q_s16 vld1q_s32 vld1q_s64 vld1q_s8 vld1q_u16 vld1q_u32 vld1q_u64 vld1q_u8 vst1 Store vector to memory Click here to expand the API list vst1_f32 vst1_f64 vst1_s16 vst1_s32 vst1_s64 vst1_s8 vst1_u16 vst1_u32 vst1_u64 vst1_u8 vst1q_f32 vst1q_f64 vst1q_s16 vst1q_s32 vst1q_s64 vst1q_s8 vst1q_u16 vst1q_u32 vst1q_u64 vst1q_u8 vget_lane Get vector element Click here to expand the API list vget_lane_f32 vget_lane_f64 vget_lane_s16 vget_lane_s32 vget_lane_s64 vget_lane_s8 vget_lane_u16 vget_lane_u32 vget_lane_u64 vget_lane_u8 vgetq_lane_f32 vgetq_lane_f64 vgetq_lane_s16 vgetq_lane_s32 vgetq_lane_s64 vgetq_lane_s8 vgetq_lane_u16 vgetq_lane_u32 vgetq_lane_u64 vgetq_lane_u8 vset_lane Set vector element Click here to expand the API list vset_lane_f32 vset_lane_f64 vset_lane_s16 vset_lane_s32 vset_lane_s64 vset_lane_s8 vset_lane_u16 vset_lane_u32 vset_lane_u64 vset_lane_u8 vsetq_lane_f32 vsetq_lane_f64 vsetq_lane_s16 vsetq_lane_s32 vsetq_lane_s64 vsetq_lane_s8 vsetq_lane_u16 vsetq_lane_u32 vsetq_lane_u64 vsetq_lane_u8 Permutation Operation Description APIs vext Extract vector from pair of vectors Click here to expand the API list vext_f32 vext_f64 vext_s16 vext_s32 vext_s64 vext_s8 vext_u16 vext_u32 vext_u64 vext_u8 vextq_f32 vextq_f64 vextq_s16 vextq_s32 vextq_s64 vextq_s8 vextq_u16 vextq_u32 vextq_u64 vextq_u8 vtbl1 Table vector Lookup Click here to expand the API list vtbl1_s8 vtbl1_u8 vtbx1 Table vector lookup extension Click here to expand the API list vtbx1_s8 vtbx1_u8 vqtbl1 Table vector Lookup Click here to expand the API list vqtbl1_s8 vqtbl1_u8 vqtbl1q_s8 vqtbl1q_u8 vqtbx1 Table vector lookup extension Click here to expand the API list vqtbx1_s8 vqtbx1_u8 vqtbx1q_s8 vqtbx1q_u8 vrbit Reverse bit order Click here to expand the API list vrbit_s8 vrbit_u8 vrbitq_s8 vrbitq_u8 vrev16 Reverse elements in 16-bit halfwords Click here to expand the API list vrev16_s8 vrev16_u8 vrev16q_s8 vrev16q_u8 vrev32 Reverse elements in 32-bit words Click here to expand the API list vrev32_s16 vrev32_s8 vrev32_u16 vrev32_u8 vrev32q_s16 vrev32q_s8 vrev32q_u16 vrev32q_u8 vrev64 Reverse elements in 64-bit doublewords Click here to expand the API list vrev64_f32 vrev64_s16 vrev64_s32 vrev64_s8 vrev64_u16 vrev64_u32 vrev64_u8 vrev64q_f32 vrev64q_s16 vrev64q_s32 vrev64q_s8 vrev64q_u16 vrev64q_u32 vrev64q_u8 vtrn1 Transpose vectors (primary) Click here to expand the API list vtrn1_f32 vtrn1_s16 vtrn1_s32 vtrn1_s8 vtrn1_u16 vtrn1_u32 vtrn1_u8 vtrn1q_f32 vtrn1q_f64 vtrn1q_s16 vtrn1q_s32 vtrn1q_s64 vtrn1q_s8 vtrn1q_u16 vtrn1q_u32 vtrn1q_u64 vtrn1q_u8 vtrn2 Transpose vectors (secondary) Click here to expand the API list vtrn2_f32 vtrn2_s16 vtrn2_s32 vtrn2_s8 vtrn2_u16 vtrn2_u32 vtrn2_u8 vtrn2q_f32 vtrn2q_f64 vtrn2q_s16 vtrn2q_s32 vtrn2q_s64 vtrn2q_s8 vtrn2q_u16 vtrn2q_u32 vtrn2q_u64 vtrn2q_u8 vzip1 Zip vectors (primary) Click here to expand the API list vzip1_f32 vzip1_s16 vzip1_s32 vzip1_s8 vzip1_u16 vzip1_u32 vzip1_u8 vzip1q_f32 vzip1q_f64 vzip1q_s16 vzip1q_s32 vzip1q_s64 vzip1q_s8 vzip1q_u16 vzip1q_u32 vzip1q_u64 vzip1q_u8 vzip2 Zip vectors (secondary) Click here to expand the API list vzip2_f32 vzip2_s16 vzip2_s32 vzip2_s8 vzip2_u16 vzip2_u32 vzip2_u8<br/vzip2q_f32 vzip2q_f64 vzip2q_s16 vzip2q_s32 vzip2q_s64 vzip2q_s8 vzip2q_u16 vzip2q_u32 vzip2q_u64 vzip2q_u8 vuzp1 Unzip vectors (primary) Click here to expand the API list vuzp1_f32 vuzp1_s16 vuzp1_s32 vuzp1_s8 vuzp1_u16 vuzp1_u32 vuzp1_u8 vuzp1q_f32 vuzp1q_f64 vuzp1q_s16 vuzp1q_s32 vuzp1q_s64 vuzp1q_s8 vuzp1q_u16 vuzp1q_u32 vuzp1q_u64 vuzp1q_u8 vuzp2 Unzip vectors (secondary) Click here to expand the API list vuzp2_f32 vuzp2_s16 vuzp2_s32 vuzp2_s8 vuzp2_u16 vuzp2_u32 vuzp2_u8 vuzp2q_f32 vuzp2q_f64 vuzp2q_s16 vuzp2q_s32 vuzp2q_s64 vuzp2q_s8 vuzp2q_u16 vuzp2q_u32 vuzp2q_u64 vuzp2q_u8 Cryptographic Operation APIs CRC32 Click here to expand the API list __crc32b __crc32cb __crc32cd __crc32ch __crc32cw __crc32d __crc32h __crc32w SHA1 Click here to expand the API list vsha1cq_u32 vsha1h_u32 vsha1mq_u32 vsha1pq_u32 vsha1su0q_u32 vsha1su1q_u32 SHA256 Click here to expand the API list vsha256h2q_u32 vsha256hq_u32 vsha256su0q_u32 vsha256su1q_u32 AES Click here to expand the API list vaesdq_u8 vaeseq_u8 vaesimcq_u8 vaesmcq_u8 Miscellaneous Operation Description APIs vsqrt Square root Click here to expand the API list vsqrt_f32 vsqrt_f64 vsqrtq_f32 vsqrtq_f64 vdot Dot product Click here to expand the API list vdot_s32 vdot_u32 vdotq_s32 vdotq_u32 vdot_lane Dot product Click here to expand the API list vdot_lane_s32 vdot_lane_u32 vdot_laneq_s32 vdot_laneq_u32 vdotq_lane_s32 vdotq_lane_u32 vdotq_laneq_s32 vdotq_laneq_u32"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics-processors.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics-processors.html",
    "title": "Processor specific SIMD extensions | mmo-rpg-unity",
    "keywords": "Processor specific SIMD extensions Burst exposes all Intel SIMD intrinsics from SSE up to and including AVX2 in the Unity.Burst.Intrinsics.X86 family of nested classes. The Unity.Burst.Intrinsics.Arm.Neon class provides intrinsics for Arm Neon's Armv7, Armv8, and Armv8.2 (RDMA, crypto, dotprod). Organizing your code You should statically import these intrinsics because they contain plain static functions: using static Unity.Burst.Intrinsics.X86; using static Unity.Burst.Intrinsics.X86.Sse; using static Unity.Burst.Intrinsics.X86.Sse2; using static Unity.Burst.Intrinsics.X86.Sse3; using static Unity.Burst.Intrinsics.X86.Ssse3; using static Unity.Burst.Intrinsics.X86.Sse4_1; using static Unity.Burst.Intrinsics.X86.Sse4_2; using static Unity.Burst.Intrinsics.X86.Popcnt; using static Unity.Burst.Intrinsics.X86.Avx; using static Unity.Burst.Intrinsics.X86.Avx2; using static Unity.Burst.Intrinsics.X86.Fma; using static Unity.Burst.Intrinsics.X86.F16C; using static Unity.Burst.Intrinsics.X86.Bmi1; using static Unity.Burst.Intrinsics.X86.Bmi2; using static Unity.Burst.Intrinsics.Arm.Neon; Burst CPU intrinsics are translated into specific CPU instructions. However, Burst has a special compiler pass which makes sure that your CPU target set in Burst AOT Settings is compatible with the intrinsics used in your code. This ensures you don't try to call unsupported instructions (for example, AArch64 Neon on an Intel CPU or AVX2 instructions on an SSE4 CPU), which causes the process to abort with an \"Invalid instruction\" exception. A compiler error is generated if the check fails. However, if you want to provide several code paths with different CPU targets, or to make sure your intrinsics code is compatible with any target CPU, you can wrap your intrinsics code with the followinf property checks: IsNeonSupported IsNeonArmv82FeaturesSupported IsNeonCryptoSupported IsNeonDotProdSupported IsNeonRDMASupported For example: if (IsAvx2Supported) { // Code path for AVX2 instructions } else if (IsSse42Supported) { // Code path for SSE4.2 instructions } else if (IsNeonArmv82FeaturesSupported) { // Code path for Armv8.2 Neon instructions } else if (IsNeonSupported) { // Code path for Arm Neon instructions } else { // Fallback path for everything else } These branches don't affect performance. Burst evaluates the IsXXXSupported properties at compile-time and eliminates unsupported branches as dead code, while the active branch stays there without the if check. Later feature levels implicitly include the previous ones, so you should organize tests from most recent to oldest. Burst emits compile-time errors if you've used intrinsics that aren't part of the current compilation target. Burst doesn't bracket these with a feature level test, which helps you to narrow in on what to put inside a feature test. If you run your application in .NET, Mono or IL2CPP without Burst enabled, all the IsXXXSupported properties return false. However, if you skip the test you can still run a reference version of most intrinsics in Mono (exceptions listed below), which is helpful if you need to use the managed debugger. Reference implementations are slow and only intended for managed debugging. Important There isn't a reference managed implementation of Arm Neon intrinsics. This means that you can't use the technique mentioned in the previous paragraph to step through the intrinsics in Mono. FMA intrinsics that operate on doubles don't have a software fallback because of the inherit complexity in emulating fused 64-bit floating point math. Intrinsics use the types v64 (Arm only), v128 and v256, which represent a 64-bit, 128-bit or 256-bit vector respectively. For example, given a NativeArray<float> and a Lut lookup table of v128 shuffle masks, a code fragment like this performs lane left packing, demonstrating the use of vector load/store reinterpretation and direct intrinsic calls: v128 a = Input.ReinterpretLoad<v128>(i); v128 mask = cmplt_ps(a, Limit); int m = movemask_ps(a); v128 packed = shuffle_epi8(a, Lut[m]); Output.ReinterpretStore(outputIndex, packed); outputIndex += popcnt_u32((uint)m); Intel intrinsics The Intel intrinsics API mirrors the C/C++ Intel instrinsics API, with a the following differences: All 128-bit vector types (__m128, __m128i and __m128d) are collapsed into v128 All 256-bit vector types (__m256, __m256i and __m256d) are collapsed into v256 All _mm prefixes on instructions and macros are dropped, because C# has namespaces All bitfield constants (for example, rounding mode selection) are replaced with C# bitflag enum values Arm Neon intrinsics The Arm Neon intrinsics API mirrors the Arm C Language Extensions, with the following differences: All vector types are collapsed into v64 and v128, becoming typeless. This means that the vector type must contain expected element types and count when calling an API. The *x2, *x3, *x4 vector types aren't supported. poly* types aren't supported. reinterpret* functions aren't supported (they aren't needed because of the usage of v64 and v128 vector types). Intrinsic usage is only supported on Armv8 (64-bit) hardware. Burst's CPU intrinsics use typeless vectors. Because of this, Burst doesn't perform any type checks. For example, if you call an intrinsic which processes 4 ints on a vector that was initialized with 4 floats, then there's no compiler error. The vector types have fields that represent every element type, in a union-like struct, which gives you flexibility to use these intrinsics in a way that best fits your code. Arm Neon C intrinsics (ACLE) use typed vectors, for example int32x4_t, and has special APIs (for example, reinterpret_\\*) to convert to a vector of another element type. Burst CPU intrinsics vectors are typeless, so these APIs are not needed. The following APIs provide the equivalent functionality: v64 (Arm Neon only) v128 v256 For a categorized index of Arm Neon intrinsics supported in Burst, see the Arm Neon intrinsics reference."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-burst-intrinsics.html",
    "title": "Burst intrinsics overview | mmo-rpg-unity",
    "keywords": "Burst intrinsics overview Burst provides low level intrinsics in the Unity.Burst.Intrinsics namespace. This is useful if you know how to write single instruction, multiple data (SIMD) assembly code, and you want to get extra performance from Burst code. For most use cases, you won't need to use these. This section contains the following information Page Description Burst intrinsics Common class Overview of the Burst.Intrinsics.Common class, which provides functionality shared across the hardware targets that Burst supports. DllImport and internal calls Overview of [DllImport], which is for calling native functions. Processor specific SIMD extensions Overview of the Intel and Arm Neon intrinsics. Arm Neon intrinsics reference Reference of the methods in the Burst.Intrinsics.Arm.Neon class."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-calling-burst-code.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-calling-burst-code.html",
    "title": "Calling Burst-compiled code | mmo-rpg-unity",
    "keywords": "Calling Burst-compiled code You can call Burst-compiled methods direct from managed code. Calling generic methods or methods whose declaring type is generic isn't supported, otherwise the rules as for function pointers apply. However, you don't need to worry about the extra boiler plate needed for function pointers. The following example shows a Burst-compiled utility class. Because it uses structs, it passes by reference per the function pointer rules. [BurstCompile] public static class MyBurstUtilityClass { [BurstCompile] public static void BurstCompiled_MultiplyAdd(in float4 mula, in float4 mulb, in float4 add, out float4 result) { result = mula * mulb + add; } } Use this method from managed code like so: public class MyMonoBehaviour : MonoBehaviour { void Start() { var mula = new float4(1, 2, 3, 4); var mulb = new float4(-1,1,-1,1); var add = new float4(99,0,0,0); MyBurstUtilityClass.BurstCompiled_MultiplyAdd(mula, mulb, add, out var result); Debug.Log(result); } } If you attach this script to an object and run it, float4(98f, 2f, -3f, 4f) is printed to the log. Code transformation Burst uses IL Post Processing to automatically transform the code into a function pointer and call. For more information, see the documentation on Function pointers. To disable the direct call transformation, addDisableDirectCall = true to the BurstCompile options. This prevents the Post Processor from running on the code: [BurstCompile] public static class MyBurstUtilityClass { [BurstCompile(DisableDirectCall = true)] public static void BurstCompiled_MultiplyAdd(in float4 mula, in float4 mulb, in float4 add, out float4 result) { result = mula * mulb + add; } }"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-function-pointers.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-function-pointers.html",
    "title": "Function pointers | mmo-rpg-unity",
    "keywords": "Function pointers To work with dynamic functions that process data based on other data states, use FunctionPointer<T>. Because Burst treats delegates as managed objects, you can't use C# delegates to work with dynamic functions. Support details Function pointers don't support generic delegates. Also, avoid wrapping BurstCompiler.CompileFunctionPointer<T> within another open generic method. If you do this, Burst can't apply required attributes to the delegate, perform additional safety analysis, or perform potential optimizations. Argument and return types are subject to the same restrictions as DllImport and internal calls. For more information, see the documentation on DllImport and internal calls. Interoperability with IL2CPP Interoperability of function pointers with IL2CPP requires System.Runtime.InteropServices.UnmanagedFunctionPointerAttribute on the delegate. Set the calling convention to CallingConvention.Cdecl. Burst automatically adds this attribute to delegates that are used with BurstCompiler.CompileFunctionPointer<T>. Using function pointers To use function pointers, identify the static functions that you want Burst to compile and do the following: Add a [BurstCompile] attribute to these functions Add a [BurstCompile] attribute to the containing type. This helps the Burst compiler find the static methods that have [BurstCompile] attribute Declare a delegate to create the \"interface\" of these functions Add a [MonoPInvokeCallbackAttribute] attribute to the functions. You need to add this so that IL2CPP works with these functions. For example: // Instruct Burst to look for static methods with [BurstCompile] attribute [BurstCompile] class EnclosingType { [BurstCompile] [MonoPInvokeCallback(typeof(Process2FloatsDelegate))] public static float MultiplyFloat(float a, float b) => a * b; [BurstCompile] [MonoPInvokeCallback(typeof(Process2FloatsDelegate))] public static float AddFloat(float a, float b) => a + b; // A common interface for both MultiplyFloat and AddFloat methods public delegate float Process2FloatsDelegate(float a, float b); } Compile these function pointers from regular C# code: // Contains a compiled version of MultiplyFloat with Burst FunctionPointer<Process2FloatsDelegate> mulFunctionPointer = BurstCompiler.CompileFunctionPointer<Process2FloatsDelegate>(MultiplyFloat); // Contains a compiled version of AddFloat with Burst FunctionPointer<Process2FloatsDelegate> addFunctionPointer = BurstCompiler. CompileFunctionPointer<Process2FloatsDelegate>(AddFloat); Using function pointers in a job To use the function pointers directly from a job, pass them to the job struct: // Invoke the function pointers from HPC# jobs var resultMul = mulFunctionPointer.Invoke(1.0f, 2.0f); var resultAdd = addFunctionPointer.Invoke(1.0f, 2.0f); Burst compiles function pointers asynchronously for jobs by default. To force a synchronous compilation of function pointers use [BurstCompile(SynchronousCompilation = true)]. Using function pointers in C# code To use these function pointers from regular C# code, cache the FunctionPointer<T>.Invoke property (which is the delegate instance) to a static field to get the best performance: private readonly static Process2FloatsDelegate mulFunctionPointerInvoke = BurstCompiler.CompileFunctionPointer<Process2FloatsDelegate>(MultiplyFloat).Invoke; // Invoke the delegate from C# var resultMul = mulFunctionPointerInvoke(1.0f, 2.0f); Using Burst-compiled function pointers from C# might be slower than their pure C# version counterparts if the function is too small compared to the overhead of P/Invoke interop. Performance considerations Where possible, you use a job over a function pointer to run Burst compiled code, because jobs are more optimal. Burst provides better aliasing calculations for jobs because the job safety system has more optimizations by default. You also can't pass most of the [NativeContainer] structs like NativeArray directly to function pointers and must use a job struct to do so. Native container structs contain managed objects for safety checks that the Burst compiler can work around when compiling jobs, but not for function pointers. The following example shows a bad example of how to use function pointers in Burst. The function pointer computes math.sqrt from an input pointer and stores it to an output pointer. MyJob feeds this function pointer sources from two NativeArrays which isn't optimal: ///Bad function pointer example [BurstCompile] public class MyFunctionPointers { public unsafe delegate void MyFunctionPointerDelegate(float* input, float* output); [BurstCompile] public static unsafe void MyFunctionPointer(float* input, float* output) { *output = math.sqrt(*input); } } [BurstCompile] struct MyJob : IJobParallelFor { public FunctionPointer<MyFunctionPointers.MyFunctionPointerDelegate> FunctionPointer; [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public unsafe void Execute(int index) { var inputPtr = (float*)Input.GetUnsafeReadOnlyPtr(); var outputPtr = (float*)Output.GetUnsafePtr(); FunctionPointer.Invoke(inputPtr + index, outputPtr + index); } } This example isn't optimal for the following reasons: Burst can't vectorize the function pointer because it's being fed a single scalar element. This means that 4-8x performance is lost from a lack of vectorization. The MyJob knows that the Input and Output native arrays can't alias, but this information isn't communicated to the function pointer. There is a non-zero overhead to constantly branching to a function pointer somewhere else in memory. To use a function pointer in an optimal way, always process batches of data in the function pointer, like so: [BurstCompile] public class MyFunctionPointers { public unsafe delegate void MyFunctionPointerDelegate(int count, float* input, float* output); [BurstCompile] public static unsafe void MyFunctionPointer(int count, float* input, float* output) { for (int i = 0; i < count; i++) { output[i] = math.sqrt(input[i]); } } } [BurstCompile] struct MyJob : IJobParallelForBatch { public FunctionPointer<MyFunctionPointers.MyFunctionPointerDelegate> FunctionPointer; [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public unsafe void Execute(int index, int count) { var inputPtr = (float*)Input.GetUnsafeReadOnlyPtr() + index; var outputPtr = (float*)Output.GetUnsafePtr() + index; FunctionPointer.Invoke(count, inputPtr, outputPtr); } } Thee modified MyFunctionPointer takes a count of elements to process, and loops over the input and output pointers to do a lot of calculations. The MyJob becomes an IJobParallelForBatch, and the count is passed directly into the function pointer. This is better for performance because of the following reasons: Burst vectorizes the MyFunctionPointer call. Because Burst processes count items per function pointer, any overhead of calling the function pointer is reduced by count times. For example, if you run a batch of 128, the function pointer overhead is 1/128th per index of what it was previously. Batching results in a 1.53x performance gain over not batching. However, to get the best possible performance, use a job. This gives Burst the most visibility over what you want it to do, and the most opportunities to optimize: [BurstCompile] struct MyJob : IJobParallelFor { [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public unsafe void Execute(int index) { Output[i] = math.sqrt(Input[i]); } } This runs 1.26x faster than the batched function pointer example, and 1.93x faster than the non-batched function pointer examples. Burst has perfect aliasing knowledge and can make the broadest modifications to the above. This code is also a lot simpler than either of the function pointer cases."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-hpc-overview.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-hpc-overview.html",
    "title": "| mmo-rpg-unity",
    "keywords": "HPC# overview Burst uses a high performance subset of C# called High Performance C# (HPC#). Supported C# features in HPC# HPC# supports most expressions and statements in C#. It supports the following: Supported feature Notes Extension methods. Instance methods of structs. Unsafe code and pointer manipulation. Loading from static read-only fields. For more information, see the documentation on Static read-only fields and static constructors. Regular C# control flows. if else switch case for while break continue ref and out parameters fixed statements Some IL opcodes. cpblk initblk sizeof DLLImport and internal calls. For more information, see the documentation on DLLImport and internal calls. try and finally keywords. Burst also supports the associated IDisposable patterns, using and foreach. If an exception happens in Burst, the behavior is different from .NET. In .NET, if an exception occurs inside a try block, control flow goes to the finally block. However, in Burst, if an exception happens inside or outside a try block, the exception throws as if any finally blocks do not exist. Invoking foreach calls is supported by Burst, but there is a foreach edge case that burst currently does not support (see \"Foreach and While\" section for more details). Strings and ProfilerMarker. For more information, see the documentation on Support for Unity Profiler markers. throw expressions. Burst only supports simple throw patterns, for example, throw new ArgumentException(\"Invalid argument\"). When you use simple patterns like this, Burst extracts the static string exception message and includes it in the generated code. Strings and Debug.Log. Only partially supported. For more information, see the documentation on String support and Debug.Log. Burst also provides alternatives for some C# constructions not directly accessible to HPC#: Function pointers as an alternative to using delegates within HPC# Shared static to access static mutable data from both C# and HPC# Exception expressions Burst supports throw expressions for exceptions. Exceptions thrown in the editor can be caught by managed code, and are reported in the console window. Exceptions thrown in player builds will always cause the application to abort. Thus with Burst you should only use exceptions for exceptional behavior. To ensure that code doesn't end up relying on exceptions for things like general control flow, Burst produces the following warning on code that tries to throw within a method not attributed with [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")]: Burst warning BC1370: An exception was thrown from a function without the correct [Conditional(\"ENABLE_UNITY_COLLECTIONS_CHECKS\")] guard. Exceptions only work in the editor and so should be protected by this guard Foreach and While Burst supports invoking foreach and while. However, there is an edge case which is currently unsupported - methods that take one or more generic collection parameters T: IEnumerable<U> and invoke foreach or while on at least one of the collections in the method body. To illustrate, the following example methods exemplify this limitation: public static void IterateThroughConcreteCollection(NativeArray<int> list) { foreach (var element in list) { // This works } } public static void IterateThroughGenericCollection<S>(S list) where S : struct, IEnumerable<int> { foreach (var element in list) { // This doesn't work } } Note that the uppermost method IterateThroughConcreteCollection()'s parameter is specified to be a concrete collection type, in this case NativeArray<int>. Because it's concrete iterating through it inside the method will compile in Burst. In the method IterateThroughGenericCollection() below it, however, the parameter is specified to be a generic collection type S. Iterating through S inside the method will therefore not compile in Burst. It will instead throw the following error: Can't call the method (method name) on the generic interface object type (object name). This may be because you are trying to do a foreach over a generic collection of type IEnumerable. Unsupported C# features in HPC# HPC# doesn't support the following C# features: Catching exceptions catch in a try/catch. Storing to static fields except via Shared Static Any methods related to managed objects, for example, string methods."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-language-support.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-language-support.html",
    "title": "C# language support | mmo-rpg-unity",
    "keywords": "C# language support Burst uses a high performance subset of C# called High Performance C# (HPC#) which has a number of limitations and differences between C#. Topic Description HPC# overview Understand how HPC# works with Burst. C#/.NET type support Understand the supported C# features. C#/.NET System namespace support Understand what's supported in the System namespace. Static read-only fields and static constructor support Use static read-only fields and static constructors in Burst code. String support Use strings in Burst code. Calling Burst compiled code Call Burst compiled code from managed code. Function pointers Use function pointers to work with dynamic functions. SharedStatic struct Use SharedStatic to share static mutable data. Additional resources Burst instrinsics overview"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-shared-static.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-shared-static.html",
    "title": "SharedStatic struct | mmo-rpg-unity",
    "keywords": "SharedStatic struct Burst has basic support for accessing static readonly data. However, if you want to share static mutable data between C# and HPC#, use the SharedStatic<T> struct. The following example shows accessing an int static field that both C# and HPC# can change: public abstract class MutableStaticTest { public static readonly SharedStatic<int> IntField = SharedStatic<int>.GetOrCreate<MutableStaticTest, IntFieldKey>(); // Define a Key type to identify IntField private class IntFieldKey {} } C# and HPC# can then access this: // Write to a shared static MutableStaticTest.IntField.Data = 5; // Read from a shared static var value = 1 + MutableStaticTest.IntField.Data; When you use SharedStatic<T>, be aware of the following: The T in SharedStatic<T> defines the data type. To identify a static field, provide a context for it. To do this, create a key for both the containing type (for example, MutableStaticTest in the example above), identify the field (for example, IntFieldKey class in the example above) and pass these classes as generic arguments of SharedStatic<int>.GetOrCreate<MutableStaticTest, IntFieldKey>(). Always initialize the shared static field in C# from a static constructor before accessing it from HPC#. If you don't initialize the data before accessing it, it might lead to an undefined initialization state."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-static-read-only-support.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-static-read-only-support.html",
    "title": "Static read-only fields and static constructor support | mmo-rpg-unity",
    "keywords": "Static read-only fields and static constructor support Burst evaluates all static fields and all static constructors at compile time. It evaluates all the static fields and the static constructors for a given struct together. When there is a static field that isn't read-only in a Burst-compiled struct, a compilation error happens. This is because Burst only supports read-only static fields. When Burst fails to evaluate any static field or static constructor, all fields and constructors fail for that struct. When compile-time evaluation fails, Burst falls back to compiling all static initialization code into an initialization function that it calls once at runtime. This means that your code needs to be Burst compatible, or it will fail compilation if it fails compile-time evaluation. An exception to this is that there's limited support for initializing static read-only array fields as long as they're initialized from either an array constructor or from static data: static readonly int[] MyArray0 = { 1, 2, 3, .. }; static readonly int[] MyArray1 = new int[10]; Language support Burst doesn't support calling external functions and function pointers. It supports using the following base language with static read-only fields and constructors: Managed arrays Strings Limited intrinsic support: Unity.Burst.BurstCompiler.IsEnabled Unity.Burst.BurstRuntime.GetHashCode32 Unity.Burst.BurstRuntime.GetHashCode64 Vector type construction Limited intrinsic assertion support: UnityEngine.Debug.Assert NUnit.Framework.Assert.AreEqual NUnit.Framework.Assert.AreNotEqual Simple throw patterns. Any exceptions thrown during evaluation become compiler errors."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-string-support.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-string-support.html",
    "title": "String support | mmo-rpg-unity",
    "keywords": "String support Burst supports string usage in the following scenarios: Debug.Log Assigning a string to the FixedString structs that Unity.Collections provides, for example FixedString128Bytes. The System.Runtime.CompilerServices attributes [CallerLineNumber], [CallerMemberName], and [CallerFilePath] on arguments to Burst functions. However, you can only pass the strings directly to calls to Debug.Log. A string can be either: A string literal. For example: \"This is a string literal\". An interpolated string using $\"This is an integer {value} or using string.Format, where the string to format is also a string literal. For example, Burst supports the following constructions: Logging with a string literal: Debug.Log(\"This a string literal\"); Logging using string interpolation: int value = 256; Debug.Log($\"This is an integer value {value}\"); This is the same as using string.Format directly: int value = 256; Debug.Log(string.Format(\"This is an integer value {0}\", value)); Supported Debug.Log methods Burst supports the following Debug.Log methods: Debug.Log(object) Debug.LogWarning(object) Debug.LogError(object) String interpolation support String interpolation has the following restrictions: The string must be a string literal Burst supports the following string.Format methods: string.Format(string, object) string.Format(string, object, object) string.Format(string, object, object, object) string.Format(string, object[]). Use this for a string interpolation that contains more than three arguments, for example $\"{arg1} {arg2} {arg3} {arg4} {arg5}\". In this case, the object[] array needs to be a constant size and no arguments should involve control flows (for example, $\"This is a {(cond ? arg1 : arg2)}\"). The string must only use value types The string must take only built-in type arguments: char boolean byte / sbyte double float short / ushort int / uint long / ulong Burst supports sll vector types (for example int2, float3), except half vector types. For example: var value = new float3(1.0f, 2.0f, 3.0f); // Logs \"This value float3(1f, 2f, 3f)\" Debug.Log($\"This value `{value}`\"); Burst doesn't support ToString() of structs. It displays the full name of the struct instead. For more information, see the .NET documentation on String interpolation and Standard numeric format strings. Managed strings You can pass a managed string literal or an interpolated string directly to Debug.Log, but you can't pass a string to a user method or to use them as fields in a struct. To pass around or store strings, use one of the FixedString structs in the Unity.Collections package: int value = 256; FixedString128 text = $\"This is an integer value {value} used with FixedString128\"; MyCustomLog(text); // ... // String can be passed as an argument to a method using a FixedString, // but not using directly a managed `string`: public static void MyCustomLog(in FixedString128 log) { Debug.Log(text); } Arguments and specifiers Burst has limited support for string format arguments and specifiers: int value = 256; // Padding left: \"This value ` 256` Debug.Log($\"This value `{value,5}`\"); // Padding right: \"This value `256 ` Debug.Log($\"This value `{value,-5}`\"); // Hexadecimal uppercase: \"This value `00FF` Debug.Log($\"This value `{value:X4}`\"); // Hexadecimal lowercase: \"This value `00ff` Debug.Log($\"This value `{value:x4}`\"); // Decimal with leading-zero: \"This value `0256` Debug.Log($\"This value `{value:D4}`\");"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-system-support.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-system-support.html",
    "title": "C#/.NET System namespace support | mmo-rpg-unity",
    "keywords": "C#/.NET System namespace support Burst provides support for some of the System namespace, transforming these into Burst compatible variants in the Burst compiler. System.Math Burst supports all methods that System.Math declares, with the following exceptions: double IEEERemainder(double x, double y) is only supported when Api Compatibility Level is set to .NET Standard 2.1 in project settings System.IntPtr Burst supports all methods of System.IntPtr/System.UIntPtr, including the static fields IntPtr.Zero and IntPtr.Size System.Threading.Interlocked Burst supports atomic memory intrinsics for all methods provided by System.Threading.Interlocked (for example, Interlocked.Increment). Make sure that the source location of the interlocked methods are naturally aligned. For example, the alignment of the pointer is a multiple of the pointed-to-type: [StructLayout(LayoutKind.Explicit)] struct Foo { [FieldOffset(0)] public long a; [FieldOffset(5)] public long b; public long AtomicReadAndAdd() { return Interlocked.Read(ref a) + Interlocked.Read(ref b); } } If the pointer to the struct Foo has an alignment of 8, which is the natural alignment of a long value, the Interlocked.Read of a would be successful because it lies on a naturally aligned address. However, b would not be successful and undefined behavior happens at the load of b as a result. System.Threading.Thread Burst supports the MemoryBarrier method of System.Threading.Thread. System.Threading.Volatile Burst supports the non-generic variants of Read and Write provided by System.Threading.Volatile."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-type-support.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/csharp-type-support.html",
    "title": "C#/.NET type support | mmo-rpg-unity",
    "keywords": "C#/.NET type support Burst works on a subset of .NET that doesn't let you use any managed objects or reference types in your code (classes in C#). The following sections gives more details about the constructs that Burst supports, and any limitations they have. Built-in types Array types Struct types Generic types Vector types Enum types Pointer types Span types Tuple types Built-in types Supported built-in types Burst supports the following built-in types: bool byte/sbyte double float int/uint long/ulong short/ushort Unsupported built-in types Burst doesn't support the following built-in types: char decimal string because this is a managed type Array types Supported array types Burst supports read-only managed arrays loaded from static read-only fields: [BurstCompile] public struct MyJob : IJob { private static readonly int[] _preComputeTable = new int[] { 1, 2, 3, 4 }; public int Index { get; set; } public void Execute() { int x = _preComputeTable[0]; int z = _preComputeTable[Index]; } } However, accessing a static read-only managed array has the following restrictions: You can only use the read-only static managed array directly and can't pass it around, for example as a method argument. C# code that doesn't use jobs shouldn't modify the read-only static array's elements. This is because the Burst compiler makes a read-only copy of the data at compilation time. Multi-dimensional arrays aren't supported. If you've used an unsupported static constructor, Burst produces the error BC1361. For more information on how Burst initializes arrays, see Static readonly fields and static constructors. Unsupported array types Burst doesn't support managed arrays. Instead, use a native container such as NativeArray . Struct types Supported structs Burst supports the following structs: Regular structs with any field with supported types Structs with fixed array fields Note Structs with an explicit layout might generate non-optimal native code. Supported struct layout Burst supports the following struct layouts: LayoutKind.Sequential LayoutKind.Explicit StructLayoutAttribute.Pack StructLayoutAttribute.Size Burst supports System.IntPtr and System.UIntPtr natively as intrinsic structs that directly represent pointers. Generic types Burst supports generic types used with structs. It supports full instantiation of generic calls for generic types that have interface constraints, for example when a struct with a generic parameter needs to implement an interface. Note There are restrictions if you use generic jobs. Vector types Burst can translate vector types from Unity.Mathematics to native SIMD vector types with the following first class support for optimizations: bool2/bool3/bool4 uint2/uint3/uint4 int2/int3/int4 float2/float3/float4 Tip For performance reasons, use the 4 wide types (bool4, uint4, float4, int4, ) over the other types. Enum types Supported enum types Burst supports all enums including enums that have a specific storage type, for example, public enum MyEnum : short. Unsupported enums Burst doesn't support Enum methods, for example Enum.HasFlag. Pointer types Burst supports any pointer types to any Burst supported types Span types Burst supports Span<T> and ReadOnlySpan<T> types in the Unity Editors that support them. You can only use span types in Burst jobs or function-pointers, but not across the interface to them. This is because in C#'s implementation of the span types it supports taking spans into managed data types (like a managed array). For example, the following code is invalid: [BurstCompile] public static void SomeFunctionPointer(Span<int> span) {} This is because Span is used across the managed and Burst boundary. In Burst, span types respect any safety check setting, and only perform performance-intensive checks when safety checks are enabled. Tuple types Burst supports value tuples ValueTuple<T1,T2> in Burst-compiled jobs or static methods, but not across the interface to them. This is because value tuples are of struct layout LayoutKind.Auto. Burst does not support LayoutKind.Auto (to see a list of struct layouts Burst supports see the section Struct types). However, one can use a regular struct to emulate a tuple like so: [BurstCompile] private struct MyTuple { public int item1; public float item2; }"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/debugging-profiling-tools.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/debugging-profiling-tools.html",
    "title": "Debugging and profiling tools | mmo-rpg-unity",
    "keywords": "Debugging and profiling tools The following sections describe how to debug and profile your Burst-compiled code in the Editor and in player builds. Tip Before attempting to debug Burst-compiled code, enable script debugging for the Editor, or a player build by following the steps in Debug C# code in Unity. Although you can theoretically debug Burst-compiled code even when the script compilation mode is set to Release, in practice it doesn't work reliably. Breakpoints might be skipped, and variables might not appear in the Locals window, for example. Debugging Burst-compiled code in the Editor To debug Burst-compiled code in the Editor, you can either use a managed debugger, or a native debugger. This section explains both options. Attach a managed debugger You can attach a managed debugger such as Visual Studio, Visual Studio for Mac, or JetBrains Rider. This is the same type of debugger you can use to debug regular managed C# code in your Unity project. The ways of attaching a debugger differ depending on the version of Unity you're using: Unity 2022.2+: When you place a breakpoint inside Burst-compiled code, and you have a managed debugger attached, Unity disables Burst automatically for that code path. This allows you to use a managed debugger to debug the managed version of your code. When you remove all breakpoints from that code path, Unity re-enables Burst for that code path. Unity 2022.1 and older: Disable Burst, either with the global option in the Editor Burst menu (Jobs > Burst > Enable Compilation), or comment out the [BurstCompile] attribute from the specific entry-point that you want to debug. Attach a native debugger You can attach a native debugger such as Visual Studio or Xcode. Before doing so, you need to disable Burst optimizations. You can do this in the following ways: Use the Native Debug Mode Compilation setting in the Editor Burst menu (Jobs > Burst > Native Debug Mode Compilation). Important: This setting disables optimizations across all jobs, which impacts the performance of Burst code. If you want to disable optimizations only for a specific job, use the other option in this list. Add the Debug = true flag to your job, which disables optimizations and enables debugging on that specific job: [BurstCompile(Debug = true)] public struct MyJob : IJob { // ... } Tip Player builds pick up the Debug flag, so you can also use this to debug a player build. To attach a native debugger to the Unity Editor process, see the native debugging section below. Debugging Burst-compiled code in a player build Because of the way that Unity builds the code for a player, you need to tell the debugging tool where to find the symbols. To do this, point the tool to the folder that contains the lib_burst_generated files, which is usually in the Plugins folder. To debug Burst-compiled code in a player build, you need to attach a native debugger (such as Visual Studio or Xcode) to the player process. Before doing so, you need to: Enable symbol generation. You can do this in either of two ways: Enable the Development Build option before you build the player, or Enable the Force Debug Information option in Burst AOT Player Settings Disable Burst optimizations. You can do this in either of two ways: Disable the Enable Optimizations option in Burst AOT Player Settings. Important: This setting disables optimizations across all jobs, which impacts the performance of Burst code. If you want to disable optimizations only for a specific job, use the other option in this list. Add the Debug = true flag to your job, which disables optimizations and enables debugging on that specific job: [BurstCompile(Debug = true)] public struct MyJob : IJob { // ... } To attach a native debugger to the player process, see the native debugging section below. Native debugging Follow the instructions above to setup native debugging correctly for the Editor or a player build. Then, attach a native debugger such as Visual Studio or Xcode. Native debugging limitations Native debuggers can't discover lambda captures on Entity.ForEach, so you can't inspect variables originating from these. Structs that use [StructLayout(LayoutKind=Explicit)] and have overlapping fields are represented by a struct that hides one of the overlaps. Types that are nested, are namespaced in C/C++ style. e.g. namespace Pillow { public struct Spot { public struct SubSpot { public int a; public int b; } public int a; public int b; public SubSpot sub; } You would refer to SubSpot as Pillow::Spot::SubSpot in this case (for instance if you were trying to cast a pointer in a debugger watch window). Code-based breakpoints Burst supports code-based breakpoints through the System.Diagnostics.Debugger.Break method. This method generates a debug trap in your code. You must attach a debugger to your code so that it can intercept the break. Breakpoints trigger whether you've attached a debugger or not. Burst adds information to track local variables, function parameters and breakpoints. If your debugger supports conditional breakpoints, use these over adding breakpoints in your code, because they only fire when you've attached a debugger. Profiling Burst-compiled code Profiling using standalone profiling tools You can use profiling tools (such as Instruments or Superluminal) to profile Burst-compiled code in a player build. Because of the way that Unity builds the code for a player, you need to tell the profiling tool where to find the symbols. To do this, point the tool to the folder that contains the lib_burst_generated files, which is usually in the Plugins folder. Unity Profiler markers To improve the data you get from Unity Profiler (either for Burst-compiled code running in the Editor or in an attached player), you can create Unity Profiler markers from Burst code by calling new ProfilerMarker(\"MarkerName\"): [BurstCompile] private static class ProfilerMarkerWrapper { private static readonly ProfilerMarker StaticMarker = new ProfilerMarker(\"TestStaticBurst\"); [BurstCompile(CompileSynchronously = true)] public static int CreateAndUseProfilerMarker(int start) { using (StaticMarker.Auto()) { var p = new ProfilerMarker(\"TestBurst\"); p.Begin(); var result = 0; for (var i = start; i < start + 100000; i++) { result += i; } p.End(); return result; } } }"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/editor-burst-inspector.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/editor-burst-inspector.html",
    "title": "Burst Inspector window reference | mmo-rpg-unity",
    "keywords": "Burst Inspector window reference The Burst Inspector window displays all the jobs and other Burst compile targets in the project. To open the Burst Inspector window, go to Jobs > Burst > Open Inspector. The Burst Inspector displays all the Jobs that it can compile. It also displays the generated intermediate and native assembly code. When opening a new target job in the Burst Inspector, it will try to focus the assembly directly related to the chosen bursted job. Furthermore, if branch flow arrows are shown, and they fill more than half of the assembly view, the inspector will scroll horizontally rightwards to focus the code instead of the branches. Burst Inspector with Branch Flow enabled Burst Inspector panes The Compile Targets pane on the left of the window displays an alphabetical list of the jobs in the project that Burst can compile. By default jobs either in the Unity namespace or with \".Generated\" in the name are excluded. This can be changed via the toggles Show Unity Namespace and Show \".Generated\" respectively. Disabled jobs in the list don't have the [BurstCompile] attribute. The right output pane of the Burst Inspector window displays options to view the assembly and intermediate code for the job you've selected in the Compile Targets list. To expand or collapse elements of the code, select the colored boxes (some with ellipses) . By default. the Burst Inspector automatically collapses blocks that it considers non-essential, such as most directives and data. It is possible to select lines of assembly. This will highlight the selected line, by underlining it. If this line contains any registers, the usage of these registers will be highlighted throughout the code; note that implicit registers are ignored for this feature. To select and copy the text in this pane, either click and drag with your mouse, or use Shift + arrow keys to select the text. To copy the text, either right-click and select Copy Selection, or press Ctrl + C (Command + C on macOS). Default behavior for the Burst Inspector's copy is to include underlying color tags. To change this, right-click with the mouse on the right pane, to open up the context menu, and untick Copy Color Tags. At the top of the window, the following display options are available: Display option Function Output dropdown Use the dropdown to select how to output the information in the Burst Inspector window Plain Without Debug Information Displays the raw output. Plain With Debug Information Displays the raw output with debug information. Enhanced with Minimal Debug Information (Only available in Assembly view) Displays the line information interweaved with the assembly to guide you to what line in your code matches what assembly output. If you've enabled Show Branch Flow, the branch flow indicates where jump instruction might branch off to. Enhanced With Full Debug Information (Only available in Assembly view) Displays the same information as Enhanced with Minimal Debug Information but with debug information included. Coloured With Minimal Debug Information (Only available in Assembly view) Displays the same information as Enhanced with Minimal Debug Information, but displays the output in color. Coloured With Full Debug Information (Only available in Assembly view) Displays the same information as Enhanced with Full Debug Information, but displays the output in color. Safety Checks Enable this option to generate code that includes container access safety checks, for example, to check if a job is attempting to write to a read-only native container. Font Size Select the size of the text in the output pane. Architecture dropdown Select the target architecture for your build. Focus on Code (Only available in Enhanced or Coloured output) Collapses the least important blocks of the disassembly. When you select this, Unity hides most of the assembly language directives and non code segments, allowing you to focus on the code itself. Expand all (Only available in Enhanced or Coloured output) Expands all collapsed blocks of disassembly and displays all the hidden assembly language directives and data elements. Show Branch Flow (Only available in Enhanced or Coloured output) Enable this option to display arrows that show branch flow in the code. When enabled, the code moves to the right, to make space to display the arrows. Highlight SIMD Scalar vs Packed (Only available in Enhanced or Coloured output) Enable this option to display SIMD instruction differently depending on their nature (Whether they work on packed or scalar inputs). This can be used to quickly assess the quality of the generated vectorized code (see SIMD smell test by Andreas Fredriksson). Assembly Displays the final optimized native code that Burst generated. .NET IL Displays the original .NET IL extracted from the job method. LLVM IR (Unoptimized) Displays the internal LLVM IR before optimizations. LLVM IR (Optimized) Displays the internal LLVM IR after optimizations. LLVM IR Optimization Diagnostics Displays LLVM diagnostics of the optimizations, such as if they succeeded or failed."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/editor-burst-menu.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/editor-burst-menu.html",
    "title": "Burst menu reference | mmo-rpg-unity",
    "keywords": "Burst menu reference In the Editor, use the settings in the Burst menu to control how Burst works. To access this menu, go to Jobs > Burst. The following settings are available: Setting Function Enable Compilation Enable this setting to activate Burst compilation. When you enable this setting, Burst compiles jobs and Burst custom delegates that you tag with the attribute [BurstCompile]. Enable Safety Checks Choose what safety checks Burst should use. For more information see the Enable Safety Checks setting section of this documentation. Off Disable safety checks across all Burst jobs and function-pointers. Only use this setting if you want more realistic profiling results from in-Editor captures. When you reload the Editor, this setting always resets to On. On Enable safety checks on code that uses collection containers (e.g NativeArray<T>). Checks include job data dependency and container indexes out of bounds. This is the default setting. Force On Force safety checks on even for jobs and function-pointers that have DisableSafetyChecks = true. Use this setting to rule out any problems that safety checks might have caught. Synchronous Compilation Enable this setting to compile Burst synchronously. For more information, see Synchronous compilation. Native Debug Mode Compilation Enable this setting to deactivate optimizations on all code that Burst compiles. This makes it easier to debug via a native debugger. For more information, see Native Debugging tools. Show Timings Enable this setting to log the time it takes to JIT compile a job in the Editor and display it in the Console. For more information see the Show Timings setting section of this documentation. Open Inspector Opens the Burst Inspector window. Enable Safety Checks setting To disable Burst's safety check code, use DisableSafetyChecks. This results in faster code generation, however make sure that you use containers in a safe fashion. To disable safety checks on a job or function-pointer set DisableSafetyChecks to true: [BurstCompile(DisableSafetyChecks = true)] public struct MyJob : IJob { // ... } Burst ignores code marked explicitly with DisableSafetyChecks = true when it safety checks your code if you set Enable Safety Checks to On in the Editor. Select Force On to make Burst to safety check all code, including code marked with DisableSafetyChecks = true. Show Timings setting When you enable the Show Timings setting, Unity logs an output in the Console window for each library of entry points that Burst compiles. Burst batches the compilation into units of methods-per-assembly, and groups multiple entry-points together in a single compilation task. This output is useful if you want to report outliers in compilation to the Burst compiler team (via the Burst forum). Unity splits Burst's output into the following major sections: Method discovery (where Burst works out what it needs to compile) Front end (where Burst turns C# IL into an LLVM IR module) Middle end (where Burst specializes, optimizes, and cleans up the module) Back-end (where Burst turns the LLVM IR module into a native DLL) The compile time in the front end and optimizer is linear to the amount operations that it needs to compile. More functions and more instructions means a longer compile time. The more generic functions you have, the higher the front end performance timings, because generic resolutions have non-zero costs. The compile time in the back-end scales with the number of entry-points in the module. This is because each entry point is in its own native object file. If the optimizer takes a significant amount of time, use [BurstCompile(OptimizeFor = OptimizeFor.FastCompilation)] which reduces the optimizations that Burst does, but compiles things much faster. Profile the job before and after to make sure that this tradeoff is right for that entry-point."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/editor-reference-overview.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/editor-reference-overview.html",
    "title": "Editor reference | mmo-rpg-unity",
    "keywords": "Editor reference Explore the specific Burst Editor features. Topic Description Burst menu Use the Burst menu to control the Burst settings in your project. Burst Inspector Use the Burst Inspector to see the jobs and Burst compiled targets in your project. Additional resources Building your project"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/getting-started.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/getting-started.html",
    "title": "Getting started | mmo-rpg-unity",
    "keywords": "Getting started Burst is primarily designed to work with Unity's job system. To start using the Burst compiler in your code, decorate a Job struct with the [BurstCompile] attribute. Add the [BurstCompile] attribute to the type and the static method you want Burst to compile. using Unity.Burst; using Unity.Collections; using Unity.Jobs; using UnityEngine; public class MyBurst2Behavior : MonoBehaviour { void Start() { var input = new NativeArray<float>(10, Allocator.Persistent); var output = new NativeArray<float>(1, Allocator.Persistent); for (int i = 0; i < input.Length; i++) input[i] = 1.0f * i; var job = new MyJob { Input = input, Output = output }; job.Schedule().Complete(); Debug.Log(\"The result of the sum is: \" + output[0]); input.Dispose(); output.Dispose(); } // Using BurstCompile to compile a Job with Burst [BurstCompile] private struct MyJob : IJob { [ReadOnly] public NativeArray<float> Input; [WriteOnly] public NativeArray<float> Output; public void Execute() { float result = 0.0f; for (int i = 0; i < Input.Length; i++) { result += Input[i]; } Output[0] = result; } } } Limitations Burst supports most C# expressions and statements, with a few exceptions. For more information, see C# language support. Compilation Burst compiles your code just-in-time (JIT) while in Play mode in the Editor, and ahead-of-time (AOT) when your application runs in a Player. For more information on compilation, see Burst compilation Command line options You can pass the following options to the Unity Editor on the command line to control Burst: --burst-disable-compilation disables Burst. --burst-force-sync-compilation force Burst to compile synchronously. For more information, see Burst compilation."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/index.html",
    "title": "About Burst | mmo-rpg-unity",
    "keywords": "About Burst Burst is a compiler that you can use with Unity's job system to create code that enhances and improves your application's performance. It translates your code from IL/.NET bytecode to optimized native CPU code that uses the LLVM compiler. Installation To install this package, follow the instructions in the Package Manager documentation. If you change the Burst package version (for example, via Update), you need to close and restart the Editor. Further resources Videos Conference presentations given by the Burst team: Getting started with Burst - Unite Copenhagen 2019 (slides) Supercharging mobile performance with ARM Neon and Unity Burst Compiler Using Burst Compiler to optimize for Android - Unite Now 2020 Intrinsics: Low-level engine development with Burst - Unite Copenhagen 2019 (slides) Behind the Burst compiler: Converting .NET IL to highly optimized native code - DotNext 2018 Deep dive into the Burst compiler - Unite LA 2018 C# to machine code: GDC 2018 Using the native debugger for Burst compiled code Blogs Blog posts written by members of the Burst team : Raising your game with Burst 1.7 Enhancing mobile performance with the Burst compiler Enhanced aliasing with Burst In parameters in Burst"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/modding-support.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/modding-support.html",
    "title": "Modding support | mmo-rpg-unity",
    "keywords": "Modding support From Unity 2021.1, you can load additional Burst compiled libraries, which provide a way to create modifications that use Burst compiled code. Burst only provides a method to load additional libraries, and doesn't provide any tooling to create mods. You need a copy of the Unity Editor to compile the additional libraries. This section gives an example approach to modding with Burst and is a proof of concept. Supported uses You can use this function in Play mode (or Standalone Players) only. Make sure you load the libraries as soon as possible, and before the first Burst compiled use of a C# method. Unity unloads any Burst libraries that BurstRuntime.LoadAdditionalLibraries loads when you exit Play mode in the Editor, quit a Standalone Player. Example modding system Note This example is limited in scope. You should have knowledge of assemblies and asmdefs to follow this example. This example declares an interface that the mods abide by: using UnityEngine; public interface PluginModule { void Startup(GameObject gameObject); void Update(GameObject gameObject); } You can use this interface to create new classes which follow these specifications and ship it separate to your application. Passing a single GameObject along limits the state that the plug-ins can affect. Modding manager The following is an example of a modding manager: using System; using System.Collections.Generic; using System.IO; using System.Reflection; using UnityEngine; using Unity.Burst; public class PluginManager : MonoBehaviour { public bool modsEnabled; public GameObject objectForPlugins; List<PluginModule> plugins; void Start() { plugins = new List<PluginModule>(); // If mods are disabled, early out - this allows us to disable mods, enter Play Mode, exit Play Mode //and be sure that the managed assemblies have been unloaded (assuming DomainReload occurs) if (!modsEnabled) return; var folder = Path.GetFullPath(Path.Combine(Application.dataPath, \"..\", \"Mods\")); if (Directory.Exists(folder)) { var mods = Directory.GetDirectories(folder); foreach (var mod in mods) { var modName = Path.GetFileName(mod); var monoAssembly = Path.Combine(mod, $\"{modName}_managed.dll\"); if (File.Exists(monoAssembly)) { var managedPlugin = Assembly.LoadFile(monoAssembly); var pluginModule = managedPlugin.GetType(\"MyPluginModule\"); var plugin = Activator.CreateInstance(pluginModule) as PluginModule; plugins.Add(plugin); } var burstedAssembly = Path.Combine(mod, $\"{modName}_win_x86_64.dll\"); // Burst dll (assuming windows 64bit) if (File.Exists(burstedAssembly)) { BurstRuntime.LoadAdditionalLibrary(burstedAssembly); } } } foreach (var plugin in plugins) { plugin.Startup(objectForPlugins); } } // Update is called once per frame void Update() { foreach (var plugin in plugins) { plugin.Update(objectForPlugins); } } } This code scans the \"Mods\" folder, and for each folder it finds within, it attempts to load both a managed dll and a Burst compiled dll. It does this by adding them to an internal list that it can then iterate on and call the respective interface functions. The names of the files are arbitrary: see Simple Create Mod Menu Button, which is the code that generated those files. Because this code loads the managed assemblies into the current domain, you need a domain reload to unload those before you can overwrite them. Unity automatically unloads the Burst dll files automatically unloaded when you exit Play mode. This is why a Boolean to disable the modding system is included, for testing in the Editor. A mod that uses Burst Create a separate Unity project for this to use the project to produce the mod. The following script attaches to a UI Canvas that contains a text component called Main UI Label, and changes the text when the mod is used. The text is either Plugin Updated : Bursted or Plugin Updated : Not Bursted. You will see the Plugin Updated : Bursted by default, but if you comment out the lines that load the Burst library in the PluginManager above, then the Burst compiled code doesn't load and the message changes appropriately. using Unity.Burst; using Unity.Collections; using Unity.Jobs; using UnityEngine; using UnityEngine.UI; public class MyPluginModule : PluginModule { Text textComponent; public void Startup(GameObject gameObject) { var childTextComponents = gameObject.GetComponentsInChildren<Text>(); textComponent = null; foreach (var child in childTextComponents) { if (child.name == \"Main UI Label\") { textComponent = child; } } if (textComponent==null) { Debug.LogError(\"something went wrong and i couldn't find the UI component i wanted to modify\"); } } public void Update(GameObject gameObject) { if (textComponent != null) { var t = new CheckBurstedJob { flag = new NativeArray<int>(1, Allocator.TempJob, NativeArrayOptions.UninitializedMemory) }; t.Run(); if (t.flag[0] == 0) textComponent.text = \"Plugin Updated : Not Bursted\"; else textComponent.text = \"Plugin Updated : Bursted\"; t.flag.Dispose(); } } [BurstCompile] struct CheckBurstedJob : IJob { public NativeArray<int> flag; [BurstDiscard] void CheckBurst() { flag[0] = 0; } public void Execute() { flag[0] = 1; CheckBurst(); } } } Put the above script in a folder along with an assembly definition file with an assembly name of TestMod_Managed, so that the next script can locate the managed part. Simple Create Mod Menu button The below script adds a menu button. When you use the menu button, it builds a Standalone Player, then copies the C# managed dll and the lib_burst_generated.dll into a chosen Mod folder. This example assumes you are using Windows. using UnityEditor; using System.IO; using UnityEngine; public class ScriptBatch { [MenuItem(\"Modding/Build X64 Mod (Example)\")] public static void BuildGame() { string modName = \"TestMod\"; string projectFolder = Path.Combine(Application.dataPath, \"..\"); string buildFolder = Path.Combine(projectFolder, \"PluginTemp\"); // Get filename. string path = EditorUtility.SaveFolderPanel(\"Choose Final Mod Location\", \"\", \"\"); FileUtil.DeleteFileOrDirectory(buildFolder); Directory.CreateDirectory(buildFolder); // Build player. var report = BuildPipeline.BuildPlayer(new[] { \"Assets/Scenes/SampleScene.unity\" }, Path.Combine(buildFolder, $\"{modName}.exe\"), BuildTarget.StandaloneWindows64, BuildOptions.Development); if (report.summary.result == UnityEditor.Build.Reporting.BuildResult.Succeeded) { // Copy Managed library var managedDest = Path.Combine(path, $\"{modName}_Managed.dll\"); var managedSrc = Path.Combine(buildFolder, $\"{modName}_Data/Managed/{modName}_Managed.dll\"); FileUtil.DeleteFileOrDirectory(managedDest); if (!File.Exists(managedDest)) // Managed side not unloaded FileUtil.CopyFileOrDirectory(managedSrc, managedDest); else Debug.LogWarning($\"Couldn't update manged dll, {managedDest} is it currently in use?\"); // Copy Burst library var burstedDest = Path.Combine(path, $\"{modName}_win_x86_64.dll\"); var burstedSrc = Path.Combine(buildFolder, $\"{modName}_Data/Plugins/x86_64/lib_burst_generated.dll\"); FileUtil.DeleteFileOrDirectory(burstedDest); if (!File.Exists(burstedDest)) FileUtil.CopyFileOrDirectory(burstedSrc, burstedDest); else Debug.LogWarning($\"Couldn't update bursted dll, {burstedDest} is it currently in use?\"); } } }"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-assumerange.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-assumerange.html",
    "title": "AssumeRange attribute | mmo-rpg-unity",
    "keywords": "AssumeRange attribute Use the AssumeRange attribute to tell Burst that a given scalar-integer lies within a certain constrained range. If Burst has this information, it can improve the performance of your application. The following code is an example of this: [return:AssumeRange(0u, 13u)] static uint WithConstrainedRange([AssumeRange(0, 26)] int x) { return (uint)x / 2u; } This example tells Burst the following: The variable x is in the closed-interval range [0..26], or more plainly that x >= 0 && x <= 26. The return value from WithConstrainedRange is in the closed-interval range [0..13], or more plainly that x >= 0 && x <= 13. Burst uses these assumptions to create better code generation. However, there are some restrictions: You can only place these on scalar-integer (signed or unsigned) types. The type of the range arguments must match the type being attributed. Burst has deductions for the .Length property of NativeArray and NativeSlice which indicates that these always return non-negative integers: static bool IsLengthNegative(NativeArray<float> na) { // Burst always replaces this with the constant false return na.Length < 0; } For example, if you have a container like the following: struct MyContainer { public int Length; // Some other data... } The following example shows how to tell Burst that Length is always a positive integer: struct MyContainer { private int _length; [return: AssumeRange(0, int.MaxValue)] private int LengthGetter() { return _length; } public int Length { get => LengthGetter(); set => _length = value; } // Some other data... }"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-constant.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-constant.html",
    "title": "Constant intrinsic | mmo-rpg-unity",
    "keywords": "Constant intrinsic Use the IsConstantExpression intrinsic to check if a given expression is constant at compile-time: using static Unity.Burst.CompilerServices.Constant; var somethingWhichWillBeConstantFolded = math.pow(42.0f, 42.0f); if (IsConstantExpression(somethingWhichWillBeConstantFolded)) { // Burst knows that somethingWhichWillBeConstantFolded is a compile-time constant } This is useful to check if a complex expression is always constant folded. You can use it for optimizations for a known constant value. For example, if you want to implement a pow-like function for integer powers: using static Unity.Burst.CompilerServices.Constant; public static float MyAwesomePow(float f, int i) { if (IsConstantExpression(i) && (2 == i)) { return f * f; } else { return math.pow(f, (float)i); } } The IsConstantExpression check means that Burst always removes the branch if i isn't constant, because the if condition is false. This means that if i is constant and is equal to 2, you can use a more optimal simple multiply instead. The result of IsConstantExpression intentionally depends on the result of the optimizations being run. Therefore the result can change based on whether a function gets inlined or not. For example in the case above: IsConstantExpression(i) is false on its own, because i is a function argument which is obivously not constant. However, if MyAwesomePow gets inlined with a constant value for i, then it will evaluate to true. But if MyAwesomePow ends up not being inlined for whatever reason, then IsConstantExpression(i) will remain false. Note Constant folding only takes place during optimizations. If you've disabled optimizations, the intrinsic returns false."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-hint.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-hint.html",
    "title": "Hint intrinsics | mmo-rpg-unity",
    "keywords": "Hint intrinsics Use the Hint intrinsics to add information to your code which helps with Burst optimization. It has the following methods: Unity.Burst.CompilerServices.Hint.Likely: Tells Burst that a Boolean condition is likely to be true. Unity.Burst.CompilerServices.Hint.Unlikely: Tells Burst that a Boolean condition is unlikely to be true. Unity.Burst.CompilerServices.Hint.Assume: Tells Burst that it can assume a Boolean condition is true. Likely intrinsic The Likely intrinsic is most useful to tell Burst which branch condition has a high probability of being true. This means that Burst can focus on the branch in question for optimization purposes: if (Unity.Burst.CompilerServices.Hint.Likely(b)) { // Any code in here will be optimized by Burst with the assumption that we'll probably get here! } else { // Whereas the code in here will be kept out of the way of the optimizer. } Unlikely intrinsic The Unlikely intrinsic tells Burst the opposite of the Likely intrinsic: the condition is unlikely to be true, and it should optimize against it: if (Unity.Burst.CompilerServices.Hint.Unlikely(b)) { // Whereas the code in here will be kept out of the way of the optimizer. } else { // Any code in here will be optimized by Burst with the assumption that we'll probably get here! } The Likely and Unlikely intrinsics make sure that Burst places the code most likely to be hit after the branching condition in the binary. This means that the code has a high probability of being in the instruction cache. Burst can also hoist the code out of the likely branch and spend extra time optimizing it, and not spend as much time looking at the unlikely code. An example of an unlikely branch is to check if result of an allocation is valid. The allocation is valid most of all the time, so you want the code to be fast with that assumption, but you want an error case to fall back to. Assume intrinsic The Assume intrinsic is powerful. Use it with caution because it tells Burst that a condition is always true. Warning When you use Assume, Burst assumes the value is true without checking whether it's true. Unity.Burst.CompilerServices.Hint.Assume(b); if (b) { // Burst has been told that b is always true, so this branch will always be taken. } else { // Any code in here will be removed from the program because b is always true! } Use the Assume intrinsic to arbitrarily tell Burst that something is true. For example, you can use Assume to tell Burst to assume that a loop end is always a multiple of 16, which means that it can provide perfect vectorization without any scalar spilling for that loop. You could also use it to tell Burst that a value isn't NaN, or it's negative."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-loop-vectorization.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-loop-vectorization.html",
    "title": "Loop vectorization | mmo-rpg-unity",
    "keywords": "Loop vectorization Burst uses loop vectorization to improve the performance of your code. It uses this technique to loop over multiple values at the same time, rather than looping over single values at a time, which speeds up the performance of your code. For example: [MethodImpl(MethodImplOptions.NoInlining)] private static unsafe void Bar([NoAlias] int* a, [NoAlias] int* b, int count) { for (var i = 0; i < count; i++) { a[i] += b[i]; } } public static unsafe void Foo(int count) { var a = stackalloc int[count]; var b = stackalloc int[count]; Bar(a, b, count); } Burst converts the scalar loop in Bar into a vectorized loop. Then, instead of looping over a single value at a time, it generates code that loops over multiple values at the same time, which produces faster code. This is the x64 assembly Burst generates for AVX2 for the loop in Bar above: .LBB1_4: vmovdqu ymm0, ymmword ptr [rdx + 4*rax] vmovdqu ymm1, ymmword ptr [rdx + 4*rax + 32] vmovdqu ymm2, ymmword ptr [rdx + 4*rax + 64] vmovdqu ymm3, ymmword ptr [rdx + 4*rax + 96] vpaddd ymm0, ymm0, ymmword ptr [rcx + 4*rax] vpaddd ymm1, ymm1, ymmword ptr [rcx + 4*rax + 32] vpaddd ymm2, ymm2, ymmword ptr [rcx + 4*rax + 64] vpaddd ymm3, ymm3, ymmword ptr [rcx + 4*rax + 96] vmovdqu ymmword ptr [rcx + 4*rax], ymm0 vmovdqu ymmword ptr [rcx + 4*rax + 32], ymm1 vmovdqu ymmword ptr [rcx + 4*rax + 64], ymm2 vmovdqu ymmword ptr [rcx + 4*rax + 96], ymm3 add rax, 32 cmp r8, rax jne .LBB1_4 Burst has unrolled and vectorized the loop into four vpaddd instructions, which calculate eight integer additions each, for a total of 32 integer additions per loop iteration. Loop vectorization intrinsics Burst includes experimental intrinsics to express loop vectorization assumptions: Loop.ExpectVectorized and Loop.ExpectNotVectorized. Burst then validates the loop vectorization at compile-time. This is useful in a situation where you might break the auto vectorization. For example, if you introduce a branch to the code: [MethodImpl(MethodImplOptions.NoInlining)] private static unsafe void Bar([NoAlias] int* a, [NoAlias] int* b, int count) { for (var i = 0; i < count; i++) { if (a[i] > b[i]) { break; } a[i] += b[i]; } } This changes the assembly to the following: .LBB1_3: mov r9d, dword ptr [rcx + 4*r10] mov eax, dword ptr [rdx + 4*r10] cmp r9d, eax jg .LBB1_4 add eax, r9d mov dword ptr [rcx + 4*r10], eax inc r10 cmp r8, r10 jne .LBB1_3 This isn't ideal because the loop is scalar and only has 1 integer addition per loop iteration. It can be difficult to spot this happening in your code, so use the experimental intrinsics Loop.ExpectVectorized and Loop.ExpectNotVectorized to express loop vectorization assumptions. Burst then validates the loop vectorization at compile-time. Because the intrinsics are experimental, you need to use the UNITY_BURST_EXPERIMENTAL_LOOP_INTRINSICS preprocessor define to enable them. The following example shows the original Bar example with the Loop.ExpectVectorized intrinsic: [MethodImpl(MethodImplOptions.NoInlining)] private static unsafe void Bar([NoAlias] int* a, [NoAlias] int* b, int count) { for (var i = 0; i < count; i++) { Unity.Burst.CompilerServices.Loop.ExpectVectorized(); a[i] += b[i]; } } Burst then validates at compile-time whether the loop is vectorized. If the loop isn't vectorized, Burst emits a compiler error. The following example produces an error: [MethodImpl(MethodImplOptions.NoInlining)] private static unsafe void Bar([NoAlias] int* a, [NoAlias] int* b, int count) { for (var i = 0; i < count; i++) { Unity.Burst.CompilerServices.Loop.ExpectVectorized(); if (a[i] > b[i]) { break; } a[i] += b[i]; } } Burst emits the following error at compile-time: LoopIntrinsics.cs(6,9): Burst error BC1321: The loop is not vectorized where it was expected that it is vectorized. Important These intrinsics don't work inside if statements. Burst doesn't prevent this from happening, so you won't see a compile-time error for this."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-overview.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-overview.html",
    "title": "Optimization | mmo-rpg-unity",
    "keywords": "Optimization Best practices around optimizing Burst-compiled code. Topic Description Debugging and profiling tools Debug and profile your Burst-compiled code in the Editor and in player builds. Loop vectorization optimization Understand how Burst uses loop vectorization to optimize your code. Memory aliasing Use memory aliasing to tell Burst how your code uses data. AssumeRange attribute Use AssumeRange to tell Burst a given scalar-integer lies within a certain constrained range. Hint intrinsic Use the Hint intrinsic to give Burst more information about your data. Constant intrinsic Use IsConstantExpression top check if an expression is constant at run time. SkipLocalsInit attribute Use SkipLocalsInitAttribute to tell Burst that any stack allocations within a method don't have to be initialized to zero. Additional resources Burst intrinsics"
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-skiplocalsinit.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Documentation~/optimization-skiplocalsinit.html",
    "title": "SkipLocalsInit attribute | mmo-rpg-unity",
    "keywords": "SkipLocalsInit attribute Use SkipLocalsInitAttribute, to tell Burst that any stack allocations within a method don't have to be initialized to zero. In C# all local variables are initialized to zero by default. This is useful because it means an entire class of bugs surrounding undefined data disappears. But this can impact runtime performance, because initializing this data to zero takes work: static unsafe int DoSomethingWithLUT(int* data); static unsafe int DoSomething(int size) { int* data = stackalloc int[size]; // Initialize every field of data to be an incrementing set of values. for (int i = 0; i < size; i++) { data[i] = i; } // Use the data elsewhere. return DoSomethingWithLUT(data); } The X86 assembly for this is: push rbp .seh_pushreg rbp push rsi .seh_pushreg rsi push rdi .seh_pushreg rdi mov rbp, rsp .seh_setframe rbp, 0 .seh_endprologue mov edi, ecx lea r8d, [4*rdi] lea rax, [r8 + 15] and rax, -16 movabs r11, offset __chkstk call r11 sub rsp, rax mov rsi, rsp sub rsp, 32 movabs rax, offset burst.memset.inline.X64_SSE4.i32@@32 mov rcx, rsi xor edx, edx xor r9d, r9d call rax add rsp, 32 test edi, edi jle .LBB0_7 mov eax, edi cmp edi, 8 jae .LBB0_3 xor ecx, ecx jmp .LBB0_6 .LBB0_3: mov ecx, eax and ecx, -8 movabs rdx, offset __xmm@00000003000000020000000100000000 movdqa xmm0, xmmword ptr [rdx] mov rdx, rsi add rdx, 16 movabs rdi, offset __xmm@00000004000000040000000400000004 movdqa xmm1, xmmword ptr [rdi] movabs rdi, offset __xmm@00000008000000080000000800000008 movdqa xmm2, xmmword ptr [rdi] mov rdi, rcx .p2align 4, 0x90 .LBB0_4: movdqa xmm3, xmm0 paddd xmm3, xmm1 movdqu xmmword ptr [rdx - 16], xmm0 movdqu xmmword ptr [rdx], xmm3 paddd xmm0, xmm2 add rdx, 32 add rdi, -8 jne .LBB0_4 cmp rcx, rax je .LBB0_7 .p2align 4, 0x90 .LBB0_6: mov dword ptr [rsi + 4*rcx], ecx inc rcx cmp rax, rcx jne .LBB0_6 .LBB0_7: sub rsp, 32 movabs rax, offset \"DoSomethingWithLUT\" mov rcx, rsi call rax nop mov rsp, rbp pop rdi pop rsi pop rbp ret In this example, the movabs rax, offset burst.memset.inline.X64_SSE4.i32@@32 line means that you've had to inject a memset to zero out the data. In the above example, you know that the array is entirely initialized in the following loop, but Burst doesn't know that. To fix this problem, use Unity.Burst.CompilerServices.SkipLocalsInitAttribute, which tells Burst that any stack allocations within a method don't have to be initialized to zero. Note Only use this attribute if you're certain that you won't run into undefined behavior bugs. For example: using Unity.Burst.CompilerServices; static unsafe int DoSomethingWithLUT(int* data); [SkipLocalsInit] static unsafe int DoSomething(int size) { int* data = stackalloc int[size]; // Initialize every field of data to be an incrementing set of values. for (int i = 0; i < size; i++) { data[i] = i; } // Use the data elsewhere. return DoSomethingWithLUT(data); } The assembly after adding the [SkipLocalsInit] on the method is: push rbp .seh_pushreg rbp mov rbp, rsp .seh_setframe rbp, 0 .seh_endprologue mov edx, ecx lea eax, [4*rdx] add rax, 15 and rax, -16 movabs r11, offset __chkstk call r11 sub rsp, rax mov rcx, rsp test edx, edx jle .LBB0_7 mov r8d, edx cmp edx, 8 jae .LBB0_3 xor r10d, r10d jmp .LBB0_6 .LBB0_3: mov r10d, r8d and r10d, -8 movabs rax, offset __xmm@00000003000000020000000100000000 movdqa xmm0, xmmword ptr [rax] mov rax, rcx add rax, 16 movabs rdx, offset __xmm@00000004000000040000000400000004 movdqa xmm1, xmmword ptr [rdx] movabs rdx, offset __xmm@00000008000000080000000800000008 movdqa xmm2, xmmword ptr [rdx] mov r9, r10 .p2align 4, 0x90 .LBB0_4: movdqa xmm3, xmm0 paddd xmm3, xmm1 movdqu xmmword ptr [rax - 16], xmm0 movdqu xmmword ptr [rax], xmm3 paddd xmm0, xmm2 add rax, 32 add r9, -8 jne .LBB0_4 cmp r10, r8 je .LBB0_7 .p2align 4, 0x90 .LBB0_6: mov dword ptr [rcx + 4*r10], r10d inc r10 cmp r8, r10 jne .LBB0_6 .LBB0_7: sub rsp, 32 movabs rax, offset \"DoSomethingWithLUT\" call rax nop mov rsp, rbp pop rbp ret The call to memset is now gone, because you've told Burst that any stack allocations within a method don't have to be initialized to zero."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Burst copyright © 2022 Unity Technologies Source code of the package is licensed under the Unity Companion License (see https://unity3d.com/legal/licenses/unity_companion_license); otherwise licensed under the Unity Package Distribution License (see https://unity3d.com/legal/licenses/Unity_Package_Distribution_License ). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.burst@1.8.17/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.burst@1.8.17/Third Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This package contains third-party software components governed by the license(s) indicated below: Component Name: LLVM License Type: Apache 2.0 with LLVM Exceptions Copyright: The LLVM project does not collect copyright assignments, which means that the copyright for the code in the project is held by the respective contributors. Because you (or your company) retain ownership of the code you contribute, you know it may only be used under the terms of the open source license you contributed it under: the license for your contributions cannot be changed in the future without your approval. https://github.com/llvm/llvm-project/tree/main/llvm Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. --- LLVM Exceptions to the Apache 2.0 License --- As an exception, if, as a result of your compiling your source code, portions of this Software are embedded into an Object form of such source code, you may redistribute such embedded portions in such Object form without complying with the conditions of Sections 4(a), 4(b) and 4(d) of the License. In addition, if you combine or link compiled forms of this Software with software that is licensed under the GPLv2 (\"Combined Software\") and if a court of competent jurisdiction determines that the patent provision (Section 3), the indemnity provision (Section 9) or other Section of the License conflicts with the conditions of the GPLv2, you may retroactively and prospectively choose to deem waived or otherwise exclude such Section(s) of the License, but only in their entirety and only with respect to the Combined Software. Component Name: Legacy LLVM License License Type: The University of Illinois/NCSA Open Source License (NCSA) Copyright (c) 2007-2019 University of Illinois at Urbana-Champaign. All rights reserved. https://llvm.org/docs/DeveloperPolicy.html#legacy Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution. LLVM Team, University of Illinois at Urbana-Champaign, nor the names of its contributors may be used to endorse or promote products derived from this Software without specific prior written permission. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE. Component Name: Mono.Cecil License Type: MIT Copyright (c) 2008 - 2015 Jb Evain All rights reserved. Copyright (c) 2008 - 2011 Novell, Inc. All rights reserved. https://github.com/jbevain/cecil Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Smash License Type: BSD 2-Clause Copyright (c) 2021, Alexandre Mutel All rights reserved. https://github.com/xoofx/smash Redistribution and use in source and binary forms, with or without modification , are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Component Name: xxHash Library License Type: BSD 2-Clause Copyright (c) 2012-2021, Yann Collet All rights reserved. https://github.com/Cyan4973/xxHash Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Component Name: musl musl as a whole is licensed under the following standard MIT license: Copyright © 2005-2019 Rich Felker, et al. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Authors/contributors include: A. Wilcox Alex Dowad Alex Suykov Alexander Monakov Andre McCurdy Andrew Kelley Anthony G. Basile Aric Belsito Arvid Picciani Bartosz Brachaczek Benjamin Peterson Bobby Bingham Boris Brezillon Brent Cook Chris Spiegel Clément Vasseur Daniel Micay Daniel Sabogal Daurnimator David Carlier David Edelsohn Denys Vlasenko Dmitry Ivanov Dmitry V. Levin Drew DeVault Emil Renner Berthing Fangrui Song Felix Fietkau Felix Janda Gianluca Anzolin Hauke Mehrtens He X Hiltjo Posthuma Isaac Dunham Jaydeep Patil Jens Gustedt Jeremy Huntwork Jo-Philipp Wich Joakim Sindholt John Spencer Josiah Worcester Julien Ramseier Justin Cormack Kaarle Ritvanen Khem Raj Kylie McClain Leah Neukirchen Luca Barbato Luka Perkov M Farkas-Dyck (Strake) Mahesh Bodapati Markus Wichmann Masanori Ogino Michael Clark Michael Forney Mikhail Kremnyov Natanael Copa Nicholas J. Kain orc Pascal Cuoq Patrick Oppenlander Petr Hosek Petr Skocik Pierre Carrier Reini Urban Rich Felker Richard Pennington Ryan Fairfax Samuel Holland Segev Finer Shiz sin Solar Designer Stefan Kristiansson Stefan O'Rear Szabolcs Nagy Timo Teräs Trutz Behn Valentin Ochs Will Dietz William Haddon William Pitcock Portions of this software are derived from third-party works licensed under terms compatible with the above MIT license: The TRE regular expression implementation (src/regex/reg* and src/regex/tre*) is Copyright © 2001-2008 Ville Laurikari and licensed under a 2-clause BSD license (license text in the source files). The included version has been heavily modified by Rich Felker in 2012, in the interests of size, simplicity, and namespace cleanliness. Much of the math library code (src/math/* and src/complex/*) is Copyright © 1993,2004 Sun Microsystems or Copyright © 2003-2011 David Schultz or Copyright © 2003-2009 Steven G. Kargl or Copyright © 2003-2009 Bruce D. Evans or Copyright © 2008 Stephen L. Moshier and labelled as such in comments in the individual source files. All have been licensed under extremely permissive terms. The ARM memcpy code (src/string/arm/memcpy_el.S) is Copyright © 2008 The Android Open Source Project and is licensed under a two-clause BSD license. It was taken from Bionic libc, used on Android. The implementation of DES for crypt (src/crypt/crypt_des.c) is Copyright © 1994 David Burren. It is licensed under a BSD license. The implementation of blowfish crypt (src/crypt/crypt_blowfish.c) was originally written by Solar Designer and placed into the public domain. The code also comes with a fallback permissive license for use in jurisdictions that may not recognize the public domain. The smoothsort implementation (src/stdlib/qsort.c) is Copyright © 2011 Valentin Ochs and is licensed under an MIT-style license. The x86_64 port was written by Nicholas J. Kain and is licensed under the standard MIT terms. The mips and microblaze ports were originally written by Richard Pennington for use in the ellcc project. The original code was adapted by Rich Felker for build system and code conventions during upstream integration. It is licensed under the standard MIT terms. The mips64 port was contributed by Imagination Technologies and is licensed under the standard MIT terms. The powerpc port was also originally written by Richard Pennington, and later supplemented and integrated by John Spencer. It is licensed under the standard MIT terms. All other files which have no copyright comments are original works produced specifically for use as part of this library, written either by Rich Felker, the main author of the library, or by one or more contibutors listed above. Details on authorship of individual files can be found in the git version control history of the project. The omission of copyright and license comments in each file is in the interest of source tree size. In addition, permission is hereby granted for all public header files (include/* and arch//bits/) and crt files intended to be linked into applications (crt/, ldso/dlstart.c, and arch//crt_arch.h) to omit the copyright notice and permission notice otherwise required by the license, and to use these files without any requirement of attribution. These files include substantial contributions from: Bobby Bingham John Spencer Nicholas J. Kain Rich Felker Richard Pennington Stefan Kristiansson Szabolcs Nagy all of whom have explicitly granted such permission. This file previously contained text expressing a belief that most of the files covered by the above exception were sufficiently trivial not to be subject to copyright, resulting in confusion over whether it negated the permissions granted in the license. In the spirit of permissive licensing, and of not having licensing issues being an obstacle to adoption, that text has been removed. Component Name: SLEEF Boost Software License - Version 1.0 - August 17th, 2003 Permission is hereby granted, free of charge, to any person or organization obtaining a copy of the software and accompanying documentation covered by this license (the \"Software\") to use, reproduce, display, distribute, execute, and transmit the Software, and to prepare derivative works of the Software, and to permit third-parties to whom the Software is furnished to do so, all subject to the following: The copyright notices in the Software and this entire statement, including the above license grant, this restriction and the following disclaimer, must be included in all copies of the Software, in whole or in part, and all derivative works of the Software, unless such copies or derivative works are solely in the form of machine-executable object code generated by a source language processor. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: gRPC for .NET Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Component Name: Google.Protobuf Copyright 2008 Google Inc. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: * Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. * Neither the name of Google Inc. nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Code generated by the Protocol Buffer compiler is owned by the owner of the input file used when generating it. This code is not standalone and requires a support library to be linked with it. This support library is itself covered by the above license. Component Name: mimalloc MIT License Copyright (c) 2018-2021 Microsoft Corporation, Daan Leijen Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog All notable changes to this package will be documented in this file. [2.4.4] - 2024-07-19 Fixed Fixed the Unity Editor stuck on \"Creating workspace\" when \"Use Unity Version Control\" was selected from the Hub [2.4.3] - 2024-06-20 Added Changed the default ignore.conf to not ignore itself Added \"Undo unchanged\" and \"Undo checkouts keeping changes\" options to pending changes view Removed focus redirection after Check-in Fixed Moving folders in the Editor now correctly use the UVCS \"Move\" operation Fixed hang on domain reload Fixed \"item with the same key has already been added\" error Fixed failure to delete a .meta file when deleting a private folder from the pending changes Supported workspace name with non-latin characters in Pending Changes Fixed text cut-off in filter rules dialog Fixed unexpected error while switching between branches Fixed error after renaming a parent branch of the working branch Fixed variables's value becoming clear after resolving conflict in inspector Removed misleading indication about shelves Fixed column sorting in pending changes view Fixed missing incoming changes after removing a branch Fixed \"Collection was modified\" error when doing multiple renames in a row Fixed undo & check-in operations not working when the current scene was never saved Fixed check in error if nothing is selected in the pending changes tree [2.3.1] - 2024-02-27 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added New view to list and manage locks. Fixed Fixed DropdownField not working properly on a ModalUtility window on MacOS. Fixed issue with existing checkout operations locking the workspace. Reviewed initialization and application lifecycle. Fixed layout error when switching checkout status in the inspector. Fixed Diff option unavailable for .prefab. Fixed UI error when opening and closing multiple closable tabs. Ensured branch creations start from the latest changeset. Unable to expand added item list after collapsing. Pending Changes context menu had the view file history greyed out for asset+meta. Preconfigured date format was not recognized as a valid DateTime. Fixed finding changes operation being firing constantly. Removed obsolete content in package documentation. Fixed typo in locks tooltip. Replaced the text \"plasticscm.com\" by a https://unity.com/solutions/version-control in the package.json [2.2.0] - 2023-10-06 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added button for organization owner/admins to upgrade to DevOps subscription. Included new decorators for retained & locked files. Changed Updated description in the package.json, including an updated link to get started. Fixed Fixed failed operations when the workspace is already locked. [2.1.0] - 2023-09-01 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added command to support Hub creating a new project, and connecting a project to Unity Version Control. Show a message with a link to invite users to the organization after the first checkin. Changed Moved the button to invite users to the organization from the submenu to the toolbar. Removed Don't write cloudProjectId in ProjectSettings.asset anymore since it should only be managed by Services. Fixed Fixed Add to ignored/hidden changes list from the Project window creating a negative rule. Fixed Switch to changeset not working on Gluon partial workspace. [2.0.7] - 2023-07-25 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed the Unity Version Control icon disappearing from the Editor Toolbar on domain reload. Fixed the popup stating \"An existing checkout operation has locked the workspace\" when trying to check in a scene with unsaved changes. [2.0.5] - 2023-05-31 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed remaining references to 'Plastic SCM' in localized labels. [2.0.4] - 2023-04-14 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed 'Texture2D' does not contain a definition for 'ignoreMipmapLimit' error when installing Unity Version Control on previous Unity Editor Versions Fixed broken sign in dialog style when waiting for user to complete sign in Fixed NullReferenceException when opening a new project and the user doesn't have a Unity Version Control organization linked to a Unity ID [2.0.3] - 2023-03-29 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Changed Changed the icons for Unity Version Control rebranding Changed onboarding workflow Fixed Fixed blurry icons in the Unity Version Control window and toolbar button Fixed Pending Changes tab not always opening its selected item's location in Project window Fixed \"Checked-out (changed)\" status icon not showing up on Pending Changes tab Fixed issue that prevented new packages from being installed unless user enters play mode [2.0.1] - 2023-02-17 Unity Version Control is now available as part of the Version Control Package! You can enable Unity Version Control via Window > Unity Version Control to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Changed Updated branding from \"Plastic SCM\" to \"Unity Version Control\" Improved offline experience by disabling the plugin when there is no internet connection [2.0.0] - 2023-01-11 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Changed Removed Collab from the package [1.17.7] - 2022-10-28 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added offline mode toggle for smoother offline experience Fixed Fixed performance issue with FindWorkspaceForPath method called multiple times every frame Fixed performance issue with UI.CooldownWindowDelayer.OnUpdate running on project without Plastic SCM workspace [1.17.6] - 2022-10-06 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Changed Changed the \"Go back to changeset\" option in Changesets tab to \"Revert to changeset\" Improved notification banner appearance Fixed Fixed editor refresh triggering when a workspace update is in progress Fixed pending changes show global ignored as private Removed encryption checkbox from create organization dialog [1.17.2] - 2022-07-06 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added notification banner on the status bar for live updates Changed Renamed \"Invite members to workspace\" option to \"Invite members to organization\" Fixed Fixed not being able to view changesets in a Gluon workspace Fixed not being able to insert carriage return in checkin dialog [1.17.1] - 2022-06-21 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed missing references in synced prefabs [1.17.0] - 2022-06-13 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added option to enable changelists and display them in pending changes tab Added changelist related options to pending changes context menu Fixed Fixed editor hangs when there is no network available Fixed existing checkout has locked the workspace error Fixed checkin fails over unstable connection [1.15.18] - 2022-05-18 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Fixed Fixed editor hang when entering Play Mode [1.15.17] - 2022-04-27 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added checkin comment column to Incoming Changes view Changed Updated Go Back confirmation message to be consistent with feature Updated Create Child Branch dialog to focus on branch name field when opened Improved messaging of Subtractive Merge after using Go Back feature Fixed Fixed assets not added correctly when Plastic SCM window is not open Fixed wrong position of overlay icons on Pending Changes view Disallowed Go Back feature to a changeset from another branch [1.15.16] - 2022-03-28 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added \"Switch to changeset\" menu option in changesets view Added \"Go back to changeset\" menu option in changesets view Changed Removed category icons from views Removed \"com.unity.services.core\" package dependency Fixed Fixed light theme icons used in dark theme after pulling incoming changes Fixed \"Input string was not in a correct format\" error [1.15.15] - 2022-03-09 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added checkout option in scene prefab view Changed Updated file overlay icon size to adapt to project window zoom level Updated the styling of number of items in a category in Gluon incoming changes view Fixed Fixed Plastic X not opening from plugin menu Fixed error when trying to invite members to proect Fixed editor unhandled errors being hijacked by the plugin Fixed toolbar icon not displaying incoming changes notification when Plastic window is closed Fixed VCCache::instance != NULL error when opening a project with Plastic window opened [1.15.13] - 2022-02-14 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added branch name column in changeset view Changed Updated checkin comment box to keep the last comment after checkin error Fixed Fixed performance regression in large projects due to FindObjectsOfTypeAll calls [1.15.12] - 2022-01-27 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added option to \"Save Revision as\" to the context menu in the changesets view Added incoming changes overview bar for Gluon workspace Changed Updated the styling for number of items in category for pending changes view Updated the styling for number of items in category for changesets view Updated the styling for tabs close button Updated the color in different sections of the plugin Reduced dialog padding for the \"Create Branch\" dialog Updated the display overlay icons to show even if PlasticSCM window is closed Updated styling of number of items in incoming changes category Improved plugin initialization process and let the plugin functions without needing the Plastic window opened Disabled the invite button when user does not have invite permission or not on a cloud repo Fixed Fixed size info in incoming changes view does not match actual changes size Fixed checkin and checkout options not respecting inspector locked status Fixed buttons in inspector view displayed even when Plastic window is closed Fixed icon incorrect sizes Fixed errors on create branch dialog Fixed Newtonsoft.Json.dll conflicts with other external packages Fixed editor objects count increasing when hovering over Plastic window or toolbar button Fixed ArgumentOutOfRange exception when creating a branch Fixed scene reloading not happening after creating a new branch [1.15.7] - 2021-12-02 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added option to \"Save Revision as\" to the context menu in the changesets view Added incoming changes overview bar for Gluon workspace Changed Moved Plastic Package settings to the Unity Project Settings window Refined styling for Updating Workplace success state Updated texts for empty state and overview bar Removed Incoming Changes notification from empty state Updated the text for Forced Checkout option Refined the status overlay icons Updated the refresh icon on the toolbar Updated the texts for empty checkin message dialog Fixed Fixed capitalization of Pending Changes and File History tab names Fixed the amount of spacing after the Item column title in the Pending Changes tab Removed pin striping from line items in File History tab Fixed project view context menu and icons missing after Collaborate project migration Fixed migrated projects not downloading correctly from Unity Hub [1.15.4] - 2021-11-10 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Add option to \"Add to ignore file\" in context menu in the project view Added empty state message for Pending Changes tab Added success state message for Pending Changes tab Added metrics for Branches tab functionalities Changed Removed pinstriping in the Gluon Incoming Changes window Removed the “Nothing to download” bar from the Incoming Changes window when there are no items to download Changed the default metadata columns shown in the Incoming Changes screen Updated the alignment of sorting arrows to the right of the column Fixed Fixed UI overlays in Project view missing on changed assets when force checkout is disabled Fixed console error when selecting object in Scene view hierarchy or creating a new asset Fixed NullReferenceException after closing the Plastic SCM window [1.15.1] - 2021-10-21 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added visual overview bar to the incoming changes tab Added progress dialog for the migration process Added Branches tab that shows a list of all branches in the repository Added option and dialog to create a child branch from selected branch. Added option to switch to another branch Added option and dialog to rename a branch Added option to delete a branch Added a preference to save if the window should open the Branches tab by default Added metrics for Plastic SCM installation window usage Changed Updated texts for workspace modes selection and checkin comment box Updated status bar notification icons Fixed Fixed inverted text for the force checkout option Fixed typing capital O in checkin comment would open the selected item Fixed loading indicator not centered on Plastic SCM installation window Fixed installing Plastic SCM would sign out user from the plugin Removed extra refresh button on Gluon's Incoming Changes tab Fixed loading indicator not centered on Plastic SCM installation window Fixed missing Plastic SCM window option when user is not signed in on Unity Hub Removed meta file warning message for the deleted Beta folder Fixed Plastic SCM menu missing from Project view context menu [1.13.5] - 2021-09-27 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added workspace migration from Collab to Plastic which can be done with or without Plastic installed Added notification status icons Added light and dark mode versions of avatar icon Changed Updated texts for migration Improved usage analytics around Editor and Plugin version Workspace Migration Adjustments Fixed Renamed the CoreServices namespace so it doesn't conflict with other packages Devex integration to properly depend on Core Fixed some situations where the history window would be blank Fixed missing Enterprise login link Fixed low resolution icons in light theme [1.11.2] - 2021-08-27 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added horizontal scroll bar to Changesets list for easier viewing Added auto-login for SSO credentials handler Added metrics for changeset tab usage Added metrics for checkin actions Added new Undo icon Added missing API documentation Added ability to modify assets without checkout Added ability to allow empty checkin messages Added empty checking message localization Added Plastic toolbar button to Unity editor Added notification icon for incoming changes to Plastic toolbar button Changed Removed the unneeded refresh button from History Tab Moved search bar to the top right global icon section in all tabs Updated capitalization of options in the Settings context menu Updated tab button styling to be consistent with Unity Editor conventions Status bar visible across all tabs Moved refresh button to the toolbar at the top right corner of the window Moved changesets time period selector to the right corner of the window Removed \"Changes of changeset\" header on the Changesets tab Moved number of selected items next to \"Item\" metadata title on the Pending Changes tab Improved refresh icon resolution Changed changesets detail to appear in vertical column Reduced default number of columns in changesets tab The number of changesets is no longer displayed in changesets tab Changed Launch branch explorer into an icon with tooltip Removed the hide changes button in changesets tab Moved incoming change prompt and button into a status bar Changed \"Launch Plastic\" to \"Launch Plastic SCM\" in options menu Wording change for plastic installation Updated file status icons Fixed Fixed a bug where the Texture2D error would pop up after downloading a project Fixed a bug when context menu would sometimes disappear Fixed small textbox on checkin dialog when launched from context menu Fixed a workspace NullReferenceException bug Fixed notification icon not showing on Plastic window Fixed auto login errors not showing up for users Fixed unexpected error message after user switched workspace to a label [1.9.0] - 2021-07-13 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added Checkin and Update confirmation notification Added auto sign in when logged into Unity account Changed Simplified UI: decluttered UI Improved load time performance Fixed Fixed view not switching to workspace after creating an Enterprise Gluon workspace Fixed contextual menu not showing up in project view Fixed SSO renew token after password change Fixed some namespace collisions with Antlr3 [1.7.1] - 2021-06-25 Plastic SCM for Unity is now available as part of the Version Control Package! You can enable Plastic SCM via Window > Plastic SCM to get started! If you have previously used the Unity Asset Store Plastic SCM plug-in, you can now simply use this package. Make sure you delete the plug-in from your project. Removing a previously added Plastic SCM Asset Store Plug-In: Select the PlasticSCM folder in the Assets\\Plugins folder on the Project tab, then click Edit > Delete Close the Unity Editor and open your project again. You will find the Plastic SCM menu item in the Window menu. Added Added support for inviting other members. This option is available from the gear / settings icon. Added support for signing in with Cloud Edition. This is available during the onboarding screen if you have never signed in. Added support for turning off Plastic in their project. This option removes the Plastic metadata from your directory. This option is available under Assets > Plastic SCM > Turn off Plastic SCM Added notification on the Plastic SCM tab title to indicate incoming changes. Users will no longer need to have the Plastic SCM window visible to know there are incoming changes. Auto configuration of SSO Added date column in incoming changes Changed Updating license to better conform with expected customer usage. Updated documentation file to meet standards. Updated third-party usage. No longer requires downloading of the full Plastic client. Basic features will work without additional installation. Features that require the full Plastic client will allow download and install as needed. Usability improvements around checking in code Improved update workspace tab UX Plastic SCM context menu is now available even if the Plastic SCM window is closed Fixed Stability and performance improvements [1.5.7] - 2021-04-07 Unreleased The Version Control package will be expanding to include both Collaborate and Plastic SCM version control interfaces. This release is preparing for that move and contains no new functionality or bug fixes for Collaborate. Changed Collaborate Package renamed to Version Control with changes to package display name and description. Fixed Fixed NPE when updating the version of the Collab package. [1.3.9] - 2020-07-13 Fixed Unnecessary use of texture compression in icons that slowed down platform switching Update publish button state when selected changes update Use colorized icons when changes are available. [1.3.8] - 2020-06-08 Fixed Fix incorrect priority of error messages Fix Collab button being stuck in inprogress state Fix error when partially publishing without the window open [1.3.7] - 2020-01-30 Changed Bulk revert is now supported. Collab is blocked in play mode. Fixed Fixed services window's links to open Collab. [1.3.6] - 2020-01-21 Fixed Fixed compile errors when removing the NUnit package by removing unnecessary references. [1.3.5] - 2020-01-08 Fixed Fix \"accept mine\" / \"accept remote\" icon swap in conflicts view. [1.3.4] - 2019-12-16 Changed Window state is no longer restored after the window is closed and opened. Fixed History tab failing to load on startup if it is left open in the previous session. Progress bar percentage not matching the bar. History list correctly updates after a new revision is published. UI instabilities when restoring or going back to a revision with a different package manifest. Improve handling of changes to the project id. [1.3.3] - 2019-12-10 Changed Disable UI test cases that can be unstable. [1.3.2] - 2019-12-05 Changed Update UX to UIElements. Increased minimum supported version to 2020.1. Update Documentation to required standards. [1.2.16] - 2019-02-11 Fixed Update stylesheet to pass USS validation [1.2.15] - 2018-11-16 Changed Added support for non-experimental UIElements. [1.2.11] - 2018-09-04 Fixed Made some performance improvements to reduce impact on ReloadAssemblies. [1.2.9] - 2018-08-13 Fixed Test issues for the Collab History Window are now fixed. [1.2.7] - 2018-08-07 Fixed Toolbar drop-down will no longer show up when package is uninstalled. [1.2.6] - 2018-06-15 Fixed Fixed an issue where Collab's History window wouldn't load properly. [1.2.5] - 2018-05-21 This is the first release of Unity Package CollabProxy. Added Collab history and toolbar windows Collab view and presenter classes Collab Editor tests for view and presenter"
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/AccessRemoteProjects.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/AccessRemoteProjects.html",
    "title": "Access remote projects | mmo-rpg-unity",
    "keywords": "Access remote projects In the Unity Hub v3, click Open > Open Remote Project to see the list of your version control repositories that contain a Unity project. Select the project and click Next. Select the Editor version and platform and click the change version button. Your local version control workspace will be created for you. The latest version of the project will be downloaded and the Editor will open with the latest version of your Unity project."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/AddMembers.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/AddMembers.html",
    "title": "Add team members | mmo-rpg-unity",
    "keywords": "Add team members To invite team members to contribute to your project: From the toolbar, click Invite Members to Workspace. In your DevOps version control dashboard, click Add new user. You can also send invitations and add different permission types for each user."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/CreateProjects.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/CreateProjects.html",
    "title": "Create projects | mmo-rpg-unity",
    "keywords": "Create projects To create projects: In the Unity Editor, open the Unity Version Control window and click on Create Workspace. It will suggest names for your repository (shared files and history on the server) and workspace (your local copy on your computer). If you wish to use an existing version control repository, click the three dots next to the repository name, and select a repository from the list. Select the type of workspace that fits your needs. Developer workspace With this workspace, you can work with branching and merging. Gluon workspace This workspace tailored for artists allows you to pick the files you want to work on and check them back in without updating your whole workspace. Add asset files associated with your project. version control will display the project files from the asset folder in the Pending changes tab. You can choose specific files to include or add all to the repository by selecting the files and clicking Checkin changes. version control will automatically perform a check in for appropriate folders and files – such as package files and project settings – when it’s set up from the Unity Editor. You can view these in the Changesets tab. Once your initial asset check in is complete, you’re set up with version control for Unity and ready to create. See also See also the get started detailed guides: Get started with a new repository. Get started with an existing repository."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/GetStarted.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/GetStarted.html",
    "title": "Get started with Unity Version Control | mmo-rpg-unity",
    "keywords": "Get started with Unity Version Control The Version Control package provides an integration of Unity Version Control (Unity VCS, formerly Plastic SCM) in the Unity Editor. Unity Version Control enables you to work collaboratively by providing advanced features such as branching, locking, merging, and a standalone Desktop GUI. Learn more about Unity Version Control. To start with a new version control repository for your project, see Get started with a new repository. To start from an existing Unity Version Control repository, see Get started with an existing repository. For more information on how to get started, refer to the Unity Version Control documentation."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/GetStartedExistingRepository.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/GetStartedExistingRepository.html",
    "title": "Get started with an existing Unity Version Control repository | mmo-rpg-unity",
    "keywords": "Get started with an existing Unity Version Control repository Suppose you want to start working on a Unity project in an existing Unity Version Control repository and already have a Unity Version Control account linked to your Unity ID. In that case, you will be able to open the project straight from the Unity Hub. A workspace will automatically be created for your project on your machine. In the Unity Hub v3 Beta, click Open > Open remote project to see the list of your Unity Version Control repositories that contain a Unity project. Click the project and click Next. Click the Editor version and platform and click the change version button. In the Editor pop-up, click the Migrate button to migrate your local workspace to a Unity Version Control workspace Once the migration is completed, click the Open Unity Version Control button. Accessing the Unity Version Control Window You can access the Unity Version Control window in the Unity Editor by clicking Window > Unity Version Control."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/GetStartedNewRepository.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/GetStartedNewRepository.html",
    "title": "Get started with a new version control repository | mmo-rpg-unity",
    "keywords": "Get started with a new version control repository Note: To start from an existing version control repository, see Get started with an existing version control repository. You can walk through a straightforward onboarding wizard when creating a repository for your Unity project. This new wizard will help you: Set up your account and configure your repository for your Unity project, enabling you to sync to a version control Cloud Edition repository. Generate a standard ignore file that prevents unnecessary components of your Unity project from being checked in. Automatically do the first check-in so that your repository is in sync with your local changes. Open your Unity project. To access the version control window in the Unity Editor, click Window > version control: In the version control onboarding window, complete the steps to continue: Unity connects your project to your version control Cloud repository; version control automatically creates an ignore file in the workspace for Unity projects so it doesn't track files that shouldn't be part of the repository. It also creates a standard automatic checkin during the initial setup. So now you're all set to start using version control! Note: Basic version control actions, such as viewing pending changes, checking in changes, and viewing changesets, don’t require a version control Client install. However, if you want to use more advanced features, such as branching and diffing changeset, you will be prompted to download the version control client (if you have not already done so):"
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/GitUsers.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/GitUsers.html",
    "title": "Unity version control for Git users | mmo-rpg-unity",
    "keywords": "Unity version control for Git users GIT Unity VCS Explanation To Commit To Check in To Check in is to submit changes to the repo. Commit Changeset Each new change on the history of the repo, grouping several individual file and directory changes. Master Main When you create a repo in Unity VCS, there's always an \"empty\" branch. Unity VCS calls it Main. To checkout To update Downloading content to the workspace (working copy). This is called \"update\" because in Unity VCS, \"checkout\" has a different meaning. Checkout When you checkout a file in Unity VCS, you're saying you are going to modify the file. Exclusive checkout or lock This is locking a file so nobody can touch it. It’s only useful for non-mergeable files, like binaries, images, or art in a video game. Rebase Unity VCS handles branching differently than Git. In Unity VCS, a rebase is just a merge operation. Repository Repository Where the entire history of the project is stored. Working copy Workspace In Git, you have the working copy and the repository in the exact location. You have a working copy and a .git hidden dir with the repository. In Unity VCS, this is slightly different since repositories and workspaces are separated. You can have several workspaces working with the same local repository."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/Glossary.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/Glossary.html",
    "title": "Glossary | mmo-rpg-unity",
    "keywords": "Glossary General terms Project In Unity, you use a project to design and develop a game. A project stores all of the files related to a game, such as the asset and Scene files. See 2D or 3D projects. Version Control A system for managing changes to a set of files. You can use Unity in conjunction with most version control tools, including Unity Version Control and Perforce. See Version Control. Ignore file A special file used in many Version Control Systems which specifies files to be excluded from version control. In Unity projects, several folders should be excluded from version control. Repository A shared history of changes made to the project's files, saved on a server. Workspace Your local copy of the repository, interacting with the version control system. It's where you download the project's files, make the required changes and perform checkins. Check-in Check-in is the act of submitting changes from your workspace to the shared repository. You can enter a comment before checking in your changes. Unity Version Control terms Developer Workflow Developers have access to the branch explorer directly from inside Unity and easily switch branches. Gluon Workflow Artists can take advantage of the Gluon visualized interface and workflow from inside Unity. Organization The organization handles different sets of repositories in the Cloud. Inside the organization, you can create as many repositories as you need."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/MainFeatures.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/MainFeatures.html",
    "title": "Overview of features | mmo-rpg-unity",
    "keywords": "Overview of features Pending Changes The Pending Changes tab allows you to view all pending changes in your workspace. These changes are not checked into the repository. In this tab, you can select which files you want to check in, add a comment, and check in the changes. Note : You can check in a specific file using the version control contextual menu in the project view or the Checkin button in the Inspector window. In the example below, the user adds a GameScene. They can check in the scene using the Pending Changes tab or the Checkin option in the contextual menu. Incoming Changes The Incoming Changes tab allows you to view all incoming changes and conflicts and update your local project. Any changes made to your project prompts an \"Incoming changes\" notification at the top right of the version control window. Tip : Check the Incoming Changes tab frequently to avoid facing future change conflicts in your team. Project History Use the Changesets tab to view all changes made to your project as they occur chronologically, along with who made the changes and when. You can sort by columns and alter the chronological view of the story. Double-click any file in a changeset to go to the File History tab, and display every changeset. In the File History view, right-click on a change and click Save the revision as… to restore the file's former state. This is useful if you had previously deleted some logic that you now need. You can also view the changes made to a specific file in the Project view through a contextual menu, then revert to an earlier revision of the file. Locks The File locks tab allows you to list and filter all locks in your repository, and gives you the ability to release or remove them selectively. To open the view, you can use the \"Show Locks\" button available in the toolbar."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/MoreHelp.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/MoreHelp.html",
    "title": "More help | mmo-rpg-unity",
    "keywords": "More help To find more information on working with the Unity version control plug-in, see Getting started with Unity Version control. You can also post and find questions related to Unity version control in the Unity forum."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/QuickStartGuide.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/QuickStartGuide.html",
    "title": "Quick start guide | mmo-rpg-unity",
    "keywords": "Quick start guide The Version Control package provides an integration of Unity Version Control (Unity VCS, formerly Plastic SCM) in the Unity Editor. Get started with Unity Version Control"
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/ReconnectCB.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/ReconnectCB.html",
    "title": "Connect Unity Cloud Build | mmo-rpg-unity",
    "keywords": "Connect Unity Cloud Build Unity Cloud Build is a continuous integration that automatically creates multiplatform builds in the Cloud in minutes. You can point Cloud Build toward your version control system to: Automate new builds Build faster Catch problems earlier Iterate on your builds more efficiently with agility. To get started, see Pay as you go with Cloud Build."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "About the Version Control package Quick start guide Create projects Access remote projects Add team members Connect Cloud Build Get started with Unity Version Control Get started with a new version control repository Get started with an existing version control repository Main features Pending Changes Incoming Changes Project History Locks Unity Version Control for Git users Glossary General terms Unity Version Control terms More help"
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Documentation~/index.html",
    "title": "About the Version Control package | mmo-rpg-unity",
    "keywords": "About the Version Control package The Version Control package provides an integration of Unity Version Control (Unity VCS, formerly Plastic SCM) in the Unity Editor. It is installed by default with the Editor, and follows the Unity support schedule. Currently, the minimum supported version of the Unity Editor is 2020.3 LTS. Quick start guide Get started with Unity Version Control"
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Version Control copyright © 2023 Unity Technologies Licensed under the Unity Package Distribution License (see https://unity3d.com/legal/licenses/Unity_Package_Distribution_License). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/README.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/README.html",
    "title": "Unity Version Control Package | mmo-rpg-unity",
    "keywords": "Unity Version Control Package This package provides an in-editor interface for teams to work with Unity Version Control (Unity VCS), our leading version control solution, directly in Unity. Note this project is the natural evolution of the old Collaborate package, hence its name. Documentation - Changelog - Yamato Compatibility The minimum supported version of the Unity Editor is 2021.3 LTS. Windows and macOS are officially supported. The solution is exclusively targeting .NetStandard 2.0, and will not work with the legacy Mono runtime. Maintenance This project is currently maintained by the VCS Ecosystem team (@vcs-ecosystem-team), part of UGS DevOps. All suggestions and issues are very welcome in the Slack channel #devs-unity-version-control. Development For developers Option 1: clone this repository out into the packages/ directory in a project. Option 2: clone elsewhere and link with the packages/manifest.json file in the project: \"com.unity.collab-proxy\": \"file:/some/path/to/package\" To add testing support also add the testibles section to the manifest. Your manifest should look like this: { \"dependencies\": { \"com.unity.collab-proxy\": \"file:/some/path/to/package\", ... }, \"testables\": [ \"com.unity.collab-proxy\", ... ] } For internal testers Simply add the git url into the packages/manifest.json file: \"com.unity.collab-proxy\": \"git://git@github.cds.internal.unity3d.com:unity/com.unity.cloud.collaborate.git\" If you need a specific revisision: \"com.unity.collab-proxy\": \"git://git@github.cds.internal.unity3d.com:unity/com.unity.cloud.collaborate.git#<rev>\" If you need more information, read the Documentation for package dependencies from git. Code style is as dictated in Unity Meta."
  },
  "Library/PackageCache/com.unity.collab-proxy@2.4.4/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.collab-proxy@2.4.4/Third Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This package contains third-party software components governed by the license(s) indicated below: Component Name: File System Watcher https://docs.microsoft.com/en-us/dotnet/api/system.io.filesystemwatcher?view=net-5.0 License Type: MIT Copyright (c) Microsoft Corporation Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Zlib64 https://zlib.net/ License Type: zlib/libpng License (Zlib) version 1.2.11, January 15th, 2017 Copyright (C) 1995-2017 Jean-loup Gailly and Mark Adler This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software. Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions: The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software. This notice may not be removed or altered from any source distribution. Jean-loup Gailly Mark Adler jloup@gzip.org madler@alumni.caltech.edu Component Name: LZ4 Library/LZ4x64 https://github.com/lz4 License Type: BSD [The BSD License] Copyright (c) 2011-2020, Yann Collet All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Component Name: Antlr3/Antlr https://www.antlr3.org/ License Type: BSD [The BSD License] Copyright (c) 2010 Terence Parr All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of the author nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Component Name: Log4Net https://logging.apache.org/log4net/ License Type: Apache 2.0 Copyright (c) 2004-2017 The Apache Software Foundation Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  "Library/PackageCache/com.unity.collections@1.2.4/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.collections@1.2.4/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [1.2.4] - 2022-05-31 Changed Reverted some NativeArray test changes that were introduced in 1.0.0-pre.4 Fixed Added an assembly definition file for sample code in the package to avoid spurious warnings when adding the package [1.2.3] - 2022-03-18 Changed Minor fixes to changelog [1.2.3-pre.1] - 2022-03-04 Changed Updated package dependencies [1.2.2] - 2022-03-03 Changed Updated package com.unity.test-framework to version 1.1.31. Updated package com.unity.burst to version 1.6.4. [1.2.1] - 2022-02-17 Fixed Shutdown the WordStorage with application exit to ensure memory is freed. NativeList.AsDeferredJobArray allocator label is changed to Allocator.Invalid to infer that the array is in list mode. Added Added FixedStringMethods.CopyFromTruncated to copy a string to a FixedString explicitly allowing truncation Added NativeText.ReadOnly type which provides a readonly, lightweight copy of a NativeText or UnsafeText type. New public API AllocatorHandle.UnmanagedUnregister, which unregisters an allocator without using managed code. Changed Native/UnsafeMultiHashMap.GetUniqueKeyArrayNBC extension methods from Unity.Collections.NotBurstCompatible are not necessary anymore. Burst supports tuple. Original methods Native/UnsafeMultiHashMap.GetUniqueKeyArray are now available again. Reverted some NativeArray test changes that were introduced in 1.0.0-pre.4 Static safety ID created for all types containing a uniquely represented AtomicSafetyHandle [1.1.0] - 2021-10-27 Added REMOVE_DISPOSE_SENTINEL ifdefs in all containers for future removal of DisposeSentinel. Bounds check to Fixed/Native/UnsafeList. SetCapacity and TrimExcess to NativeList. A custom allocator wrapper AllocatorHelper to facilitate custom allocator creation and destruction. NativeList<>.ArraysEqual & UnsafeList<>.ArraysEqual UnsafeList.CopyFrom Changed Only lower 15 bits of an allocator handle version are valid. Fixed Error in leak detection for NativeList created by RewindableAllocator. Removed pointer caching from Native/UnsafeList.ParallelWriter. AtomicSafetyHandle issue preventing use of foreach iterator in jobs for NativeHashSet, NativeHashMap, and NativeMultiHashMap containers. [1.0.0-pre.6] - 2021-08-31 Removed VirtualMemoryUtility BaselibErrorState BaselibSourceLocation VMRange DisposeSentinel (managed object) from all Native* containers. Changed Native container memory allocations align to multiple cacheline size. UnsafeText is marshalable now (doesn't contain generic field UnsafeList ). Fixed AllocatorManager.AllocateBlock no longer ignores alignment when allocating. Redundant and wrong computation of memory allocation alignment. [1.0.0-pre.5] - 2021-08-20 Changed Renamed FixedListN to FixedListNBytes, for all N, and same for FixedString Fixed NativeBitArray, NativeQueue, NativeStream, and NativeText will no longer throw an exception when using a custom allocator inside of a job. [1.0.0-pre.4] - 2021-08-11 Added FixedList* overflow checks when UNITY_DOTS_DEBUG is enabled. Disposed NativeArray related tests and updated some invalidated native array from native list tests to confirm that exceptions are thrown when accessing an object's Length and indexer following its disposal Changed Updated internal dependencies InvalidArrayAccessFromListJob check in the InvalidatedArrayAccessFromListThrowsInsideJob unit test to expect an ObjectDisposedException due to a change in the type thrown for AtomicSafetyHandle.CheckAndThrow Fixed Setting UnsafeList.Length will now resize the storage properly. [1.0.0-pre.3] - 2021-06-29 Added Native/UnsafeList*.RemoveRange* with index/count arguments. Upgraded to burst 1.5.2 UnsafeText added. Changed Burst compatibility tests now treat any explicit uses of [BurstCompatible] on private methods as an error (as opposed to silently ignoring) to avoid giving the impression that private methods are being tested. NativeList<T> generic constraint T is changed from struct to unmanaged to match UnsafeList<T>. User code can be simply fixed by changing struct to unmanaged when using NativeList<T> inside generic container. NativeHashMap.GetBucketData renamed to NativeHashMap.GetUnsafeBucketData Update the package to 1.0.0 HeapString renamed to NativeText. NativeText is based on UnsafeText. Deprecated Generated FixedList[Byte/Int/Float][32/64/128/256/512] are deprecated, and replaced with generics FixedList[32/64/128/256/512]<T>. UnsafeMultiHashMap<TKey, TValue>.GetUniqueKeyArray replaced with extension method UnsafeMultiHashMap<TKey, TValue>.GetUniqueKeyValueNBC from Unity.Collections.NotBurstCompatible namespace. NativeMultiHashMap<TKey, TValue>.GetUniqueKeyArray replaced with extension method NativeMultiHashMap<TKey, TValue>.GetUniqueKeyValueNBC from Unity.Collections.NotBurstCompatible namespace. NativeList<T>.ToArray replaced with extension method NativeList<T>.ToArrayNBC from Unity.Collections.NotBurstCompatible NativeList<T>.CopyFrom replaced with extension method NativeList<T>.CopyFromNBC from Unity.Collections.NotBurstCompatible namespace. UnsafeAppendBuffer.Add replaced with extension methodUnsafeAppendBuffer.AddNBC from Unity.Collections.LowLevel.Unsafe.NotBurstCompatible namespace. UnsafeAppendBuffer.ToBytes replaced with extension method UnsafeAppendBuffer.ToBytesNBC from Unity.Collections.LowLevel.Unsafe.NotBurstCompatible namespace. UnsafeAppendBuffer.Reader.ReadNext replaced with extension method UnsafeAppendBuffer.Reader.ReadNextNBC from Unity.Collections.LowLevel.Unsafe.NotBurstCompatible namespace. Native/UnsafeList*.RemoveRange*WithBeginEnd methods with begin/end arguments in favor of Native/UnsafeList*.RemoveRange* with index/count arguments. UnsafeList and replaced it with UnsafeList<T>. VirtualMemoryUtility. Removed NativeQueue.PersistentMemoryBlockCount and NativeQueue.MemoryBlockSize are now internal APIs. Fixed Burst compatibility tests will now ignore any method containing a '$' in the name, which can be generated by the Burst direct call IL post processor. xxHash3 is initialized after assembly load to avoid an exception that could be thrown if xxHash3 is accessed for the first time on a thread other than the main thread. Security [0.17.0] - 2021-03-15 Added [NotBurstCompatible] attribute to FixedStringN constructors that use a String argument. [NotBurstCompatible] attribute to NativeQueue constructor. UnsafeList<T>.Create and UnsafeList<T>.Destroy API. BurstCompatibilityTests now has a constructor that accepts multiple assembly names to verify Burst compatibility. This allows one test to verify multiple assemblies and can dramatically reduce CI times by avoiding costly setup overhead. UnsafePtrList<T> to replace deprecated untyped UnsafePtrList. Burst compatibility tests now also write the generated code to the Temp directory in order to make it easier to inspect. FixedList*.RemoveRange* with index/count arguments. FixedString parsing to type uint Deprecated untyped UnsafePtrList, and added UnsafePtrList<T> as replacement. FixedList*.RemoveRange*WithBeginEnd methods with begin/end arguments in favor of FixedList*.RemoveRange* with index/count arguments. Removed Removed single arg FixedString*.Format extension methods, use Clear() followed by Append(). CollectionsBurstTests has been removed and placed into the Entities test project. com.unity.test-framework.performance preview package dependency, and moved performance unit tests depending on it into different location. Fixed *BitArray.Clear when clearing with very short bit arrays. NativeQueue.AsParallelWriter doesn't need to be cached when chaining jobs. Removed unnecessary safety handle that was preventing calling NativeQueue.AsParallelWriter() multiple times when scheduling jobs. [0.16.0] - 2021-01-26 Deprecated Sort methods that return a JobHandle deprecated in favor of new SortJob methods that return a job struct. Less conveniently, the user is responsible for calling Schedule on the struct, but this pattern better accommodates scheduling generic jobs from Bursted code (See https://docs.unity3d.com/Packages/com.unity.entities@latest/index.html?subfolder=/manual/ecs_generic_jobs.html). Removed Removed deprecated FixedListN.IndexOf and SortJob variants Fixed An ENABLE_UNITY_COLLECTIONS_CHECKS define was misspelled. Now Memory is checked for reasonable byte length when enabled. Many methods that use IJob were marked as [NotBurstCompatible] to reflect their true Burst compatibility. Changed Updated com.unity.burst to 1.4.4 [0.15.0] - 2020-11-13 Added NativeReference constructor to initialize it with existing value. T[] *HashSet.ToArray() returns an array of all elements in the set. xxHash3 now also has a utility method to hash a struct directly (Previously it was only pointer + size) [BurstCompatible] attribute to FixedList and extensions. [BurstCompatible] attribute to CollectionHelper. [BurstCompatible] attribute to FixedBytesN. [BurstCompatible] attribute to HeapString. [BurstCompatible] attribute to NativeArrayExtensions. [BurstCompatible] attribute to NativeBitArray. [BurstCompatible] attribute to NativeBitArrayUnsafeUtility. [BurstCompatible] attribute to NativeHashMap. [BurstCompatible] attribute to NativeHashMapExtensions. [BurstCompatible] attribute to NativeHashSet. [BurstCompatible] attribute to NativeList. [BurstCompatible] attribute to NativeListUnsafeUtility. [BurstCompatible] attribute to NativeMultiHashMap. [BurstCompatible] attribute to NativeQueue. [BurstCompatible] attribute to NativeReference. [BurstCompatible] attribute to NativeStream. [BurstCompatible] attribute to NativeString. [BurstCompatible] attribute to UTF8ArrayUnsafeUtility. [BurstCompatible] attribute to Unicode and Rune. [BurstCompatible] attribute to NativeStringView. [BurstCompatible] attribute to UnsafeAppendBuffer. [BurstCompatible] attribute to UnsafeAtomicCounter32 and UnsafeAtomicCounter64. [BurstCompatible] attribute to UnsafeHashMap. [BurstCompatible] attribute to UnsafeHashSet. [BurstCompatible] attribute to UnsafeList, UnsafeListExtensions, UnsafePtrList, UnsafePtrListExtensions. [BurstCompatible] attribute to UnsafeRingQueue. [BurstCompatible] attribute to UnsafeScratchAllocator. [BurstCompatible] attribute to UnsafeUtilityExtensions. [BurstCompatible] attribute to VMRange, Baselib_ErrorState, and VirtualMemoryUtility. [BurstCompatible] attribute to xxHash3. Changed Update burst to 1.4.1. *BitArray Length would previously report backing capacity which is always 64-bit aligned, changed it to report number of bits user requested on allocation. For example, allocating 3 bits will now report Length 3 instead capacity which is always aligned to 64-bits. Update minimum editor version to 2020.1.2f1 Fixed Code generation for indexers in structs with [BurstCompatible] attribute. *BitArray search for empty bits when number of bits is less than 7 and backing storage is fragmented with 0x81 bit pattern. Namespace for *HashSet.ExceptWith/IntersectWith/UnionWith extension methods, so that use of Unity.Collections.LowLevel.Unsafe namespace is not necessary. using FixedList.ToNativeArray with collection checks enabled used to throw a null reference exception. [0.14.0] - 2020-09-24 Added *UnsafeBitArray.Find with pos/count search range arguments. Changed UnsafeStream block allocation performance has been improved by ~16% by appending to the start of the per-thread block lists rather than the end. Removed FixedList*.InsertRange, FixedList*.RemoveRangeSwapBack, FixedList*.RemoveRange, NativeString*, NativeList.RemoveRangeSwapBack, NativeList.RemoveRange, UnsafeList.RemoveRangeSwapBack, UnsafeList.RemoveRange, FixedString*.Format, FixedString*.AppendFrom, NativeHashSet.TryAdd, UnsafeHashSet.TryAdd. [NativeContainerSupportsDeallocateOnJobCompletion] attribute from NativeReference container. It didn't work properly. Users can use Dispose(JobHandle) method instead. Fixed FixedList<T> Remove and RemoveSwapBack extension methods were modifying copy, fixed by passing this by reference to modify actual container. [0.13.0] - 2020-08-26 Added Added *BitArray.Find linear search for 0-bit range. Added SortJob extension methods for NativeList, UnsafeList, UnsafeList<T>, and NativeSlice. Added Sort method that accepts custom comparator, and job dependency, to all supported containers. Added BinarySearch extension methods for NativeArray, NativeList, UnsafeList, UnsafeList<T>, and NativeSlice. Added foreach support to UnsafeList<T>. Changed Sort functions that take an IComparer no longer require the sorted elements to be IComparable Bumped Burst to 1.3.5. Deprecated Deprecated SortJob with default job dependency argument. Use Sort that require an explicit JobHandle argument. If no dependency is needed, pass a default valued JobHandle. Removed Removed: UnsafeUtilityEx, Unity.Collections.Experimental*,FixedString*.UTF8LengthInBytes, and *Stream.ComputeItemCount() Fixed Fixed performance regression of *HashMap.Count() introduced in Collections 0.10.0. [0.12.0] - 2020-08-04 Added Added Sort method with custom comparer to FixedList* and UnsafeList<T>. Added IsEmpty property and Clear method to INativeList intefrace. Added INativeDisposable interface which provides a mechanism for scheduling release of unmanaged resources. Added InsertRangeWithBeginEnd to NativeList, UnsafeList, UnsafeList<T>, and UnsafePtrList. Added AddRange and AddRangeNoResize to FixedList*. Added properties to BaselibErrorState to check if an operation resulted in success, out of memory, or accessing an invalid address range. Added HeapString type, for arbitrary-length (up to 2GB) heap-allocated strings compatible with the FixedString* methods. Allocating a HeapString requires specifying an allocator and disposing appropriately. Deprecated Deprecated FixedList* method IndexOf with index and index/count arguments. Removed Removed: IJobNativeMultiHashMapMergedSharedKeyIndices JobNativeMultiHashMapUniqueHashExtensions IJobNativeMultiHashMapVisitKeyValue JobNativeMultiHashMapVisitKeyValue IJobNativeMultiHashMapVisitKeyMutableValue JobNativeMultiHashMapVisitKeyMutableValue IJobUnsafeMultiHashMapMergedSharedKeyIndices JobUnsafeMultiHashMapUniqueHashExtensions IJobUnsafeMultiHashMapVisitKeyValue JobUnsafeMultiHashMapVisitKeyValue IJobUnsafeMultiHashMapVisitKeyMutableValue JobUnsafeMultiHashMapVisitKeyMutableValue Fixed Fixed *HashMap.IsEmpty when items are added and removed from *HashMap. IsEmpty previously used allocated count only to report emptiness, but returning not-empty didn't actually meant that *HashMap is not empty. Fixed bug where *HashSet.Enumerator.Current would always return the default value instead of the actual value from the set. Fixed bug with *HashMap/Set.Enumerator returning wrong index and dereferencing out of bounds memory. [0.11.0] - 2020-07-10 Added Added VirtualMemoryUtility providing low-level virtual memory utility functions backed by baselib. *HashMap and *HashSet now implement IEnumerable<>. ReadArrayElementBoundsChecked and WriteArrayElementBoundsChecked for ease of debugging ReadArrayElement and WriteArrayElement without sacrificing performance by adding bounds checking directly to those functions. Added InsertRangeWithBeginEnd, RemoveRangeSwapBackWithBeginEnd, and RemoveRangeWithBeginEnd to list containers. *WithBeginEnd in name signifies that arguments are begin/end instead of more standard index/count. Once InsertRange, RemoveRangeSwapBack, and RemoveRange are completely deprecated and removed, those methods will be added with correct index/count arguments. Added xxHash3 type to expose 64/128bits hashing API using xxHash3 algorithm (corresponding to the C++ version https://github.com/Cyan4973/xxHash/releases/tag/v0.8.0) Changed Updated minimum Unity Editor version to 2020.1.0b15 (40d9420e7de8) Bumped burst to 1.3.2 version. Changed *HashSet.Add API to return bool when adding element to set. UnsafeUtilityExtensions is now public. NativeReference methods Equals and GetHashCode will now operate on the value instead of the data pointer. FixedString{32,64,128,512,4096} have been reworked. Functionality is shared via generics as much as possible. The API attempts to follow StringBuilder semantics. Append methods now consistently append. Append variant to append a char was added (appends the char, does not resolve to int overload). Format methods that replaced the contents of the target have been deprecated. Use Clear() followed by Append(). Because FixedStrings start out cleared, in most cases just an Append is sufficient. Format that takes a format string has been renamed to AppendFormat. The static FixedString.Format methods still exist for convenience, and return a FixedString128. It is possible for users to extend the Append family of methods to support appending their own types. See FixedStringAppendMethods.cs for examples of how to declare your own extension methods. Deprecated Deprecated *HashSet.TryAdd. *HashSet.Add is equivalent. Deprecated NativeString*. The functionality is replaced by FixedString*. Deprecated InsertRange, RemoveRangeSwap, and RemoveRange from list containers, and added InsertRangeWithBeginEnd, RemoveRangeSwapBackWithBeginEnd, and RemoveRangeWithBeginEnd. *WithBeginEnd in name signifies that arguments are begin/end instead of more standard index/count. Once InsertRange, RemoveRangeSwapBack, and RemoveRange are completely deprecated and removed, those methods will be added with correct index/count arguments. Removed Removed System.Runtime.CompilerServices.Unsafe.dll from package. Known Issues This version is not compatible with 2020.2.0a17. Please update to the forthcoming alpha. All containers allocated with Allocator.Temp on the same thread use a shared AtomicSafetyHandle instance. This is problematic when using NativeHashMap, NativeMultiHashMap, NativeHashSet and NativeList together in situations where their secondary safety handle is used. This means that operations that invalidate an enumerator for either of these collections (or the NativeArray returned by NativeList.AsArray) will also invalidate all other previously acquired enumerators. For example, this will throw when safety checks are enabled: var list = new NativeList<int>(Allocator.Temp); list.Add(1); // This array uses the secondary safety handle of the list, which is // shared between all Allocator.Temp allocations. var array = list.AsArray(); var list2 = new NativeHashSet<int>(Allocator.Temp); // This invalidates the secondary safety handle, which is also used // by the list above. list2.TryAdd(1); // This throws an InvalidOperationException because the shared safety // handle was invalidated. var x = array[0]; This defect will be addressed in a future release. [0.10.0] - 2020-05-27 Added Added Native/UnsafeHashSet containers. Added IsEmpty method to *Queue, *HashMap, *MultiHashMap, *List, FixedString. This method should be prefered to Count() > 0 due to simpler checks for empty container. Added a new container NativeReference to hold unmanaged allocation. Added CollectionsTestFixture to enable jobs debugger and verify safety checks are enabled. Added NativeList.CopyFrom(NativeArray<> array) Changed Updated minimum Unity Editor version to 2020.1.0b9 (9c0aec301c8d) Updated package com.unity.burst to version 1.3.0-preview.12. Made several tests inherit CollectionsTestFixture to prevent crashing when running tests without jobs debugger or safety checks enabled. Added NativeBitArray.AsNativeArray<T> method to reinterpret NativeBitArray as NativeArray of desired type. Deprecated Deprecated NativeArrayChunked8 and NativeArrayFullSOA from Unity.Collections.Experimental. Deprecated UnsafeUtilityEx.As/AsRef/ArrayElementAsRef. The functionality is available in UnsafeUtility. Fixed FixedString and FixedList types now display their contents in the Entity Inspector. Fixed NativeHashMap.ParallelWriter.TryAdd race condition. [0.9.0] - 2020-05-04 Added Added RemoveAt and RemoveRange to List containers in collections. These methods remove elements in list container while preserving order of the list. These methods are slower than Remove*SwapBack methods and users should prefer Remove*SwapBack if they don't care about preserving order inside *List container. Added *BitArray.Copy between two different bit arrays. Added NativeBitArrayUnsafeUtility.ConvertExistingDataToNativeBitArray for assigning view into data as bit array. Changed Updated package com.unity.burst to version 1.3.0-preview.11 Fixed Moved NativeMultiHashMap.Remove<TValueEQ>(TKey key, TValueEq value) into an extension method and made it Burst compatible Fixed bug in *HashMap.Remove to not throw when removing from empty hash map. [0.8.0] - 2020-04-24 Added Added Native/UnsafeBitArray.Copy for copying or shifting bits inside array. Added UnsafeAtomicCounter32/64 providing helper interface for atomic counter functionality. Added NativeBitArray providing arbitrary sized bit array functionality with safety mechanism. Changed Bumped Burst version to improve compile time and fix multiple bugs. Deprecated Deprecated IJobNativeMultiHashMapMergedSharedKeyIndices, JobNativeMultiHashMapUniqueHashExtensions, IJobNativeMultiHashMapVisitKeyValue, JobNativeMultiHashMapVisitKeyValue, IJobNativeMultiHashMapVisitKeyMutableValue, JobNativeMultiHashMapVisitKeyMutableValue, and introduced NativeHashMap.GetUnsafeBucketData and NativeMultiHashMap.GetUnsafeBucketData to obtain internals to implement deprecated functionality inside user code. If this functionality is used, the best is to copy deprecated code into user code. Removed Removed expired API class TerminatesProgramAttribute [0.7.1] - 2020-04-08 Deprecated Deprecated Length property from NativeHashMap, UnsafeHashMap, NativeMultiHashMap, UnsafeMultiHashMap, NativeQueue, and replaced it with Count() to reflect that there is computation being done. Fixed Fixed an issue where FixedListDebugView<T> only existed for IComparable types, which lead to a crash while debugging other types. Removed code that made NativeStream incompatible with Burst. [0.7.0] - 2020-03-13 Added Added ability to dispose NativeKeyValueArrays from job (DisposeJob). Added NativeQueue<T>.ToArray to copy a native queue to an array efficiently Changed Upgraded Burst to fix multiple issues and introduced a native debugging feature. Deprecated Deprecated Length property from NativeHashMap, UnsafeHashMap, NativeMultiHashMap, UnsafeMultiHashMap, NativeQueue, and replaced it with Count() to reflect that there is computation being done. Removed Removed expired API CollectionHelper.CeilPow2() Removed expired API CollectionHelper.lzcnt() Removed expired API struct ResizableArray64Byte<T> Fixed Removed code that made NativeStream incompatible with Burst. [0.6.0] - 2020-03-03 Added Added ability to dispose UnsafeAppendBuffer from a DisposeJob. Added NativeHashSetExtensions and UnsafeHashSetExtensions for HashSetExtensions in different namespaces. Changed UnsafeAppendBuffer field Size renamed to Length. Removed [BurstDiscard] from all validation check functions. Validation is present in code compiled with Burst. Removed Removed expired overloads for NativeStream.ScheduleConstruct without explicit allocators. Removed HashSetExtensions, replaced with NativeHashSetExtensions and UnsafeHashSetExtensions. Fixed Fixed UnsafeBitArray out-of-bounds access. [0.5.2] - 2020-02-17 Changed Changed NativeList<T> parallel reader/writer to match functionality of UnsafeList parallel reader/writer. Updated dependencies of this package. Removed Removed expired API UnsafeUtilityEx.RestrictNoAlias Fixed Fixed bug in NativeList.CopyFrom. [0.5.1] - 2020-01-28 Changed Updated dependencies of this package. [0.5.0] - 2020-01-16 Added Added UnsafeRingQueue<T> providing fixed-size circular buffer functionality. Added missing IDisposable constraint to UnsafeList and UnsafeBitArray. Added ReadNextArray<T> to access a raw array (pointer and length) from an UnsafeAppendBuffer.Reader. Added FixedString types, guaranteed binary-layout identical to NativeString types, which they are intended to replace. Added FixedList<T> generic self-contained List struct Added BitArray.SetBits with arbitrary ulong value. Added BitArray.GetBits to retrieve bits as ulong value. Changed Changed UnsafeBitArray memory initialization option default to NativeArrayOptions.ClearMemory. Changed FixedList structs to pad to natural alignment of item held in list Deprecated BlobAssetComputationContext.AssociateBlobAssetWithGameObject(int, GameObject) replaced by its UnityEngine.Object counterpart BlobAssetComputationContext.AssociateBlobAssetWithUnityObject(int, UnityEngine.Object) to allow association of BlobAsset with any kind of UnityEngine.Object derived types. Adding removal dates to the API that have been deprecated but did not have the date set. Removed Removed IEquatable constraint from UnsafeList<T>. Fixed Fixed BitArray.SetBits. [0.4.0] - 2019-12-16 This version requires Unity 2019.3.0f1+ New Features Adding FixedListTN as a non-generic replacement for ResizableArrayN<T>. Added UnsafeBitArray providing arbitrary sized bit array functionality. Fixes Updated performance package dependency to 1.3.2 which fixes an obsoletion warning Adding [NativeDisableUnsafePtrRestriction] to UnsafeList to allow burst compilation. [0.3.0] - 2019-12-03 New Features Added fixed-size BitField32 and BitField64 bit array. Changes Removed the following deprecated API as announced in/before 0.1.1-preview: Removed struct Concurrent and ToConcurrent() for NativeHashMap, NativeMultiHashMap and NativeQueue (replaced by the ParallelWriter API). From NativeStream.cs: struct NativeStreamReader and struct NativeStreamWriter, replaced by struct NativeStream.Reader and struct NativeStream.Writer. From NativeList.cs: ToDeferredJobArray() (replaced by AsDeferredJobArray() API). [0.2.0] - 2019-11-22 This version requires Unity 2019.3 0b11+ New Features Added fixed-size UTF-8 NativeString in sizes of 32, 64, 128, 512, and 4096 bytes. Added HPC# functions for float-to-string and string-to-float. Added HPC# functions for int-to-string and string-to-int. Added HPC# functions for UTF16-to-UTF8 and UTF8-to-UTF16. New Native(Multi)HashMap.GetKeyValueArrays that will query keys and values at the same time into parallel arrays. Added UnsafeStream, UnsafeHashMap, and UnsafeMultiHashMap, providing functionality of NativeStream container but without any safety mechanism (intended for advanced users only). Added AddNoResize methods to NativeList. When it's known ahead of time that list won't grow, these methods won't try to resize. Rather exception will be thrown if capacity is insufficient. Added ParallelWriter support for UnsafeList. Added UnsafeList.TrimExcess to set capacity to actual number of elements in the container. Added convenience blittable UnsafeList<T> managed container with unmanaged T constraint. Changes UnsafeList.Resize now doesn't resize to lower capacity. User must call UnsafeList.SetCapacity to lower capacity of the list. This applies to all other containers based on UnsafeList. Updated dependencies for this package. Fixes Fixed NativeQueue pool leak. [0.1.1] - 2019-08-06 Fixes NativeHashMap.Remove(TKey key, TValueEQ value) is now supported in bursted code. Adding deprecated NativeList.ToDeferredJobArray() back in - Use AsDeferredJobArray() instead. The deprecated function will be removed in 3 months. This can not be auto-upgraded prior to Unity 2019.3. Fixing bug where TryDequeue on an empty NativeQueue that previously had enqueued elements could leave it in an invalid state where Enqueue would fail silently afterwards. Changes Updated dependencies for this package. [0.1.0] - 2019-07-30 New Features NativeMultiHashMap.Remove(key, value) has been addded. It lets you remove all key & value pairs from the hashmap. Added ability to dispose containers from job (DisposeJob). Added UnsafeList.AddNoResize, and UnsafeList.AddRangeNoResize. BlobString for storing string data in a blob Upgrade guide Native*.Concurrent is renamed to Native*.ParallelWriter. Native*.ToConcurrent() function is renamed to Native*.AsParallelWriter(). NativeStreamReader/Writer structs are subclassed and renamed to NativeStream.Reader/Writer (note: changelot entry added retroactively). Changes Deprecated ToConcurrent, added AsParallelWriter instead. Allocator is not an optional argument anymore, user must always specify the allocator. Added Allocator to Unsafe*List container, and removed per method allocator argument. Introduced memory intialization (NativeArrayOptions) argument to Unsafe*List constructor and Resize. Fixes Fixed UnsafeList.RemoveRangeSwapBack when removing elements near the end of UnsafeList. Fixed safety handle use in NativeList.AddRange. [0.0.9-preview.20] - 2019-05-24 Changes Updated dependencies for Unity.Collections.Tests [0.0.9-preview.19] - 2019-05-16 New Features JobHandle NativeList.Dispose(JobHandle dependency) allows Disposing the container from a job. Exposed unsafe NativeSortExtension.Sort(T* array, int length) method for simpler sorting of unsafe arrays Imporoved documentation for NativeList Added CollectionHelper.WriteLayout debug utility Fixes Fixes a NativeQueue alignment issue. [0.0.9-preview.18] - 2019-05-01 Change tracking started with this version."
  },
  "Library/PackageCache/com.unity.collections@1.2.4/Documentation~/allocation.html": {
    "href": "Library/PackageCache/com.unity.collections@1.2.4/Documentation~/allocation.html",
    "title": "Using unmanaged memory | mmo-rpg-unity",
    "keywords": "Using unmanaged memory The Native- and Unsafe- collections in this package are allocated from unmanaged memory, meaning their existence is unknown to the garbage collector. You are responsible for deallocating any unmanaged memory that you no longer need. Failing to deallocate large or numerous allocations can lead to wasting more and more memory, which may eventually slow down or even crash your program. Allocators An allocator governs some unmanaged memory from which you can make allocations. Different allocators organize and track their memory in different ways. The three standard provided allocators are: Allocator.Temp The fastest allocator. For very short-lived allocations. Temp allocations cannot be passed into jobs. Each frame, the main thread creates a Temp allocator which is deallocated in its entirety at the end of the frame. Each job also creates one Temp allocator per thread, and these are deallocated in their entireties at the end of the job. Because a Temp allocator gets discarded as a whole, you actually don't need to manually deallocate your Temp allocations (in fact, doing so is a no-op). Temp allocations are only safe to use within the thread where they were allocated. So while Temp allocations can be made within a job, main thread Temp allocations cannot be passed into a job. For example, a NativeArray that's Temp allocated in the main thread cannot be passed into a job. Allocator.TempJob The next fastest allocator. For short-lived allocations. TempJob allocations can be passed into jobs. You are expected to deallocate your TempJob allocations within 4 frames of their creation. The number 4 was chosen because it's common to want allocations that last a couple frames: the limit of 4 accommodates this need with a comfortable extra margin. For the Native- collection types, the disposal safety checks will throw an exception if a TempJob allocation lives longer than 4 frames. For the Unsafe- collection types, you are still expected to deallocate them within 4 frames, but no safety checks are performed to ensure you do so. Allocator.Persistent The slowest allocator. For indefinite lifetime allocations. Persistent allocations can be passed into jobs. Because Persistent allocations are allowed to live indefinitely, no safety check can detect if a Persistent allocation has outlived its intended lifetime. Consequently, you should be extra careful to deallocate a Persistent allocation when you no longer need it. Disposal (deallocation) Each collection retains a reference to the allocator from which its memory was allocated because deallocation requires specifying the allocator. An Unsafe- collection's Dispose method deallocates its memory. A Native- collection's Dispose method deallocates its memory and frees the handles needed for safety checks. An enumerator's Dispose method is a no-op. The method is included only to fulfill the IEnumerator<T> interface. We often want to dispose a collection after the jobs which need it have run. The Dispose(JobHandle) method creates and schedules a job which will dispose the collection, and this new job takes the input handle as its dependency. Effectively, the method differs disposal until after the dependency runs: NativeArray<int> nums = new NativeArray<int>(10, Allocator.TempJob); // Create and schedule a job that uses the array. ExampleJob job = new ExampleJob { Nums = nums }; JobHandle handle = job.Schedule(); // Create and schedule a job that will dispose the array after the ExampleJob has run. // Returns the handle of the new job. handle = nums.Dispose(handle); The IsCreated property The IsCreated property of a collection is false only in two cases: Immediately after creating a collection with its default constructor. After Dispose has been called on the collection. Understand, however, that you're not intended to use a collections's default constructor. It's only made available because C# requires all structs to have a public default constructor. Also note that calling Dispose on a collection sets IsCreated to false only in that struct, not in any copies of the struct. Consequently, IsCreated may still be true even after the collection's underlying memory was deallocated if... Dispose was called on a different copy of the struct. Or the underlying memory was deallocated via an alias. Aliasing An alias is a collection which does not have its own allocation but instead shares the allocation of another collection, in whole or in part. For example, an UnsafeList can be created that doesn't allocate its own memory but instead uses a NativeList's allocation. Writing to this shared memory via the UnsafeList affects the content of the NativeList, and vice versa. You do not need to dispose aliases, and in fact, calling Dispose on an alias does nothing. Once an original is disposed, the aliases of that original can no longer be used: NativeList<int> nums = new NativeList<int>(10, Allocator.TempJob); nums.Length = 5; // Create an array of 5 ints that aliases the content of the list. NativeArray<int> aliasedNums = nums.AsArray(); // Modify the first element of both the array and the list. aliasedNums[0] = 99; // Only the original need be disposed. nums.Dispose(); // Throws an ObjectDisposedException because disposing // the original deallocates the aliased memory. aliasedNums[0] = 99; Aliasing can be useful in a few scenarios: Getting a collection's data in the form of another collection type without copying the data. For example, you can create an UnsafeList that aliases a NativeArray. Getting a subrange of a collection's data without copying the data. For example, you can create an UnsafeList that aliases a subrange of another list or array. Array reinterpretation. Perhaps surprisingly, it's allowed for an Unsafe- collection to alias a Native- collection even though such cases undermine the safety checks. For example, if an UnsafeList aliases a NativeList, it's not safe to schedule a job that accesses one while also another job is scheduled that accesses the other, but the safety checks do not catch these cases. It is your responsibility to avoid such mistakes. Array reinterpretation A reinterpretation of an array is an alias of the array that reads and writes the content as a different element type. For example, a NativeArray<int> which reinterprets a NativeArray<ushort> shares the same bytes, but it reads and writes the bytes as ints instead of ushorts; because each int is 4 bytes while each ushort is 2 bytes, each int corresponds to two ushorts, and the reinterpretation has half the length of the original. NativeArray<int> ints = new NativeArray<int>(10, Allocator.Temp); // Length of the reinterpreted array is 20 // (because it has two shorts per one int of the original). NativeArray<short> shorts = ints.Reinterpret<int, short>(); // Modifies the first 4 bytes of the array. shorts[0] = 1; shorts[1] = 1; int val = ints[0]; // val is 65537 (2^16 + 2^0) // Like with other aliased collections, only the original // needs to be disposed. ints.Dispose(); // Throws an ObjectDisposedException because disposing // the original deallocates the aliased memory. shorts[0] = 1;"
  },
  "Library/PackageCache/com.unity.collections@1.2.4/Documentation~/collection-types.html": {
    "href": "Library/PackageCache/com.unity.collections@1.2.4/Documentation~/collection-types.html",
    "title": "Collection types | mmo-rpg-unity",
    "keywords": "Collection types Array-like types A few key array-like types are provided by the core module, including Unity.Collections.NativeArray<T> and Unity.Collections.NativeSlice<T>. This package itself provides: Data structure Description @Unity.Collections.NativeList`1 A resizable list. Has thread- and disposal-safety checks. @Unity.Collections.LowLevel.Unsafe.UnsafeList`1 A resizable list. @Unity.Collections.LowLevel.Unsafe.UnsafePtrList`1 A resizable list of pointers. @Unity.Collections.NativeStream A set of append-only, untyped buffers. Has thread- and disposal-safety checks. @Unity.Collections.LowLevel.Unsafe.UnsafeStream A set of append-only, untyped buffers. @Unity.Collections.LowLevel.Unsafe.UnsafeAppendBuffer An append-only untyped buffer. @Unity.Collections.NativeQueue`1 A resizable queue. Has thread- and disposal-safety checks. @Unity.Collections.LowLevel.Unsafe.UnsafeRingQueue`1 A fixed-size circular buffer. @Unity.Collections.FixedList32Bytes`1 A 32-byte list, including 2 bytes of overhead, so 30 bytes are available for storage. Max capacity depends upon T. FixedList32Bytes<T> has variants of larger sizes: FixedList64Bytes<T>, FixedList128Bytes<T>, FixedList512Bytes<T>, FixedList4096Bytes<T>. There are no multi-dimensional array types, but you can simply pack all the data into a single-dimension. For example, for an int[4][5] array, use an int[20] array instead (because 4 * 5 is 20). When using the Entities package, a DynamicBuffer component is often the best choice for an array- or list-like collection. See also @Unity.Collections.NativeArrayExtensions, @Unity.Collections.ListExtensions, @Unity.Collections.NativeSortExtension. Map and set types Data structure Description @Unity.Collections.NativeHashMap`2 An unordered associative array of key-value pairs. Has thread- and disposal-safety checks. @Unity.Collections.LowLevel.Unsafe.UnsafeHashMap`2 An unordered associative array of key-value pairs. @Unity.Collections.NativeHashSet`1 A set of unique values. Has thread- and disposal-safety checks. @Unity.Collections.LowLevel.Unsafe.UnsafeHashSet`1 A set of unique values. @Unity.Collections.NativeMultiHashMap`2 An unordered associative array of key-value pairs. The keys do not have to be unique, i.e. two pairs can have equal keys. Has thread- and disposal-safety checks. @Unity.Collections.LowLevel.Unsafe.UnsafeMultiHashMap`2 An unordered associative array of key-value pairs. The keys do not have to be unique, i.e. two pairs can have equal keys. See also @Unity.Collections.HashSetExtensions, @Unity.Collections.NotBurstCompatible.Extensions, and @Unity.Collections.LowLevel.Unsafe.NotBurstCompatible.Extensions Bit arrays and bit fields Data structure Description @Unity.Collections.BitField32 A fixed-size array of 32 bits. @Unity.Collections.BitField64 A fixed-size array of 64 bits. @Unity.Collections.NativeBitArray An arbitrary-sized array of bits. Has thread- and disposal-safety checks. @Unity.Collections.LowLevel.Unsafe.UnsafeBitArray An arbitrary-sized array of bits. String types Data structure Description @Unity.Collections.NativeText A UTF-8 encoded string. Mutable and resizable. Has thread- and disposal-safety checks. @Unity.Collections.FixedString32Bytes A 32-byte UTF-8 encoded string, including 3 bytes of overhead, so 29 bytes available for storage. FixedString32Bytes has variants of larger sizes: FixedString64Bytes, FixedString128Bytes, FixedString512Bytes, FixedString4096Bytes. See also @Unity.Collections.FixedStringMethods Other types Data structure Description @Unity.Collections.NativeReference`1 A reference to a single value. Functionally equivalent to an array of length 1. Has thread- and disposal-safety checks. @Unity.Collections.LowLevel.Unsafe.UnsafeAtomicCounter32 A 32-bit atomic counter. @Unity.Collections.LowLevel.Unsafe.UnsafeAtomicCounter64 A 64-bit atomic counter. Job safety checks The purpose of the job safety checks is to detect job conflicts. Two jobs conflict if: Both jobs access the same data. One job or both jobs have write access to the data. In other words, there's no conflict if both jobs just have read only access to the data. For example, you generally wouldn't want one job to read an array while meanwhile another job is writing the same array, so the safety checks consider that possibility to be a conflict. To resolve such conflicts, you must make one job a dependency of the other to ensure their execution does not overlap. Whichever of the two jobs you want to run first should be the dependency of the other. When the safety checks are enabled, each Native- collection has an AtomicSafetyHandle for performing thread-safety checks. Scheduling a job locks the AtomicSafetyHandle's of all Native- collections in the job. Completing a job releases the AtomicSafetyHandle's of all Native- collections in the job. While a Native- collection's AtomicSafetyHandle is locked: Jobs which use the collection can only be scheduled if they depend upon all the already scheduled job(s) which also use it. Accessing the collection from the main thread will throw an exception. Read only access in jobs As a special case, there's no conflict between two jobs if they both strictly just read the same data, .e.g. there's no conflict if one job reads from an array while meanwhile another also job reads from the same array. The @Unity.Collections.ReadOnlyAttribute marks a Native- collection in a job struct as being read only: public struct MyJob : IJob { // This array can only be read in the job. [ReadOnly] public NativeArray<int> nums; public void Execute() { // If safety checks are enabled, an exception is thrown here // because the array is read only. nums[0] = 100; } } Marking collections as read only has two benefits: The main thread can still read a collection if all scheduled jobs that use the collection have just read only access. The safety checks will not object if you schedule multiple jobs with read only access to the same collection, even without any dependencies between them. Therefore these jobs can run concurrently with each other. Enumerators Most of the collections have a GetEnumerator method, which returns an implementation of IEnumerator<T>. The enumerator's MoveNext method advances its Current property to the next element. NativeList<int> nums = new NativeList<int>(10, Allocator.Temp); // Calculate the sum of all elements in the list. int sum = 0; NativeArray<int>.Enumerator enumerator = nums.GetEnumerator(); // The first MoveNext call advances the enumerator to the first element. // MoveNext returns false when the enumerator has advanced past the last element. while (enumerator.MoveNext()) { sum += enumerator.Current; } // The enumerator is no longer valid to use after the array is disposed. nums.Dispose(); Parallel readers and writers Several of the collection types have nested types for reading and writing from parallel jobs. For example, to write safely to a NativeList<T> from a parallel job, you need a NativeList<T>.ParallelWriter: NativeList<int> nums = new NativeList<int>(1000, Allocator.TempJob); // The parallel writer shares the original list's AtomicSafetyHandle. var job = new MyParallelJob {NumsWriter = nums.AsParallelWriter()}; public struct MyParallelJob : IJobParallelFor { public NativeList<int>.ParallelWriter NumsWriter; public void Execute(int i) { // A NativeList<T>.ParallelWriter can append values // but not grow the capacity of the list. NumsWriter.AddNoResize(i); } } Note that these parallel readers and writers do not usually support the full functionality of the collection. For example, a NativeList cannot grow its capacity in a parallel job (because there is no way to safely allow this without incurring significantly more synchronization overhead). Deterministic reading and writing Although a ParallelWriter ensures the safety of concurrent writes, the order of the concurrent writes is inherently indeterminstic because it depends upon the happenstance of thread scheduling (which is controlled by the operating system and other factors outside of your program's control). Likewise, although a ParallelReader ensures the safety of concurrent reads, the order of the concurrent reads is inherently indeterminstic, so it can't be known which threads will read which values. One solution is to use either @Unity.Collections.NativeStream or @Unity.Collections.LowLevel.Unsafe.UnsafeStream, which splits reads and writes into a separate buffer for each thread and thereby avoids indeterminism. Alternatively, you can effectively get a deterministic order of parallel reads if you deterministically divide the reads into separate ranges and process each range in its own thread. You can also get a deterministic order if you deterministically sort the data after it has been written to the list."
  },
  "Library/PackageCache/com.unity.collections@1.2.4/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.collections@1.2.4/Documentation~/index.html",
    "title": "Unity Collections package | mmo-rpg-unity",
    "keywords": "Unity Collections package This package provides unmanaged data structures that can be used in jobs and Burst-compiled code. The collections provided by this package fall into three categories: The collection types in Unity.Collections whose names start with Native- have safety checks for ensuring that they're properly disposed and are used in a thread-safe manner. The collection types in Unity.Collections.LowLevel.Unsafe whose names start with Unsafe- do not have these safety checks. The remaining collection types are not allocated and contain no pointers, so effectively their disposal and thread safety are never a concern. These types hold only small amounts of data. The Native- types perform safety checks to ensure that indexes passed to their methods are in bounds, but the other types in most cases do not. Several Native- types have Unsafe- equivalents, for example, NativeList has UnsafeList, and NativeHashMap has UnsafeHashMap. While you should generally prefer using the Native- collections over their Unsafe- equivalents, Native- collections cannot contain other Native- collections (owing to the implementation of their safety checks). So if, say, you want a list of lists, you can have a NativeList<UnsafeList<T>> or an UnsafeList<UnsafeList<T>>, but you cannot have a NativeList<NativeList<T>>. When safety checks are disabled, there is generally no significant performance difference between a Native- type and its Unsafe- equivalent. In fact, most Native- collections are implemented simply as wrappers of their Unsafe- counterparts. For example, NativeList is comprised of an UnsafeList plus a few handles used by the safety checks. For more information on the specific collection types, see the documentation on Collection types"
  },
  "Library/PackageCache/com.unity.collections@1.2.4/Documentation~/issues.html": {
    "href": "Library/PackageCache/com.unity.collections@1.2.4/Documentation~/issues.html",
    "title": "Known issues | mmo-rpg-unity",
    "keywords": "Known issues All containers allocated with Allocator.Temp on the same thread use a shared AtomicSafetyHandle instance rather than each having their own. On the one hand, this is fine because Temp allocated collections cannot be passed into jobs. On the other hand, this is problematic when using NativeHashMap, NativeMultiHashMap, NativeHashSet, and NativeList together in situations where their secondary safety handle is used. (A secondary safety handle ensures that a NativeArray which aliases a NativeList gets invalidated when the NativeList is reallocated due to resizing.) Operations that invalidate an enumerator for these collection types (or invalidate the NativeArray returned by NativeList.AsArray) will also invalidate all other previously acquired enumerators. For example, this will throw when safety checks are enabled: var list = new NativeList<int>(Allocator.Temp); list.Add(1); // This array uses the secondary safety handle of the list, which is // shared between all Allocator.Temp allocations. var array = list.AsArray(); var list2 = new NativeHashSet<int>(Allocator.Temp); // This invalidates the secondary safety handle, which is also used // by the list above. list2.TryAdd(1); // This throws an InvalidOperationException because the shared safety // handle was invalidated. var x = array[0]; This defect will be addressed in a future release."
  },
  "Library/PackageCache/com.unity.collections@1.2.4/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.collections@1.2.4/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Unity.Collections © 2017 Unity Technologies Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.collections@1.2.4/README.html": {
    "href": "Library/PackageCache/com.unity.collections@1.2.4/README.html",
    "title": "Unity.Collections | mmo-rpg-unity",
    "keywords": "Unity.Collections A C# collections library providing data structures that can be used in jobs, and optimized by Burst compiler. Package CI Summary Documentation https://docs.unity3d.com/Packages/com.unity.collections@0.14/manual/index.html Data structures The Unity.Collections package includes the following data structures: Data structure | Description | Documentation ----------------------- | ----------- | ------------- BitField32 | Fixed size 32-bit array of bits. | Documentation BitField64 | Fixed size 64-bit array of bits. | Documentation NativeBitArray | Arbitrary sized array of bits. | Documentation UnsafeBitArray | Arbitrary sized array of bits, without any thread safety check features. | Documentation NativeHashMap | Unordered associative array, a collection of keys and values. | Documentation UnsafeHashMap | Unordered associative array, a collection of keys and values, without any thread safety check features. | Documentation NativeHashSet | Set of values. | Documentation UnsafeHashSet | Set of values, without any thread safety check features. | Documentation NativeList | An unmanaged, resizable list. | Documentation UnsafeList | An unmanaged, resizable list, without any thread safety check features. | Documentation NativeMultiHashMap | Unordered associative array, a collection of keys and values. This container can store multiple values for every key. | Documentation UnsafeMultiHashMap | Unordered associative array, a collection of keys and values, without any thread safety check features. This container can store multiple values for every key. | Documentation NativeStream | A deterministic data streaming supporting parallel reading and parallel writing. Allows you to write different types or arrays into a single stream. | Documentation UnsafeStream | A deterministic data streaming supporting parallel reading and parallel writings, without any thread safety check features. Allows you to write different types or arrays into a single stream. | Documentation NativeReference | An unmanaged, reference container. | Documentation UnsafeAppendBuffer | An unmanaged, untyped, buffer, without any thread safety check features. | Documentation UnsafeRingQueue | Fixed-size circular buffer, without any thread safety check features. | Documentation UnsafeAtomicCounter32 | 32-bit atomic counter. | Documentation UnsafeAtomicCounter64 | 64-bit atomic counter. | Documentation ... The items in this package build upon the NativeArray , NativeSlice , and other members of the Unity.Collections namespace, which Unity includes in the core module. Notation Native* container prefix signifies that containers have debug safety mechanisms which will warn users when a container is used incorrectly in regard with thread-safety, or memory management. Unsafe* containers do not provide those safety warnings, and the user is fully responsible to guarantee that code will execute correctly. Almost all Native* containers are implemented by using Unsafe* container of the same kind internally. In the release build, since debug safety mechanism is disabled, there should not be any significant performance difference between Unsafe* and Native* containers. Unsafe* containers are in Unity.Collections.LowLevel.Unsafe namespace, while Native* containers are in Unity.Collections namespace. Determinism Populating containers from parallel jobs is never deterministic, except when using NativeStream or UnsafeStream. If determinism is required, consider sorting the container as a separate step or post-process it on a single thread. Known Issues All containers allocated with Allocator.Temp on the same thread use a shared AtomicSafetyHandle instance. This is problematic when using NativeHashMap, NativeMultiHashMap, NativeHashSet and NativeList together in situations where their secondary safety handle is used. This means that operations that invalidate an enumerator for either of these collections (or the NativeArray returned by NativeList.AsArray) will also invalidate all other previously acquired enumerators. For example, this will throw when safety checks are enabled: var list = new NativeList<int>(Allocator.Temp); list.Add(1); // This array uses the secondary safety handle of the list, which is // shared between all Allocator.Temp allocations. var array = list.AsArray(); var list2 = new NativeHashSet<int>(Allocator.Temp); // This invalidates the secondary safety handle, which is also used // by the list above. list2.TryAdd(1); // This throws an InvalidOperationException because the shared safety // handle was invalidated. var x = array[0]; This defect will be addressed in a future release. Licensing Unity Companion License (“License”) Software Copyright © 2017-2020 Unity Technologies ApS For licensing details see LICENSE.md"
  },
  "Library/PackageCache/com.unity.ext.nunit@1.0.6/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ext.nunit@1.0.6/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [1.0.6] - 2020-11-30 isExplicitlyReferenced set to 0 (case 1296162) [1.0.5] - 2020-11-04 Removed pdb files [1.0.4] - 2020-11-03 Added the portable-pdb (DSTR-37) [1.0.3] - 2020-10-30 Fixed being able to load mdb or portable-pdb symbolsbug (DSTR-37) Minimum unity version updated (case 1279253) [1.0.2] - 2019-12-04 Added missed metafiles [0.0.1] - 2019-02-21 This is the first release of Unity Package com.unity.ext.nunit. Migrated the custom version of nunit from inside of unity."
  },
  "Library/PackageCache/com.unity.ext.nunit@1.0.6/Documentation~/ext.nunit.html": {
    "href": "Library/PackageCache/com.unity.ext.nunit@1.0.6/Documentation~/ext.nunit.html",
    "title": "Custom Nunit build to work with Unity | mmo-rpg-unity",
    "keywords": "Custom Nunit build to work with Unity This version of nunit works with all platforms, il2cpp and Mono AOT. For Nunit Documentation: https://github.com/nunit/docs/wiki/NUnit-Documentation"
  },
  "Library/PackageCache/com.unity.ext.nunit@1.0.6/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ext.nunit@1.0.6/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Copyright (c) 2018 Charlie Poole, Rob Prouse Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.ext.nunit@1.0.6/README.html": {
    "href": "Library/PackageCache/com.unity.ext.nunit@1.0.6/README.html",
    "title": "Custom Nunit build to work with Unity | mmo-rpg-unity",
    "keywords": "Custom Nunit build to work with Unity This version of nunit works with all platforms, il2cpp and Mono AOT. For Nunit Documentation: https://github.com/nunit/docs/wiki/NUnit-Documentation"
  },
  "Library/PackageCache/com.unity.feature.2d@2.0.1/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.feature.2d@2.0.1/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [2.0.1] - 2024-05-17 Fixed Fixed quickstart link to its appropriate editor version [2.0.0] - 2023-06-04 Added Added the Aseprite Importer to the feature set. [1.0.0] - 2021-04-23 Added This is the first release of 2D feature set."
  },
  "Library/PackageCache/com.unity.ide.rider@3.0.31/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@3.0.31/CHANGELOG.html",
    "title": "Code Editor Package for Rider | mmo-rpg-unity",
    "keywords": "Code Editor Package for Rider [3.0.31] - 2024-06-17 fix RIDER-104519 Rider is reporting errors in scripts that work fine in Unity when utilizing DOTS - when Player project, by generating projects for all assemblies in \"com.unity.entities\", \"com.unity.collections\" fix RIDER-111622 Unity Rider package is not compatible with Rider Dev builds [3.0.28] - 2024-02-20 fix RIDER-103933 \"PlayerSettings.suppressCommonWarnings\" is not supported in Unity 2019.4.40f fix https://github.com/JetBrains/resharper-unity/issues/2431 and RIDER-104221 [3.0.27] - 2023-11-30 Restore the ability to select Rider installation from the custom location Fix possible extra project regeneration on moving focus from Rider to Unity Improve performance of code generation for very large projects [3.0.26] - 2023-10-04 https://github.com/JetBrains/resharper-unity/issues/2421 https://github.com/JetBrains/resharper-unity/issues/2422 [3.0.25] - 2023-08-18 unification of functionality to search JetBrains installations and open solution and file in Rider [3.0.22] - 2023-05-2 RIDER-82999 Unity's plugin SyncAll does not regenerate project files, and instead does basically nothing. #2401 Compilation issue with Unity 2021.3.0f1 [3.0.21] - 2023-04-18 RIDER-92424 JetBrains Rider Editor 3.0.20 package Update for Unity, Cause's Rider to Slows to a Crawl after updating RIDER-92419 JetBrains Rider Editor 3.0.20 for Unity has duplicate assemblies loaded into runtime [3.0.20] - 2023-04-05 fix loading Rider integration EditorPlugin on first switch of External Editor to Rider, see RIDER-91185 Keep the the PackageManager in sync with the Rider changes made to the manifest.json, it should help with RIDER-77343 Support CompilerOptions.RoslynAdditionalFilePaths and CompilerOptions.AnalyzerConfigPath [3.0.18] - 2023-01-09 RIDER-74818 Unity doesn't get to play mode if Editor is not running and user starts debug or profiling Improve performance of project generation - avoid using Directory.Exists avoid doing ProjectGeneration twice on the first start-up [3.0.17] - 2022-12-01 Avoid adding asset project parts to both editor and player projects, fixes the following issues: RIDER-75500 Local package references completions shows duplicate entries if player projects are generated RIDER-73795 Conversion to guid is not offered for assemblies with generated player projects RIDER-71238 No usages can be found for the assembly if player projects are generated [3.0.16] - 2022-09-09 Update the changelog Add folders to the generated csproj files Avoid extra RequestScriptReload call on the first start Fix shader support for folders in packages, but outside asmdef [3.0.15] - 2022-05-24 Cleanup cache after project generation to reduce memory consumption Performance optimization RIDER-76126 Rider package should generate an empty csproj for empty Unity project RIDER-77206 Unity 2020.1.3 'PlayerSettings' does not contain a definition for 'suppressCommonWarnings [3.0.14] - 2022-04-21 Move Rider package persisted state to Library, to avoid vcs collisions or adding it specifically to gitignore [3.0.13] - 2022-03-24 fix RIDER-69927 \"Test not run\" status is shown for the test suite when running unit tests for Unity project fix RIDER-74676 Unity plugin \"JetBrainseRider Editor\" completely breaks <= 2019.1.9 fix RIDER-71503 Unity Hang on \"Domain Unload\", caused by dispose of FileSystemWatcher [3.0.12] - 2022-01-28 Fix bug, which was introduced in 3.0.10: New script was not added to the csproj, because cached list of assemblies was used. [3.0.10] - 2021-12-09 Fix presentation of the TargetFramework in the csproj Fix: Auto-generated solution doesn't compile when code overrides virtual functions in other assemblies Fix RIDER-72234 Avoid full project generation, when only content of assembly was changed Fix RIDER-71985 Building large Unity projects randomly fails Fix RIDER-72174 Looking for Rider installed by dotUltimate installer [3.0.9] - 2021-11-09 Fix path for Roslyn analyser supplied with a package Minimal requirement for roslyn analyzer scope is Unity 2020.3.6f1 and above [3.0.8] - 2021-11-08 Technical release [3.0.7] - 2021-05-07 RIDER-60815 Simplify extensions lists for Rider package Fix csc.rsp -nullable+ / -nullable- parsing https://github.com/van800/com.unity.ide.rider/issues/7 Support -warnaserror/-warnaserror-:/-warnaserror+: in csc.rsp [3.0.6] - 2021-04-06 Fix bug: For Unity 2021.1+ Switching external editor from VS => Rider won't create the connection between Unity and Rider. When PlayerSettings.suppressCommonWarnings is true, it is reflected in the generated csproj with NoWarn \"0169\", \"0649\" By default include T4 templates in the generated solution (RIDER-37159) RIDER-60554 Unity crash in case of project without Unity Test Framework Package. RIDER-60445 Fix presentation of Rider external editor, when it is installed in a custom location. Improve project files generation performance RIDER-60508 Project Generation for projects without any cs files - add reference to UnityEditor/UnityEngine, so that Rider would detect Unity path and version and provide rich features for shader file. [3.0.5] - 2021-02-25 More stable in case of possible Rider product code change, improve test. Allows using \"Rider for Unreal\" with Unity projects (https://youtrack.jetbrains.com/issue/RIDER-51203) Remove implicit dependency to Test-Framework package Fix \"Unreachable code detected\" warning (https://youtrack.jetbrains.com/issue/RIDER-57930) [3.0.4] - 2021-01-26 Use LangVersion provided by Unity for generated csproj Improve documentation Support nullable provided in csc,rsp Avoid doing work in Unity secondary processes in UNITY_2021_1_OR_NEWER with UnityEditor.MPE.ProcessLevel.Secondary [3.0.3] - 2020-11-18 Update License Avoid connecting Rider from secondary UnityEditor instances Fix RIDER-53082 - Generate csproj without cs files, when there are any assets inside [3.0.2] - 2020-10-27 Speedup ProjectGeneration Fix RIDER-51958. Callbacks OnGeneratedCSProjectFiles would not work, but show a Warning instead. Remove release configuration Call RequestScriptReload, when External Editor is changed in Unity. [3.0.1] - 2020-10-02 RIDER-46658 Rider does not run PlayMode tests when ValueSource is combined with parameterized TestFixture RIDER-49947 Invoking PlayerSettings.SetScriptingDefineSymbolsForGroup() does not update definitions in Rider. Add static entrypoint Packages.Rider.Editor.RiderScriptEditor.SyncSolution to allow generating solution from commandline. [2.0.7] - 2020-08-18 Improve performance Add support for asmdef Root Namespace in .csproj generation ProjectGeneration for custom roslyn analysers https://docs.unity3d.com/2020.2/Documentation/Manual/roslyn-analyzers.html Switch target platform in Unity would regenerate csproj files (https://github.com/JetBrains/resharper-unity/issues/1740) [2.0.6] - 2020-08-10 Improve performance Add support for asmdef Root Namespace in .csproj generation ProjectGeneration for custom roslyn analysers https://docs.unity3d.com/2020.2/Documentation/Manual/roslyn-analyzers.html Switch target platform in Unity would regenerate csproj files (https://github.com/JetBrains/resharper-unity/issues/1740) [2.0.5] - 2020-05-27 Fix Regression in 2.0.3: In Unity 2019.2.9 on Mac, changing csproj and calling AssetDatabase.Refresh is not regenerating csproj. Regenerate projects on changes in manifest.json and Project Settings (EditorOnlyScriptingUserSettings.json) (#51) Fix: Assembly references to package assemblies break IDE projects. Fix: Reporting test duration. [2.0.2] - 2020-03-18 fix bug in searching Rider path on MacOS [2.0.1] - 2020-03-05 Speed improvements, ProjectTypeGuids for unity-generated project Improve UI for Project Generation settings Changes in csc.rsp would cause project-generation Remove NoWarn 0169 from generated csproj Support custom JetBrains Toolbox installation location [1.2.1] - 2019-12-09 Load optimised EditorPlugin version compiled to net 461, with fallback to previous version. On ExternalEditor settings page: reorder Generate all ... after Extensions handled Better presentation for Rider of some version in ExternalEditors list Initial support for Code Coverage with dotCover plugin in Rider Added support for Player Project generation [1.1.4] - 2019-11-21 Fix warning - unreachable code [1.1.3] - 2019-10-17 Update External Editor, when new toolbox build was installed Add xaml to default list of extensions to include in csproj Avoid initializing Rider package in secondary Unity process, which does Asset processing Reflect multiple csc.rsp arguments to generated csproj files: https://github.com/JetBrains/resharper-unity/issues/1337 Setting, which allowed to override LangVersion removed in favor of langversion in csc.rsp Environment.NewLine is used in generated project files instead of Windows line separator. [1.1.2] - 2019-09-18 performance optimizations: avoid multiple evaluations avoid reflection in DisableSyncSolutionOnceCallBack project generation optimization fixes: avoid compilation error with incompatible Test Framework package [1.1.1] - 2019-08-26 parse nowarn in csc.rsp warning, when Unity was started from Rider, but external editor was different improved unit test support workaround to avoid Unity internal project-generation (fix #28) [1.1.0] - 2019-07-02 new setting to manage list of extensions to be opened with Rider avoid breaking everything on any unhandled exception in RiderScriptEditor cctor hide Rider settings, when different Editor is selected dynamically load only newer rider plugins path detection (work on unix symlinks) speed up for project generation lots of bug fixing [1.0.8] - 2019-05-20 Fix NullReferenceException when External editor was pointing to non-existing Rider everything was broken by null-ref. [1.0.7] - 2019-05-16 Initial migration steps from rider plugin to package. Fix OSX check and opening of files. [1.0.6] - 2019-04-30 Ensure asset database is refreshed when generating csproj and solution files. [1.0.5] - 2019-04-27 Add support for generating all csproj files. [1.0.4] - 2019-04-18 Fix relative package paths. Fix opening editor on mac. [1.0.3] - 2019-04-12 Fixing null reference issue for callbacks to Asset pipeline. [1.0.2] - 2019-01-01 This is the first release of Unity Package rider_editor. Using the newly created api to integrate Rider with Unity."
  },
  "Library/PackageCache/com.unity.ide.rider@3.0.31/CONTRIBUTING.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@3.0.31/CONTRIBUTING.html",
    "title": "Contributing | mmo-rpg-unity",
    "keywords": "Contributing All contributions are subject to the Unity Contribution Agreement(UCA) By making a pull request, you are confirming agreement to the terms and conditions of the UCA, including that your Contributions are your original creation and that you have complete right and authority to make your Contributions. Once you have a change ready following these ground rules. Simply make a pull request"
  },
  "Library/PackageCache/com.unity.ide.rider@3.0.31/Documentation~/README.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@3.0.31/Documentation~/README.html",
    "title": "Code Editor Package for Rider | mmo-rpg-unity",
    "keywords": "Code Editor Package for Rider This package is not intended to be modified by users. Nor does it provide any api intended to be included in user projects."
  },
  "Library/PackageCache/com.unity.ide.rider@3.0.31/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@3.0.31/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "About JetBrains Rider Editor Using the JetBrains Rider Editor package"
  },
  "Library/PackageCache/com.unity.ide.rider@3.0.31/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@3.0.31/Documentation~/index.html",
    "title": "About JetBrains Rider Editor | mmo-rpg-unity",
    "keywords": "About JetBrains Rider Editor The JetBrains Rider editor package integrates support for the JetBrains Rider .NET Integrated Development Environment (IDE), into the Unity Editor. This package provides an end-point for Rider to call different Unity APIs and to generate .csproj and .sln files, which Rider uses to implement support for Unity in its plug-in. This package ensures that IDE features like autocomplete suggestions and flagging dependency conflicts work in Rider. It uses .cproj and .sln files which store information about your project such as: Versioning information Build files Platform requirements Web server or database settings Not all code in Unity is directly visible to code editors, particularly when using packages. This is because packages don’t provide their own .csproj files, and Unity doesn’t create them for installed packages by default. This means that IDE features like autocomplete suggestions and flagging dependency conflicts do not work with code in these packages. The purpose of this package is to produce the .csproj files that make these features possible by default when you use Rider. Installation As of Unity version 2019.2, this package comes as a part of the default Unity installation. If you are updating your project from an older version of Unity, you might need to install this package via the Package Manager. Requirements This version of the JetBrains Rider editor package is compatible with the following versions of the Unity Editor: 2019.2.6 or later To use this package, you must have the following third-party products installed: JetBrains Rider version 2019.3 or newer For more information about the Rider IDE, see the JetBrains Rider documentation. Submitting issues This package is maintained by JetBrains and Unity. Submit issues to the JetBrains/resharper-unity/issues GitHub page. Unity intends for this package to become accessible to the public on GitHub in the future."
  },
  "Library/PackageCache/com.unity.ide.rider@3.0.31/Documentation~/using-the-jetbrains-rider-editor-package.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@3.0.31/Documentation~/using-the-jetbrains-rider-editor-package.html",
    "title": "Using the JetBrains Rider Editor package | mmo-rpg-unity",
    "keywords": "Using the JetBrains Rider Editor package To use the package, go to Edit > Preferences > External Tools, click on the External Script Editor dropdown menu and select your version of Rider. When you select this option, the window reloads. After the window reloads, new settings that control production of .csproj files become available. External Tools tab in the Preferences window Commandline endpoints Q: Generate sln/csproj files for CI? A: Unity -batchmode -quit -projectPath ProjectPath -executeMethod Packages.Rider.Editor.RiderScriptEditor.SyncSolution Q: Generate sln/csproj and open External Editor? A: Unity -batchmode -quit -projectPath ProjectPath -executeMethod Packages.Rider.Editor.RiderScriptEditor.SyncSolutionAndOpenExternalEditor Package preferences Property: Description: Extensions handled This field lists the file extensions that open in JetBrains Rider. This field contains a variety of extensions by default. Generate .csproj files for: Each setting in this list enables or disables production of .csproj files for a different type of package. The Regenerate project files button updates existing .csproj files and creates the necessary new ones based on the settings you choose. These settings control whether to generate .csproj files for any installed packages. For more information on how to install packages, see the Adding and removing packages documentation. __ Embedded packages__ Any package that appears under your project’s Packages folder is an embedded package. An embedded package is not necessarily built-in; you can create your own packages and embed them inside your project. This setting is enabled by default. For more information on embedded packages, see the Embedded dependencies documentation. __ Local packages__ Any package that you install from a local repository stored on your machine, but from outside of your Unity project. This setting is enabled by default. __ Registry packages__ Any package that you install from either the official Unity registry or a custom registry. Packages in the Unity registry are available to install directly from the Package Manager. For more information about the Unity package registry, see the Package Registry section of the Unity Package Manager documentation. For information on creating and using custom registries in addition to the Unity registry, see the Scoped package registries documentation. __ Git packages__ Any package you install directly from a Git repository using a URL. __ Built-in packages__ Any package that is already installed as part of the default Unity installation. __ Tarball packages__ Any package you install from a GZip tarball archive on the local machine, outside of your Unity project. __ Unknown packages__ Any package which Unity cannot determine an origin for. This could be because the package doesn’t list its origin, or that Unity doesn’t recognize the origin listed. Player projects For each player project, generate an additional .csproj file named 'originalProjectName.Player.csproj'. This allows different project types to have their code included in Rider’s systems, such as assembly definitions or testing suites. This package also adds a second tab under Preferences named Rider, pictured below. Rider tab in the Preferences window Note The Logging Level menu does not control the level of Unity's logging, only the level of log messages that Rider package logs in its own log file. For more information on controlling Unity's logging level, see the Stack Trace Logging section of the Console Window documentation. Property: Description: Pass Console to Rider If Pass Console to Rider is enabled, Rider can access data that Unity sends to the Unity Console and display it within its own environment instead. Log file The Log file field contains an Open log button. Select this button to open the log file inside the Rider IDE. This button is unavailable when Logging Level is set to OFF. Logging Level The Logging Level menu controls how detailed are the Rider package logs. Those logs may be used for troubleshooting communication between Rider and Unity. Rider package logs all messages of the type you select as well as any messages of a more severe type. For example, if you choose WARN, then Rider logs all ERROR and FATAL messages as well as WARN messages. The message types are listed below in order of severity, with FATAL as the most severe type of message and TRACE as the least severe. OFF Rider does not produce any logs. **FATAL Logs information relating to serious problems that cause the application to crash. This setting produces the smallest logs. ERROR Logs information about errors that prevent some functionality from working, but don’t cause the application to fail (for example, a failed database connection). WARN Logs information about possible problems, or any unusual behaviour. Warnings don’t indicate that something has gone wrong, but that Unity detects something that might potentially cause an issue if not investigated. INFO Logs information about normal operation of the application, such as a successful database connection attempt. VERBOSE Logs detailed but not exhaustive information about your code. This setting is helpful for checking how your code executes or providing diagnostic information for other developers. TRACE Logs as much information about the application as possible. This can create a very large and detailed log, so it’s good practice to only use it when attempting to find the cause of a specific issue with your code."
  },
  "Library/PackageCache/com.unity.ide.rider@3.0.31/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ide.rider@3.0.31/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "MIT License Copyright (c) 2019 Unity Technologies Copyright (c) 2019 JetBrains s.r.o. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/CHANGELOG.html",
    "title": "Code Editor Package for Visual Studio | mmo-rpg-unity",
    "keywords": "Code Editor Package for Visual Studio [2.0.22] - 2023-10-03 Integration: Add support for XDG_DATA_DIRS and .desktop files on Linux for VS Code discovery. Use compile-time platform-specifics instead of using runtime conditions. Project generation: Suppress USG0001 warnings. Mark referenced assemblies as private (to not copy extra files to output directory when building). Add Unity capability to SDK-Style projects. Prevent circular dependency errors with SDK-Style projects. [2.0.21] - 2023-09-05 Integration: Only disable the legacy com.unity.ide.vscode package going forward. Fix json parsing issues with specific non-UTF code pages. Project generation: Target netstandard2.1 instead of netstandard2.0. Set defaultSolution in settings.json. Remove files.exclude entries for root csproj and sln files in settings.json when needed. Add vstuc launch configuration to launch.json when needed. Add visualstudiotoolsforunity.vstuc entry to extensions.json when needed. You can prevent the package from patching those configuration files by creating a .vscode/.vstupatchdisable file. [2.0.20] - 2023-06-27 Integration: Internal API refactoring. Add support for Visual Studio Code. Project generation: Add support for Sdk Style project generation. Fix an issue related to missing properties with 2021.3. [2.0.18] - 2023-03-17 Integration: Performance improvements with EditorApplication.update callbacks. Project generation: Add extra compiler options for analyzers and source generators. [2.0.17] - 2022-12-06 Integration: Fix rare deadlocks while discovering or launching Visual Studio on Windows. Improve launching Visual Studio on macOs. Project generation: Include analyzers from response files. Update supported C# versions. Performance improvements. [2.0.16] - 2022-06-08 Integration: Prevent ADB Refresh while being in safe-mode with a URP project Fixed an issue keeping the progress bar visible even after opening a script with Visual Studio. [2.0.15] - 2022-03-21 Integration: Improved project generation performance. Added support for keeping file/folder structure when working with external packages. Fixed project generation not being refreshed when selecting Visual Studio as the preferred external editor. [2.0.14] - 2022-01-14 Integration: Remove package version checking. [2.0.13] - 2022-01-12 Integration: Fixed wrong path to analyzers in generated projects when using external packages. Fixed selective project generation not creating Analyzer/LangVersion nodes. Fixed asmdef references with Player projects. Documentation: Added new documentation including ToC, overview, how to use and images. [2.0.12] - 2021-10-20 Integration: Do not block asset opening when only a VS instance without a loaded solution is found. Only check package version once per Unity session. Improved support for Visual Studio For Mac 2022. [2.0.11] - 2021-07-01 Integration: Added support for Visual Studio and Visual Studio For Mac 2022. Fixed an issue when the package was enabled for background processes. Project generation: Use absolute paths for Analyzers and rulesets. [2.0.10] - 2021-06-10 Project generation: Improved project generation performance when a file is moved, deleted or modified. Integration: Improved Inner-loop performance by avoiding to call the package manager when looking up vswhere utility. Fixed a network issue preventing the communication between Visual Studio and Unity on Windows. [2.0.9] - 2021-05-04 Project generation: Added support for CLI. Integration: Improved performance when discovering Visual Studio installations. Warn when legacy assemblies are present in the project. Warn when the package version is not up-to-date. [2.0.8] - 2021-04-09 Project generation: Improved generation performance (especially with DOTS enabled projects). Improved stability. Updated Analyzers lookup strategy. Fixed .vsconfig file not generated when using \"regenerate all\". Integration: Improved automation plugins. Documentation: Open sourced automation plugins. [2.0.7] - 2021-02-02 Integration: Remove com.unity.nuget.newtonsoft-json dependency in favor of the built-in JsonUtility for the VS Test Runner. [2.0.6] - 2021-01-20 Project generation: Improved language version detection. Integration: Added support for the VS Test Runner. Added initial support for displaying asset usage. Fixed remaining issues with special characters in file/path. [2.0.5] - 2020-10-30 Integration: Disable legacy pdb symbol checking for Unity packages. [2.0.4] - 2020-10-15 Project generation: Added support for embedded Roslyn analyzer DLLs and ruleset files. Warn the user when the opened script is not part of the generation scope. Warn the user when the selected Visual Studio installation is not found. Generate a .vsconfig file to ensure Visual Studio installation is compatible. Integration: Fix automation issues on MacOS, where a new Visual Studio instance is opened every time. [2.0.3] - 2020-09-09 Project generation: Added C#8 language support. Added UnityProjectGeneratorVersion property. Local and Embedded packages are now selected by default for generation. Added support for asmdef root namespace. Integration: When the user disabled auto-refresh in Unity, do not try to force refresh the Asset database. Fix Visual Studio detection issues with languages using special characters. [2.0.2] - 2020-05-27 Added support for solution folders. Only bind the messenger when the VS editor is selected. Warn when unable to create the messenger. Fixed an initialization issue triggering legacy code generation. Allow package source in assembly to be generated when referenced from asmref. [2.0.1] - 2020-03-19 When Visual Studio installation is compatible with C# 8.0, setup the language version to not prompt the user with unsupported constructs. (So far Unity only supports C# 7.3). Use Unity's TypeCache to improve project generation speed. Properly check for a managed assembly before displaying a warning regarding legacy PDB usage. Add support for selective project generation (embedded, local, registry, git, builtin, player). [2.0.0] - 2019-11-06 Improved Visual Studio and Visual Studio for Mac automatic discovery. Added support for the VSTU messaging system (start/stop features from Visual Studio). Added support for solution roundtrip (preserves references to external projects and solution properties). Added support for VSTU Analyzers (requires Visual Studio 2019 16.3, Visual Studio for Mac 8.3). Added a warning when using legacy pdb symbol files. Fixed issues while Opening Visual Studio on Windows. Fixed issues while Opening Visual Studio on Mac. [1.1.1] - 2019-05-29 Fix Bridge assembly loading with non VS2017 editors. [1.1.0] - 2019-05-27 Move internal extension handling to package. [1.0.11] - 2019-05-21 Fix detection of visual studio for mac installation. [1.0.10] - 2019-05-04 Fix ignored comintegration executable. [1.0.9] - 2019-03-05 Updated MonoDevelop support, to pass correct arguments, and not import VSTU plugin. Use release build of COMIntegration for Visual Studio. [1.0.7] - 2019-04-30 Ensure asset database is refreshed when generating csproj and solution files. [1.0.6] - 2019-04-27 Add support for generating all csproj files. [1.0.5] - 2019-04-18 Fix relative package paths. Fix opening editor on mac. [1.0.4] - 2019-04-12 Fixing null reference issue for callbacks to AssetPostProcessor. Ensure Path.GetFullPath does not get an empty string. [1.0.3] - 2019-01-01 This is the first release of Unity Package visualstudio_editor. Using the newly created api to integrate Visual Studio with Unity."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/CONTRIBUTING.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/CONTRIBUTING.html",
    "title": "Contributing | mmo-rpg-unity",
    "keywords": "Contributing All contributions are subject to the Unity Contribution Agreement(UCA) and Microsoft Contributor License Agreement (CLA) By making a pull request, you are confirming agreement to the terms and conditions of the UCA and CLA, including that your contributions are your original creation and that you have complete right and authority to make your contributions. Once you have a change ready following these ground rules. Simply make a pull request"
  },
  "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/Documentation~/README.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/Documentation~/README.html",
    "title": "Code Editor Package for Visual Studio | mmo-rpg-unity",
    "keywords": "Code Editor Package for Visual Studio This package is not intended to be modified by users. Nor does it provide any api intended to be included in user projects."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "About Visual Studio Editor Using the Visual Studio Editor package"
  },
  "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/Documentation~/index.html",
    "title": "Code Editor Package for Visual Studio | mmo-rpg-unity",
    "keywords": "Code Editor Package for Visual Studio About Visual Studio Editor The Visual Studio Editor package provides the Unity Editor with support for Unity-specific features from the Visual Studio Tools for Unity extension in Visual Studio and Visual Studio for Mac. These include IntelliSense auto-complete suggestions, C# editing, and debugging. Installation This package is a built-in package and installed by default. Note: If you’re using a version of the Unity Editor before 2019.4, you’ll need to install this package through the package manager. Requirements This version of the Visual Studio Editor package is compatible with the following versions of the Unity Editor: 2019.4 and later To use this package, you must have the following third-party products installed: On Windows: Visual Studio 2019 version 16.9 or newer with Visual Studio Tools for Unity 4.0.9 or newer. On macOS: Visual Studio for Mac 2019 version 8.9 or newer with Visual Studio Tools for Unity 2.0.9 or newer. For more information about using Visual Studio with Unity, see Microsoft’s Visual Studio Tools for Unity documentation. Submitting issues This package is maintained by Microsoft and Unity. Submit issues directly from Visual Studio and Visual Studio for Mac from the Help > Submit Feedback > Report a Problem menu. Unity will make this package accessible to the public on GitHub in the future."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/Documentation~/using-visual-studio-editor.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/Documentation~/using-visual-studio-editor.html",
    "title": "Using the Visual Studio Editor package | mmo-rpg-unity",
    "keywords": "Using the Visual Studio Editor package To use the package, go to Edit > Preferences > External Tools > External Script Editor and select the version of Visual Studio you have installed. When you select this option, the window reloads and displays settings that control production of .csproj files. Generate .csproj files Each setting in the table below enables or disables the production of .csproj files for a different type of package.When you click Regenerate project files, Unity updates the existing .csproj files and creates the necessary new ones based on the settings you choose. These settings control whether to generate .csproj files for any installed packages. For more information on how to install packages, see Adding and removing packages. Property Description Embedded packages Any package that appears under your project’s Packages folder is an embedded package. An embedded package is not necessarily built-in; you can create your own packages and embed them inside your project. This setting is enabled by default. For more information on embedded packages, see Embedded dependencies. Local packages Any package that you install from a local repository stored on your machine, but from outside of your Unity project. This setting is enabled by default. Registry packages Any package that you install from either the official Unity registry or a custom registry. Packages in the Unity registry are available to install directly from the Package Manager. For more information about the Unity package registry, see The Package Registry section of the Unity Package Manager documentation. For information on how to create and use custom registries in addition to the Unity registry, see Scoped package registries. Git packages Any package you install directly from a Git repository using a URL. Built-in packages Any package that is already installed as part of the default Unity installation. Tarball packages Any package you install from a GZip tarball archive on the local machine, outside of your Unity project. Unknown packages Any package which Unity cannot determine an origin for. This could be because the package doesn’t list its origin, or that Unity doesn’t recognize the origin listed. Player projects For each player project, generate an additional .csproj file named ‘originalProjectName.Player.csproj’. This allows different project types to have their code included in Visual Studio’s systems, such as assembly definitions or testing suites."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "MIT License Copyright (c) 2019 Unity Technologies Copyright (c) 2019 Microsoft Corporation. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/ThirdPartyNotices.html": {
    "href": "Library/PackageCache/com.unity.ide.visualstudio@2.0.22/ThirdPartyNotices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This package contains third-party software components governed by the license(s) indicated below: Component Name: VSWhere License Type: \"MIT\" The MIT License (MIT) Copyright (C) Microsoft Corporation. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: benbuck/EnvDTE License Type: Zero-Clause BSD Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE."
  },
  "Library/PackageCache/com.unity.ide.vscode@1.2.5/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ide.vscode@1.2.5/CHANGELOG.html",
    "title": "Code Editor Package for Visual Studio Code | mmo-rpg-unity",
    "keywords": "Code Editor Package for Visual Studio Code [1.2.5] - 2022-02-07 Introduce OnGeneratedCSProjectFiles, OnGeneratedCSProject and OnGeneratedSlnSolution callbacks. Always use forward slash in source paths Analyzers use absolute paths Ruleset files for roslyn analyzers Extra snap search paths on Ubuntu Specific c# language version for specific unity versions No longer hide .gitignore in VSCode file explorer [1.2.3] - 2020-10-23 Remove workaround for VSCode omnisharp (as of https://github.com/OmniSharp/omnisharp-vscode/issues/4113 we no longer need to disable the referenceoutputassemblies). [1.2.2] - 2020-09-04 VSC-14 - synchronize solution file when adding new assembly [1.2.1] - 2020-05-15 Source filtering adds support for asmref [1.2.0] - 2020-03-04 Do not reference projects that has not been generated (case 1211057) Only open files that exists (case 1188394) Add individual toggle buttons for generating csprojects for packages Add support for Roslyn analyzers in project generation through csc.rsp and compiled assembly references Remove Release build target from csproj and sln [1.1.4] - 2020-01-02 Delta project generation, only recompute the csproj files whose script modified. [1.1.3] - 2019-10-22 Exe version of vscode will use Normal ProcessWindowStyle while cmd will use Hidden [1.1.2] - 2019-08-30 Fixing OSX open command arguments [1.1.1] - 2019-08-19 Support for Player Project. Generates specific csproj files containing files, reference, defines, etc. that will show how the assembly will be compiled for a target platform. [1.1.0] - 2019-08-07 Adds support for choosing extensions to be opened with VSCode. This can be done through the GUI in Preferences. Avoids opening all extensions after the change in core unity. [1.0.7] - 2019-05-15 Fix various OSX specific issues. Generate project on load if they are not generated. Fix path recognition. [1.0.6] - 2019-04-30 Ensure asset database is refreshed when generating csproj and solution files. [1.0.5] - 2019-04-27 Add support for generating all csproj files. [1.0.4] - 2019-04-18 Fix relative package paths. Fix opening editor on mac. Add %LOCALAPPDATA%/Programs to the path of install paths. [1.0.3] - 2019-01-01 This is the first release of Unity Package vscode_editor. Using the newly created api to integrate Visual Studio Code with Unity."
  },
  "Library/PackageCache/com.unity.ide.vscode@1.2.5/CONTRIBUTING.html": {
    "href": "Library/PackageCache/com.unity.ide.vscode@1.2.5/CONTRIBUTING.html",
    "title": "Contributing | mmo-rpg-unity",
    "keywords": "Contributing All contributions are subject to the Unity Contribution Agreement(UCA) By making a pull request, you are confirming agreement to the terms and conditions of the UCA, including that your Contributions are your original creation and that you have complete right and authority to make your Contributions. Once you have a change ready following these ground rules. Simply make a pull request"
  },
  "Library/PackageCache/com.unity.ide.vscode@1.2.5/Documentation~/README.html": {
    "href": "Library/PackageCache/com.unity.ide.vscode@1.2.5/Documentation~/README.html",
    "title": "Code Editor Package for Visual Studio Code | mmo-rpg-unity",
    "keywords": "Code Editor Package for Visual Studio Code This package is not intended to be modified by users. Nor does it provide any api intended to be included in user projects."
  },
  "Library/PackageCache/com.unity.ide.vscode@1.2.5/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ide.vscode@1.2.5/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "MIT License Copyright (c) 2019 Unity Technologies Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "Library/PackageCache/com.unity.mathematics@1.2.6/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.mathematics@1.2.6/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [1.2.6] - 2022-02-11 Added Changed Made Il2CppEagerStaticClassConstructionAttribute internal to avoid conflicts with other definitions outside of the package. Deprecated Removed Fixed [1.2.5] - 2021-11-01 Added Changed Deprecated Removed Fixed Fixed property drawing when manually drawing a property that was hidden with [HideInInspector]. [1.2.4] - 2021-09-22 Added Added [Il2CppEagerStaticClassConstruction] to Unity.Mathematics types to run static constructors at startup. This improves IL2CPP performance slightly for types that have static constructors. Changed License file updated to satisfy Unity's package validation tests. Changed noise documentation in comments to xmldoc comments. Deprecated Removed Fixed Fixed Equals(object) override which did not check type before casting. This could cause exceptions to be thrown when the object did not match the expected type. Fixed incorrect math.tzcnt documentation which mentioned leading zero counts instead of trailing zero counts. Fixed float2x2.Rotate documentation to mention radians instead of degrees. Fixed documentation for methods and properties that were previously undocumented. [1.2.1] - 2020-08-06 Added Changed Deprecated Removed Fixed Fixed warnings for meta files existing even though the files they represent did not exist. Internal (Not ready for production) [1.2.0] - 2020-08-03 Added Added [MethodImpl(MethodImplOptions.AggressiveInlining)] to many static functions to improve IL2CPP performance. Added compress() that accepts a float4 and uint4. Added math.project() and math.projectsafe() for vector projection. Added math.EPSILON, math.INFINITY, math.NAN and their double counterparts. Added [Serializable] to RigidTransform. Added math.ceillog2(). Added math.floorlog2(). Added math.down(), math.forward(), etc for Cartesian coordinate axes that match UnityEngine Vector3 equivalents. Added math.ispow2(). Added half.MinValueAsHalf and half.MaxValueAsHalf to avoid having to explicitly convert from float. Added a float3x3 constructor which takes a float4x4 as input. Added [Serializable] to half types. Added some performance tests which can be run from the Unity test project. Added Random.CreateFromIndex() to assist in creating Random instances from loop indices. Changed Deprecated Removed Fixed Fixed documentation bug where quaternion.RotateX/Y/Z referred to a float4x4 instead of quaternion. Fixed code generation bugs which could cause Windows and Mac to generate different test code. Fixed some test asserts which used NaNs and signed zeros which failed in IL2CPP builds. Updated documentation for math.countbits() to include equivalent names on Intel and ARM architectures to aid in discoverability. Internal (Not ready for production) Added Unity.Mathematics.Geometry.Plane to represent planes in 3D space. Added more MinMaxAABB functionality from Unity.Physics.Aabb. Added Unity.Mathematics.Geometry.Math to hold static functions like AABB transformations. Added MinMaxAABB. [1.1.0] - 2019-07-08 Release stable version [1.1.0-preview.1] - 2019-06-27 Add new math.bitmask to return a bit mask from a bool4 [1.0.1] - 2019-04-15 Release stable version Modify all math constants (e.g math.PI) to provide float constant by default instead of double. Use for example math.PI_DBL to get the previous double constant. [1.0.0-preview.1] - 2019-02-28 Fixed bug where modifications on prefabs could not be reverted for vector properties when using context menu in Inspector. Fixed structure of the package for internal validation"
  },
  "Library/PackageCache/com.unity.mathematics@1.2.6/Documentation~/mathematics.html": {
    "href": "Library/PackageCache/com.unity.mathematics@1.2.6/Documentation~/mathematics.html",
    "title": "Unity.Mathematics | mmo-rpg-unity",
    "keywords": "Unity.Mathematics A C# math library providing vector types and math functions with a shader like syntax. Used by the Burst compiler to compile C#/IL to highly efficient native code. The main goal of this library is to provide a friendly Math API familiar to SIMD and graphic/shaders developers, using the well known float4, float3 types...etc. with all intrinsics functions provided by a static class math that can be imported easily into your C# program with using static Unity.Mathematics.math. In addition to this, the Burst compiler is able to recognize these types and provide the optimized SIMD type for the running CPU on all supported platforms (x64, ARMv7a...etc.) NOTICE: The API is a work in progress and we may introduce breaking changes (API and underlying behavior) Usage You can use this library in your Unity game by using the Package Manager and referencing the package com.unity.mathematics. See the forum Welcome page for more details. using static Unity.Mathematics.math; namespace MyNamespace { using Unity.Mathematics; ... var v1 = float3(1,2,3); var v2 = float3(4,5,6); v1 = normalize(v1); v2 = normalize(v2); var v3 = dot(v1, v2); ... } Building Open the src\\Unity.Mathematics.sln under Visual Studio 2015 or MonoDevelop and compile in Debug\\Release. Contributing We don't yet accept PR on this repository. See the FAQ below. The project is using editorconfig to keep files correctly formatted for EOL and spaces. We assume that your IDE has support for editorconfig, you can download the following extensions if your IDE is listed: VS2015/VS2017 EditorConfig extension Visual Studio Code EditorConfig extension SublimeText EditorConfig extension Frequently Asked Question Why developing another Math library instead of using existing Unity Vector3...etc.? After years of feedback and experience with the previous API, we believe that providing an API that is closer to the way graphics developers have been using math libraries should better help its adoption and the ease of its usage. HLSL / GLSL math library is a very well designed, well understood math library leading to greater consistency. Why not using System.Numerics.Vectors? Mainly for the reason mentioned above, System.Numerics.Vectors is in many ways similar to our previous Vector library (more object oriented than graphics programming oriented). Also the fact that our Burst compiler is able to recognize a lot more patterns for SIMD types and math intrinsics makes it easier to work with a dedicated API that reflects this ability. Naming convention In C# int and float are considered builtin types. Burst extends this set of bultin types to also include vectors, matrices and quaternions. These types are bultin in the sense that Burst knows about them and is be able to generate better code using these types than what would be possible with equivalent code using custom types. To signify that these types are bultin their type names are in all lower case. The operators on these bultin types found in Unity.Mathematics.math are considered intrinsics and are thus always in lower case. There are no plans to extend the set of intrinsic types beyond the current set of vectors (typeN), matrices (typeNxN) and quaternions (quaternion). This convention has the added benefit of making the library highly compatible with shader code and makes porting or sharing code between the two almost frictionless. Why can't we send a PR yet? We are working on providing a Contributor License Agreement (CLA) with a sign-over functionality and our UCL License doesn't cover this yet. Licensing Unity Companion License (“License”) Software Copyright © 2019 Unity Technologies ApS For licensing details see LICENSE.md"
  },
  "Library/PackageCache/com.unity.mathematics@1.2.6/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.mathematics@1.2.6/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.mathematics copyright © 2019 Unity Technologies Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [Unreleased] Version Updated The version number for this package has increased due to a version update of a related graphics package. [14.0.10] - 2024-04-03 This version is compatible with Unity 2022.3.24f1. Fixed Fixed lens flare occlusion format support test. Fixed DebugUI.Button not working in Rendering Debugger runtime UI. [14.0.9] - 2023-12-21 This version is compatible with Unity 2022.3.18f1. Fixed Avoid getting UnityEditor.SceneManagement.PrefabStage with reflection from the static ctor of CoreUtils. Don't display help icon for VolumeComponents that don't have a valid Help URL defined. [14.0.8] - 2023-09-27 This version is compatible with Unity 2022.3.11f1. Added Added callbacks when RenderPipeline is created or disposed. ObjectID Render Request that provides a render texture with the ObjectId of each pixel. Fixed Fixed potentially broken rendering and errors after renaming a VolumeProfile asset. Fixed popup showing multiple time when trying to remove additional data while in multi selection.. Removed some unexpected SRP changed callback invocations. Fixed Rendering Debugger runtime UI getting occluded by user UI with sorting order larger than 0. Fixed console errors when debug actions are removed from Input Manager during play mode. When building for Built-in, shaders from any SRP are completely stripped. Fixed occasional ArgumentOutOfRangeException in StaticLightingSky. [14.0.7] - 2023-05-23 This version is compatible with Unity 2022.2.22f1. Fixed Fixed Decal Projector Editor fields so they are now saved when editing a prefab. Revert Property for animation curves on Volume Components Fixed an IES Importer issue producing incorrect results. Crash on keywords::LocalKeywordState::ResetWithSpace when shader contains Grab Pass. Fixed SRPs not being able to build using mode -nographics and -batchmode, since lens flare global texture prevents this from happening. [14.0.6] - 2023-03-24 This version is compatible with Unity 2022.2.13f1. Fixed Fixed a Render Graph bug where culled passes would be delegated to releasing a resource, resulting in unwanted leaking. [14.0.5] - 2022-12-12 This version is compatible with Unity 2022.2.4f1. Changed Allow VolumeComponent BoolParameter UI to display enabled/disabled dropdown instead of checkboxes. Fixed Fixed Light Editor didn't apply changes to SerializedObject. Added Local mode to fit Probe Volumes to scene. Fixed recalculating of apv probe positions. Fixed virtual offset pushing probes outside of geometry. [14.0.4] - 2022-11-04 This version is compatible with Unity 2022.2.2f1. Added Extension method to fetch the Render Pipeline assets from a BuildTarget. New XRSystem API to allow SRPs override the XR built-in stereo matrices. Changed Improved performance of APV baking. Allow setting order for panels on the rendering debugger. Fixed Fixed the reset of APV volume placement when using multi selection. Fixed an issue so that APV dilated data not being written back to disk. Fixed realtime subdivision so it culls empty cells. Hid the warning on the reflection probe if you disable APV. Fixed so that data isn't cleared for probes to be dilated into, to avoid bright colored splotches. Fixed probes so that the max distance between then are respected. Fixed uninitialized memory for virtual offset. Fixed NaN when you bake high intensity lights. Fixed the APV touchup volume test so it uses OBB instead of AABB. Fixed null reference when you enable the Camera in a project with multiple SRPs installed. Volume Component Editor Foldouts states are now stored by type instead of by position. Fixed SerializedObjectNotCreatableException on Volume Component Editors. Fixed null reference exception when settings null Render Pipeline Global settings on the Settings provider. Fixed swapping Volume Component in a Volume profile with mixed pipeline Volume Components. Default Volume Profile can now be recovered when it is being deleted from the project folder. Fixed editor drawer for Value tuples in the Rendering Debugger. Fixed an issue where FreeCamera would print an error when using old InputSystem. Fixed missing subdivision label when looking at APV realtime subdivision preview. Fixed shadow cascade editor so the snatches now appear and the gradient appearance is improved. Fixed global probe volumes not fitting to all objects. Fixed dropdowns for multiple editors. [14.0.3] - 2021-05-09 This version is compatible with Unity 2022.2.0b15. Fixed Added Shader Stripping Watcher so you get notifications when a Shader Variant is stripped. [14.0.2] - 2021-02-04 This version is compatible with Unity 2022.2.0a14. Added Added new extension TryRemoveElementsInRange to remove a range of elements from a IList. Added error on ResourceReloader when attempting to use [ReloadGroup] on ScriptableObject. Added Screen Coordinates Override shader utilities. Added API to blend between baking states for Probe Volumes. Aded explicit control over scenario blending factor and a debug mode for visualization. Fixed Fixed texture gather macros for GLCore and moved them from target 4.6 to target 4.5. Fixed cubemap array macros for GLCore. Fixed regression on ResourceReloader due to change for supporting built-in resources. Fixed issue with debug markers in Unity Profiler in deep profiler mode [14.0.1] - 2021-12-07 Added Linear version of function that sets FSR RCAS shader constants DebugUI.ObjectPopupField to render a list of UnityEngine.Objects as a popup on the Rendering Debugger. Add probe volume influence weight parameter Added support for multiple Baking States to Prove Volumes. Hidding Volume Components not available for the current pipeline on the Volume Profile Inspector. Changed Volume Component editor are now specified by CustomEditorAttribute instead of VolumeComponentEditorAttribute. Fixed The Volume Panel on the Rendering Debugger was not corretly showing cameras when they were added or deleted. Fixed issue in DynamicResolutionHandler when camera request was turned off at runtime, the ScalableBufferManager would leak state and not unset DRS state (case 1383093). Fixed undo in for DebugUI.EnumFields on the rendering debugger. (case 1386964) Fixed DebugUI.Enum fields collapsing their parent DebugUI.Foldout Fixed IES profile importer handling of overflow (outside 0-1 range) of attenutation splines values. Fixed issue with Probe Volume Baking window incorrectly displaying the icon for probe volumes in scenes that don't contain probe volumes. Fixed unnecessary memory allocation inside FSR's RCAS shader constants helper function. Fixed the issue with the special Turkish i, when looking for the m_IsGlobal property in VolumeEditor. (case 1276892) [14.0.0] - 2021-11-17 Added Context menu on Volume Parameters to restore them to their default values. Fixed Fixed XR support in CoreUtils.DrawFullscreen function. Changed Removed FSR_ENABLE_16BIT option from FSRCommon.hlsl. The 16-bit FSR implementation is now automatically enabled when supported by the target platform. [13.1.2] - 2021-11-05 Added Added function to allocate RTHandles using RenderTextureDescriptor. Added vrUsage support for RTHandles allocation. Fixed Fixed issue when changing volume profiles at runtime with a script (case 1364256). Fixed XR support in CoreUtils.DrawFullscreen function. Fixed an issue causing Render Graph execution errors after a random amount of time. [13.1.1] - 2021-10-04 Added Added support for high performant unsafe (uint only) Radix, Merge and Insertion sort algorithms on CoreUnsafeUtils. Added DebugFrameTiming class that can be used by render pipelines to display CPU/GPU frame timings and bottlenecks in Rendering Debugger. Added new DebugUI widget types: ProgressBarValue and ValueTuple Added common support code for FSR. Added new RenderPipelineGlobalSettingsProvider to help adding a settings panel for editing global settings. Added blending for curves in post processing volumes. New extension for Render Pipeline Global Settings for shader variants settings -> IShaderVariantsSettings. [13.1.0] - 2021-09-24 Added Debug Panels Framework See IDebugDisplaySettingsQuery. Fixed Fixed keyword and float property upgrading in SpeedTree8MaterialUpgrader [13.0.0] - 2021-09-01 Version Updated The version number for this package has increased due to a version update of a related graphics package. Added New IVolumeDebugSettings interface and VolumeDebugSettings<T> class that stores the information for the Volumes Debug Panel. Added AMD FidelityFX shaders which were originally in HDRP Added support for high performant unsafe (uint only) Radix, Merge and Insertion sort algorithms on CoreUnsafeUtils. Fixed Fixed black pixel issue in AMD FidelityFX RCAS implementation Fixed a critical issue on android devices & lens flares. Accidentally creating a 16 bit texture was causing gpus not supporting them to fail. Fixed serialization of DebugStateFlags, the internal Enum was not being serialized. [12.0.0] - 2021-01-11 Added Support for the PlayStation 5 platform has been added. Support for additional properties for Volume Components without custom editor Added VolumeComponentMenuForRenderPipelineAttribute to specify a volume component only for certain RenderPipelines. Calculating correct rtHandleScale by considering the possible pixel rounding when DRS is on Support for the PlayStation 5 platform has been added. Support for the XboxSeries platform has been added. Added Editor window that allow showing an icon to browse the documentation New method DrawHeaders for VolumeComponentsEditors Unification of Material Editor Headers Scopes New API functions with no side effects in DynamicResolutionHandler, to retrieve resolved drs scale and to apply DRS on a size. Added helper for Volumes (Enable All Overrides, Disable All Overrides, Remove All Overrides). Added a blitter utility class. Moved from HDRP to RP core. Added a realtime 2D texture atlas utility classes. Moved from HDRP to RP core. New methods on CoreEditorDrawers, to allow adding a label on a group before rendering the internal drawers Method to generate a Texture2D of 1x1 with a plain color Red, Green, Blue Texture2D on CoreEditorStyles New API in DynamicResolutionHandler to handle multicamera rendering for hardware mode. Changing cameras and resetting scaling per camera should be safe. Added SpeedTree8MaterialUpgrader, which provides utilities for upgrading and importing SpeedTree 8 assets to scriptable render pipelines. Adding documentation links to Light Sections Support for Lens Flare Data Driven (from images and Procedural shapes), on HDRP New SRPLensFlareData Asset Adding documentation links to Light Sections. Added sampling noise to probe volume sampling position to hide seams between subdivision levels. Added DebugUI.Foldout.isHeader property to allow creating full-width header foldouts in Rendering Debugger. Added DebugUI.Flags.IsHidden to allow conditional display of widgets in Rendering Debugger. Added \"Expand/Collapse All\" buttons to Rendering Debugger window menu. Added mouse & touch input support for Rendering Debugger runtime UI, and fix problems when InputSystem package is used. Add automatic spaces to enum display names used in Rendering Debugger and add support for InspectorNameAttribute. Adding new API functions inside DynamicResolutionHandler to get mip bias. This allows dynamic resolution scaling applying a bias on the frame to improve on texture sampling detail. Added a reminder if the data of probe volume might be obsolete. Added new API function inside DynamicResolutionHandler and new settings in GlobalDynamicResolutionSettings to control low res transparency thresholds. This should help visuals when the screen percentage is too low. Added common include file for meta pass functionality (case 1211436) Added OverridablePropertyScope (for VolumeComponentEditor child class only) to handle the Additional Property, the override checkbox and disable display and decorator attributes in one scope. Added IndentLevelScope (for VolumeComponentEditor child class only) to handle indentation of the field and the checkbox. Added an option to change the visibilty of the Volumes Gizmos (Solid, Wireframe, Everything), available at Preferences > Core Render Pipeline Added class for drawing shadow cascades UnityEditor.Rendering.ShadowCascadeGUI.DrawShadowCascades. Added UNITY_PREV_MATRIX_M and UNITY_PREV_MATRIX_I_M shader macros to support instanced motion vector rendering Added new API to customize the rtHandleProperties of a particular RTHandle. This is a temporary work around to assist with viewport setup of Custom post process when dealing with DLSS or TAAU Added IAdditionalData interface to identify the additional datas on the core package. Added new API to draw color temperature for Lights. Fixed Help boxes with fix buttons do not crop the label. Fixed missing warning UI about Projector component being unsupported (case 1300327). Fixed the display name of a Volume Parameter when is defined the attribute InspectorName Calculating correct rtHandleScale by considering the possible pixel rounding when DRS is on Problem on domain reload of Volume Parameter Ranges and UI values Fixed Right Align of additional properties on Volume Components Editors Fixed normal bias field of reference volume being wrong until the profile UI was displayed. Fixed L2 for Probe Volumes. When adding Overrides to the Volume Profile, only show Volume Components from the current Pipeline. Fixed assertion on compression of L1 coefficients for Probe Volume. Explicit half precision not working even when Unified Shader Precision Model is enabled. Fixed ACES filter artefact due to half float error on some mobile platforms. Fixed issue displaying a warning of different probe reference volume profiles even when they are equivalent. Fixed missing increment/decrement controls from DebugUIIntField & DebugUIUIntField widget prefabs. Fixed IES Importer related to new API on core. Fixed a large, visible stretch ratio in a LensFlare Image thumbnail. Fixed Undo from script refreshing thumbnail. Fixed cropped thumbnail for Image with non-uniform scale and rotation Skip wind calculations for Speed Tree 8 when wind vector is zero (case 1343002) Fixed memory leak when changing SRP pipeline settings, and having the player in pause mode. Fixed alignment in Volume Components Virtual Texturing fallback texture sampling code correctly honors the enableGlobalMipBias when virtual texturing is disabled. Fixed LightAnchor too much error message, became a HelpBox on the Inspector. Fixed library function SurfaceGradientFromTriplanarProjection to match the mapping convention used in SampleUVMappingNormalInternal.hlsl and fix its description. Fixed Volume Gizmo size when rescaling parent GameObject Fixed rotation issue now all flare rotate on positive direction (1348570) Fixed error when change Lens Flare Element Count followed by undo (1346894) Fixed Lens Flare Thumbnails Fixed Lens Flare 'radialScreenAttenuationCurve invisible' Fixed Lens Flare rotation for Curve Distribution Fixed potentially conflicting runtime Rendering Debugger UI command by adding an option to disable runtime UI altogether (1345783). Fixed Lens Flare position for celestial at very far camera distances. It now locks correctly into the celestial position regardless of camera distance (1363291) Fixed issues caused by automatically added EventSystem component, required to support Rendering Debugger Runtime UI input. (1361901) Changed Improved the warning messages for Volumes and their Colliders. Changed Window/Render Pipeline/Render Pipeline Debug to Window/Analysis/Rendering Debugger Changed Window/Render Pipeline/Look Dev to Window/Analysis/Look Dev Changed Window/Render Pipeline/Render Graph Viewer to Window/Analysis/Render Graph Viewer Changed Window/Render Pipeline/Graphics Compositor to Window/Rendering/Graphics Compositor Volume Gizmo Color setting is now under Colors->Scene->Volume Gizmo Volume Gizmo alpha changed from 0.5 to 0.125 Moved Edit/Render Pipeline/Generate Shader Includes to Edit/Rendering/Generate Shader Includes Moved Assets/Create/LookDev/Environment Library to Assets/Create/Rendering/Environment Library (Look Dev) Changed Nintendo Switch specific half float fixes in color conversion routines to all platforms. Improved load asset time for probe volumes. ClearFlag.Depth does not implicitely clear stencil anymore. ClearFlag.Stencil added. The RTHandleSystem no longer requires a specific number of sample for MSAA textures. Number of samples can be chosen independently for all textures. Platform ShaderLibrary API headers now have a new macro layer for 2d texture sampling macros. This layer starts with PLATFORM_SAMPLE2D definition, and it gives the possibility of injecting sampling behavior on a render pipeline level. For example: being able to a global mip bias for temporal upscalers. Update icon for IES, LightAnchor and LensFlare LensFlare (SRP) can be now disabled per element LensFlare (SRP) tooltips now refer to meters. Serialize the Probe Volume asset as binary to improve footprint on disk and loading speed. LensFlare Element editor now have Thumbnail preview Improved IntegrateLDCharlie() to use uniform stratified sampling for faster convergence towards the ground truth DynamicResolutionHandler.GetScaledSize function now clamps, and never allows to return a size greater than its input. Removed DYNAMIC_RESOLUTION snippet on lens flare common shader. Its not necessary any more on HDRP, which simplifies the shader. Made occlusion Radius for lens flares in directional lights, be independant of the camera's far plane. [11.0.0] - 2020-10-21 Fixed Fixed the default background color for previews to use the original color. Fixed spacing between property fields on the Volume Component Editors. Fixed ALL/NONE to maintain the state on the Volume Component Editors. Fixed the selection of the Additional properties from ALL/NONE when the option \"Show additional properties\" is disabled Fixed ACES tonemaping for Nintendo Switch by forcing some shader color conversion functions to full float precision. Fixed a bug in FreeCamera which would only provide a speed boost for the first frame when pressing the Shfit key. Added New View Lighting Tool, a component which allow to setup light in the camera space New function in GeometryTools.hlsl to calculate triangle edge and full triangle culling. Several utils functions to access SphericalHarmonicsL2 in a more verbose and intuitive fashion. [10.2.0] - 2020-10-19 Version Updated The version number for this package has increased due to a version update of a related graphics package. [10.1.0] - 2020-10-12 Added Added context options \"Move to Top\", \"Move to Bottom\", \"Expand All\" and \"Collapse All\" for volume components. Added the support of input system V2 Fixed Fixed the scene view to scale correctly when hardware dynamic resolution is enabled (case 1158661) Fixed game view artifacts on resizing when hardware dynamic resolution was enabled Fixed issue that caused UNITY_REVERSED_Z and UNITY_UV_STARTS_AT_TOP being defined in platforms that don't support it. Changed LookDev menu item entry is now disabled if the current pipeline does not support it. [10.0.0] - 2019-06-10 Added Add rough version of ContextualMenuDispatcher to solve conflict amongst SRP. Add api documentation for TextureCombiner. Add tooltips in LookDev's toolbar. Add XRGraphicsAutomatedTests helper class. Fixed Fixed compile errors for platforms with no VR support Replaced reference to Lightweight Render Pipeline by Universal Render Pipeline in the package description Fixed LighProbes when using LookDev. Fix LookDev minimal window size. Fix object rotation at instentiation to keep the one in prefab or used in hierarchy. Fixed shader compile errors when trying to use tessellation shaders with PlayStation VR on PS4. Fixed shader compile errors about LODDitheringTransition not being supported in GLES2. Fix WaveIsFirstLane() to ignore helper lanes in fragment shaders on PS4. Fixed a bug where Unity would crash if you tried to remove a Camera component from a GameObject using the Inspector window, while other components dependended on the Camera component. Fixed errors due to the debug menu when enabling the new input system. Fix LookDev FPS manipulation in view Fix LookDev zoom being stuck when going near camera pivot position Fix LookDev manipulation in view non responsive if directly using an HDRI Fix LookDev behaviour when user delete the EnvironmentLibrary asset Fix LookDev SunPosition button position Fix LookDev EnvironmentLibrary tab when asset is deleted Fix LookDev used Cubemap when asset is deleted Fixed the definition of rcp() for GLES2. Fixed copy/pasting of Volume Components when loading a new scene Fix LookDev issue when adding a GameObject containing a Volume into the LookDev's view. Fixed duplicated entry for com.unity.modules.xr in the runtime asmdef file Fixed the texture curve being destroyed from another thread than main (case 1211754) Fixed unreachable code in TextureXR.useTexArray Fixed GC pressure caused by VolumeParameter<T>.GetHashCode() Fixed issue when LookDev window is opened and the CoreRP Package is updated to a newer version. Fix LookDev's camera button layout. Fix LookDev's layout vanishing on domain reload. Fixed issue with the shader TransformWorldToHClipDir function computing the wrong result. Fixed division by zero in V_SmithJointGGX function. Fixed null reference exception in LookDev when setting the SRP to one not implementing LookDev (case 1245086) Fix LookDev's undo/redo on EnvironmentLibrary (case 1234725) Fix a compil error on OpenGL ES2 in directional lightmap sampling shader code Fix hierarchicalbox gizmo outside facing check in symetry or homothety mode no longer move the center Fix artifacts on Adreno 630 GPUs when using ACES Tonemapping Fixed a null ref in the volume component list when there is no volume components in the project. Fixed issue with volume manager trying to access a null volume. HLSL codegen will work with C# file using both the GenerateHLSL and C# 7 features. Changed Restored usage of ENABLE_VR to fix compilation errors on some platforms. Only call SetDirty on an object when actually modifying it in SRP updater utility Set depthSlice to -1 by default on SetRenderTarget() to clear all slices of Texture2DArray by default. ResourceReloader will now add additional InvalidImport check while it cannot load due to AssetDatabase not available. Replaced calls to deprecated PlayerSettings.virtualRealitySupported property. Enable RWTexture2D, RWTexture2DArray, RWTexture3D in gles 3.1 Updated macros to be compatible with the new shader preprocessor. Updated shaders to be compatible with Microsoft's DXC. Changed CommandBufferPool.Get() to create an unnamed CommandBuffer. (No profiling markers) Deprecating VolumeComponentDeprecad, using HideInInspector or Obsolete instead [7.1.1] - 2019-09-05 Added Add separated debug mode in LookDev. Changed Replaced usage of ENABLE_VR in XRGraphics.cs by a version define (ENABLE_VR_MODULE) based on the presence of the built-in VR module ResourceReloader now works on non-public fields. Removed normalize from UnpackNormalRGB to match UnpackNormalAG. Fixed shadow routines compilation errors when \"real\" type is a typedef on \"half\". Removed debug menu in non development build. [7.0.1] - 2019-07-25 Fixed Fixed a precision issue with the ACES tonemapper on mobile platforms. [7.0.0] - 2019-07-17 Added First experimental version of the LookDev. Works with all SRP. Only branched on HDRP at the moment. LookDev out of experimental [6.7.0-preview] - 2019-05-16 [6.6.0] - 2019-04-01 Fixed Fixed compile errors in XRGraphics.cs when ENABLE_VR is not defined [6.5.0] - 2019-03-07 [6.4.0] - 2019-02-21 Added Enabled support for CBUFFER on OpenGL Core and OpenGL ES 3 backends. [6.3.0] - 2019-02-18 [6.2.0] - 2019-02-15 [6.1.0] - 2019-02-13 [6.0.0] - 2019-02-23 Fixed Fixed a typo in ERROR_ON_UNSUPPORTED_FUNCTION() that was causing the shader compiler to run out of memory in GLES2. [Case 1104271] (https://issuetracker.unity3d.com/issues/mobile-os-restarts-because-of-high-memory-usage-when-compiling-shaders-for-opengles2) [5.2.0] - 2018-11-27 [5.1.0] - 2018-11-19 Added Added a define for determining if any instancing path is taken. Changed The Core SRP package is no longer in preview. [5.0.0-preview] - 2018-10-18 Changed XRGraphicConfig has been changed from a read-write control of XRSettings to XRGraphics, a read-only accessor to XRSettings. This improves consistency of XR behavior between the legacy render pipeline and SRP. XRGraphics members have been renamed to match XRSettings, and XRGraphics has been modified to only contain accessors potentially useful to SRP You can now have up to 16 additional shadow-casting lights. Fixed LWRP no longer executes shadow passes when there are no visible shadow casters in a Scene. Previously, this made the Scene render as too dark, overall. [4.0.0-preview] - 2018-09-28 Added Space transform functions are now defined in ShaderLibrary/SpaceTransforms.hlsl. Changed Removed setting shader inclue path via old API, use package shader include paths [3.3.0] - 2018-01-01 [3.2.0] - 2018-01-01 [3.1.0] - 2018-01-01 Added Add PCSS shadow filter Added Core EditMode tests Added Core unsafe utilities Improvements Improved volume UI & styling Fixed CoreUtils.QuickSort infinite loop when two elements in the list are equals. Changed Moved root files into folders for easier maintenance"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Camera-Switcher.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Camera-Switcher.html",
    "title": "Camera Switcher | mmo-rpg-unity",
    "keywords": "Camera Switcher The CameraSwitcher component allows you to define a List of Cameras in the Scene and then use the Debug Window to switch between them in Play Mode. This is useful when you want a set of different fixed views for profiling purposes where you need to guarantee that the Camera view is in the same position between sessions. Properties Property Description Cameras Drag and drop GameObjects that have a Camera component attached to add them to this List of Cameras. The Debug Window can switch between the Cameras in this List."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Common/lens-flare-data-driven-asset.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Common/lens-flare-data-driven-asset.html",
    "title": "Lens Flare (SRP) Asset | mmo-rpg-unity",
    "keywords": "Lens Flare (SRP) Asset Unity’s Scriptable Render Pipeline (SRP) includes the Lens Flare Element asset. You can use this asset to create lens flares in your scene and control their appearance. To create a Lens Flare Element asset, navigate to Assets > Create > SRP Lens Flare. To use this asset, assign it to the Lens Flare Data property of an SRP Lens Flare Override Component. Properties The Lens Flare Element asset has the following properties: Type Image Circle Polygon Common AxisTransform Distortion Multiple Elements Uniform Curve Random Type Property Description Type Select the type of Lens Flare Element this asset creates: • Image • Circle • Polygon Image Property Description Flare Texture The Texture this lens flare element uses. Preserve Aspect Ratio Fixes the width and height (aspect ratio) of the Flare Texture. You can use Distortion to change this property. Circle Property Description Gradient Controls the offset of the circular flare's gradient. This value ranges from 0 to 1. Falloff Controls the falloff of the circular flare's gradient. This value ranges from 0 to 1, where 0 has no falloff between the tones and 1 creates a falloff that is spread evenly across the circle. Inverse Enable this property to reverse the direction of the gradient. Polygon Property Description Gradient Controls the offset of the polygon flare's gradient. This value ranges from 0 to 1. Falloff Controls the falloff of the polygon flare's gradient. This value ranges from 0 to 1, where 0 has no falloff between the tones and 1 creates a falloff that is spread evenly across the polygon. Side Count Determines how many sides the polygon flare has. Roundness Defines how smooth the edges of the polygon flare are. This value ranges from 0 to 1, where 0 is a sharp polygon and 1 is a circle. Inverse Enable this property to reverse the direction of the gradient Color Property Description Tint Changes the tint of the lens flare. If this asset is attached to the light, this property is based on the light tint. Modulate By Light Color Allows light color to affect this Lens Flare Element. This only applies when the asset is used in a SRP Lens Flare Override Component that is attached to a point, spot, or area light. Intensity Controls the intensity of this element. Blend Mode Select the blend mode of the Lens Flare Element this asset creates: • Additive • Screen • Premultiplied • Lerp Transform Property Description Position Offset Defines the offset of the lens flare's position in screen space, relative to its source. Auto Rotate Enable this property to automatically rotate the Lens Flare Texture relative to its angle on the screen. Unity uses the Auto Rotate angle to override the Rotation parameter. To ensure the Lens Flare can rotate, assign a value greater than 0 to the Starting Position property. Rotation Rotates the lens flare. This value operates in degrees of rotation. Size Use this to adjust the scale of this lens flare element. This property is not available when the Type is set to Image and Preserve Aspect Ratio is enabled. Scale The size of this lens flare element in world space. AxisTransform Property Description Starting Position Defines the starting position of the lens flare relative to its source. This value operates in screen space. Angular Offset Controls the angular offset of the lens flare, relative to its current position. This value operates in degrees of rotation. Translation Scale Limits the size of the lens flare offset. For example, values of (1, 0) create a horizontal lens flare, and (0, 1) create a vertical lens flare. You can also use this property to control how quickly the lens flare appears to move. For example, values of (0.5, 0.5) make the lens flare element appear to move at half the speed. Distortion Property Description Enable Set this property to True to enable distortion. Radial Edge Size Controls the size of the distortion effect from the edge of the screen. Radial Edge Curve Blends the distortion effect along a curve from the center of the screen to the edges of the screen. Relative To Center Set this value to True to make distortion relative to the center of the screen. Otherwise, distortion is relative to the screen position of the lens flare. Multiple Elements Property Description Enable Enable this to allow multiple lens flare elements in your scene. Count Determines the number of identical lens flare elements Unity generates. A value of 1 appears the same as a single lens flare element. Distribution Select the method that Unity uses to generate multiple lens flare elements: •Uniform •Curve •Random Length Spread Controls how spread out multiple lens flare elements appear. Relative To Center If true the distortion is relative to center of the screen otherwise relative to lensFlare source screen position. Uniform Property Description Colors The range of colors that this asset applies to the lens flares. Rotation The angle of rotation (in degrees) applied to each element incrementally. Curve Property Description Colors The range of colors that this asset applies to the lens flares. You can use the Position Spacing curve to determine how this range affects each lens flare. Position Variation Adjust this curve to change the placement of the lens flare elements in the Lens Spread. Rotation The uniform angle of rotation (in degrees) applied to each element distributed along the curve. This value ranges from -180° to 180°. Scale Adjust this curve to control the size range of the lens flare elements. Random Property Description Seed The base value that this asset uses to generate randomness. Intensity Variation Controls the variation of brightness across the lens flare elements. A high value can make some elements might invisible. Colors The range of colors that this asset applies to the lens flares. This property is based on the Seed value. Position Variation Controls the position of the lens flares. The X value is spread along the same axis as Length Spread. A value of 0 means there is no change in the lens flare position. The Y value is spread along the vertical screen space axis based on the Seed value. Rotation Variation Controls the rotation variation of the lens flares, based on the Seed value. The Rotation and Auto Rotate parameters inherit from this property. Scale Variation Controls the scale of the lens flares based on the Seed value."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Common/lens-flare-data-driven-component.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Common/lens-flare-data-driven-component.html",
    "title": "Lens Flare (SRP) Component | mmo-rpg-unity",
    "keywords": "Lens Flare (SRP) Component Unity’s Scriptable Render Pipeline (SRP) includes the SRP Lens Flare Override component to control a Lens Flare (SRP) Data asset. You can attach an Lens Flare (SRP) Component to any GameObject. Some properties only appear when you attach this component to a light. Properties General Property Description Lens Flare Data Select the Lens Flare (SRP) Asset asset this component controls. Intensity Multiplies the intensity of the lens flare. Scale Multiplies the scale of the lens flare. Attenuation by Light Shape Enable this property to automatically change the appearance of the lens flare based on the type of light you attached this component to. For example, if this component is attached to a spot light and the camera is looking at this light from behind, the lens flare will not be visible. This property is only available when this component is attached to a light. Attenuation Distance The distance between the start and the end of the Attenuation Distance Curve. This value operates between 0 and 1 in world space. Attenuation Distance Curve Fades out the appearance of the lens flare over the distance between the GameObject this asset is attached to, and the Camera. Scale Distance The distance between the start and the end of the Scale Distance Curve. This value operates between 0 and 1 in world space. Scale Distance Curve Changes the size of the lens flare over the distance between the GameObject this asset is attached to, and the Camera. Screen Attenuation Curve Reduces the effect of the lens flare based on its distance from the edge of the screen. You can use this to display a lens flare at the edge of your screen Occlusion Property Description Enable Enable this property to partially obscure the lens flare based on the depth buffer Occlusion Radius Defines how far from the light source Unity occludes the lens flare. This value is in world space. Sample Count The number of random samples the CPU uses to generate the Occlusion Radius. Occlusion Offset Offsets the plane that the occlusion operates on. A higher value moves this plane closer to Camera. This value is in world space. For example, if a lens flare is inside the light bulb, you can use this to sample occlusion outside the light bulb. Occlusion Remap Curve Specifies the curve used to remap the occlusion of the flare. By default, the occlusion is linear, between 0 and 1. This can be specifically useful to occlude flare more drastically when behind clouds. Allow Off Screen Enable this property to allow lens flares outside the Camera's view to affect the current field of view."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Common/light-anchor.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Common/light-anchor.html",
    "title": "Light Anchor | mmo-rpg-unity",
    "keywords": "Light Anchor You can use a Light Anchor to light a scene in Rendered Camera Space. To use a Light Anchor, you must connect it to a Light. Properties Property Description Orbit Use the left icon to control the Orbit of the light. This tool becomes green when you move the icon. Elevation Use the middle icon to control the Elevation of the light. This tool becomes blue when you move the icon. Roll Use the right icon to control the Rollof the light. This tool becomes gray when you move the icon. This is especially useful if the light has an IES or a Cookie. Distance Controls the distance between the light and its anchor in world space. Up Direction Defines the space of the up direction of the anchor. When this value is set to Local, the Up Direction is relative to the camera. Common Assigns a preset to the light component based on the behaviour of studio lights."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Free-Camera.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Free-Camera.html",
    "title": "Free Camera | mmo-rpg-unity",
    "keywords": "Free Camera The FreeCamera component provides you with an implementation for a simple free camera. When you add this component to a Camera, you can use the keyboard and mouse, or a controller, to control the Camera's position and rotation in Play Mode. Properties Property Description Look Speed Controller Set the look speed of the Camera when using a controller. Look Speed Mouse Set the look speed of the Camera when using a mouse. Move Speed Set the speed at which the Camera moves. Move Speed Increment Set the value of the increment that you can increase or decrease the Move Speed by. This is useful if you have a large Scene and the current Move Speed is not enough to easily traverse it. Turbo Set the value that this component multiplies the Move Speed by when you press the key or button assigned to \"Fire1\"."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Look-Dev-Environment-Library.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Look-Dev-Environment-Library.html",
    "title": "Environment Library | mmo-rpg-unity",
    "keywords": "Environment Library An Environment Library is an Asset that contains a list of environments that you can use in Look Dev to simulate different lighting conditions. Each environment uses an HDRI (High Dynamic Range Image) for its skybox and also includes properties that you can use to fine-tune the environment. Creating an Environment Library To create an Environment Library Asset, either: Select Assets > Create > Rendering Environment Library (Look Dev). Open Look Dev and click the New Library button. Creating and editing an environment After you create an Environment Library, you can add environments to it which you can then use in Look Dev. To create environments or edit their properties, use the Look Dev window itself. To create and edit environments, you need to open an Environment Library in Look Dev. To do this, either: Go to the Look Dev window (menu: Window > Rendering > Look Dev) and drag your Environment Library from your Project window into the sidebar. In your Project window, click on your Environment Library Asset. Then, in the Inspector, click the Open in LookDev window button. If you already have environments in the Environment Library, you can see a list of them in the sidebar. When you click on any of the HDRI previews for an environment, a box appears at the bottom of the Environment Library list. This contains the selected environment's properties for you to edit. To add, remove, or duplicate environments, use the toolbar at the bottom of the Environment Library list, which contains the following buttons. Button Function Description Add Click this button to add a new environment to the bottom of the list. Remove Click this button to remove the environment currently selected. Note that the environment that you have selected is the one with the blue frame. Duplicate Click this button to duplicate the currently selected environment and add it as a new environment to the bottom of the list. Properties Property Description Sky with Sun Set the HDRI Texture that Look Dev uses for the sky lighting when using this environment. For information on how to import an HDRI Texture, see Importing an HDRI Texture. Sky without Sun Set the HDRI Texture that Look Dev uses for compositing the shadows when simulating a sun in the view. If you do not assign this value, Look Dev uses a lower intensity version of the same HDRI Texture in Sky with Sun. For information on how to import an HDRI Texture, see Importing an HDRI Texture. Rotation Set the offset longitude that Look Dev applies for the whole sky and sun position. Exposure Set the exposure that Look Dev uses when it renders the environment. Sun Position Set the position of the sun when compositing the shadows. The Sun button at the end of the line automatically places the sun on the brightest spot of the Sky with Sun HDRI Texture. Shadow Tint Use the color picker to set the color of the tint that Look Dev uses to color shadows. Importing an HDRI Texture To import an HDRI Texture into the Unity Editor, load an .hdr or .exr file into your Unity Project like you would any other image. In the Texture Importer Inspector window, set Texture Type to Default, set Texture Shape to Cube, and set Convolution Type to None. When you want to test an HDRI Texture Asset or a skybox cube map Material, drag and drop it into the Look Dev view."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Look-Dev.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/Look-Dev.html",
    "title": "Look Dev | mmo-rpg-unity",
    "keywords": "Look Dev Look Dev is an image-based lighting tool that contains a viewer for you to check and compare Assets to ensure they work well in various lighting conditions. Look Dev uses the Scriptable Render Pipeline, so it can display the Asset in the same way as it looks in your Scene. You can load Assets into Look Dev either as Prefabs or from the Hierarchy window. Look Dev is only available in Edit mode. The Look Dev window closes when you enter Play mode. Asset validation Asset validation confirms whether Assets are authored correctly and behave as expected in different lighting environments. You must use an HDRI (high dynamic range image) to validate your Assets in Look Dev. An HDRI contains real-world lighting with incredibly high detail. As such, it offers perfect lighting that is difficult to create by hand. By using such an accurate lighting environment to test an Asset, you can determine whether the Asset itself or your Project's lighting is reducing the visual quality of your Scene. You can load two different Assets into Look Dev at the same time and compare them in two viewports. For example, an Art Director can check that a new Asset matches the art direction guidelines of a reference Asset. Using Look Dev To open Look Dev in the Unity Editor, select Window > Rendering > Look Dev. The first time you use Look Dev, you must either create a new Environment Library or load one. For information on how to create an Environment Library, see the Environment Library documentation. Viewports By default, there is only one viewport in Look Dev, but you can choose from a selection of split-screen views (see the Multi-view section). Controls Navigation with the Look Dev Camera works in a similar way to the Scene view Camera: Rotate around pivot: Left click and drag (this is similar to the Scene view except that you need to press the Alt key for the Scene view Camera). Pan camera: Middle click and drag. Zoom: Alt + right click and drag. Forward/backward: Mouse wheel. First Person mode: Right click + W, A,S, and D. Loading Assets into Look Dev Look Dev lets you view: Prefabs - To load a Prefab into Look Dev, drag it from the Project window into the Look Dev viewport. GameObjects - To load a copy of a Hierarchy GameObject, drag the GameObject from the Hierarchy into the Look Dev viewport. Viewport modes Use the toolbar in the top-left of the window to change which viewing mode Look Dev uses. Single viewport By default, Look Dev displays a single viewport which contains the Prefab or GameObject you are working with. If you are in another viewing mode, you can click either the number 1 or number 2 button to go back to single view. Each button corresponds to a viewport in Look Dev. Select button 1 to use viewport 1, and button 2 to use viewport 2. Multi-viewport Use multiple viewports to compare different environments and settings for the same Asset. You can arrange viewports: Vertically side-by-side. Use this mode to compare two different lighting conditions on the same Asset to check that the Asset behaves correctly. Horizontally side-by-side. Use this mode to compare two different lighting conditions for horizontal objects, like an environment Asset, to check that the Asset behaves correctly. Split-screen. Use this mode investigate texture problems using a debug Shader mode (for example, use one screen to view Normal or Albedo shading, and the other for environment-lit mode). Side-by-side and split-screen: Use this mode to compare two different versions of the same Asset using the same lighting conditions to see which changes improve the Asset’s quality. All three of these modes are useful to compare two different versions of the same Asset using the same lighting conditions to see which changes improve the Asset’s quality. To load a different Prefab or Hierarchy GameObject into each split-screen view, drag and drop the Asset into the viewport that you want to view it in. When using multiple viewports, it only makes sense to compare different Prefabs or GameObjects when you want to look at two versions of the same Asset. Comparing completely different Assets doesn’t give you a good idea of the difference in lighting or visual effect. Vertical or horizontal side-by-side Vertical and horizontal side-by-side viewports show an identical view of your Asset. Split-screen In a split-screen view, there is a red/blue manipulation Gizmo that separates the two viewports. For information on how to use this Gizmo, see Using the manipulation Gizmo. Multi-viewport Camera By default, Look Dev synchronizes the camera movement for both views. To decouple the Cameras from one another, and manipulate them independently, click the Synchronized Cameras button in-between the two numbered Camera buttons. To align the cameras with each other, or reset them, click on the drop-down arrow next to the viewport 2 icon: Using the manipulation Gizmo The manipulation Gizmo represents the separation plane between the two viewports. It has different behavior in split-screen mode, but you use it in the same way for both side-by-side or split-screen modes. Moving the separator To move the separator, click and drag the straight line of the Gizmo to the location you want. Changing the orientation and length To change the orientation and length of the manipulator Gizmo, click and drag the circle at either end of the manipulator. Changing the length of the Gizmo lets you set the orientation and blending values more precisely. ) Changing the split in increments To change the split in increments, click and hold the circle on the end of the manipulation Gizmo, then hold Shift as you move the mouse. This snaps the manipulation Gizmo to set angles in increments of 22.5°, which is useful for a perfectly horizontal, vertical or diagonal angle. Blending The central white circle on the separator allows you to blend between the two views. Left click on it and drag along the red line to blend the left-hand view with the right-hand view. Drag along the blue line to blend the right-hand view with the left-hand view (as shown in the image below). The white circle automatically snaps back into the center when you drag it back. This helps you get back to the default blending value quickly. HDRI environments in Look Dev Lighting in Look Dev uses an HDRI. The Look Dev view allows you to manipulate and easily switch between HDRIs to simulate different environments for the Asset you are working on. Look Dev uses the Environment Library Asset to store a list of environments, which are HDRIs with extra properties that you can use to further refine the environment. For information on how to create, edit, and assign Environment Libraries, see the Environment Library documentation. Implementing Look Dev for your custom Scriptable Render Pipeline In order to use Look Dev in your custom Scriptable Render Pipeline, you must implement the UnityEngine.Rendering.LookDev.IDataProvider interface. Function Description void FirstInitScene(StageRuntimeInterface stage) Look Dev calls this function after it initializes the Scene with a Light and Camera. It uses this function to add and configure extra components according to the needs of your Scriptable Render Pipeline. void UpdateSky(Camera camera, Sky sky, StageRuntimeInterface stage) Look Dev uses this function to update the environment when you change something in Look Dev. You can handle the sky in various ways, so add code that corresponds to your Scriptable Render Pipeline. IEnumerable** ** supportedDebugModes { get; } Use this function to specify the list of supported debug modes. You do not need to add None because Look Dev handles that automatically. void UpdateDebugMode(int debugIndex) Use this function to update the debug mode based on what the user selects. The debugIndex matches the list in supportedDebugModes. If the user selects None, then the debugIndex is -1; void GetShadowMask(ref RenderTexture output, StageRuntimeInterface stage) This function computes a shadow map. The given StageRuntimeInterface contains access to the Camera and a Light simulating the sun."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "SRP Core What's new 12 13 Camera components Free Camera Camera Switcher Render Graph Benefits of the render graph system Render graph fundamentals Writing a Render Pipeline RTHandle system RTHandle fundamentals Using the RTHandle system Custom Material Inspector Adding properties in the menu Synchronizing shader code and C# Shaders Use shader methods from the SRP Core shader library Synchronizing shader code and C# Look Dev Environment Library Light Anchor"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/View-Lighting-Tool.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/View-Lighting-Tool.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Light Anchor The Light Anchor can help to place light sources around subjects, in relation to a Camera and an anchor point. It's particularly effective for cinematic lighting, which often requires multiple light sources orbiting a subject. Using the Light Anchor Component To add a Light Anchor component to a GameObject in your Scene: Select a Light GameObject in the hierarchy to open its Inspector window. Go to Add Component > Rendering > Light Anchor By default, the Anchor's position is the same as the position of the GameObject the Light Anchor Component is attached to. Note: To use the Light Anchor, you must set the Tag of at least one Camera to \"MainCamera\". Use the Orbit and Elevation to control the orientation of the light, in degrees, relative to the main Camera's and Anchor's positions. If the Light has a Cookie or an IES Profile, use the Roll to change their orientation. Use the Distance to control how far from the anchor, in meters, you want to place the Light. You can use the Anchor Position Override to provide a GameObject’s Transform as an anchor point for the Light. This is useful if you want the Light to follow a specific GameObject in the Scene. Note: The above example uses the Main Camera as the reference Camera that adjusts the light rotation. The Common presets might create a different result in the Scene View if your view isn't aligned with the Main Camera. You can set a Position Offset for this custom Anchor. This is useful if the Transform position of the custom Anchor isn't centered appropriately for the light to orbit correctly around the custom Anchor. The Light Anchor component also includes a list of Presets that you can use to set the Light's orientation relative to the main Camera. Properties Property Description Orbit Use the left icon to control the Orbit of the light. This tool becomes green when you move the icon. Elevation Use the middle icon to control the Elevation of the light. This tool becomes blue when you move the icon. Roll Use the right icon to control the Roll of the light. This tool becomes gray when you move the icon. This is useful if the light has an IES or a Cookie. Distance Controls the distance between the light and its anchor in world space. Up Direction Defines the space of the up direction of the anchor. When you set this value to Local, the Up Direction is relative to the Camera. Anchor Position Override Allows you to use a GameObject's Transform as anchor position instead of the LightAnchor's Transform. When the Transform of the GameObject you assigned to this property changes, the Light Anchor's Transform also changes. Common Assigns a preset to the light component based on the behavior of studio lights."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/adding-properties.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/adding-properties.html",
    "title": "Adding properties to the Core Render Pipeline settings section | mmo-rpg-unity",
    "keywords": "Adding properties to the Core Render Pipeline settings section To add properties in the Core Render Pipeline settings section (Edit > Preferences > Core Render Pipeline), create a class that implements the interface ICoreRenderPipelinePreferencesProvider. For example: class MyPreference : ICoreRenderPipelinePreferencesProvider { class Styles { public static readonly GUIContent myBoolLabel = EditorGUIUtility.TrTextContent(\"My check box\", \"The description of the property.\"); } public List<string> keywords => new List<string>() {Styles.myBoolLabel.text}; public GUIContent header => EditorGUIUtility.TrTextContent(\"My property section\", \"The description of my property section.\"); public static bool s_MyBoolPreference; public void PreferenceGUI() { EditorGUI.BeginChangeCheck(); var newValue = EditorGUILayout.Toggle(Styles.myBoolLabel, s_MyBoolPreference); if (EditorGUI.EndChangeCheck()) { s_MyBoolPreference = newValue; } } } Unity shows the new properties in the Core Render Pipeline settings section:"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/built-in-shader-methods.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/built-in-shader-methods.html",
    "title": "Use shader methods from the SRP Core shader library | mmo-rpg-unity",
    "keywords": "Use shader methods from the SRP Core shader library SRP Core has a library of High-Level Shader Language (HLSL) shader files that contain helper methods. You can import these files into your custom shader files and use the helper methods. To use the following methods, add #include \"Packages/com.unity.render-pipelines.core/ShaderLibrary/SpaceTransforms.hlsl\" inside the HLSLPROGRAM in your shader file. Get matrices Method Syntax Description CreateTangentToWorld real3x3 CreateTangentToWorld(real3 normal, real3 tangent, real flipSign) Returns the matrix that converts tangents to world space. GetObjectToWorldMatrix() float4x4 GetObjectToWorldMatrix() Returns the matrix that converts positions in object space to world space. GetViewToHClipMatrix() float4x4 GetViewToHClipMatrix() Returns the matrix that converts positions in view space to clip space. GetViewToWorldMatrix() float4x4 GetViewToWorldMatrix() Returns the matrix that converts positions in view space to world space. GetWorldToHClipMatrix() float4x4 GetWorldToHClipMatrix() Returns the matrix that converts positions in world space to clip space. GetWorldToObjectMatrix() float4x4 GetWorldToObjectMatrix() Returns the matrix that converts positions in world space to object space. GetWorldToViewMatrix() float4x4 GetWorldToViewMatrix() Returns the matrix that converts positions in world space to view space. Transform positions Method Syntax Description TransformObjectToHClip float4 TransformObjectToHClip(float3 positionInObjectSpace) Converts a position in object space to clip space. TransformObjectToWorld float3 TransformObjectToWorld(float3 positionInObjectSpace) Converts a position in object space to world space. TransformViewToWorld float3 TransformViewToWorld(float3 positionInViewSpace) Converts a position in view space to world space. TransformWorldToHClip float4 TransformWorldToHClip(float3 positionInWorldSpace) Converts a position in world space to clip space. TransformWorldToObject float3 TransformWorldToObject(float3 positionInWorldSpace) Converts a position in world space to object space. TransformWorldToView float3 TransformWorldToView(float3 positionInWorldSpace) Converts a position in world space to view space. TransformWViewToHClip float4 TransformWViewToHClip(float3 positionInViewSpace) Converts a position in view space to clip space. Transform directions Method Syntax Description TransformObjectToTangent real3 TransformObjectToTangent(real3 directionInObjectSpace, real3x3 tangentToWorldMatrix) Converts a direction in object space to tangent space, using a tangent-to-world matrix. TransformObjectToWorldDir float3 TransformObjectToWorldDir(float3 directionInObjectSpace, bool normalize = true) Converts a direction in object space to world space. TransformTangentToObject real3 TransformTangentToObject(real3 dirTS, real3x3 tangentToWorldMatrix) Converts a direction in tangent space to object space, using a tangent-to-world matrix. TransformTangentToWorldDir real3 TransformTangentToWorldDir(real3 directionInWorldSpace, real3x3 tangentToWorldMatrix, bool normalize = false) Converts a direction in tangent space to world space, using a tangent-to-world matrix. TransformViewToWorldDir real3 TransformViewToWorldDir(real3 directionInViewSpace, bool normalize = false) Converts a direction in view space to world space. TransformWorldToHClipDir real3 TransformWorldToHClipDir(real3 directionInWorldSpace, bool normalize = false) Converts a direction in world space to clip space. TransformWorldToObjectDir float3 TransformWorldToObjectDir(float3 directionInWorldSpace, bool normalize = true) Converts a direction in world space to object space. TransformWorldToTangentDir real3 TransformWorldToTangentDir(real3 directionInWorldSpace, real3x3 tangentToWorldMatrix, bool normalize = false) Converts a direction in world space to tangent space, using a tangent-to-world matrix. TransformWorldToViewDir real3 TransformWorldToViewDir(real3 directionInWorldSpace, bool normalize = false) Converts a direction in world space to view space. Transform surface normals Method Syntax Description TransformObjectToWorldNormal float3 TransformObjectToWorldNormal(float3 normalInObjctSpace, bool normalize = true) Converts a normal in object space to world space. TransformTangentToWorld float3 TransformTangentToWorld(float3 normalInTangentSpace, real3x3 tangentToWorldMatrix, bool normalize = false) Converts a normal in tangent space to world space, using a tangent-to-world matrix. TransformViewToWorldNormal real3 TransformViewToWorldNormal(real3 normalInViewSpace, bool normalize = false) Converts a normal in view space to world space. TransformWorldToObjectNormal float3 TransformWorldToObjectNormal(float3 normalInWorldSpace, bool normalize = true) Converts a normal in world space to object space. TransformWorldToTangent float3 TransformWorldToTangent(float3 normalInWorldSpace, real3x3 tangentToWorldMatrix, bool normalize = true) Converts a normal in world space to tangent space using a tangent-to-world matrix. TransformWorldToViewNormal real3 TransformWorldToViewNormal(real3 normalInWorldSpace, bool normalize = false) Converts a normal in world space to view space. Additional resources HLSL in Unity"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/custom-material-inspector.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/custom-material-inspector.html",
    "title": "Custom Material Inspector | mmo-rpg-unity",
    "keywords": "Custom Material Inspector Custom Material Inspectors enable you to define how Unity displays properties in the Material Inspector for a particular shader. This is useful if a shader includes a lot of properties and you want to organize them in the Inspector. The Universal Render Pipeline (URP) and High Definition Render Pipeline (HDRP) both support custom Material Inspectors, but the method to create them is slightly different. Creating a custom Material Inspector The implementation for custom Material Inspectors differs between URP and HDRP. For example, for compatibility purposes, every custom Material Inspector in HDRP must inherit from HDShaderGUI which does not exist in URP. For information on how to create custom Material Inspectors for the respective render pipelines, see: HDRP: HDRP custom Material Inspectors. URP: Unity Custom Shader GUI. Assigning a custom Material Inspector When you create a shader, either hand-written or using Shader Graph, both URP and HDRP provide a default editor for it to use. To override this default and provide your own custom Material Inspector, the method differs depending on whether you hand-wrote the shader or used Shader Graph. Using hand-written shaders To set a custom Material Inspector for a hand-written shader: Open the shader source file. Assign a string that contains the class name of the custom Material Inspector to the CustomEditor shader instruction. This is the same method as for the Built-in Renderer's custom shader GUI. For an example of how to do this, see the following shader code sample. In this example, the name of the custom Material Inspector class is ExampleCustomMaterialInspector: Shader \"Custom/Example\" { Properties { // Shader properties } SubShader { // Shader code } CustomEditor \"ExampleCustomMaterialInspector\" } Using Shader Graph To set a custom Material Inspector for a Shader Graph shader: Open the Shader Graph. In the Graph Inspector, open the Graph Settings tab. If Active Targets does not include the render pipeline your project uses, click the plus button then, in the drop-down, click the render pipeline. In the render pipeline section (HDRP or URP depending on the render pipeline your project uses) find the Custom Editor GUI property and provide it the name of the custom Material Inspector."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/generating-shader-includes.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/generating-shader-includes.html",
    "title": "Synchronizing shader code and C# | mmo-rpg-unity",
    "keywords": "Synchronizing shader code and C# Unity can generate HLSL code based on C# structs to synchronize data and constants between shaders and C#. In Unity, the process of generating the HLSL code from C# code is called generating shader includes. When Unity generates shader includes, it parses all the C# files in the project and, for every file that contains a struct with a GenerateHLSL attribute, generates corresponding HLSL code. It places this HLSL code in a file with the same name as the origin, but uses the .cs.hlsl file extension. Generating shader includes To generate an HLSL equivalent for a C# struct: Add the GenerateHLSL attribute to the struct. To do this, above the line that declares the struct, add [GenerateHLSL(PackingRules.Exact, false)]. For an example on how to do this, see the sample code below. For more information about the GenerateHLSL attribute, see the API documentation. In the Unity Editor, go to Edit > Render Pipeline > Generate Shader Includes. The following code example is from the High Definition Render Pipeline (HDRP). It shows an extract of the C# representation of a directional light. The original file is LightDefinition.cs. When Unity generates the HLSL shader code, it places it in a new file called LightDefinition.cs.hlsl. // LightDefinition.cs [GenerateHLSL(PackingRules.Exact, false)] struct DirectionalLightData { public Vector3 positionRWS; public uint lightLayers; public float lightDimmer; public float volumetricLightDimmer; // Replaces 'lightDimer' public Vector3 forward; public Vector4 surfaceTextureScaleOffset; }; // LightDefinition.cs.hlsl // Generated from UnityEngine.Rendering.HighDefinition.DirectionalLightData // PackingRules = Exact struct DirectionalLightData { float3 positionRWS; uint lightLayers; float lightDimmer; float volumetricLightDimmer; float3 forward; float4 surfaceTextureScaleOffset; };"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/index.html",
    "title": "SRP Core | mmo-rpg-unity",
    "keywords": "SRP Core The Scriptable Render Pipeline (SRP) is a Unity feature that allows you to write C# scripts to control the way Unity renders each frame. SRP Core is a package that makes it easier to create or customize an SRP. SRP Core contains reusable code, including boilerplate code for working with platform-specific graphics APIs, utility functions for common rendering operations, and the shader libraries used in the High Definition Render Pipeline (HDRP) and Universal Render Pipeline (URP). If you are creating a custom SRP from scratch or customizing a prebuilt SRP, using SRP Core will save you time. For more information on SRP, including a guide to getting started with a custom SRP, see the SRP documentation. For more information on Unity's prebuilt SRPs, see the Universal Render Pipeline (URP) documentation, or the High Definition Render Pipeline (HDRP) documentation."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/render-graph-benefits.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/render-graph-benefits.html",
    "title": "Benefits of the render graph system | mmo-rpg-unity",
    "keywords": "Benefits of the render graph system Efficient memory management When you manage resource allocation manually, you have to account for scenarios when every rendering feature is active at the same time and thus allocate for the worst-case scenario. When particular rendering features are not active, the resources to process them are there, but the render pipeline does not use them. A render graph only allocates resources that the frame actually uses. This reduces the memory footprint of the render pipeline and means that there is no need to create complicated logic to handle resource allocation. Another benefit of efficient memory management is that, because a render graph can reuse resources efficiently, there are more resources available to create features for your render pipeline. Automatic synchronization point generation Asynchronous compute queues can run in parallel to the regular graphic workload and, as a result, may reduce the overall GPU time it takes to process a render pipeline. However, it can be difficult to manually define and maintain synchronization points between an asynchronous compute queue and the regular graphics queue. A render graph automates this process and, using the high-level declaration of the render pipeline, generates correct synchronization points between the compute and graphics queue. Maintainability One of the most complex issues in render pipeline maintenance is the management of resources. Because a render graph manages resources internally, it makes it much easier to maintain your render pipeline. Using the RenderGraph API, you can write efficient self-contained rendering modules that declare their input and output explicitly and are able to plug in anywhere in a render pipeline."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/render-graph-fundamentals.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/render-graph-fundamentals.html",
    "title": "Render graph fundamentals | mmo-rpg-unity",
    "keywords": "Render graph fundamentals This document describes the main principles of a render graph and an overview of how Unity executes it. Main principles Before you can write render passes with the RenderGraph API, you need to know the following foundational principles: You no longer handle resources directly and instead use render graph system-specific handles. All RenderGraph APIs use these handles to manipulate resources. The resource types a render graph manages are RTHandles, ComputeBuffers, and RendererLists. Actual resource references are only accessible within the execution code of a render pass. The framework requires an explicit declaration of render passes. Each render pass must state which resources it reads from and/or writes to. There is no persistence between each execution of a render graph. This means that the resources you create inside one execution of the render graph cannot carry over to the next execution. For resources that need persistence (from one frame to another for example), you can create them outside of a render graph, like regular resources, and import them in. They behave like any other render graph resource in terms of dependency tracking, but the graph does not handle their lifetime. A render graph mostly uses RTHandles for texture resources. This has a number of implications on how to write shader code and how to set them up. Resource Management The render graph system calculates the lifetime of each resource with the high-level representation of the whole frame. This means that when you create a resource via the RenderGraph API, the render graph system does not create the resource at that time. Instead, the API returns a handle that represents the resource, which you then use with all RenderGraph APIs. The render graph only creates the resource just before the first pass that needs to write it. In this case, “creating” does not necessarily mean that the render graph system allocates resources. Rather, it means that it provides the necessary memory to represent the resource so that it can use the resource during a render pass. In the same manner, it also releases the resource memory after the last pass that needs to read it. This way, the render graph system can reuse memory in the most efficient manner based on what you declare in your passes. If the render graph system does not execute a pass that requires a specific resource, then the system does not allocate the memory for the resource. Render graph execution overview Render graph execution is a three-step process that the render graph system completes, from scratch, every frame. This is because a graph can change dynamically from frame to frame, for example, depending on the actions of the user. Setup The first step is to set up all the render passes. This is where you declare all the render passes to execute and the resources each render pass uses. Compilation The second step is to compile the graph. During this step, the render graph system culls render passes if no other render pass uses their outputs. This allows for less organized setups because you can reduce specific logic when you set up the graph. A good example of that is debug render passes. If you declare a render pass that produces a debug output that you don't present to the back buffer, the render graph system culls that pass automatically. This step also calculates the lifetime of resources. This allows the render graph system to create and release resources in an efficient way as well as compute the proper synchronization points when it executes passes on the asynchronous compute pipeline. Execution Finally, execute the graph. The render graph system executes all render passes that it did not cull, in declaration order. Before each render pass, the render graph system creates the proper resources and releases them after the render pass if later render passes do not use them."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/render-graph-system.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/render-graph-system.html",
    "title": "The render graph system | mmo-rpg-unity",
    "keywords": "The render graph system The render graph system sits on top of Unity's Scriptable Render Pipeline (SRP). It allows you to author a custom SRP in a maintainable and modular way. Unity's High Definition Render Pipeline (HDRP) uses the render graph system. You use the RenderGraph API to create a render graph. A render graph is a high-level representation of the custom SRP's render passes, which explicitly states how the render passes use resources. Describing render passes in this way has two benefits: it simplifies render pipeline configuration, and it allows the render graph system to efficiently manage parts of the render pipeline, which can result in improved runtime performance. For more information on the benefits of the render graph system, see benefits of the render graph system. To use the render graph system, you need to write your code in a different way to a regular custom SRP. For more information on how to write code for the render graph system, see writing a render pipeline. For information on the technical principles behind the render graph system, see render graph fundamentals. Note: Render graph is currently experimental which means Unity might change its API during future development. This section contains the following pages: Render graph benefits Render graph fundamentals Writing a render pipeline"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/render-graph-writing-a-render-pipeline.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/render-graph-writing-a-render-pipeline.html",
    "title": "Writing a render pipeline | mmo-rpg-unity",
    "keywords": "Writing a render pipeline This page covers the process of how to use the RenderGraph API to write a render pipeline. For information about the RenderGraph API, see render graph system and render graph fundamentals. Initialization and cleanup of Render Graph To begin, your render pipeline needs to maintain at least one instance of RenderGraph. This is the main entry point for the API. You can use more than one instance of a render graph, but be aware that Unity does not share resources across RenderGraph instances so for optimal memory usage, only use one instance. using UnityEngine.Experimental.Rendering.RenderGraphModule; public class MyRenderPipeline : RenderPipeline { RenderGraph m_RenderGraph; void InitializeRenderGraph() { m_RenderGraph = new RenderGraph(“MyRenderGraph”); } void CleanupRenderGraph() { m_RenderGraph.Cleanup(); m_RenderGraph = null; } } To initialize a RenderGraph instance, call the constructor with an optional name to identify the render graph. This also registers a render graph-specific panel in the SRP Debug window which is useful for debugging the RenderGraph instance. When you dispose of a render pipeline, call the Cleanup() method on the RenderGraph instance to properly free all the resources the render graph allocated. Starting a render graph Before you add any render passes to the render graph, you first need to initialize the render graph. To do this, call the RecordAndExecute method. This method will return a disposable struct of type RenderGraphExecution that you can use with a scope. When the RenderGraphExecution struct exits the scope or its Dispose function is called, the render graph is executed. This pattern ensures that the render graph is always executed correctly even in the case of an exception during the recording of the graph. For details about this method's parameters, see the API documentation var renderGraphParams = new RenderGraphExecuteParams() { scriptableRenderContext = renderContext, commandBuffer = cmd, currentFrameIndex = frameIndex }; using (m_RenderGraph.RecordAndExecute(renderGraphParams)) { // Add your passes here } Creating resources for the render graph When you use a render graph, you never directly allocate resources yourself. Instead, the RenderGraph instance handles the allocation and disposal of its own resources. To declare resources and use them in a render pass, you use render graph specific APIs that return handles to the resource. There are two main types of resources that a render graph uses: Internal resources: These resources are internal to a render graph execution and you cannot access them outside of the RenderGraph instance. You also cannot pass these resources from one execution of a graph to another. The render graph handles the lifetime of these resources. Imported resources: These usually come from outside the render graph execution. Typical examples are the back buffer (provided by the camera) or buffers that you want the graph to use across multiple frames for temporal effects (like using the camera color buffer for temporal anti-aliasing). You are responsible for handling the lifetime of these resources. After you create or import a resource, the render graph system represents it as a resource type-specific handle (TextureHandle, ComputeBufferHandle, or RendererListHandle). This way, the render graph can use internal and imported resources in the same way in all of its APIs. public TextureHandle RenderGraph.CreateTexture(in TextureDesc desc); public ComputeBufferHandle RenderGraph.CreateComputeBuffer(in ComputeBufferDesc desc) public RendererListHandle RenderGraph.CreateRendererList(in RendererListDesc desc); public TextureHandle RenderGraph.ImportTexture(RTHandle rt); public TextureHandle RenderGraph.ImportBackbuffer(RenderTargetIdentifier rt); public ComputeBufferHandle RenderGraph.ImportComputeBuffer(ComputeBuffer computeBuffer); The main ways to create resources are described above, but there are variations of these functions. For the complete list, see the API documentation. Note that the specific function to use to import the camera back buffer is RenderTargetIdentifier. To create resources, each API requires a descriptor structure as a parameter. The properties in these structures are similar to the properties in the resources they represent (respectively RTHandle, ComputeBuffer, and RendererLists). However, some properties are specific to render graph textures. Here are the most important ones: clearBuffer: This property tells the graph whether to clear the buffer when the graph creates it. This is how you should clear textures when using the render graph. This is important because a render graph pools resources, which means any pass that creates a texture might get an already existing one with undefined content. clearColor: This property stores the color to clear the buffer to, if applicable. There are also two notions specific to textures that a render graph exposes through the TextureDesc constructors: xrReady: This boolean indicates to the graph whether this texture is for XR rendering. If true, the render graph creates the texture as an array for rendering into each XR eye. dynamicResolution: This boolean indicates to the graph whether it needs to dynamically resize this texture when the application uses dynamic resolution. If false, the texture does not scale automatically. You can create resources outside render passes, inside the setup code for a render pass, but not in the rendering code. Creating a resource outside of all render passes can be useful for cases where the first pass uses a given resource that depends on logic in the code that might change regularly. In this case, you must create the resource before any of those passes. A good example is using the color buffer for either a deferred lighting pass or a forward lighting pass. Both of these passes write to the color buffer, but Unity only executes one of them depending on the current rendering path chosen for the camera. In this case, you would create the color buffer outside both passes and pass it to the correct one as a parameter. Creating a resource inside a render pass is usually for resources the render pass produces itself. For example, a blur pass requires an already existing input texture, but creates the output itself and returns it at the end of the render pass. Note that creating a resource like that does not allocate GPU memory every frame. Instead, the render graph system reuses pooled memory. In the context of the render graph, think of resource creation more in terms of data flow in the context of a render pass than actual allocation. If a render pass creates a whole new output then it “creates” a new texture in the render graph. Writing a render pass Before Unity can execute the render graph, you must declare all the render passes. You write a render pass in two parts: setup and rendering. Setup During setup, you declare the render pass and all the data it needs to execute. The render graph represents data by a class specific to the render pass that contains all the relevant properties. These can be regular C# constructs (struct, PoDs, etc) and render graph resource handles. This data structure is accessible during the actual rendering code. class MyRenderPassData { public float parameter; public TextureHandle inputTexture; public TextureHandle outputTexture; } After you define the pass data, you can then declare the render pass itself: using (var builder = renderGraph.AddRenderPass<MyRenderPassData>(\"My Render Pass\", out var passData)) { passData.parameter = 2.5f; passData.inputTexture = builder.ReadTexture(inputTexture); TextureHandle output = renderGraph.CreateTexture(new TextureDesc(Vector2.one, true, true) { colorFormat = GraphicsFormat.R8G8B8A8_UNorm, clearBuffer = true, clearColor = Color.black, name = \"Output\" }); passData.outputTexture = builder.WriteTexture(output); builder.SetRenderFunc(myFunc); // details below. } You define the render pass in the using scope around the AddRenderPass function. At the end of the scope, the render graph adds the render pass to the internal structures of the render graph for later processing. The builder variable is an instance of RenderGraphBuilder. This is the entry point to build the information relating to the render pass. There are several important parts to this: Declaring resource usage: This is one of the most important aspects of the RenderGraph API. Here you explicitly declare whether the render pass needs read and/or write access to the resources. This allows the render graph to have an overall view of the whole rendering frame and thus determine the best use of GPU memory and synchronization points between various render passes. Declaring the rendering function: This is the function in which you call graphics commands. It receives the pass data you define for the render pass as a parameter as well as the render graph context. You set the rendering function for a render pass via SetRenderFunc and the function runs after the graph compiles. Creating transient resources: Transient, or internal, resources are resources you create for the duration of this render pass only. You create them in the builder rather than the render graph itself to reflect their lifetime. Creating transient resources uses the same parameters as the equivalent function in the RenderGraph APIs. This is particularly useful when a pass uses temporary buffers that should not be accessible outside of the pass. Outside the pass where you declare a transient resource, the handle to the resource becomes invalid and Unity throws errors if you try to use it. The passData variable is an instance of the type you provide when you declare the pass. This is where you set the data that the rendering code can access. Note that the render graph does not use the contents of passData right away, but later in the frame, after it registers all the passes and the render graph compiles and executes. This means that any reference the passData stores must be constant across the whole frame. Otherwise, if you change the content before the render pass executes, it does not contain the correct content during the render pass. For this reason, it is best practice to only store value types in the passData unless you are certain that a reference stays constant until the pass finishes execution. For an overview of the RenderGraphBuilder APIs, see the below table. For more details, see the API documentation: Function Purpose TextureHandle ReadTexture(in TextureHandle input) Declares that the render pass reads from the input texture you pass into the function. TextureHandle WriteTexture(in TextureHandle input) Declares that the render pass writes to the input texture you pass into the function. TextureHandle UseColorBuffer(in TextureHandle input, int index) Same as WriteTexture but also automatically binds the texture as a render texture at the provided binding index at the beginning of the pass. TextureHandle UseDepthBuffer(in TextureHandle input, DepthAccess flags) Same as WriteTexture but also automatically binds the texture as a depth texture with the access flags you pass into the function. TextureHandle CreateTransientTexture(in TextureDesc desc) Create a transient texture. This texture exists for the duration of the pass. RendererListHandle UseRendererList(in RendererListHandle input) Declares that this render pass uses the Renderer List you pass in. The render pass uses the RendererList.Draw command to render the list. ComputeBufferHandle ReadComputeBuffer(in ComputeBufferHandle input) Declares that the render pass reads from the input ComputeBuffer you pass into the function. ComputeBufferHandle WriteComputeBuffer(in ComputeBufferHandle input) Declares that the render pass writes to the input Compute Buffer you pass into the function. ComputeBufferHandle CreateTransientComputeBuffer(in ComputeBufferDesc desc) Create a transient Compute Buffer. This texture exists for the duration of the Compute Buffer. void SetRenderFunc (RenderFunc renderFunc) where PassData : class, new() Set the rendering function for the render pass. void EnableAsyncCompute(bool value) Declares that the render pass runs on the asynchronous compute pipeline. void AllowPassCulling(bool value) Specifies whether Unity should cull the render pass (default is true). This can be useful when the render pass has side effects and you never want the render graph system to cull. Rendering Code After you complete the setup, you can declare the function to use for rendering via the SetRenderFunc method on the RenderGraphBuilder. The function you assign must use the following signature: delegate void RenderFunc<PassData>(PassData data, RenderGraphContext renderGraphContext) where PassData : class, new(); You can either pass a render function as a static function or a lambda. The benefit of using a lambda function is that it can bring better code clarity because the rendering code is next to the setup code. Note that if you use a lambda, be very careful not to capture any parameters from the main scope of the function as that generates garbage, which Unity later locates and frees during garbage collection. If you use Visual Studio and hover over the arrow =>, it tells you if the lambda captures anything from the scope. Avoid accessing members or member functions because using either captures this. The render function takes two parameters: PassData data: This data is of the type you pass in when you declare the render pass. This is where you can access the properties initialized during the setup phase and use them for the rendering code. RenderGraphContext renderGraphContext. This stores references to the ScriptableRenderContext and the CommandBuffer that provide utility functions and allow you to write rendering code. Accessing resources in the render pass Inside the rendering function, you can access all the render graph resource handles stored inside the passData. The conversion to actual resources is automatic so, whenever a function needs an RTHandle, a ComputeBuffer, or a RendererList, you can pass the handle and the render graph converts the handle to the actual resource implicitly. Note that doing such implicit conversion outside of a rendering function results in an exception. This exception occurs because, outside of rendering, the render graph may have not allocated those resources yet. Using the RenderGraphContext The RenderGraphContext provides various functionality you need to write rendering code. The two most important are the ScriptableRenderContext and the CommandBuffer, which you use to call all rendering commands. The RenderGraphContext also contains the RenderGraphObjectPool. This class helps you to manage temporary objects that you might need for rendering code. Get temp functions Two functions that are particularly useful during render passes are GetTempArray and GetTempMaterialPropertyBlock. T[] GetTempArray<T>(int size); MaterialPropertyBlock GetTempMaterialPropertyBlock(); GetTempArray returns a temporary array of type T and size size. This can be useful to allocate temporary arrays for passing parameters to materials or creating a RenderTargetIdentifier array to create multiple render target setups without the need to manage the array’s lifetime yourself. GetTempMaterialPropertyBlock returns a clean material property block that you can use to set up parameters for a Material. This is particularly important because more than one pass might use a material and each pass could use it with different parameters. Because the rendering code execution is deferred via command buffers, copying material property blocks into the command buffer is mandatory to preserve data integrity on execution. The render graph releases and pools all the resources these two functions return automatically after the pass execution. This means you don’t have to manage them yourself and does not create garbage. Example render pass The following code example contains a render pass with a setup and render function: TextureHandle MyRenderPass(RenderGraph renderGraph, TextureHandle inputTexture, float parameter, Material material) { using (var builder = renderGraph.AddRenderPass<MyRenderPassData>(\"My Render Pass\", out var passData)) { passData.parameter = parameter; passData.material = material; // Tells the graph that this pass will read inputTexture. passData.inputTexture = builder.ReadTexture(inputTexture); // Creates the output texture. TextureHandle output = renderGraph.CreateTexture(new TextureDesc(Vector2.one, true, true) { colorFormat = GraphicsFormat.R8G8B8A8_UNorm, clearBuffer = true, clearColor = Color.black, name = \"Output\" }); // Tells the graph that this pass will write this texture and needs to be set as render target 0. passData.outputTexture = builder.UseColorBuffer(output, 0); builder.SetRenderFunc( (MyRenderPassData data, RenderGraphContext ctx) => { // Render Target is already set via the use of UseColorBuffer above. // If builder.WriteTexture was used, you'd need to do something like that: // CoreUtils.SetRenderTarget(ctx.cmd, data.output); // Setup material for rendering var materialPropertyBlock = ctx.renderGraphPool.GetTempMaterialPropertyBlock(); materialPropertyBlock.SetTexture(\"_MainTexture\", data.input); materialPropertyBlock.SetFloat(\"_FloatParam\", data.parameter); CoreUtils.DrawFullScreen(ctx.cmd, data.material, materialPropertyBlock); }); return output; } } Ending the frame Over the course of your application, the render graph needs to allocate various resources. It might use these resources for a time but then might not need them. For the graph to free up those resources, call the EndFrame() method once a frame. This deallocates any resources that the render graph has not used since the last frame. This also executes all internal processing the render graph requires at the end of the frame. Note that you should only call this once per frame and after all the rendering is complete (for example, after the last camera renders). This is because different cameras might have different rendering paths and thus need different resources. Calling the purge after each camera could result in the render graph releasing resources too early even though they might be necessary for the next camera."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/rthandle-system-fundamentals.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/rthandle-system-fundamentals.html",
    "title": "| mmo-rpg-unity",
    "keywords": "RTHandle system fundamentals This document describes the main principles of the RTHandle (RTHandle) system. The RTHandle system is an abstraction on top of Unity's RenderTexture API. It makes it trivial to reuse render textures across Cameras that use various resolutions. The following principles are the foundation of how the RTHandle system works: You no longer allocate render textures yourself with a fixed resolution. Instead, you declare a render texture using a scale related to the full screen at a given resolution. The RTHandle system allocates the texture only once for the whole render pipeline so that it can reuse it for different Cameras. There is now the concept of reference size. This is the resolution the application uses for rendering. It is your responsibility to declare it before the render pipeline renders every Camera at a particular resolution. For information on how to do this, see the Updating the RTHandle system section. Internally, the RTHandle system tracks the largest reference size you declare. It uses this as the actual size of render textures. The largest reference size is the maximum size. Every time you declare a new reference size for rendering, the RTHandle system checks if it is larger than the current recorded largest reference size. If it is, the RTHandle system reallocates all render textures internally to fit the new size and replaces the largest reference size with the new size. An example of this process is as follows. When you allocate the main color buffer, it uses a scale of 1 because it is a full-screen texture. You want to render it at the resolution of the screen. A downscaled buffer for a quarter-resolution transparency pass would use a scale of 0.5 for both the x-axis and y-axis. Internally the RTHandle system allocates render textures using the largest reference size multiplied by the scale you declare for the render texture. After that and before each Camera renders, you tell the system what the current reference size is. Based on that and the scaling factor for all textures, the RTHandle system determines if it needs to reallocate render textures. As mentioned above, if the new reference size is larger than the current largest reference size, the RTHandle system reallocates all render textures. By doing this, the RTHandle system ends up with a stable maximum resolution for all render textures, which is most likely the resolution of your main Camera. The key takeaway of this is that the actual resolution of the render textures is not necessarily the same as the current viewport: it can be bigger. This has implications when you write a renderer using RTHandles, which the Using the RTHandle system documentation explains. The RTHandleSystem also allows you to allocate textures with a fixed size. In this case, the RTHandle system never reallocates the texture. This allows you to use the RTHandle API consistently for both automatically-resized textures that the RTHandle system manages and regular fixed size textures that you manage."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/rthandle-system-using.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/rthandle-system-using.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Using the RTHandle system This page covers how to use the RTHandle system to manage render textures in your render pipeline. For information about the RTHandle system, see RTHandle system and RTHandle system fundamentals. Initializing the RTHandle System All operations related to RTHandles require an instance of the RTHandleSystem class. This class contains all the APIs necessary to allocate RTHandles, release RTHandles, and set the reference size for the frame. This means that you must create and maintain an instance of RTHandleSystem in your render pipeline or make use of the static RTHandles class mentioned later in this section. To create your own instance of RTHandleSystem, see the following code sample: RTHandleSystem m_RTHandleSystem = new RTHandleSystem(); m_RTHandleSystem.Initialize(Screen.width, Screen.height); When you initialize the system, you must supply the starting resolution. The above code example uses the width and height of the screen. Because the RTHandle system only reallocates render textures when a Camera requires a resolution larger than the current maximum size, the internal RTHandle resolution can only increase from the value you pass in here. It is good practice to initialize this resolution to be the resolution of the main display. This means the system does not need to unnecessarily reallocate the render textures (and cause unwanted memory spikes) at the beginning of the application. You must only call the Initialize function once at the beginning of the application. After this, you can use the initialized instance to allocate textures. Because you allocate the majority of RTHandles from the same RTHandleSystem instance, the RTHandle system also provides a default global instance through the RTHandles static class. Rather than maintain your own instance of RTHandleSystem, this allows you to use the same API that you get with an instance, but not worry about the lifetime of the instance. Using the static instance, the initialization becomes this: RTHandles.Initialize(Screen.width, Screen.height); The code examples in the rest of this page use the default global instance. Updating the RTHandle System Before rendering with a Camera, you need to set the resolution the RTHandle system uses as a reference size. To do so, call the SetReferenceSize function. RTHandles.SetReferenceSize(width, height); Calling this function has two effects: If the new reference size you provide is bigger than the current one, the RTHandle system reallocates all the render textures internally to match the new size. After that, the RTHandle system updates internal properties that set viewport and render texture scales for when the system uses RTHandles as active render textures. Allocating and releasing RTHandles After you initialize an instance of RTHandleSystem, whether this is your own instance or the static default instance, you can use it to allocate RTHandles. There are three main ways to allocate an RTHandle. They all use the same Alloc method on the RTHandleSystem instance. Most of the parameters of these functions are the same as the regular Unity RenderTexture ones, so for more information see the RenderTexture API documentation. This section focuses on the parameters that relate to the size of the RTHandle: Vector2 scaleFactor: This variant requires a constant 2D scale for width and height. The RTHandle system uses this to calculate the resolution of the texture against the maximum reference size. For example, a scale of (1.0f, 1.0f) generates a full-screen texture. A scale of (0.5f 0.5f) generates a quarter-resolution texture. ScaleFunc scaleFunc: For cases when you don't want to use a constant scale to calculate the size of an RTHandle, you can provide a functor that calculates the size of the texture. The functor should take a Vector2Int as a parameter, which is the maximum reference size, and return a Vector2Int, which represents the size you want the texture to be. int width, int height: This is for fixed-size textures. If you allocate a texture like this, it behaves like any regular RenderTexture. There are also overrides that create RTHandles from RenderTargetIdentifier. RenderTextures, or Textures. These are useful when you want to use the RTHandle API to interact with all your textures, even though the texture might not be an actual RTHandle. The following code sample contains example uses of the Alloc function: // Simple Scale RTHandle simpleScale = RTHandles.Alloc(Vector2.one, depthBufferBits: DepthBits.Depth32, dimension: TextureDimension.Tex2D, name: \"CameraDepthStencil\"); // Functor Vector2Int ComputeRTHandleSize(Vector2Int screenSize) { return DoSpecificResolutionComputation(screenSize); } RTHandle rtHandleUsingFunctor = RTHandles.Alloc(ComputeRTHandleSize, colorFormat: GraphicsFormat.R32_SFloat, dimension: TextureDimension.Tex2D); // Fixed size RTHandle fixedSize = RTHandles.Alloc(256, 256, colorFormat: GraphicsFormat.R8G8B8A8_UNorm, dimension: TextureDimension.Tex2D); When you no longer need a particular RTHandle, you can release it. To do this, call the Release method. myRTHandle.Release(); Using RTHandles After you allocate an RTHandle, you can use it exactly like a regular RenderTexture. There are implicit conversions to RenderTargetIdentifier and RenderTexture, which means you can use them with regular related Unity APIs. However, when you use the RTHandle system, the actual resolution of the RTHandle might be different from the current resolution. For example, if the main Camera renders at 1920x1080 and a secondary Camera renders at 512x512, all RTHandle resolutions are based on the 1920x1080 resolution, even when rendering at lower resolutions. Because of this, take care when you set an RTHandle up as a render target. There are a number of APIs available in the CoreUtils class to help you with this. For example: public static void SetRenderTarget(CommandBuffer cmd, RTHandle buffer, ClearFlag clearFlag, Color clearColor, int miplevel = 0, CubemapFace cubemapFace = CubemapFace.Unknown, int depthSlice = -1) This function sets the RTHandle as the active render target but also sets up the viewport based on the scale of the RTHandle and the current reference size, not the maximum size. For example, when the reference size is 512x512, even if the maximum size is 1920x1080, a texture of scale (1.0f, 1.0f) uses the 512x512 size and therefore sets up a 512x512 viewport. A (0.5f, 0.5f) scaled texture sets up a viewport of 256x256 and so on. This means that, when using these helper functions, the RTHandle system generates the correct viewport based on the RTHandle parameters. This example is one of many different overrides for the SetRenderTarget function. For the full list of overrides, see the documentation. Using RTHandles in shaders When you sample from a full-screen render texture in a shader in the usual way, UVs span the whole 0 to 1 range. This is not always the case with RTHandles. The current rendering might only occur in a partial viewport. To take this into account, you must apply a scale to UVs when you sample RTHandles that use a scale. All the information necessary to handle RTHandles specificity inside shaders is in the RTHandleProperties structure that the RTHandleSystem instance provides. To access it, use: RTHandleProperties rtHandleProperties = RTHandles.rtHandleProperties; This structure contains the following properties: public struct RTHandleProperties { public Vector2Int previousViewportSize; public Vector2Int previousRenderTargetSize; public Vector2Int currentViewportSize; public Vector2Int currentRenderTargetSize; public Vector4 rtHandleScale; } This structure provides: The current viewport size. This is the reference size you set for rendering. The current render target size. This is the actual size of the render texture based on the maximum reference size. The rtHandleScale. This is the scale to apply to full-screen UVs to sample an RTHandle. Values for previous frames are also available. For more information, see Camera specific RTHandles. Generally, the most important property in this structure is rtHandleScale. It allows you to scale full-screen UV coordinates and use the result to sample an RTHandle. For example: float2 scaledUVs = fullScreenUVs * rtHandleScale.xy; However, because the partial viewport always starts at (0, 0), when you use integer pixel coordinates within the viewport to load content from a texture, there is no need to rescale them. Another important thing to consider is that, when you render a full-screen quad into a partial viewport, there is no benefit from standard UV addressing mechanisms such as wrap or clamp. This is because the texture might be bigger than the viewport. For this reason, take care when you sample pixels outside of the viewport. Custom SRP specific information There are no shader constants provided by default with SRP. So, when you use RTHandles with your own SRP, you must provide these constants to their shaders themselves. Camera specific RTHandles Most of the render textures that a rendering loop uses can be shared by all Cameras. If their content does not need to carry from one frame to another, this is fine. However, some render textures need persistence. A good example of this is using the main color buffer in subsequent frames for Temporal Anti-aliasing. This means that the Camera cannot share its RTHandle with other Cameras. Most of the time, this also means that these RTHandles must be at least double-buffered (written to during the current frame, read from during the previous frame). To address this problem, the RTHandle system includes BufferedRTHandleSystems. A BufferedRTHandleSystem is an RTHandleSystem that can multi-buffer RTHandles. The principle is to identify a buffer by a unique ID and provide APIs to allocate a number of instances of the same buffer then retrieve them from previous frames. These are history buffers. Usually, you must allocate one BufferedRTHandleSystem for each Camera. Each one owns their Camera-specific RTHandles. Not every Camera needs history buffers. For example, if a Camera does not need Temporal Anti-aliasing, you do not need to assign a BufferedRTHandleSystem to it. History buffers require memory which means you can save memory by not assigning history buffers to Cameras that do not need them. Another consequence is that the system only allocates history buffers at the resolution of the Camera that the buffers are for. If the main Camera is 1920x1080 and another Camera renders in 256x256 and needs a history color buffer, the second Camera only uses a 256x256 buffer and not a 1920x1080 buffer as the non-Camera specific RTHandles would. To create an instance of a BufferedRTHandleSystem, see the following code sample: BufferedRTHandleSystem m_HistoryRTSystem = new BufferedRTHandleSystem(); To allocate an RTHandle using a BufferedRTHandleSystem, the process is different from a normal RTHandleSystem: public void AllocBuffer(int bufferId, Func<RTHandleSystem, int, RTHandle> allocator, int bufferCount); The bufferId is a unique ID that the system uses to identify the buffer. The allocator is a function you provide to allocate the RTHandles when needed (all instances are not allocated upfront), and the bufferCount is the number of instances requested. From there, you can retrieve each RTHandle by its ID and instance index like so: public RTHandle GetFrameRT(int bufferId, int frameIndex); The frame index is between zero and the number of buffers minus one. Zero always represents the current frame buffer, one the previous frame buffer, two the one before that, and so on. To release a buffered RTHandle, call the Release function on the BufferedRTHandleSystem, passing in the ID of the buffer to release: public void ReleaseBuffer(int bufferId); In the same way that you provide the reference size for regular RTHandleSystems, you must do this for each instance of BufferedRTHandleSystem. public void SwapAndSetReferenceSize(int width, int height); This works the same way as regular RTHandleSystem but it also swaps the buffers internally so that the 0 index for GetFrameRT still references the current frame buffer. This slightly different way of handling Camera-specific buffers also has implications when you write shader code. With a multi-buffered approach like this, RTHandles from a previous frame might have a different size to the one from the current frame. For example, this can happen with dynamic resolution or even when you resize the window in the Editor. This means that when you access a buffered RTHandle from a previous frame, you must scale it accordingly. The scale Unity uses to do this is in RTHandleProperties.rtHandleScale.zw. Unity uses this in exactly the same way as xy for regular RTHandles. This is also the reason why RTHandleProperties contains the viewport and resolution of the previous frame. It can be useful when doing computation with history buffers. Dynamic Resolution One of the byproducts of the RTHandle System design is that you can also use it to simulate software dynamic resolution. Because the current resolution of the Camera is not directly correlated to the actual render texture objects, you can provide any resolution you want at the beginning of the frame and all render textures scale accordingly. Reset Reference Size Sometimes, you might need to render to a higher resolution than normal for a short period of time. If your application does not require this resolution anymore, the additional memory allocated is wasted. To avoid that, you can reset the current maximum resolution of an RTHandleSystem like so: RTHandles.ResetReferenceSize(newWidth, newHeight); This forces the RTHandle system to reallocate all RTHandles to the new provided size. This is the only way to shrink the size of RTHandles."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/rthandle-system.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/rthandle-system.html",
    "title": "The RTHandle system | mmo-rpg-unity",
    "keywords": "The RTHandle system Render target management is an important part of any render pipeline. In a complicated render pipeline where there are many interdependent render passes that use many different render textures, it is important to have a maintainable and extendable system that allows for easy memory management. One of the biggest issues occurs when a render pipeline uses many different Cameras, each with their own resolution. For example, off-screen Cameras or real-time reflection probes. In this scenario, if the system allocated render textures independently for each Camera, the total amount of memory would increase to unmanageable levels. This is particularly bad for complex render pipelines that use many intermediate render textures. Unity can use temporary render textures, but unfortunately, they do not suit this kind of use case because temporary render textures can only reuse memory if a new render texture uses the exact same properties and resolution. This means that when rendering with two different resolutions, the total amount of memory Unity uses is the sum of all resolutions. To solve these issues with render texture memory allocation, Unity's Scriptable Render Pipeline includes the RTHandle system. This system is an abstraction layer on top of Unity's RenderTexture API that handles render texture management automatically. This section contains the following pages: RTHandle system fundamentals Using the RTHandle system"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/shaders.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/shaders.html",
    "title": "Shaders | mmo-rpg-unity",
    "keywords": "Shaders Work with shader code in the Scriptable Render Pipeline (SRP). Page Description Use shader methods from the SRP Core shader library SRP Core has a library of High-Level Shader Language (HLSL) shader files that contain helper methods. You can import these files into your custom shader files and use the helper methods. Synchronizing shader code and C# Generate HLSL code based on C# structs to synchronize data and constants between shaders and C#. Additional resources HLSL in Unity"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/whats-new-12.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/whats-new-12.html",
    "title": "What's new in SRP Core version 12 / Unity 2021.2 | mmo-rpg-unity",
    "keywords": "What's new in SRP Core version 12 / Unity 2021.2 This page contains an overview of new features, improvements, and issues resolved in version 12 of the Core Render Pipeline package, embedded in Unity 2021.2. Improvements RTHandle System and MSAA The RTHandle System no longer requires you to specify the number of MSAA samples at initialization time. This means that you can now set the number of samples on a per texture basis, rather than for the whole system. In practice, this means that the initialization APIs no longer require MSAA related parameters. The Alloc functions have replaced the enableMSAA parameter and enables you to explicitly set the number of samples. New API to disable runtime Rendering Debugger UI It is now possible to disable the Rendering Debugger UI at runtime by using DebugManager.enableRuntimeUI. Added High performance sorting algorithms in CoreUnsafeUtils New high performance sorting algorithms in the CoreUnsafeUtils helper methods. The new sorting algorithms include: RadixSort - ideal for very large lists, more then 512 elements. MergeSort (non recursive) - ideal for mid size lists, less than 512 elements. InsertionSort - ideal for very small lists, less than 32 elements. The sorting algorithms only work on uint elements. They include methods that support standard c# arrays, NativeArray objects or raw pointers. RadixSort and MergeSort require support array data, which can be allocated by the user, or allocated automatically via ref parameter passing. InsertionSort is in-place and does not require support data. These algorithms are compatible with burst kernels when using raw pointers or NativeArray. Currently HDRP utilizes them to sort lights in the CPU lightloop."
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/whats-new-13.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/whats-new-13.html",
    "title": "What's new in SRP Core version 13 / Unity 2022.1 | mmo-rpg-unity",
    "keywords": "What's new in SRP Core version 13 / Unity 2022.1 This page contains an overview of new features, improvements, and issues resolved in version 13 of the Core Render Pipeline package, embedded in Unity 2022.1. Added AMD Fidelity FX Super Sampling helper API - FSRUtils Introducing new stream lined API for AMD Fidelity FX Super Sampling. The new API is located in the static class FSRUtils and allows scriptable pipelines to have direct access / implement and integrate easilty FSR super sampler. For more information please review the API located in Runtime/Utitilies/FSRUtils.cs"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/whats-new.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/Documentation~/whats-new.html",
    "title": "What's new in SRP Core | mmo-rpg-unity",
    "keywords": "What's new in SRP Core This section contains information about changes to SRP Core. Each page contains a list of new features and, if relevant, a list of improvements and a list of resolved issues. The list of pages is as follows: 12 13"
  },
  "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.core@14.0.11/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.render-pipelines.core copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal-config@14.0.10/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal-config@14.0.10/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [Unreleased] Version Updated The version number for this package has increased due to a version update of a related graphics package. Started Changelog"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal-config@14.0.10/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal-config@14.0.10/Documentation~/index.html",
    "title": "Universal Render Pipeline Configuration Package | mmo-rpg-unity",
    "keywords": "Universal Render Pipeline Configuration Package The Universal Render Pipeline (URP) uses this package to control the settings of some of its features. If you want to use this package to configure URP, you must link it as a local package. For information on how to set up and use the URP Config package, see URP Config. For documentation on URP itself, see URP documentation."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal-config@14.0.10/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal-config@14.0.10/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.render-pipelines.universal-config copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [Unreleased] Version Updated The version number for this package has increased due to a version update of a related graphics package. [14.0.10] - 2024-04-03 This version is compatible with Unity 2022.3.24f1. Changed The Auto option in SH Evaluation Mode, in the URP Asset, now chooses Per Vertex instead of Per Pixel on mobile and similar devices. Fixed Fixed sRGB conversion without PostProcessing. Fixed an issue with missing variant in builds when using Strict Variant Matching and Deferred Rendering. Fixed RenderRequest using wrong renderer. Fixed an issue where downsampled SSAO had serious artefacts on Android. Fixed an issue where Screen Space Decals keyword was missing when Strip Unused Variants was turned off. Added UI features to encourage the use of Rendering Layers in URP to control selective lighting, instead of using culling mask. The former works across Deferred, Forward and Forward+, while the latter only works with Forward. Fixed incorrect alpha-clip behavior on transparent surfaces. Fixed an issue where using Alpha Clipped shaders and Depth Priming resulted in invisible objects. Ensure motion vector depth buffer is valid for cameras with motion vectors enabled. Fixed an issue where keywords were incorrectly enabled/disabled when shadows were enabled in the URP Asset and \"Transparent Receive Shadows\" was disabled on the renderer. SSAO is now rendered in deferred when no light is present. Early exit from URP RendererFeatures if they require color and is rendered to a depth on target. Reflection probes now works correctly using mip maps with forward+. Preview cameras now skip render objects. Reflection probes are now sorted in the correct order. Fixed an issue where setting light position, direction and shadow bias allocated due to using strings instead of integers. Motion Vector pass can now render after opaques. It correctly follows its depth dependency in pass order. Disabled depth priming for cameras with depth only render targets. Added logic to enforce consistent hardware dynamic resolution settings during rendering to avoid issues when external code changes the global setting. Fixed an issue where an incorrect WorldToCamera matrix was used in the main and additional light shadow passes. Fixed an issue where errors appeared due to _CameraDepthTexture_TexelSize being added to DeclareDepthTexture. Fixed an issue where logging an error gave a NullReferenceException for Server Builds. Fixed false-negative missing RendererFeatures errors. Restore EditorGUIUtility.labelWidth to default after drawing MaterialHeaderScopes. Fix shadow flickering when using Screen Space shadows and have depth priming enabled Fixed the NativeRenderPass camera target MSAA logic to match the non-NRP path Fix depth buffer disappearing after using SwapColorBuffer [14.0.9] - 2023-12-21 This version is compatible with Unity 2022.3.18f1. Changed Vulkan URP will use MSAA samples count fallback from player settings. Prior to this x2 fallback would have been to upgrade to x4. Improved renderViewportScale for XR intermediate textures. Improved runtime performance by adding checks for _ALPHATEST_ON when rendering depth, shadows and depth normals. Fixed Fixed per-vertex light layers. Added workarounds for MSAA-specific visual artifacts on materials that use alpha clipping in unexpected ways. Fixed an issue causing decals to be culled erroneously when using the Screen Space technique. Fixed an issue where Rendering Layers didn't work properly when opening a project. Disabled Motion Blur effect in EditMode to keep the game view clear while editing. Motion Blur works as before in PlayMode and standalone builds. Fixed _WorldSpaceCameraPos is not set correctly in XR Multipass. Fixed Color Grading Mode set to Low Dynamic Range on one camera in the stack despite HDR output active. Fixed an issue where building a project using deferred with batchmode and nographics resulted in incorrect variant stripping. Fixed an issue where Unlit shaders would not output correct normals when using deferred and Accurate GBuffer Normals. Fixed HDR Debug Views break the native render pass when enabled once. Updated the documentation to mention that the Screen Space decal technique does not support blending of normals when using the Deferred rendering path with Accurate G-Buffer Normals enabled. The Automatic decal technique now prefers the D-Buffer technique if Accurate G-Buffer Normals are enabled. Fixed partially corrupted Android screen when Vulkan display rotation during rendering is enabled. Use local random state for post-processing. Fixed SH vertex evaluation mode in URPLit shader graph. Fixed FXAA resulting in a too-dark image when using in combination with HDR output, and bilinear/nearest-neightbor upscaling. Fixed an issue where screen space decals would not calculate ambient lighting correctly. The Fullscreen Render Feature doesn't cause rendering layers to run in the depth normals prepass anymore. Fixed an issue where Light Layers did not check scene lighting setting when enabling the keyword. [14.0.8] - 2023-09-27 This version is compatible with Unity 2022.3.11f1. Fixed Fixed TAA resource leak on entering/exiting the playmode. Fixed rare iOS shader building failure due to URP Lit Forward Pass shader varyings struct variable mismatch Fixed an issue with broken documentation links. Stripped BlitHDROverlay from build if HDR output is not allowed and stripping unused shader is allowed. Fixed an issue where switching Volume Update modes between Every Frame and Via Scripting gave an error. Fixed, URP & core package leaking materials when entering/exiting Play Mode. Fixed for the UI being drawn twice in some scenarios. Fixed an issue where assets were incorrectly being saved when making builds. Fixed incorrect MSAA sample count when using Deferred renderer but rendering to a target texture. Fixed ShaderGraph preview window not showing anything when using DepthNormals pass. 2D - Remove serialization and cache vertices and indices for sprite lights causing bloat in prefabs. Changed the ScreenSpace Decals sorting criteria to None to fix flickering issues. Fixed redundant blit is used due to postFX, although it is disabled in rendererData. Support DOTS_INSTANCING in DebugReplacement shader. Fixed a bug where color space conversion is applied twice in URP in specific conditions (HDR Output and Debug HDR Views enabled). Fixed using RenderTextureSubElement.Stencil in URP not binding properly. Fixed error message in filtered view when decals are enabled. Fixed Screen space Overlay UI rendered at the wrong size for scaling mode \"Constant Pixel Size\" or \"Constant Physical Size\", when HDR output is active. Fixed WebGL1 throwing errors when using depth copy texture. Fixed typo in RenderSingleCamera obsolete message. 2D - Fixed additional draw call when Foremost Sorting Layer is enabled during unlit. Fixed removal of renderer features if a renderer feature is missing. Fixed data-driven lens-flare occlusion and y-flip on opengl. Fixed an issue where rendering layers keywords were not enabled correctly when using Decals & SSAO in Deferred. Fixed an issue where incorrect Shader Keyword Prefiltering was used with SSAO when AfterOpaque was used. Fixed Native RenderPass errors when using RenderingLayers. Fixed exception for missing _Color Shader Property. Fixed runtime performance drops when multiple views that uses incompatible RTHandle descriptors are rendered within a frame. Fixed an issue where Shader ID's weren't reset properly in the DepthNormals pass. Fixed black screen issue when using URP hardware Dynamic Resolution with DX12. Fixed Native RenderPass errors when using RendererFeature which is executed in between GBuffer and Deferred Lighting passes. Fixed color and depth mismatch when scaling is on. Fixed an issue where IndexOutOfRangeException was thrown when creating a stacked camera from script. Fixed an issue where NullReferenceException was thrown when camera prefab referenced a camera outside the prefab in the camera stack. Fixed an issue where settings would disappear when deleting a child Camera of the Main Camera. Fixed an issue where additional lights were not rendering correctly when using a mix of shadow settings in deferred. Added GBuffer (fill) passes to ComplexLit and Unlit shader to prevent GBuffer data holes. Fixed render texture memory leak when rtHandle realloc failed to be added to pool. Fixed an issue where it wasn't possible to add a Renderer Feature on a renderer if another feature had a missing/broken script. Fixed an issue with Screen Space Decals where dark artefacts appeared in the editor. Fixed an issue where reflection probes were not updating correctly when using Forward+. Fixed an issue causing 'implicit truncation of vector type' warning when using ShaderGraph shaders in the Forward+ Rendering Path. Fixed HDR Output can't be turned off via the HDROutputSettings API in the editor. Add Shader Keywords for Soft Shadow quality levels and disable per-light quality level on untethered XR platforms Fix IndexOutOfRangeException error when using Native RenderPass on Deferred Fixed an issue where selecting a stacked camera caused the editor to freeze and sometimes crash. Fixed TAA Very High option flicker. [14.0.7] - 2023-05-23 This version is compatible with Unity 2022.2.22f1. Changed The two subshaders in main URP shaders (Lit, SimpleLit, BakedLit, ComplexLit, Particles) have now been combined in to one. The Forward+ rendering path now supports XR rendering, and cameras using orthographic projection. Fixed Fixed Render Targets being released when using multiple cameras. Fixed the Screen flicker in Scene view. Increased lighting BRDF specular max for half float math (mobile) to match the visual look of full float math (desktop) better. Disabled MSAA on devices without MSAA store support (Apple GPUs A8 and lower). Fixed an issue where using the Reflection Probe Node with the Forward+ rendering path would result in flickering on the object. Fixed TAA resource leak on entering/exiting the playmode. Fixed rare iOS shader building failure due to URP Lit Forward Pass shader varyings struct variable mismatch [14.0.6] - 2023-03-24 This version is compatible with Unity 2022.2.13f1. Fixed Fixed ComplexLit mixed lighting by matching ComplexLit shader keywords with the Lit shader. Fixed an issue causing materials using Shader Graphs with material override to disappear when using the Deferred rendering path if alpha clipping is enabled in the material. Fixed y-flipped shading on gizmos in game view. Fixed a light cookie out of bounds. Fixed an issue causing Dynamic Resolution to be disabled during URP rendering. Fixed a missing keyword in ParticlesSimpleLit for Lightmap shadow mixing. Fixed Reflection Probe baking throwing errors with Render Scale set not to 1 Fixed issue where disabling/enabling ShadowCaster2Ds can create duplicate shadows. Fixed an issue so that deferred rendering now works correctly in builds with Accurate GBuffer Normals enabled. Fixed the 2D Sprite Light & Freeform Light fast normal map quality setting to correctly use the normal map. Fixed a bug with the shadow mesh bounds of ShadowCaster2D so that shadows no longer disappear. Fixed GC.Allocs with sorting layers in Light2D. Prevent negative color and NaN write to TAA history. Fixed an issue where scenes were not marked dirty after changing the volume update setting on cameras. Fixed resource leak in URP deferred. Added vertex SH option to URP rendering and fixed HL2 forward light perf regression. Fixed an issue where instantiating and destroying cameras, with Volume Update Mode set to ViaScripting, would allocate each time 2d - Fix null exception when adding a sorting layer Fixed an issue where main light shadows were incorrect if scene and game windows were open. [14.0.5] - 2022-12-12 This version is compatible with Unity 2022.2.4f1. Changed Shader parameters used by additional lights are now removed when additional lights are disabled in URP Assets. Fixed Set default contribution to 0 for ColorLookup VolumeComponent, which makes the interpolation with the implicit default global volume behave as expected. Fixed Full Screen Pass functionality when used with XR. RenderObjects Render Features now render correctly when injected after rendering. Fixed an issue in deferred rendering mode where the Material inspector would log errors about color and depth dimensions not matching. Fixed an issue where a ParticlesUnlit.mat warning appeared when creating a new material. Fixed an issue with slower build-times caused by large Additional Light Shadows arrays in URP Shaders. Fixed a bug where lights with different blend styles may have missing shadows. Fixed mixed lights when using deferred rendering and shadow mask. Fixed releasing render targets when using multiple renderers. Fixed an issue where the Universal Renderer could incorrectly clear the render target during the forward opaques pass even if the render target contains valid rendering data produced by a pass that ran before opaque rendering. [14.0.4] - 2022-11-04 This version is compatible with Unity 2022.2.2f1. Added UniversalRenderPipeline.SingleCameraRequest. Use this as the RequestData parameter in SubmitRenderRequest to render a single camera. Changed Adapted URP to use Blitter interface for full screen draws. Removed DRAW_PRCEDURAL variant for shaders. Factored out full screen blits to utility function. Updated terrain SSAO tests for DX11 and DX12 by using the reference images from Vulkan. Improved edge quality for alpha-clipped materials when multisampling is used in URP. Reduced the number of memcpy operations from NativeArray access in URP for performance. Added tooltips for upscaling filters. Added Screen space for the Transform node. Integrated Foveated Rendering into URP for supported platforms. SSAO: The samples field has been changed to a dropdown: High (12 samples), Medium (8 samples) and Low (4 samples). SSAO: The final After Opaque passes have now been merged with the last blur pass. SSAO: Downsampling will now not only affect the AO pass but also the blur passes. SSAO: Depth test improved to avoid incorrectly adding AO in places where two objects are far away from one another. Moved Volume Update Mode out of Additional Settings. Messages regarding reducing resolution for additional punctual lights are now only displayed in debug builds. Avoid using Depth32Stencil8 format on Android. Fixed Fixed a crash on standalone profiler executing the URP Upgrader. Fixed so objects don't disappear when using Depth Priming and Rendering Debugger. Improved fallback to single shadow cascade on GLES2. Fixed materials that use Autodesk Interactive shader to convert correctly. Fixed a shader compilation error on certain platforms. (URP-1415). Fixed incorrect output when post process is enabled in URP 2D. Fixed vertex color for sprite shapes in URP 2D. Fixed Light2D upgrading issue with m_AlphaBlendOnOverlap property. Fixed Gizmo and grid artifact in editor view URP: Fixed SSAO being flipped in after opaque. URP: Fixed Decals being flipped. Fixed an issue with Depth Priming when executing the DepthNormals prepass with MSAA on. Fixed Gizmos in Game View when using Viewports (UUM-7069). Fixed SpeedTree Shadergraph causes errors spammed in console. Fixed specular highlight edges on Android. Fixed depth pre-pass being always executed on GLES devices. Fixed incorrect light brightness when using SimpleLit shader. Fixed alpha discard on Unlit Sprite targets for Shadergraph. Fixed 2D Spot Light artifacts in light. Fixed additional light perf regression on Quest. Fixed memory leak issue in URP deferred when resizing preview camera window. Fixed an issue where camera UI inspector's clearFlag is not respected. Fixed issue where selecting the URP asset could break HDRP blitter when HDRP is the active pipeline. Fixed an issue that the Shaders now correctly fallback to error shader. Fixed excessive banding from FSR in URP. Fixed decals correctly handle last batch. Fixed decal msaa error then camera is selected in deferred rendering path. Fixed render scale correctly work with screen size property. This includes decals. Fixed decals to produce correct world to tangent matrix. Fixed decals to pass correct viewDirectionWS to screen space and gbuffer lighting. Fixed decal screen space to work without intermediate texture and DBuffer to force using intermediate texture. Fixed instacing error when decals loaded, but not the decal shaders. Display Stats is now always shown in the first position on the Rendering Debugger. Fixed wireframe view in URP (UUM-2548). 2D - Fixed incorrect blit material set during Pixel Perfect Upscale pass. Disabled depth priming on GLES when MSAA is enabled. Disabled depth priming when baking reflection probes. Fixed a resource leak when switching between scenes with different pipeline assets. Fixed missing Depth Copy texture in Scene view. Fixed soft shadow filtering quality when using large empty shadow atlas. Use allocated atlas size instead of requested size. Fixed light banding artifacts on normal maps. Fixed render scale with SMAA. Removed RenderSingleCamera is now obsolete. Please use RenderPipeline.SubmitRenderRequest with RequestData of the SingleCameraRequest type. Graphics: Camera.SubmitRenderRequests is now obsolete. Please use RenderPipeline.SubmitRenderRequest with RequestData of a supported type such as RenderPipeline.StandardRequest. [14.0.3] - 2021-05-09 This version is compatible with Unity 2022.2.0b15. Changed Added new UI/UX for the converter framework. Changed so Unity exports shader variants information into a file in a temp folder. Fixed Fixed setters so they don't cause an infinite loop in URP pipeline asset. Fixed spot and point light harsh distance falloff artefact on some platforms due to fp16 precision issue. Fixed _InternalLut so it isn't released too early and logs warnings when using post-processing in stacked camera's in URP 2D. Reverted behavior to allow FinalBlit to be skipped when you have no ScriptableRenderPasses with AfterRendering as renderEvent while finalPostProcessing is not needed. Fixed the shader graph usage of Unity cross fade. Fixed a stencil test issue when a RendererObjects feature is injected after Post Processing. Fixed incorrect Depth for Camera Stacks. Fixed a capture pass issue so the recorder screenshot doesn't miss the post processing results. Fixed a capture pass issue so the recorder screenshot doesn't miss the post processing results. Fixed stale light cookie data when the last cookie is removed inside a prefab. Added a warning when there are more visible lights than maximum light cookies. Added multi_compile_instancing to the SimpleLit shader on SM 2.0. [14.0.2] - 2021-02-04 This version is compatible with Unity 2022.2.0a14. Added Added Soft Shadows filtering quality as per light option. Low, PCF 3x3 pixel area with fixed offsets which is recommended for mobile. Medium, Tent 5x5 pixel area as the default. High, Tent 7x7 pixel area. Added default DOTS compatible loading shader (FallbackLoading.shader) Add #pragma editor_sync_compilation directive to FallbackError.shader Added commandBuffer variable to RenderingData struct and switched all of the renderer to use that buffer instead of creating local command buffers. Added automatic Alpha-To-Coverage feature which improves visual quality for alpha-clipped opaque geometry when MSAA is enabled Changed PostProcessPass to internal visibility since it's in Internal namespace. Removed SHADER_API_MOBILE from shaders in cases where it affected quality. Removed SHADER_HINT_NICE_QUALITY from shaders. Removed low quality light fade for lighting consistency on both desktop and mobile. Removed SHADER_QUALITY_LOW, SHADER_QUALITY_MEDIUM, SHADER_QUALITY_HIGH from shaders. Everything is now \"SHADER_QUALITY_HIGH\". Merged MaterialError.shader and FallbackError.shader Fixed Fixed camera sorting layer render target not being allocated in the 2d renderer case 1389780 Fixed an issue with too many variants being included in ShaderGraph shaders used in URP. [case 1378545] Fixed an issue in where a user could stack cameras with different renderers and not get a warning in the editor (this is not supported). Fixed decal automatic technique to correctly work with webgl. case 1370326 Fixed ScreenSpaceShadows target which was not bound during draw. case 1388353 Use D24_UNorm_S8_UInt depth buffer format on some platforms to improve performance. [14.0.1] - 2021-12-07 Added Added support for user-selected upscaling filters. Current options are automatic, bilinear, and nearest-neighbor. Added batch mode support for the converters. Added FP16 camera render target option. Added support for user-selected upscaling filters. Current options are automatic, bilinear, and nearest-neighbor. Added support for FidelityFX Super Resolution 1.0 upscaling filter. Added Downscale and Max Iterations options for Bloom Changed Re-added the menu button to be able to convert selected materials. Reverted intermediate texture behavior. Shader Variant Log Level moved from the URP Asset to URP Global Settings. Particle alpha channel blend mode to match standard shader. Removed skipIterations from Bloom settings. It has now been replaced with maxIterations. Fixed Fix mismatch on some platforms between Editor-side and Runtime-side implementations of UnityEngine.Rendering.Universal.DecalRendererFeature.IsAutomaticDBuffer() [case 1364134] Fixed incorrect light indexing on Windows Editor with Android target. case 1378103 Fixed missing depth for Depth of Field in an overlay camera. case 1365623 Fixed FXAA quality issues when render scale is not 1.0. Fixed material converter not being able to be called in batch mode. [case 1375962] Fixed an issue where specular color was not matching behaviour in Legacy and HDRP. case 1326941 Fixed issue where ShadowCasterGroup2D would throw an exception when there were no shadow casters. case 1387201 Fixed a shader compiler issue with mismatching variable types when calling lerp. Fixed single channel compressed (BC4) cookies on main light. Fixed URP Deferred Fog pass does not work in XR singlepass. case 1390236 Fixed an issue where preview cameras were missing the descriptor for creating their RenderTexture case 1393818 Fixed max light count cpu/gpu mismatch on Windows Editor with Android target. case 1392965 Fixed missing shader keyword SHADOWS_SHADOWMASK for shader graph using deferred rendering. Fixed double alpha modulate for particle unlit shader. Fixed incorrect light indexing on Windows Editor with Android target. case 1378103 Fixed missing depth for Depth of Field in an overlay camera. case 1365623 Fixed FXAA quality issues when render scale is not 1.0. Fixed Screen Space Decal to work with fog. 1383719 [14.0.0] - 2021-11-17 Added Renderer Features can now use the HelpURLAttribute to specify a documentation URL to be used in the inspector. Added inspector documentation URLs to the SSAO, Decal, and Render Objects renderer features. Changed \"_USE_DRAW_PROCEDURAL\" to be used only in vertex shader in Post Processing related shaders as they are not needed for fragment shaders. In result we now generate less shader variants. Added support for user-selected upscaling filters. Current options are automatic, bilinear, and nearest-neighbor. Added missing documentation in UniversalRenderPipelineAsset. Reflection Probe sample showing how Probe Blending and box projection works. Fixed Fix shadow rendering correctly to work with shader stripping in WebGl. case 1381881 Fixed incorrect shadow batching and shadow length case 1387859 VFX: Incorrect Decal rendering when rendescale is different than one case 1343674 Fixed inspector documentation URLs for the URP asset and Universal Renderer asset. Fixed render scale setting unintentionally affecting the scene view camera. Fixed property wrappers around material properties. Fixed incorrect light indexing on Windows Editor with Android target. case 1378103 Fixed missing depth for Depth of Field in an overlay camera. case 1365623 Fixed FXAA quality issues when render scale is not 1.0. Fixed an issue where specular color was not matching behaviour in Legacy and HDRP. case 1326941 [13.1.2] - 2021-11-05 Added Added minimal picking support for DOTS 1.0 (on parity with Hybrid Renderer V2) Added support for RTHandle. Changed Converted internal render targets to use RTHandle targets instead of RenderTargetHandle and RenderTargetIdentifier. Set usage of RenderTargetHandle and public functions using RenderTargetIdentifier as obsolete for future removal. Split RendererFeatures AddRenderPasses into two functions with SetupRenderPasses so render targets can be used after allocation. The \"Add Renderer Feature\" menu now supports filtering. Removed the name input for the SSAO and Screen Space Shadows renderer features. Fixed Fixed an issue where 2D global lights with shadows enabled could break light layer batching case 1376487 Fixed broken soft shadow filtering. case 1374960 Fixed Lens Flare not accounting Render Scale setting. case 1376820 Fixed an issue where SSAO would throw a \"RenderingCommandBuffer: invalid pass index\" errors. case 1374215 Fixed performance regression for 2D shaders where alpha discard was disabled. [case 1335648] Fixed an issue with MSAA falling back to the incorrect value when sample count 2 is not supported on some Android GPUs Fixed decals to work with native render pass case 1353141 Fixed decals to work with render scale 1353885 Fixed an issue in where the _ScreenParams is not setup correctly. Fixed an issue where intermediate rendertextures were not scaled when a camera was rendering to a texture case 1342895 [13.1.1] - 2021-10-04 Added Added Depth Texture setting for Overlay Camera. Added Depth Priming support for Vulkan with MSAA. Added Shadows and Additional Lights off variants stripping. Added Adaptive Performance Decals scaler. Exposed public API for DebugDisplaySettings. Added Display Stats panel to Rendering Debugger that displays CPU/GPU frame timings and bottlenecks. Preserve Specular blend mode toggle for glass like materials where the specular reflection itself is not transparent. Emulate alpha for multiply blend mode by whitening the base map colors using the alpha value. Keyword _ALPHAMODULATE_ON is set for multiply blend mode. Changed Main light shadow, additional light shadow and additional light keywords are now enabled based on urp setting instead of existence in scene. This allows better variant stripping. Now using the SpeedTree8 PBRLit shadergraph as the default SpeedTree8 shader for Universal. Changed default target sorting layers of Light2D to \"Everything\". Newly added sorting layers will be included in Light2Ds that have target sorting layers already set to \"Everything\". Separated Premultiplied blend mode and Preserve Specular Lighting feature from each other. Premultiplied blend mode is now true straight premultiply mode. Preserve Specular Lighting, which applies alpha differently for diffuse and specular parts of lighting, is now a separate option for Alpha and Additive blend modes. The results of previous Premultiplied blend implementation can be achieved by using Alpha blend mode with Preserve Specular Lighting toggled on. Multiply blend now keeps DstAlpha as it's RGB only. Particle AlphaModulate() renamed to AlphaModulateAndPremultiply() as it does both. Moved separate AlphaModulate() and AlphaPremultiply() to URP shader library. Fix double alpha multiply for ParticleLit. Improved blending modes trigger a material update which tries to keep the existing look intact. This is not always possible and manual blend mode changes might be required. Fixed Fixed incorrect premultiply blend mode. case 1260085, case 1357703, case 1347301 Fixed a regression where ShaderGraph screen position was not correct in game view and when using XR [1369450] Fixed overwriting of preview camera background color. case 1357004 Fixed ShadowCaster now requires varying normalWS to include changed normals from vertex shader in shader graph. Fixed typo in numIterationsEnclosingSphere api name Fix for rendering thumbnails. case 1348209 Fixed a regression bug where XR camera postion can not be modified in beginCameraRendering [case 1365000] Fixed an issue in where installing the Adaptive Performance package caused errors to the inspector UI 1368161 Fixed a regression where filtering the scene view yielded incorrect visual results 1360233 Fixed disabled debug lighting modes on Vulkan and OpenGL following a shader compiler fix. [case 1334240] Fixed an issue in where the Convert Renderering Settings would cause a freeze. case 1353885 Fixed incorrect behavior of Reflections with Smoothness lighting debug mode. [case 1374181] Fixed a performance regression in the 2D renderer regarding the PostProcessPass [case 1347893] Fixed light banding artifacts on some mobile platforms. case 1375791 [13.1.0] - 2021-09-24 Added Added public api and updated docs for Light2D shape properties. Changed URP will no longer render via an intermediate texture unless actively required by a Renderer Feature. See the upgrade guide for compatibility options and how assets are upgraded. MaterialReimporter.ReimportAllMaterials now batches the asset database changes to improve performance. Fixed Fixed post processing with Pixel Perfect camera case 1363763 Fixed the LensFlare flicker with TAA on SceneView (case 1356734). Fixed an issue where Unlit and ParticlesUnlit shaders did not have HDR color selection for albedo case 1283767 [13.0.0] - 2021-09-01 Added URP global setting for stripping post processing shader variants. URP global setting for stripping off shader variants. Terrain grass shader alpha changed to always write 1 to alpha. Enabled alpha channel write mask. Changed Removed experimental tile deferred code. VFX: New shadergraph support directly on Universal target. Fixed Added warning for lit shader detailed abledo, if texture is not linear. 1342011 Fixed lit detail correctly upgraded from standard shader. 1323725 URP asset can now use multi-edit. case 1364966 Fixed an issue in where the current open scene didn't load after running the converters. [case 1365101] Added \"Conservative Enclosing Sphere\" setting to fix shadow frustum culling issue where shadows are erroneously culled in corners of cascades case 1153151 Fixed memory leak with XR combined occlusion meshes. [case 1366173] Fixed a bug with Sprite Targets in ShaderGraph not rendering correctly in game view [1352225] Changed Remove use of deprecated UNITY_USE_NATIVE_HDR keyword in shaders. [12.0.0] - 2021-01-11 Added Added support for default sprite mask shaders for the 2D Renderer in URP. Added View Vector node to mimic old behavior of View Direction node in URP. Added support for the PlayStation 5 platform. Enabled deferred renderer in UI. Added support for light layers, which uses Rendering Layer Masks to make Lights in your Scene only light up specific Meshes. 2D Light Texture Node. A Shader Graph node that enable sampling of the Light Textures generated by the 2D Renderer in a lit scene. Fixed an error where multisampled texture being bound to a non-multisampled sampler in XR. case 1297013 Added _SURFACE_TYPE_TRANSPARENT keyword to URP shaders. Added Depth and DepthNormals passes to particles shaders. Added support for SSAO in Particle and Unlit shaders. Added Decal support. This includes new Decal Projector component, Decal renderer feature and Decal shader graph. Added a SpeedTree 8 Shader Graph but did not set it as the default when importing or upgrading Speed Tree 8 assets. Because URP doesn't yet support per-material culling, this Shader Graph does not yet behave in the same way as the existing handwritten SpeedTree 8 shader for URP. Added optional Depth Priming. Allows the forward opaque pass of the base camera to skip shading certain fragments if they don't contribute to the final opaque output. Added blending and box projection for reflection probes. Added 'Store Actions' option that enables bandwidth optimizations on mobile GPU architectures. Added \"Allow Material Override\" option to Lit and Unlit ShaderGraph targets. When checked, allows Material to control the surface options (transparent/opaque, blend mode, etc). Added a new UI for Render Pipeline Converters. Used now for Built-in to Universal conversion. Added sections on Light Inspector. Reorder camera inspector to be in the same order as HDRP. Added new URP Debug Views under Window/Analysis/Rendering Debugger. Added support for controlling Volume Framework Update Frequency in UI on Cameras and URP Asset as well as through scripting. Added URP Global Settings Asset to the Graphics Settings - a common place for project-wide URP settings. Added possibility to rename light layer values. Added Light cookies support to directional, point and spot light. Directional light cookie is main light only feature. Added GetUniversalAdditionalLightData, a method that returns the additional data component for a given light or create one if it doesn't exist yet. VFX: Basic support of Lit output. Added Motion Vector render pass for URP. VFX: Fix light cookies integration. Added Lights 2D to the Light Explorer window. Two new URP specific scene templates, Basic which has a camera and directional light, then Standard which has the addition of a global volume with basic post effects setup. Added Render Settings Converter to the Render Pipeline Converter, this tool creates and assigns URP Assets based off rendering settings of a Builtin project. XR: Added Late Latching support to reduce VR latency (Quest). Fixed incorrect shadow fade in deferred rendering mode. Added a help button on material editor to show the shader documentation page Added \"Copy Depth Mode\" Universal Renderer Data option that allows to specify if URP should copy the depth after the opaques pass or after the transparents pass. This can lead to bandwidth savings on mobile. Changed Moved fog evaluation from vertex shader to pixel shader. This improves rendering of fog for big triangles and fog quality. This can change the look of the fog slightly. UNITY_Z_0_FAR_FROM_CLIPSPACE now remaps to [0, far] range on all platforms consistently. Previously OpenGL platforms did not remap, discarding small amount of range [-near, 0]. Moved all 2D APIs out of experimental namespace. ClearFlag.Depth does not implicitely clear stencil anymore. ClearFlag.Stencil added. The Forward Renderer asset is renamed to the Universal Renderer asset. The Universal Renderer asset contains the property Rendering Path that lets you select the Forward or the Deferred Rendering Path. Improved PixelPerfectCamera UI/UX Changed Pixel Snapping and Upscale Render Texture in the PixelPerfectCamera to a dropdown. Move Assets/Create/Rendering/Universal Render Pipeline/Pipeline Asset (2D Renderer) to Assets/Create/Rendering/URP Asset (with 2D Renderer) Move Assets/Create/Rendering/Universal Render Pipeline/2D Renderer to Assets/Create/Rendering/URP 2D Renderer Move Assets/Create/Rendering/Universal Render Pipeline/Renderer Feature to Assets/Create/Rendering/URP Renderer Feature Move Assets/Create/Rendering/Universal Render Pipeline/Post-process Data to Assets/Create/Rendering/URP Post-process Data Move Assets/Create/Rendering/Universal Render Pipeline/Pipeline Asset (Forward Renderer) to Assets/Create/Rendering/URP Asset (with Forward Renderer) Move Assets/Create/Rendering/Universal Render Pipeline/XR System Data to Assets/Create/Rendering/URP XR System Data Move Assets/Create/Rendering/Universal Render Pipeline/Forward Renderer to Assets/Create/Rendering/URP Forward Renderer Removing unused temporary depth buffers for Depth of Field and Panini Projection. Optimized the Bokeh Depth of Field shader on mobile by using half precision floats. Changed UniversalRenderPipelineCameraEditor to URPCameraEditor Made 2D shadow casting more efficient Reduced the size of the fragment input struct of the TerrainLitPasses and LitGBufferPass, SimpleLitForwardPass and SimpleLitGBufferPass lighting shaders. Bokeh Depth of Field performance improvement: moved some calculations from GPU to CPU. Advanced Options > Priority has been renamed to Sorting Priority Opacity as Density blending feature for Terrain Lit Shader is now disabled when the Terrain has more than four Terrain Layers. This is now similar to the Height-blend feature for the Terrain Lit Shader. DepthNormals passes now sample normal maps if used on the material, otherwise output the geometry normal. SSAO Texture is now R8 instead of ARGB32 if supported by the platform. Enabled subsurface scattering with GI on handwritten Universal ST8 shader. Material upgrader now also upgrades AnimationClips in the project that have curves bound to renamed material properties. 2D Lights now inherit from Light2DBase. The behavior of setting a camera's Background Type to \"Dont Care\" has changed on mobile. Previously, \"Dont Care\" would behave identically to \"Solid Color\" on mobile. Now, \"Dont Care\" corresponds to the render target being filled with arbitrary data at the beginning of the frame, which may be faster in some situations. Note that there are no guarantees for the exact content of the render target, so projects should use \"Dont care\" only if they are guaranteed to render to, or otherwise write every pixel every frame. Stripping shader variants per renderer features instead of combined renderer features. When MSAA is enabled and a depth texture is required, the opaque pass depth will be copied instead of scheduling a depth prepass. URP Asset Inspector - Advanced settings have been reordered under Show Additional Properties on each section. Changed the default name when a new urp asset is created. URP Asset Inspector - General section has been renamed to Rendering. Refactored some of the array resizing code around decal projector rendering to use new APIs in render core UniversalRendererData and ForwardRendererData GUIDs have been reversed so that users coming from 2019LTS, 2020LTS and 2021.1 have a smooth upgrade path, you may encounter issues coming from 2021.2 Alpha/Beta versions and are recommended to start with a fresh library if initial upgrade fails. Fixed Fixed an issue in PostProcessPass causing OnGUI draws to not show on screen. [case 1346650] Fixed an issue with the blend mode in Sprite-Lit-Default shader causing alpha to overwrite the framebuffer. case 1331392 Fixed pixel perfect camera rect not being correctly initialized. case 1312646 Camera Inspector Stack list edition fixes. Fix indentation of Emission map on material editor. Fixed additional camera data help url Fixed additional light data help url Fixed Opacity as Density blending artifacts on Terrain that that caused Terrain to have modified splat weights of zero in some areas and greater than one in others. case 1283124 Fixed an issue where Sprite type Light2Ds would throw an exeception if missing a sprite Fixed an issue where Sprite type Light2Ds were missing a default sprite Fixed an issue where ShadowCasters were sometimes being rendered twice in the editor while in playmode. Fixed an issue where ShadowCaster2D was generating garbage when running in the editor. case 1304158 Fixed an issue where the 2D Renderer was not rendering depth and stencil in the normal rendering pass Fixed an issue where 2D lighting was incorrectly calculated when using a perspective camera. Fixed an issue where objects in motion might jitter when the Pixel Perfect Camera is used. case 1300474 Fixed an issue where filtering in the scene view would not properly highlight the filtered objects. case 1324359 Fixed an issue where the scene view camera was not correctly cleared for the 2D Renderer. case 1311377 Fixed an issue where the letter box/pillar box areas were not properly cleared when the Pixel Perfect Camera is used. case 1291224 Fixed an issue where the Cinemachine Pixel Perfect Extension might cause the Orthographic Size of the Camera to jump to 1 when the Scene is loaded. case 1249076 Fixed an issue where 2D Shadows were casting to the wrong layers [case 1300753][https://issuetracker.unity3d.com/product/unity/issues/guid/1300753/] Fixed an issue where Light2D did not upgrade Shadow Strength, Volumetric Intensity, Volumetric Shadow Strength correctly case 1317755 Fixed an issue where render scale was breaking SSAO in scene view. case 1296710 Fixed GC allocations from XR occlusion mesh when using multipass. SMAA post-filter only clear stencil buffer instead of depth and stencil buffers. Fixed an issue where the inspector of Renderer Data would break after adding RenderObjects renderer feature and then adding another renderer feature. Fixed an issue where soft particles did not work with orthographic projection. case 1294607 Fixed wrong shader / properties assignement to materials created from 3DsMax 2021 Physical Material. (case 1293576) Normalized the view direction in Shader Graph to be consistent across Scriptable Render Pieplines. Fixed material upgrader to run in batch mode [case 1305402] Fixed gizmos drawing in game view. case 1302504 Fixed an issue in shaderGraph target where the ShaderPass.hlsl was being included after SHADERPASS was defined Fixed base camera to keep render texture in sync with camera stacks. case 1288105 Fixed base camera to keep viewport in sync with camera stacks. case 1311268 Fixed base camera to keep display index in sync with camera stacks. case 1252265 Fixed base camera to keep display index in sync with camera stacks for canvas. case 1291872 Fixed render pass reusage with camera stack on vulkan. case 1226940 Fixed camera stack UI correctly work with prefabs. case 1308717 Fixed an issue where Particle Lit shader had an incorrect fallback shader [case 1312459] Fixed an issue with backbuffer MSAA on Vulkan desktop platforms. Fixed shadow cascade blend culling factor. Fixed remove of the Additional Light Data when removing the Light Component. Fixed remove of the Additional Camera Data when removing the Camera Component. Fixed shadowCoord error when main light shadow defined in unlit shader graph case 1175274 Removed Custom.meta which was causing warnings. case 1314288 Fixed a case where shadow fade was clipped too early. Fixed an issue where SmoothnessSource would be upgraded to the wrong value in the material upgrader. Fixed multi editing of Bias property on lights. [case 1289620] Fixed an issue where bokeh dof is applied incorrectly when there is an overlay camera in the camera stack. case 1303572 Fixed SafeNormalize returning invalid vector when using half with zero length. [case 1315956] Fixed lit shader property duplication issue. case 1315032 Fixed undo issues for the additional light property on the UniversalRenderPipeline Asset. [case 1300367] Fixed an issue where SSAO would sometimes not render with a recently imported renderer. Fixed a regression where the precision was changed. case 1313942 Fixed an issue where motion blur would allocate memory each frame. case 1314613 Fixed an issue where using Camera.targetTexture with Linear Color Space on an Android device that does not support sRGB backbuffer results in a RenderTexture that is too bright. [case 1307710] Fixed issue causing missing shaders on DirectX 11 feature level 10 GPUs. case 1278390 Fixed errors when the Profiler is used with XR multipass. case 1313141 Fixed materials being constantly dirty. Fixed double sided and clear coat multi editing shader. Fixed issue where copy depth depth pass for gizmos was being skipped in game view case 1302504 Fixed an issue where transparent objects sampled SSAO. Fixed an issue where Depth Prepass was not run when SSAO was set to Depth Mode. Fixed an issue where changing camera's position in the BeginCameraRendering do not apply properly. [case 1318629] (https://issuetracker.unity3d.com/issues/camera-doesnt-move-when-changing-its-position-in-the-begincamerarendering-and-the-endcamerarendering-methods) Fixed depth of field pass usage on unsupported devices. case 1327076 Fixed an issue where SMAA did not work for OpenGL case 1318214 Fixed an issue with Shader Graph Lit shaders where the normalized view direction produced incorrect lighting. [1332804] Fixed return values from GetStereoProjectionMatrix() and SetStereoViewMatrix(). case 1312813 Fixed CopyDepthPass incorrectly always enqueued when deferred rendering mode was enabled when it should depends on the pipeline asset settings. Fixed renderer post processing option to work with asset selector re-assing. case 1319454 Fixed post processing to be enabled by default in the renderer when creating URP asset option. case 1333461 Fixed shaderGraph shaders to render into correct depthNormals passes when deferred rendering mode and SSAO are enabled. Fixed ordering of subshaders in the Unlit Shader Graph, such that shader target 4.5 takes priority over 2.0. case 1328636 Fixed issue where it will clear camera color if post processing is happening on XR [case 1324451] Fixed a case where camera dimension can be zero. case 1321168 Fixed renderer creation in playmode to have its property reloaded. [case 1333463] Fixed gizmos no longer allocate memory in game view. [case 1328852] Fixed an issue where shadow artefacts appeared between cascades on Terrain Detail objects. Fixed ShaderGraph materials to select render queue in the same way as handwritten shader materials by default, but allows for a user override for custom behavior. [case 1335795] Fixed sceneview debug mode rendering (case 1211436). URP Global Settings can now be unassigned in the Graphics tab (case 1343570). VFX: Fixed soft particles when HDR or Opaque texture isn't enabled VFX: Fixed OpenGL soft particles fallback when depth texture isn't available Fixed soft shadows shader variants not set to multi_compile_fragment on some shaders (gbuffer pass, speedtree shaders, WavingGrass shader). Fixed issue with legacy stereo matrices with XR multipass. [case 1342416] Fixed unlit shader function name ambiguity Fixed Terrain holes not appearing in shadows [case 1349305] VFX: Compilation issue with ShaderGraph and planar lit outputs case 1349894 Fixed an issue where _AfterPostProcessTexture was no longer being assigned in UniversalRenderer. Fixed an issue where TerrainLit was rendering color lighter than Lit [case 1340751] (https://issuetracker.unity3d.com/product/unity/issues/guid/1340751/) Fixed Camera rendering when capture action and post processing present. [case 1350313] Fixed artifacts in Speed Tree 8 billboard LODs due to SpeedTree LOD smoothing/crossfading [case 1348407] Fix sporadic NaN when using normal maps with XYZ-encoding case 1351020 Support undo of URP Global Settings asset assignation (case 1342987). Removed unsupported fields from Presets of Light and Camera [case 1335979]. Fixed graphical artefact when terrain height map is used with rendering layer mask for lighting. Fixed URP's vignette effect to respect XR's view center, since with Asymmetric FOV, the center of the view is not always the center of the texture case 1358336 Fixed an issue where screen space shadows has flickering with deferred mode case 1354681 Fixed shadowCascadeBlendCullingFactor to be 1.0 Fixed missing property values in a RendererFeature of screen space shadows by adding tooltip for it instead of showing them. [case 1327356] Changed Change Asset/Create/Shader/Universal Render Pipeline/Lit Shader Graph to Asset/Create/Shader Graph/URP/Lit Shader Graph Change Asset/Create/Shader/Universal Render Pipeline/Sprite Lit Shader Graph to Asset/Create/Shader Graph/URP/Sprite Lit Shader Graph Change Asset/Create/Shader/Universal Render Pipeline/Unlit Shader Graph to Asset/Create/Shader Graph/URP/Unlit Shader Graph Change Asset/Create/Shader/Universal Render Pipeline/Sprite Unlit Shader Graph to Asset/Create/Shader Graph/URP/Sprite Unlit Shader Graph Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Project Materials to 2D Renderer Materials to Edit/Rendering/Materials/Convert All Built-in Materials to URP 2D Renderer Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Scene Materials to 2D Renderer Materials to Edit/Rendering/Materials/Convert All Built-in Scene Materials to URP 2D Renderer Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Project URP Parametric Lights to Freeform to Edit/Rendering/Lights/Convert Project URP Parametric Lights to Freeform Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Scene URP Parametric Lights to Freeform to Edit/Rendering/Lights/Convert Scene URP Parametric Lights to Freeform Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Project Materials to URP Materials to Edit/Rendering/Materials/Convert All Built-in Materials to URP Moved Edit/Render Pipeline/Universal Render Pipeline/Upgrade Selected Materials to URP Materials to Edit/Rendering/Materials/Convert Selected Built-in Materials to URP Deprecated GetShadowFade in Shadows.hlsl, use GetMainLightShadowFade or GetAdditionalLightShadowFade. Improved shadow cascade GUI drawing with pixel perfect, hover and focus functionalities. Shadow fade now uses border value for calculating shadow fade distance and fall off linearly. Improved URP profiling scopes. Remove low impact scopes from the command buffer for a small performance gain. Fix the name and invalid scope for context.submit() scope. Change the default profiling name of ScriptableRenderPass to Unnamed_ScriptableRenderPass. Using the same MaterialHeaderScope for material editor as HDRP is using Removed Code to upgrade from LWRP to URP was removed. This means if you want to upgrade from LWRP you must first upgrade to previous versions of URP and then upgrade to this version. [11.0.0] - 2020-10-21 Added Added real-time Point Light Shadows. Added a supported MSAA samples count check, so the actual supported MSAA samples count value can be assigned to RenderTexture descriptors. Added the TerrainCompatible SubShader Tag. Use this Tag in your custom shader to tell Unity that the shader is compatible with the Terrain system. Added _CameraSortingLayerTexture global shader variable and related parameters Added preset shapes for creating a freeform light Added serialization of Freeform ShapeLight mesh to avoid CPU cost of generating them on the runtime. Added 2D Renderer Asset Preset for creating a Universal Renderer Asset Added an option to use faster, but less accurate approximation functions when converting between the sRGB and Linear color spaces. Added screen space shadow as renderer feature Added [DisallowMultipleRendererFeature] attribute for Renderer Features. Added support for Enlighten precomputed realtime Global Illumination. Changed Optimized 2D Renderer performance on mobile GPUs by reducing the number of render target switches. Optimized 2D Renderer performance by rendering the normal buffer at the same lower resolution as the light buffers. Improved Light2D UI/UX Improved 2D Menu layout Deprecated Light2D Parametric Light Deprecated Light2D point light cookie Renamed Light2D point light to spot light 2D Renderer: The per Blend Style render texture scale setting was replaced by a global scale setting for all Blend Styles. Optimized 2D Renderer performance by using a tiny light texture for layer/blend style pairs for which no light is rendered. Reorgnized the settings in 2D Renderer Data Inspector. FallOff Lookup Texture is now part of 2D RenderData. Creating a Shadow Caster 2D will use try and use sprite and physics bounds as the default shape Deleting all points in a Shadow Caster will cause the shape to use the bounds. Improved Geometry for Smooth Falloff of 2D Shape Lights. Updated the tooltips for Light 2D Inspector. Removed the Custom blend Mode option from the Blend Styles. New default Blend Styles when a new 2D Renderer Data asset is created. Added a supported MSAA samples count check, so the actual supported MSAA samples count value can be assigned to RenderTexture descriptors. Bloom in Gamma color-space now more closely matches Linear color-space, this will mean project using Bloom and Gamma color-space may need to adjust Bloom Intensity to match previous look. Autodesk Interactive Shader Graph files and folders containing them were renamed. The new file paths do not have spaces. Moved FinalPostProcessPass to AfterRenderingPostProcessing event from AfterRendering. This allows user pass to execute before and after FinalPostProcessPass and CapturePass to capture everything. Changed shader keywords of main light shadow from toggling to enumerating. Always use \"High\" quality normals, which normalizes the normal in pixel shader. \"Low\" quality normals looked too much like a bug. Re-enabled implicit MSAA resolve to backbuffer on Metal MacOS. Optimized 2D performance by rendering straight to the backbuffer if possible Changed Post Process Data to bool. When it is no enabled all post processing is stripped from build, when it is enabled you can still override resources there. Converted XR automated tests to use MockHMD. Improved 2D Renderer performance on mobile GPUs when using MSAA Reduced the size of the fragment input struct of the Terrain and Forward lighting shaders. Fixed Fixed an issue where additional lights would not render with WebGL 1 Fixed an issue where the 2D Renderer was incorrectly rendering transparency with normal maps on an empty background. Fixed an issue that that caused a null error when creating a Sprite Light. case 1307125 Fixed an issue where Sprites on one Sorting Layer were fully lit even when there's no 2D light targeting that layer. Fixed an issue where null reference exception was thrown when creating a 2D Renderer Data asset while scripts are compiling. case 1263040 Fixed an issue where no preview would show for the lit sprite master node in shadergraph Fixed an issue where no shader was generated for unlit sprite shaders in shadergraph Fixed an issue where Sprite-Lit-Default shader's Normal Map property wasn't affected by Tiling or Offset. case 1270850 Fixed an issue where normal-mapped Sprites could render differently depending on whether they're dynamically-batched. case 1286186 Removed the warning about mis-matched vertex streams when creating a default Particle System. case 1285272 Fixed latest mockHMD renderviewport scale doesn't fill whole view after scaling. [case 1286161] (https://issuetracker.unity3d.com/issues/xr-urp-renderviewportscale-doesnt-fill-whole-view-after-scaling) Fixed camera renders black in XR when user sets invalid MSAA value. Fixed an issue causing additional lights to stop working when set as the sun source. case 1278768 Fixed an issue causing passthrough camera to not render. case 1283894 Fixed an issue that caused a null reference when Lift Gamma Gain was being displayed in the Inspector and URP was upgraded to a newer version. case 1283588 Fixed an issue where soft particles were not rendered when depth texture was disabled in the URP Asset. case 1162556 Fixed an issue where soft particles were rendered opaque on OpenGL. case 1226288 Fixed an issue where the depth texture sample node used an incorrect texture in some frames. case 1268079 Fixed a compiler error in BakedLit shader when using Hybrid Renderer. Fixed an issue with upgrading material set to cutout didn't properly set alpha clipping. case 1235516 Fixed XR camera fov can be changed through camera inspector. Fixed an issue where Universal Render Pipeline with disabled antiAliasing was overwriting QualitySettings.asset on frequent cases. case 1219159 Fixed a case where overlay camera with output texture caused base camera not to render to screen. case 1283225 Fixed an issue where the scene view camera ignored the pipeline assets HDR setting. case 1284369 Fixed an issue where the Camera inspector was grabbing the URP asset in Graphics Settings rather than the currently active. Fixed an issue where the Light Explorer was grabbing the URP asset in Graphics Settings rather than the currently active. Fixed an issue causing materials to be upgraded multiple times. Fixed bloom inconsistencies between Gamma and Linear color-spaces. Fixed an issue in where all the entries in the Renderer List wasn't selectable and couldn't be deleted. Fixed Deferred renderer on some Android devices by forcing accurate GBuffer normals. [case 1288042] Fixed an issue where MSAA did not work in Editor Game View on Windows with Vulkan. Fixed issue where selecting and deselecting Forward Renderer asset would leak memory case 1290628 Fixed the default background color for previews to use the original color. Fixed an issue where the scene view would turn black when bloom was enabled. case 1298790 Fixed an issue where having \"Opaque Texture\" and MSAA enabled would cause the opaque texture to be rendered black on old Apple GPUs case 1247423 Fixed SAMPLE_TEXTURECUBE_ARRAY_LOD macro when using OpenGL ES. case 1285132 Fixed an issue such that it is now posible to enqueue render passes at runtime. Fixed SpeedTree LOD fade functionality. [case 1198135] [10.2.0] - 2020-10-19 Changed Changed RenderObjectsFeature UI to only expose valid events. Previously, when selecting events before BeforeRenderingPrepasses objects would not be drawn correctly as stereo and camera setup only happens before rendering opaques objects. Transparent Lit ShaderGraph using Additive blending will now properly fade with alpha [1270344] Fixed Fixed the Unlit shader not being SRP Batcher compatible on OpenGLES/OpenGLCore. case 1263720 Fixed an issue with soft particles not rendering correctly for overlay cameras with post processing. case 1241626 Fixed MSAA override on camera does not work in non-XR project if target eye is selected to both eye. [10.1.0] - 2020-10-12 Added support for the Shadowmask Mixed Lighting Mode (Forward only), which supports up to four baked-shadow Lights. Added ComplexLit shader for advanced material features and deferred forward fallback. Added Clear Coat feature for ComplexLit shader and for shader graph. Added Parallax Mapping to the Lit shader (Lit.shader). Added the Detail Inputs setting group in the Lit shader (Lit.shader). Added Smooth shadow fading. Added SSAO support for deferred renderer. The pipeline now outputs a warning in the console when trying to access camera color or depth texture when those are not valid. Those textures are only available in the context of ScriptableRenderPass. Added a property to access the renderer from the CameraData. Changed Shader functions SampleSH9, SampleSHPixel, SampleSHVertex are now gamma corrected in gamma space. As result LightProbes are gamma corrected too. The maximum number of visible lights when using OpenGL ES 3.x on Android now depends on the minimum OpenGL ES 3.x version as configured in PlayerSettings. The default value of the HDR property of a newly created Universal Render Pipeline Asset, is now set to true. Fixed Fixed an issue where the CapturePass would not capture the post processing effects. Fixed an issue were the filter window could not be defocused using the mouse. case 1242032 Fixed camera backgrounds not matching between editor and build when background is set to 'Uninitialized'. case 1224369 Fixed a case where main light hard shadows would not work if any other light is present with soft shadows.case 1250829 Fixed issue that caused color grading to not work correctly with camera stacking. case 1263193 Fixed an issue that caused an infinite asset database reimport when running Unity in command line with -testResults argument. Fixed ParticlesUnlit shader to use fog color instead of always black. [case 1264585] Fixed issue that caused some properties in the camera to not be bolded and highlighted when edited in prefab mode. case 1230082 Fixed issue where blur would sometimes flicker case 1224915 Fixed an issue in where the camera inspector didn't refresh properly when changing pipeline in graphic settings. case 1222668 Fixed depth of field to work with dynamic resolution. case 1225467 Fixed FXAA, SSAO, Motion Blur to work with dynamic resolution. Fixed an issue where Pixel lighting variants were stripped in builds if another URP asset had Additional Lights set to Per Vertex case 1263514 Fixed an issue where transparent meshes were rendered opaque when using custom render passes case 1262887 Fixed regression from 8.x.x that increased launch times on Android with GLES3. case 1269119 Fixed an issue with a render texture failing assertion when chosing an invalid format. case 1222676 Fixed an issue that caused the unity_CameraToWorld matrix to have z flipped values. case 1257518 Fixed not using the local skybox on the camera game object when the Skybox Material property in the Lighting window was set to null. Fixed an issue where, if URP was not in use, you would sometimes get errors about 2D Lights when going through the menus. Fixed GC when using XR single-pass automated tests. Fixed an issue that caused a null reference when deleting camera component in a prefab. case 1244430 Fixed resolution of intermediate textures when rendering to part of a render texture. case 1261287 Fixed indirect albedo not working with shadergraph shaders in some rare setups. case 1274967 Fixed XR mirroView sRGB issue when color space is gamma. Fixed an issue where XR eye textures are recreated multiple times per frame due to per camera MSAA change. Fixed an issue wehre XR mirror view selector stuck. Fixed LightProbes to have gamma correct when using gamma color space. case 1268911 Fixed GLES2 shader compilation. Fixed useless mip maps on temporary RTs/PostProcessing inherited from Main RT descriptor. Fixed issue with lens distortion breaking rendering when enabled and its intensity is 0. Fixed mixed lighting subtractive and shadowmask modes for deferred renderer. Fixed issue that caused motion blur to not work in XR. Fixed 2D renderer when using Linear rendering on Android directly to backbuffer. Fixed issue where multiple cameras would cause GC each frame. case 1259717 Fixed Missing camera cannot be removed after scene is saved by removing the Missing camera label. case 1252255 Fixed MissingReferenceException when removing Missing camera from camera stack by removing Missing camera label. case 1252263 Fixed slow down in the editor when editing properties in the UI for renderer features. case 1279804 Fixed test 130_UnityMatrixIVP on OpenGL ES 3 Fixed MSAA on Metal MacOS and Editor. [10.0.0] - 2020-06-10 Added Added the option to strip Terrain hole Shader variants. Added support for additional Directional Lights. The amount of additional Directional Lights is limited by the maximum Per-object Lights in the Render Pipeline Asset. Added Package Samples: 2 Camera Stacking, 2 Renderer Features Added default implementations of OnPreprocessMaterialDescription for FBX, Obj, Sketchup and 3DS file formats. Added Transparency Sort Mode and Transparency Sort Axis to 2DRendererData. Added support for a user defined default material to 2DRendererData. Added the option to toggle shadow receiving on transparent objects. Added XR multipass rendering. Multipass rendering is a requirement on many VR platforms and allows graceful fallback when single-pass rendering isn't available. Added support for Camera Stacking when using the Forward Renderer. This introduces the Camera Render Type property. A Base Camera can be initialized with either the Skybox or Solid Color, and can combine its output with that of one or more Overlay Cameras. An Overlay Camera is always initialized with the contents of the previous Camera that rendered in the Camera Stack. Added AssetPostprocessors and Shadergraphs to handle Arnold Standard Surface and 3DsMax Physical material import from FBX. Added [MainTexture] and [MainColor] shader property attributes to URP shader properties. These will link script material.mainTextureOffset and material.color to _BaseMap and _BaseColor shader properties. Added the option to specify the maximum number of visible lights. If you set a value, lights are sorted based on their distance from the Camera. Added the option to control the transparent layer separately in the Forward Renderer. Added the ability to set individual RendererFeatures to be active or not, use ScriptableRendererFeature.SetActive(bool) to set whether a Renderer Feature will execute, ScriptableRendererFeature.isActive can be used to check the current active state of the Renderer Feature. additional steps to the 2D Renderer setup page for quality and platform settings. If Unity Editor Analytics are enabled, Universal collects anonymous data about usage of Universal. This helps the Universal team focus our efforts on the most common scenarios, and better understand the needs of our customers. Added a OnCameraSetup() function to the ScriptableRenderPass API, that gets called by the renderer before rendering each camera Added a OnCameraCleanup() function to the ScriptableRenderPass API, that gets called by the renderer after rendering each camera Added Default Material Type options to the 2D Renderer Data Asset property settings. Added additional steps to the 2D Renderer setup page for quality and platform settings. Added option to disable XR autotests on test settings. Shader Preprocessor strips gbuffer shader variants if DeferredRenderer is not in the list of renderers in any Scriptable Pipeline Assets. Added an option to enable/disable Adaptive Performance when the Adaptive Performance package is available in the project. Added support for 3DsMax's 2021 Simplified Physical Material from FBX files in the Model Importer. Added GI to SpeedTree Added support for DXT5nm-style normal maps on Android, iOS and tvOS Added stencil override support for deferred renderer. Added a warning message when a renderer is used with an unsupported graphics API, as the deferred renderer does not officially support GL-based platforms. Added option to skip a number of final bloom iterations. Added support for Screen Space Ambient Occlusion and a new shader variant _SCREEN_SPACE_OCCLUSION. Added support for Normal Texture being generated in a prepass. Added a ConfigureInput() function to ScriptableRenderPass, so it is possible for passes to ask that a Depth, Normal and/or Opaque textures to be generated by the forward renderer. Added a float2 normalizedScreenSpaceUV to the InputData Struct. Added new sections to documentation: Writing custom shaders, and Using the beginCameraRendering event. Added support for GPU instanced mesh particles on supported platforms. Added API to check if a Camera or Light is compatible with Universal Render Pipeline. Changed Moved the icon that indicates the type of a Light 2D from the Inspector header to the Light Type field. Eliminated some GC allocations from the 2D Renderer. Added SceneSelection pass for TerrainLit shader. Remove final blit pass to force alpha to 1.0 on mobile platforms. Deprecated the CinemachineUniversalPixelPerfect extension. Use the one from Cinemachine v2.4 instead. Replaced PlayerSettings.virtualRealitySupported with XRGraphics.tryEnable. Blend Style in the 2DRendererData are now automatically enabled/disabled. When using the 2D Renderer, Sprites will render with a faster rendering path when no lights are present. Particle shaders now receive shadows The Scene view now mirrors the Volume Layer Mask set on the Main Camera. Drawing order of SRPDefaultUnlit is now the same as the Built-in Render Pipline. Made MaterialDescriptionPreprocessors private. UniversalRenderPipelineAsset no longer supports presets. Case 1197020. The number of maximum visible lights is now determined by whether the platform is mobile or not. Renderer Feature list is now redesigned to fit more closely to the Volume Profile UI, this vastly improves UX and reliability of the Renderer Features List. Default color values for Lit and SimpleLit shaders changed to white due to issues with texture based workflows. You can now subclass ForwardRenderer to create a custom renderer based on it. URP is now computing tangent space per fragment. Optimized the 2D Renderer to skip rendering into certain internal buffers when not necessary. You can now subclass ForwardRenderer to create a custom renderer based on it. URP shaders that contain a priority slider now no longer have an offset of 50 by default. The virtual ScriptableRenderer.FrameCleanup() function has been marked obsolete and replaced by ScriptableRenderer.OnCameraCleanup() to better describe when the function gets invoked by the renderer. DepthOnlyPass, CopyDepthPass and CopyColorPass now use OnCameraSetup() instead of Configure() to set up their passes before executing as they only need to get their rendertextures once per camera instead of once per eye. Updated shaders to be compatible with Microsoft's DXC. Mesh GPU Instancing option is now hidden from the particles system renderer as this feature is not supported by URP. The 2D Renderer now supports camera stacking. 2D shaders now use half-precision floats whenever precise results are not necessary. Removed the ETC1_EXTERNAL_ALPHA variant from Shader Graph Sprite shaders. Eliminated some unnecessary clearing of render targets when using the 2D Renderer. The rendering of 2D lights is more effient as sorting layers affected by the same set of lights are now batched. Removed the 8 renderer limit from URP Asset. Merged the deferred renderer into the forward renderer. Changing the default value of Skip Iterations to 1 in Bloom effect editor Use SystemInfo to check if multiview is supported instead of being platform hardcoded Default attachment setup behaviour for ScriptableRenderPasses that execute before rendering opaques is now set use current the active render target setup. This improves performance in some situations. Combine XR occlusion meshes into one when using single-pass (multiview or instancing) to reduce draw calls and state changes. Shaders included in the URP package now use local Material keywords instead of global keywords. This increases the amount of available global user-defined Material keywords. Fixed Fixed an issue that caused WebGL to render blank screen when Depth texture was enabled case 1240228 Fixed NaNs in tonemap algorithms (neutral and ACES) on platforms defaulting to lower precision. Fixed a performance problem with ShaderPreprocessor with large amount of active shader variants in the project Fixed an issue where linear to sRGB conversion occurred twice on certain Android devices. Fixed an issue where there were 2 widgets showing the outer angle of a spot light. Fixed an issue where Unity rendered fullscreen quads with the pink error shader when you enabled the Stop NaN post-processing pass. Fixed an issue where Terrain hole Shader changes were missing. Case 1179808. Fixed an issue where the Shader Graph SceneDepth node didn't work with XR single-pass (double-wide) rendering. See case 1123069. Fixed Unlit and BakedLit shader compilations in the meta pass. Fixed an issue where the Bokeh Depth of Field shader would fail to compile on a console platform. Fixed an issue where the Scene lighting button didn't work when you used the 2D Renderer. Fixed a performance regression when you used the 2D Renderer. Fixed an issue where the Freeform 2D Light gizmo didn't correctly show the Falloff offset. Fixed an issue where the 2D Renderer rendered nothing when you used shadow-casting lights with incompatible Renderer2DData. Fixed an issue where errors were generated when the Physics2D module was not included in the project's manifest. Fixed an issue where Prefab previews were incorrectly lit when you used the 2D Renderer. Fixed an issue where the Light didn't update correctly when you deleted a Sprite that a Sprite 2D Light uses. Fixed an issue where 2D Lighting was broken for Perspective Cameras. Fixed an issue where resetting a Freeform 2D Light would throw null reference exceptions. Case 1184536. Fixed an issue where Freeform 2D Lights were not culled correctly when there was a Falloff Offset. Fixed an issue where Tilemap palettes were invisible in the Tile Palette window when the 2D Renderer was in use. Case 1162550. Fixed issue where black emission would cause unneccesary inspector UI repaints. Case 1105661. Fixed user LUT sampling being done in Linear instead of sRGB. Fixed an issue when trying to get the Renderer via API on the first frame. Case 1189196. Fixed a material leak on domain reload. Fixed an issue where deleting an entry from the Renderer List and then undoing that change could cause a null reference. Case 1191896. Fixed an issue where the user would get an error if they removed the Additional Camera Data component. Case 1189926. Fixed post-processing with XR single-pass rendering modes. Fixed an issue where Cinemachine v2.4 couldn't be used together with Universal RP due to a circular dependency between the two packages. Fixed an issue that caused shaders containing HDRP string in their path to be stripped from the build. Fixed an issue that caused only selected object to render in SceneView when Wireframe drawmode was selected. Fixed Renderer Features UI tooltips. Case 1191901. Fixed multiple issues where Shader Graph shaders failed to build for XR in the Universal RP. Fixed an issue when using the 2D Renderer where some types of renderers would not be assigned the correct material. Fixed inconsistent lighting between the forward renderer and the deferred renderer, that was caused by a missing normalize operation on vertex normals on some speedtree shader variants. Fixed issue where XR Multiview failed to render when using URP Shader Graph Shaders Fixed lazy initialization with last version of ResourceReloader Fixed broken images in package documentation. Fixed an issue where viewport aspect ratio was wrong when using the Stretch Fill option of the Pixel Perfect Camera. case 1188695 Fixed an issue where setting a Normal map on a newly created material would not update. case 1197217 Fixed an issue where post-processing was not applied for custom renderers set to run on the \"After Rendering\" event case 1196219 Fixed an issue that caused an extra blit when using custom renderers case 1156741 Fixed an issue with transparent objects not receiving shadows when using shadow cascades. case 1116936 Fixed issue where using a ForwardRendererData preset would cause a crash. case 1201052 Fixed an issue where particles had dark outlines when blended together case 1199812 Fixed an issue with deleting shader passes in the custom renderer features list case 1201664 Fixed camera inverse view-projection matrix in XR mode, depth-copy and color-copy passes. Fixed an issue with the null check when UniversalRenderPipelineLightEditor.cs tries to access SceneView.lastActiveSceneView. Fixed an issue where the 'Depth Texture' drop down was incorrectly disabled in the Camera Inspector. Fixed an issue that caused errors if you disabled the VR Module when building a project. Fixed an issue where the default TerrainLit Material was outdated, which caused the default Terrain to use per-vertex normals instead of per-pixel normals. Fixed shader errors and warnings in the default Universal RP Terrain Shader. case 1185948 Fixed an issue where the URP Material Upgrader tried to upgrade standard Universal Shaders. case 1144710 Fixed an issue where some Materials threw errors when you upgraded them to Universal Shaders. case 1200938 Fixed issue where normal maps on terrain appeared to have flipped X-components when compared to the same normal map on a mesh. case 1181518 Fixed an issue where the editor would sometimes crash when using additional lights case 1176131 Fixed RemoveComponent on Camera contextual menu to not remove Camera while a component depend on it. Fixed an issue where right eye is not rendered to. case 1170619 Fixed issue where TerrainDetailLit.shader fails to compile when XR is enabled. Fixed an issue that allowed height-based blending on Terrains with more than 4 materials, which is not supported. Fixed an issue where opaque objects were outputting incorrect alpha values case 1168283 Fixed an issue where a depth texture was always created when post-processing was enabled, even if no effects made use of it. Fixed incorrect light attenuation on some platforms. Fixed an issue where the Volume System would not use the Cameras Transform when no Volume Trigger was set. Fixed an issue where post processing disappeared when using custom renderers and SMAA or no AA Fixed an issue where the 2D Renderer upgrader did not upgrade using the correct default material Fixed an issue with soft particles having dark blending when intersecting with scene geometry case 1199812 Fixed an issue with additive particles blending incorrectly case 1215713 Fixed an issue where camera preview window was missing in scene view. case 1211971 Fixed an issue with shadow cascade values were not readable in the render pipeline asset case 1219003 Fixed an issue where MSAA isn't applied until eye textures are relocated by changing their resolution. case 1197958 Fixed an issue where camera stacking didn't work properly inside prefab mode. case 1220509 Fixed the definition of mad() in SMAA shader for OpenGL. Fixed an issue where partical shaders failed to handle Single-Pass Stereo VR rendering with Double-Wide Textures. case 1201208 Fixed an issue that caused assets to be reimported if player prefs were cleared. case 1192259 Fixed missing Custom Render Features after Library deletion. case 1196338 Fixed not being able to remove a Renderer Feature due to tricky UI selection rects. case 1208113 Fixed an issue where the Camera Override on the Render Object Feature would not work with many Render Features in a row. case 1205185 Fixed UI clipping issue in Forward Renderer inspector. case 1211954 Fixed a Null ref when trying to remove a missing Renderer Feature from the Forward Renderer. case 1196651 Fixed data serialization issue when adding a Renderer Feature to teh Forward Renderer. case 1214779 Fixed issue with AssetPostprocessors dependencies causing models to be imported twice when upgrading the package version. Fixed an issue where NullReferenceException might be thrown when creating 2D Lights. case 1219374 Fixed an issue with a blurry settings icon. case 1201895 Fixed issue that caused the QualitySettings anti-aliasing changing without user interaction. case 1195272 Fixed an issue where Shader Graph shaders generate undeclared identifier 'GetWorldSpaceNormalizeViewDir' error. Fixed an issue where rendering into RenderTexture with Single Pass Instanced renders both eyes overlapping. Fixed an issue where Renderscale setting has no effect when using XRSDK. Fixed an issue where renderScale != 1 or Display.main.requiresBlitToBackbuffer forced an unnecessary blit on XR. Fixed an issue that causes double sRGB correction on Quest. case 1209292 Fixed an issue where terrain DepthOnly pass does not work for XR. Fixed an issue that caused depth texture to be flipped when sampling from shaders case 1225362 Fixed an issue with URP switching such that every avaiable URP makes a total set of supported features such that all URPs are taken into consideration. case 1157420 Fixed an issue where XR multipass repeatedly throws error messages \"Multi pass stereo mode doesn't support Camera Stacking\". Fixed an issue with shadows not appearing on terrains when no cascades were selected case 1226530 Fixed a shader issue that caused the Color in Sprite Shape to work improperly. Fixed an issue with URP switching such that every available URP makes a total set of supported features such that all URPs are taken into consideration. case 1157420 Metallic slider on the Lit shader is now linear meaning correct values are used for PBR. Fixed an issue where Post-Processing caused nothing to render on GLES2. Fixed an issue that causes viewport to not work correctly when rendering to textures. case 1225103 Fixed an issue that caused incorrect sampling of HDR reflection probe textures. Fixed UI text of RenderObjects feature to display LightMode tag instead of Shader Pass Name. case 1201696 Fixed an issue when Linear -> sRGB conversion would not happen on some Android devices. case 1226208 Fixed issue where using DOF at the same time as Dynamic Scaling, the depth buffer was smapled with incorrect UVs. case 1225467 Fixed an issue where an exception would be thrown when resetting the ShadowCaster2D component. case 1225339 Fixe an issue where using a Subtractive Blend Style for your 2D Lights might cause artifacts in certain post-processing effects. case 1215584 Fixed an issue where Cinemachine Pixel Perfect Extension didn't work when CinemachineBrain Update Method is anything other than Late Update. Fixed an issue where Sprite Shader Graph shaders weren't double-sided by default. Fixed an issue where particles using Sprite Shader Graph shaders were invisible. Fixed an issue where Scene objects might be incorrectly affected by 2D Lights from a previous Sorting Layer. Fixed an issue where errors would appear in the Console when entering Play Mode with a 2D Light selected in the Hierarchy. Case 1226918 Fixed an issue that caused Android GLES to render blank screen when Depth texture was enabled without Opaque texture case 1219325 Fixed an issue that caused transparent objects to always render over top of world space UI. case 1219877 Fixed issue causing sorting fudge to not work between shadergraph and urp particle shaders. case 1222762 Fixed shader compilation errors when using multiple lights in DX10 level GPU. case 1222302 Fixed an issue with shadows not being correctly calculated in some shaders. Fixed invalid implementation of one function in LWRP -> URP backward compatibility support. Fixed issue where maximum number of visible lights in C# code did not match maximum number in shader code on some platforms. Fixed OpenGL ES 3.0 support for URP ShaderGraph. case 1230890 Fixed an issue where multi edit camera properties didn't work. case 1230080 Fixed an issue where the emission value in particle shaders would not update in the editor without entering the Play mode. Fixed issues with performance when importing fbx files. Fixed issues with NullReferenceException happening with URP shaders. Fixed an issue that caused memory allocations when sorting cameras. case 1226448 Fixed an issue where grid lines were drawn on top of opaque objects in the preview window. Case 1240723. Fixed an issue where objects in the preview window were affected by layer mask settings in the default renderer. Case 1204376. Fixed an issue with reflections when using an orthographic camera case 1209255 Fixed issue that caused unity_AmbientSky, unity_AmbientEquator and unity_AmbientGround variables to be unintialized. Fixed issue that caused SHADERGRAPH_AMBIENT_SKY, SHADERGRAPH_AMBIENT_EQUATOR and SHADERGRAPH_AMBIENT_GROUND variables to be uninitialized. Fixed SceneView Draw Modes not being properly updated after opening new scene view panels or changing the editor layout. Fixed GLES shaders compilation failing on Windows platform (not a mobile platform) due to uniform count limit. Fixed an issue that caused the inverse view and projection matrix to output wrong values in some platforms. case 1243990 Fixed an issue where the Render Scale setting of the pipeline asset didn't properly change the resolution when using the 2D Renderer. case 1241537 Fixed an issue where 2D lights didn't respect the Camera's Culling Mask. case 1239136 Fixed broken documentation links for some 2D related components. Fixed an issue where Sprite shaders generated by Shader Graph weren't double-sided. case 1261232 Fixed an issue where the package would fail to compile if the Animation module was disabled. case 1227068 Fixed an issue where Stencil settings wasn't serialized properly in sub object case 1241218 Fixed an issue with not being able to remove Light Mode Tags case 1240895 Fixed an issue where preset button could still be used, when it is not supposed to. case 1246261 Fixed an issue where Model Importer Materials used the Standard Shader from the Built-in Render Pipeline instead of URP Lit shader when the import happened at Editor startup. Fixed an issue where only unique names of cameras could be added to the camera stack. Fixed issue that caused shaders to fail to compile in OpenGL 4.1 or below. Fixed an issue where camera stacking with MSAA on OpenGL resulted in a black screen. case 1250602 Optimized shader compilation times by compiling different variant sets for vertex and fragment shaders. Fixed shadows for additional lights by limiting MAX_VISIBLE_LIGHTS to 16 for OpenGL ES 2.0 and 3.0 on mobile platforms. case 1244391 Fixed Lit/SimpleLit/ParticlesLit/ParticlesSimpleLit/ParticlesUnlit shaders emission color not to be converted from gamma to linear color space. [case 1249615] Fixed missing unity_MatrixInvP for shader code and shaderGraph. Fixed XR support for deferred renderer. Fixing RenderObject to reflect name changes done at CustomForwardRenderer asset in project view. case 1246256 Fixing camera overlay stacking adding to respect unity general reference restrictions. case 1240788 Fixed profiler marker errors. case 1240963 Fixed issue that caused the pipeline to not create _CameraColorTexture if a custom render pass is injected. case 1232761 Fixed target eye UI for XR rendering is missing from camera inspector. case 1261612 Fixed an issue where terrain and speedtree materials would not get upgraded by upgrade project materials. case 1204189 Fixed an issue that caused renderer feature to not render correctly if the pass was injected before rendering opaques and didn't implement Configure method. case 1259750 Fixed an issue where postFX's temp texture is not released properly. Fixed an issue where ArgumentOutOfRangeException errors were thrown after removing Render feature case 1268147 Fixed an issue where depth and depth/normal of grass isn't rendered to depth texture. Fixed an issue that impacted MSAA performance on iOS/Metal case 1219054 Fixed an issue that caused a warning to be thrown about temporary render texture not found when user calls ConfigureTarget(0). case 1220871 Fixed performance issues in the C# shader stripper. [7.1.1] - 2019-09-05 Upgrade Guide The render pipeline now handles custom renderers differently. You must now set up renderers for the Camera on the Render Pipeline Asset. Render Pipeline Assets upgrades automatically and either creates a default forward renderer in your project or links the existing custom one that you've assigned. If you have custom renderers assigned to Cameras, you must now add them to the current Render Pipeline Asset. Then you can select which renderer to use on the Camera. Added Added shader function GetMainLightShadowParams. This returns a half4 for the main light that packs shadow strength in x component and shadow soft property in y component. Added shader function GetAdditionalLightShadowParams. This returns a half4 for an additional light that packs shadow strength in x component and shadow soft property in y component. Added a Debug Level option to the Render Pipeline Asset. With this, you can control the amount of debug information generated by the render pipeline. Added ability to set the ScriptableRenderer that the Camera renders with via C# using UniversalAdditionalCameraData.SetRenderer(int index). This maps to the Renderer List on the Render Pipeline Asset. Added shadow support for the 2D Renderer. Added ShadowCaster2D, and CompositeShadowCaster2D components. Added shadow intensity and shadow volume intensity properties to Light2D. Added new Gizmos for Lights. Added CinemachineUniversalPixelPerfect, a Cinemachine Virtual Camera Extension that solves some compatibility issues between Cinemachine and Pixel Perfect Camera. Added an option that disables the depth/stencil buffer for the 2D Renderer. Added manipulation handles for the inner cone angle for spot lights. Added documentation for the built-in post-processing solution and Volumes framework (and removed incorrect mention of the PPv2 package). Changed Increased visible lights limit for the forward renderer. It now supports 256 visible lights except in mobile platforms. Mobile platforms support 32 visible lights. Increased per-object lights limit for the forward renderer. It now supports 8 per-object lights in all platforms except GLES2. GLES2 supports 4 per-object lights. The Sprite-Lit-Default shader and the Sprite Lit Shader Graph shaders now use the vertex tangents for tangent space calculations. Temporary render textures for cameras rendering to render textures now use the same format and multisampling configuration as camera's target texture. All platforms now use R11G11B10_UFloat format for HDR render textures if supported. There is now a list of ScriptableRendererData on the Render Pipeline Asset as opposed to a renderer type. These are available to all Cameras and are included in builds. The renderer override on the Camera is now an enum that maps to the list of ScriptableRendererData on the Render Pipeline Asset. Pixel Perfect Camera now allows rendering to a render texture. Light2D GameObjects that you've created now have a default position with z equal to 0. Documentation: Changed the \"Getting Started\" section into \"Install and Configure\". Re-arranged the Table of Content. Fixed Fixed LightProbe occlusion contribution. case 1146667 Fixed an issue that caused a log message to be printed in the console when creating a new Material. case 1173160 Fixed an issue where OnRenderObjectCallback was never invoked. case 1122420 Fixed an issue where Sprite Masks didn't function properly when using the 2D Renderer. case 1163474 Fixed memory leaks when using the Frame Debugger with the 2D Renderer. Fixed an issue where materials using _Time did not animate in the scene. 1175396 Fixed an issue where the Particle Lit shader had artifacts when both soft particles and HDR were enabled. 1136285 Fixed an issue where the Area Lights were set to Realtime, which caused them to not bake. 1159838 Fixed an issue where the Disc Light did not generate any light. 1175097 Fixed an issue where the alpha was killed when an opaque texture was requested on an offscreen camera with HDR enabled case 1163320. Fixed an issue that caused Orthographic camera with far plane set to 0 to span Unity console with errors. case 1172269 Fixed an issue causing heap allocation in RenderPipelineManager.DoRenderLoop case 1156241 Fixed an issue that caused shadow artifacts when using large spot angle values case 1136165 Fixed an issue that caused self-shadowing artifacts when adjusting shadow near-plane on spot lights. Fixed an issue that caused specular highlights to disappear when the smoothness value was set to 1.0. case 1161827 Fixed an issue in the Material upgrader that caused transparent Materials to not upgrade correctly to Universal RP. case 1170419. Fixed an issue causing shadows to be incorrectly rendered when a light was close to the shadow caster. Fixed post-processing for the 2D Renderer. Fixed an issue in Light2D that caused a black line to appear for a 360 degree spotlight. Fixed a post-processing rendering issue with non-fullscreen viewport. case 1177660 Fixed an issue where Undo would not undo the creation of Additional Camera Data. case 1158861 Fixed an issue where selecting the same drop-down menu item twice would trigger a change event. case 1158861 Fixed an issue where selecting certain objects that use instancing materials would throw console warnings. case 1127324 Fixed a GUID conflict with LWRP. case 1179895 Fixed an issue where the Terrain shader generated NaNs. Fixed an issue that caused the Opaque Color pass to never render at half or quarter resolution. Fixed and issue where stencil state on a ForwardRendererData was reset each time rendering happened. [7.0.1] - 2019-07-25 Changed Platform checks now provide more helpful feedback about supported features in the Inspectors. Fixed Fixed specular lighting related artifacts on Mobile case 1143049 and case 1164822. Post-processing is no longer enabled in the previews. Unity no longer force-enables post-processing on a camera by default. Fixed an issue that caused the Scene to render darker in GLES3 and linear color space. case 1169789 [7.0.0] - 2019-07-17 Universal Render Pipeline LWRP has been renamed to the \"Universal Render Pipeline\" (UniversalRP). UniversalRP is the same as LWRP in terms of features and scope. Classes have moved to the Universal namespace (from LWRP). Upgrade Guide Upgrading to URP is designed to be almost seamless from the user side. LWRP package still exists, this forwards includes and classes to the UniversalRP Package. Please see the more involved upgrade guide (https://docs.google.com/document/d/1Xd5bZa8pYZRHri-EnNkyhwrWEzSa15vtnpcg--xUCIs/). Added Initial Stadia platform support. Added a menu option to create a new ScriptableRendererFeature script. To do so in the Editor, click on Asset > Create > Rendering > Lightweight Render Pipeline > Renderer Feature. Added documentation for SpeedTree Shaders in LWRP. Added extended features to LWRP Terrain Shader, so terrain assets can be forward-compatible with HDRP. Enabled per-layer advanced or legacy-mode blending in LWRP Terrain Shader. Added the documentation page \"Rendering in LWRP\", which describes the forward rendering camera loop. Added documentation overview for how Post Processing Version 2 works in LWRP. Added documentation notes and FAQ entry on the 2D Renderer affecting the LWRP Asset. Changed Replaced beginCameraRendering callbacks by non obsolete implementation in Light2D Updated ScriptableRendererFeature and ScriptableRenderPass API docs. Changed shader type Real to translate to FP16 precision on some platforms. Fixed Fixed a case where built-in Shader time values could be out of sync with actual time. case 1142495 Fixed an issue that caused forward renderer resources to not load properly when you upgraded LWRP from an older version to 7.0.0. case 1154925 Fixed GC spikes caused by LWRP allocating heap memory every frame. Fixed distortion effect on particle unlit shader. Fixed NullReference exception caused when trying to add a ScriptableRendererFeature. Fixed issue with certain LWRP shaders not showing when using forward/2D renderer. Fixed the shadow resolve pass and the final pass, so they're not consuming unnecessary bandwidth. case 1152439 Added missing page for 2D Lights in LWRP. Tilemap tiles no longer appear black when you use the 2D renderer. Sprites in the preview window are no longer lit by 2D Scene lighting. Fixed warnings for unsupported shadow map formats for GLES2 API. Disabled shadows for devices that do not support shadow maps or depth textures. Fixed support for LWRP per-pixel terrain. case 1110520 Fixed some basic UI/usability issues with LWRP terrain Materials (use of warnings and modal value changes). Fixed an issue where using LWRP and Sprite Shape together would produce meta file conflicts. Fixed specular calculation fp16 overflow on some platforms Fixed shader compilation errors for Android XR projects. Updated the pipeline Asset UI to cap the render scale at 2x so that it matches the render pipeline implementation limit. [6.7.0] - 2019-05-16 Added Added SpeedTree Shaders. Added two Shader Graph master nodes: Lit Sprite and Unlit Sprite. They only work with the 2D renderer. Added documentation for the 2D renderer. Changed The 2D renderer and Light2D component received a number of improvements and are now ready to try as experimental features. Updated the Feature Comparison Table page to reflect the current state of LWRP features. Fixed When in playmode, the error 'Non matching Profiler.EndSample' no longer appears. case 1140750 LWRP Particle Shaders now correctly render in stereo rendering modes. case 1106699 Shaders with 'debug' in the name are no longer stripped automatically. case 1112983 Fixed tiling issue with selection outline and baked cutout shadows. in the Shadergraph Unlit Master node, Premultiply no longer acts the same as Alpha. case 1114708 Fixed an issue where Lightprobe data was missing if it was needed per-pixel and GPU instancing was enabled. The Soft ScreenSpaceShadows Shader variant no longer gets stripped form builds. case 1138236 Fixed a typo in the Particle Unlit Shader, so Soft Particles now work correctly. Fixed emissive Materials not being baked for some meshes. case 1145297 Camera matrices are now correctly set up when you call rendering functions in EndCameraRendering. case 1146586 Fixed GI not baking correctly while in gamma color space. Fixed a NullReference exception when adding a renderer feature that is contained in a global namespace. case 1147068 Shaders are now set up for VR stereo instancing on Vulkan. case 1142952. VR stereo matrices and vertex inputs are now set up on Vulkan. case 1142952. Fixed the Material Upgrader so it's now run upon updating the LWRP package. 1148764 Fixed a NullReference exception when you create a new Lightweight Render Pipeline Asset. case 1153388 [6.6.0] - 2019-04-01 Added Added support for Baked Indirect mixed lighting. You can now use Light Probes for occlusion. This means that baked lights can now occlude dynamic objects. Added RenderObjects. You can add RenderObjects to a Renderer to perform custom rendering. (WIP) Added an experimental 2D renderer that implements a 2D lighting system. (WIP) Added a Light2D component that works with the 2D renderer to add lighting effects to 2D sprites. Fixed Fixed a project import issue in the LWRP template. Fixed the warnings that appear when you create new Unlit Shader Graphs using the Lightweight Render Pipeline. Fixed light attenuation precision on mobile platforms. Fixed split-screen rendering on mobile platforms. Fixed rendering when using an off-screen camera that renders to a depth texture. Fixed the exposed stencil render state in the renderer. Fixed the default layer mask so it's now applied to a depth pre-pass. Made several improvements and fixes to the render pass UI. Fixed artifacts that appeared due to precision errors in large scaled objects. Fixed an XR rendering issue where Unity required a depth texture. Fixed an issue that caused transparent objects to sort incorrectly. [6.5.0] - 2019-03-07 Added You can now create a custom forward renderer by clicking on Assets/Create/Rendering/Lightweight Render Pipeline/Forward Renderer. This creates an Asset in your Project. You can add additional features to it and drag-n-drop the renderer to either the pipeline Asset or to a camera. You can now add ScriptableRendererFeature to the ScriptableRenderer to extend it with custom effects. A feature is an ScriptableObject that can be drag-n-dropped in the renderer and adds one or more ScriptableRenderPass to the renderer. ScriptableRenderer now exposes interface to configure lights. To do so, implement SetupLights when you create a new renderer. ScriptableRenderer now exposes interface to configure culling. To do so, implement SetupCullingParameters when you create a new renderer. ScriptableRendererData contains rendering resources for ScriptableRenderer. A renderer can be overridden globally for all cameras or on a per-camera basis. ScriptableRenderPass now has a RenderPassEvents. This controls where in the pipeline the render pass is added. ScriptableRenderPass now exposes ConfigureTarget and ConfigureClear. This allows the renderer to automatically figure out the currently active rendering targets. ScriptableRenderPass now exposes Blit. This performs a blit and sets the active render target in the renderer. ScriptableRenderPass now exposes RenderPostProcessing. This renders post-processing and sets the active render target in the renderer. ScriptableRenderPass now exposes CreateDrawingSettings as a helper for render passes that need to call ScriptableRenderContext.DrawRenderers. Changed Removed RegisterShaderPassName from ScriptableRenderPass. Instead, CreateDrawingSettings now takes one or a list of ShaderTagId. Removed remaining experimental namespace from LWRP. All APIrelated to ScriptableRenderer, ScriptableRenderPass, and render pass injection is now out of preview. Removed SetRenderTarget from ScriptableRenderPass. You should never call it. Instead, call ConfigureTarget, and the renderer automatically sets up targets for you. Removed RenderFullscreenQuad from ScriptableRenderer. Use CommandBuffer.DrawMesh and RenderingUtils.fullscreenMesh instead. Removed RenderPostProcess from ScriptableRenderer. Use ScriptableRenderPass.RenderPostProcessing instead. Removed postProcessingContext property from ScriptableRenderer. This is now exposed in RenderingUtils.postProcessingContext. Removed GetCameraClearFlag from ScriptableRenderer. Fixed Fixed y-flip in VR when post-processing is active. Fixed occlusion mesh for VR not rendering before rendering opaques. Enabling or disabling SRP Batcher in runtime works now. Fixed video player recorder when post-processing is enabled. [6.4.0] - 2019-02-21 [6.3.0] - 2019-02-18 [6.2.0] - 2019-02-15 Changed Code refactor: all macros with ARGS have been swapped with macros with PARAM. This is because the ARGS macros were incorrectly named. [6.1.0] - 2019-02-13 [6.0.0] - 2019-02-23 Added You can now implement a custom renderer for LWRP. To do so, implement an IRendererData that contains all resources used in rendering. Then create an IRendererSetup that creates and queues ScriptableRenderPass. Change the renderer type either in the Pipeline Asset or in the Camera Inspector. LWRP now uses the Unity recorder extension. You can use this to capture the output of Cameras. You can now inject a custom render pass before LWRP renders opaque objects. To do so, implement an IBeforeRender interface. Distortion support in all Particle Shaders. An upgrade system for LWRP Materials with MaterialPostprocessor. An upgrade path for Unlit shaders Tooltips for Shaders. SRP Batcher support for Particle Shaders. Docs for these Shaders: Baked Lit, Particles Lit, Particles Simple Lit, and Particles Unlit. LWRP now supports dynamic resolution scaling. The target platform must also support it. LWRP now includes version defines for both C# and Shaders in the format of LWRP_X_Y_Z_OR_NEWER. For example, LWRP_5_3_0_OR_NEWER defines version 5.3.0. The Terrain Lit Shader now samples Spherical Harmonics if you haven't baked any lightmaps for terrain. Added a Priority option, which you can use to tweak the rendering order. This is similar to render queue in the built-in render pipeline. These Shaders now have this option: Lit, Simple Lit, Baked Lit, Unlit, and all three Particle Shaders. Added support for overriding terrain detail rendering shaders, via the render pipeline editor resources asset. Changed You can now only initialize a camera by setting a Background Type. The supported options are Skybox, Solid Color, and Don't Care. LWRP now uses non-square shadowmap textures when it renders directional shadows with 2 shadow cascades. LWRP now uses RGB111110 as the HDR format on mobile devices, when this format is supported. Removed IAfterDepthPrePass interface. We’ve redesigned the Shader GUI. For example, all property names in Shaders are now inline across the board The Simple Lit Shader now has Smoothness, which can be stored in the alpha of specular or albedo maps. The Simple Lit and Particles Simple Lit Shaders now take shininess from the length (brightness) of the specular map. The Double sided property is now Render Face. This means you can also do front face culling. Changed the docs for Lit Shader, Simple Lit Shader and Unlit Shader according to Shader GUI changes. When you create a new LWRP Asset, it will now be initialized with settings that favor performance on mobile platforms. Updated the FAQ section and the Built-in/LWRP feature comparison table. Fixed Several tweaks to reduce bandwidth consumption on mobile devices. The foldouts in the Lightweight Asset inspector UI now remember their state. Added missing meta file for GizmosRenderingPass.cs. Fixed artifacts when using multiple or Depth Only cameras. Case 1072615 Fixed a typo in ERROR_ON_UNSUPPORTED_FUNCTION() that was causing the shader compiler to run out of memory in GLES2. Case 1104271 LWRP now renders shadows on scaled objects correctly. Case 1109017 LWRP now allows some Asset settings to be changed at runtime. Case 1105552 Realtime shadows now work in GLES2. Case 1087251 Framedebugger now renders correctly when stepping through drawcalls. Cameras that request MSAA and Opaque Textures now use less frame bandwidth when they render. Fixed rendering in the gamma color space, so it doesn't appear darker. Particles SImple Lit and Particles Unlit Shaders now work correctly. Soft Particles now work correctly. Camera fading for particles. Fixed a typo in the Unlit IgnoreProjector tag. Particles render in both eyes with stereo instancing Fixed specular issues on mobile. case 1109017 Fixed issue causing LWRP to create MSAA framebuffer even when MSAA setting was disabled. Post-processing in mobile VR is now forced to be disabled. It was causing many rendering issues. Fixed Editor Previews breaking in Play Mode when VR is enabled. Case 1109009 A camera's HDR enable flag is now respected when rendering in XR. Terrain detail rendering now works correctly when LWRP is installed but inactive. [5.2.0] - 2018-11-27 Added LWRP now handles blits that are required by the device when rendering to the backbuffer. You can now enable the SRP Batcher. To do so, go to the Pipeline Asset. Under Advanced, toggle SRP Batcher. Changed Renamed shader variable unity_LightIndicesOffsetAndCount to unity_PerObjectLightData. Shader variables unity_4LightIndices0 and unity_4LightIndices1 are now declared as unity_PerObjectLightIndices array. [5.1.0] - 2018-11-19 Added The user documentation for LWRP is now in this GitHub repo, instead of in the separate GitHub wiki. You can find the most up-to-date pages in the TableOfContents.md file. Pages not listed in that file are still in progress. Changed The LWRP package is no longer in preview. LWRP built-in render passes are now internal. Changed namespace from UnityEngine.Experimental.Rendering.LightweightPipeline to UnityEngine.Rendering.LWRP. Changed namespace from UnityEditor.Experimental.Rendering.LightweightPipeline to UnityEditor.Rendering.LWRP. Fixed LWRP now respects the iOS Player setting Force hard shadows. When you enable this setting, hardware filtering of shadows is disabled. Scene view mode now renders baked lightmaps correctly. Case 1092227 Shadow bias calculations are now correct for both Shader Graph and Terrain shaders. Blit shader now ignores culling. When you select Per Vertex option for Additional Lights, the Per Object Limit option is not greyed out anymore. When you change camera viewport height to values above 1.0, the Unity Editor doesn't freeze anymore. Case 1097497 When you use AR with LWRP, the following error message is not displayed in the console anymore: \"The camera list passed to the render pipeline is either null or empty.\" [5.0.0-preview] - 2018-09-28 Added Added occlusion mesh rendering/hookup for VR You can now configure default depth and normal shadow bias values in the pipeline asset. You can now add the LWRPAdditionalLightData component to a Light to override the default depth and normal shadow bias. You can now log the amount of shader variants in your build. To do so, go to the Pipeline Asset. Under Advanced, select and set the Shader Variant Log Level. Changed Removed the supportedShaderFeatures property from LWRP core. The shader stripper now figures out which variants to strip based on the current assigned pipeline Asset in the Graphics settings. Fixed The following error does not appear in console anymore: (\"Begin/End Profiler section mismatch\") When you select a material with the Lit shader, this no longer causes the following error in the console: (\"Material doesn't have...\"). case 1092354 In the Simple Lit shader, per-vertex additional lights are now shaded properly. Shader variant stripping now works when you're building a Project with Cloud Build. This greatly reduces build times from Cloud Build. Dynamic Objects now receive lighting when the light mode is set to mixed. MSAA now works on Desktop platforms. The shadow bias value is now computed correctly for shadow cascades and different shadow resolutions. case 1076285 When you use Area Light with LWRP, Cast Shadows no longer overlaps with other UI elements in the Inspector. case 1085363 Changed Read/write XRGraphicsConfig -> Read-only XRGraphics interface to XRSettings. [4.0.0-preview] - 2018-09-28 Added When you have enabled Gizmos, they now appear correctly in the Game view. Added requiresDepthPrepass field to RenderingData struct to tell if the runtime platform requires a depth prepass to generate a camera depth texture. The RenderingData struct now holds a reference to CullResults. When HDR is enabled in the Camera but disabled in the Asset, an information box in the Camera Inspector informs you about it. When MSAA is enabled in the Camera but disabled in the Asset, an information box in the Camera Inspector informs you about it. Enabled instancing on the terrain shader. Sorting of opaque objects now respects camera opaqueSortMode setting. Sorting of opaque objects disables front-to-back sorting flag, when camera settings allow that and the GPU has hidden surface removal. LWRP now has a Custom Light Explorer that suits its feature set. LWRP now supports Vertex Lit shaders for detail meshes on terrain. LWRP now has three interactive Autodesk shaders: Autodesk Interactive, Autodesk Interactive Masked and Autodesk Interactive Transparent. [Shader API] The GetMainLight and GetAdditionalLight functions can now compute shadow attenuation and store it in the new shadowAttenuation field in LightData struct. [Shader API] Added a VertexPositionInputs struct that contains vertex position in difference spaces (world, view, hclip). [Shader API] Added a GetVertexPositionInputs function to get an initialized VertexPositionInputs. [Shader API] Added a GetPerObjectLightIndex function to return the per-object index given a for-loop index. [Shader API] Added a GetShadowCoord function that takes a VertexPositionInputs as input. [ShaderLibrary] Added VertexNormalInputs struct that contains data for per-pixel normal computation. [ShaderLibrary] Added GetVertexNormalInputs function to return an initialized VertexNormalInputs. Changed The RenderingData struct is now read-only. ScriptableRendereralways performs a Clear before calling IRendererSetup::Setup. ScriptableRenderPass::Execute no longer takes CullResults as input. Instead, use RenderingDataas input, since that references CullResults. IRendererSetup_Setup no longer takes ScriptableRenderContext and CullResults as input. Shader includes are now referenced via package relative paths instead of via the deprecated shader export path mechanism https://docs.unity3d.com/2018.3/Documentation/ScriptReference/ShaderIncludePathAttribute.html. The LWRP Asset settings were re-organized to be more clear. Vertex lighting now controls if additional lights should be shaded per-vertex or per-pixel. Renamed all Local Lights nomenclature to Additional Lights. Changed shader naming to conform to our SRP shader code convention. [Shader API] Renamed SpotAttenuation function to AngleAttenuation. [Shader API] Renamed _SHADOWS_ENABLED keyword to _MAIN_LIGHT_SHADOWS [Shader API] Renamed _SHADOWS_CASCADE keyword to _MAIN_LIGHT_SHADOWS_CASCADE [Shader API] Renamed _VERTEX_LIGHTS keyword to _ADDITIONAL_LIGHTS_VERTEX. [Shader API] Renamed _LOCAL_SHADOWS_ENABLED to _ADDITIONAL_LIGHT_SHADOWS [Shader API] Renamed GetLight function to GetAdditionalLight. [Shader API] Renamed GetPixelLightCount function to GetAdditionalLightsCount. [Shader API] Renamed attenuation to distanceAttenuation in LightData. [Shader API] Renamed GetLocalLightShadowStrength function to GetAdditionalLightShadowStrength. [Shader API] Renamed SampleScreenSpaceShadowMap functions to SampleScreenSpaceShadowmap. [Shader API] Renamed MainLightRealtimeShadowAttenuation function to MainLightRealtimeShadow. [Shader API] Renamed light constants from Directional and Local to MainLight and AdditionalLights. [Shader API] Renamed GetLocalLightShadowSamplingData function to GetAdditionalLightShadowSamplingData. [Shader API] Removed OUTPUT_NORMAL macro. [Shader API] Removed lightIndex and substractiveAttenuation from LightData. [Shader API] Removed ComputeShadowCoord function. GetShadowCoord is provided instead. All LightweightPipeline references in API and classes are now named LightweightRenderPipeline. Files no longer have the Lightweight prefix. Renamed Physically Based shaders to Lit, ParticlesLit, and TerrainLit. Renamed Simple Lighting shaders to SimpleLit, and ParticlesSimpleLit. [ShaderLibrary] Renamed InputSurfacePBR.hlsl, InputSurfaceSimple.hlsl, and InputSurfaceUnlit to LitInput.hlsl, SimpleLitInput.hlsl, and UnlitInput.hlsl. These files were moved from the ShaderLibrary folder to theShaders. [ShaderLibrary] Renamed LightweightPassLit.hlsl and LightweightPassLitSimple.hlsl to LitForwardPass.hlsl and SimpleLitForwardPass.hlsl. These files were moved from the ShaderLibrary folder to Shaders. [ShaderLibrary] Renamed LightweightPassMetaPBR.hlsl, LightweightPassMetaSimple.hlsl and LighweightPassMetaUnlit to LitMetaPass.hlsl, SimpleLitMetaPass.hlsl and UnlitMetaPass.hlsl. These files were moved from the ShaderLibrary folder to Shaders. [ShaderLibrary] Renamed LightweightPassShadow.hlsl to ShadowCasterPass.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed LightweightPassDepthOnly.hlsl to DepthOnlyPass.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed InputSurfaceTerrain.hlsl to TerrainLitInput.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed LightweightPassLitTerrain.hlsl to TerrainLitPases.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed ParticlesPBR.hlsl to ParticlesLitInput.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed InputSurfacePBR.hlsl to LitInput.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed InputSurfaceUnlit.hlsl to UnlitInput.hlsl. This file was moved to the Shaders folder. [ShaderLibrary] Renamed InputBuiltin.hlsl to UnityInput.hlsl. [ShaderLibrary] Renamed LightweightPassMetaCommon.hlsl to MetaInput.hlsl. [ShaderLibrary] Renamed InputSurfaceCommon.hlsl to SurfaceInput.hlsl. [ShaderLibrary] Removed LightInput struct and GetLightDirectionAndAttenuation. Use GetAdditionalLight function instead. [ShaderLibrary] Removed ApplyFog and ApplyFogColor functions. Use MixFog and MixFogColor instead. [ShaderLibrary] Removed TangentWorldToNormal function. Use TransformTangentToWorld instead. [ShaderLibrary] Removed view direction normalization functions. View direction should always be normalized per pixel for accurate results. [ShaderLibrary] Renamed FragmentNormalWS function to NormalizeNormalPerPixel. Fixed If you have more than 16 lights in a scene, LWRP no longer causes random glitches while rendering lights. The Unlit shader now samples Global Illumination correctly. The Inspector window for the Unlit shader now displays correctly. Reduced GC pressure by removing several per-frame memory allocations. The tooltip for the the camera MSAA property now appears correctly. Fixed multiple C# code analysis rule violations. The fullscreen mesh is no longer recreated upon every call to ScriptableRenderer.fullscreenMesh. [3.3.0-preview] - 2018-01-01 Added Added callbacks to LWRP that can be attached to a camera (IBeforeCameraRender, IAfterDepthPrePass, IAfterOpaquePass, IAfterOpaquePostProcess, IAfterSkyboxPass, IAfterTransparentPass, IAfterRender) ###Changed Clean up LWRP creation of render textures. If we are not going straight to screen ensure that we create both depth and color targets. UNITY_DECLARE_FRAMEBUFFER_INPUT and UNITY_READ_FRAMEBUFFER_INPUT macros were added. They are necessary for reading transient attachments. UNITY_MATRIX_I_VP is now defined. Renamed LightweightForwardRenderer to ScriptableRenderer. Moved all light constants to _LightBuffer CBUFFER. Now _PerCamera CBUFFER contains all other per camera constants. Change real-time attenuation to inverse square. Change attenuation for baked GI to inverse square, to match real-time attenuation. Small optimization in light attenuation shader code. Fixed Lightweight Unlit shader UI doesn't throw an error about missing receive shadow property anymore. [3.2.0-preview] - 2018-01-01 Changed Receive Shadows property is now exposed in the material instead of in the renderer. The UI for Lightweight asset has been updated with new categories. A more clean structure and foldouts has been added to keep things organized. Fixed Shadow casters are now properly culled per cascade. (case 1059142) Rendering no longer breaks when Android platform is selected in Build Settings. (case 1058812) Scriptable passes no longer have missing material references. Now they access cached materials in the renderer.(case 1061353) When you change a Shadow Cascade option in the Pipeline Asset, this no longer warns you that you've exceeded the array size for the _WorldToShadow property. Terrain shader optimizations. [3.1.0-preview] - 2018-01-01 Fixed Fixed assert errors caused by multi spot lights Fixed LWRP-DirectionalShadowConstantBuffer params setting [3.0.0-preview] - 2018-01-01 Added Added camera additional data component to control shadows, depth and color texture. pipeline now uses XRSEttings.eyeTextureResolutionScale as renderScale when in XR. New pass architecture. Allows for custom passes to be written and then used on a per camera basis in LWRP Changed Shadow rendering has been optimized for the Mali Utgard architecture by removing indexing and avoiding divisions for orthographic projections. This reduces the frame time by 25% on the Overdraw benchmark. Removed 7x7 tent filtering when using cascades. Screenspace shadow resolve is now only done when rendering shadow cascades. Updated the UI for the Lighweight pipeline asset. Update assembly definitions to output assemblies that match Unity naming convention (Unity.*). Fixed Post-processing now works with VR on PC. Console platform compiler error Fixed VR multiview rendering by forcing MSAA to be off. There's a current issue in engine that breaks MSAA and Texture2DArray. Fixed UnityPerDraw CB layout GLCore compute buffer compiler error Occlusion strength not being applied on LW standard shaders CopyDepth pass is being called even when a depth from prepass is available GLES2 shader compiler error in IntegrationTests Can't set RenderScale and ShadowDistance by script VR Single Pass Instancing shadows Fixed compilation errors on platforms with limited XRSetting support. [2.0.0-preview] - 2018-01-01 Added Explicit render target load/store actions were added to improve tile utilization Camera opaque color can be requested on the pipeline asset. It can be accessed in the shader by defining a _CameraOpaqueTexture. This can be used as an alternative to GrabPass. Dynamic Batching can be enabled in the pipeline asset Pipeline now strips unused or invalid variants and passes based on selected pipeline capabilities in the asset. This reduces build and memory consuption on target. Shader stripping settings were added to pipeline asset Changed Pipeline Pipeline code is now more modular and extensible. A ForwardRenderer class is initialized by the pipeline with RenderingData and it's responsible for enqueueing and executing passes. In the future pluggable renderers will be supported. On mobile 1 directional light + up to 4 local lights (point or spot) are computed On other platforms 1 directional light + up to 8 local lights are computed Multiple shadow casting lights are supported. Currently only 1 directional + 4 spots light shadows. Shading Framework Directional Lights are always considered a main light in shader. They have a fast shading path with no branching and no indexing. GetMainLight() is provided in shader to initialize Light struct with main light shading data. Directional lights have a dedicated shadowmap for performance reasons. Shadow coord always comes from interpolator. MainLigthRealtimeShadowAttenuation(float4 shadowCoord) is provided to compute main light realtime shadows. Spot and Point lights are always shaded in the light loop. Branching on uniform and indexing happens when shading them. GetLight(half index, float3 positionWS) is provided in shader to initialize Light struct for spot and point lights. Spot light shadows are baked into a single shadow atlas. Shadow coord for spot lights is always computed on fragment. Use LocalLightShadowAttenuation(int lightIndex, float3 positionWS) to comppute realtime shadows for spot lights. Fixed Issue that was causing VR on Android to render black Camera viewport issues UWP build issues Prevent nested camera rendering in the pipeline [1.1.4-preview] - 2018-01-01 Added Terrain and grass shaders ported Updated materials and shader default albedo and specular color to midgrey. Exposed _ScaledScreenParams to shader. It works the same as _ScreenParams but takes pipeline RenderScale into consideration Performance Improvements in mobile Fixed SRP Shader library issue that was causing all constants to be highp in mobile shader error that prevented LWRP to build to UWP shader compilation errors in Linux due to case sensitive includes Rendering Texture flipping issue Standard Particles shader cutout and blending modes crash caused by using projectors issue that was causing Shadow Strength to not be computed on mobile Material Upgrader issue that caused editor to SoftLocks GI in Unlit shader Null reference in the Unlit material shader GUI [1.1.2-preview] - 2018-01-01 Changed Performance improvements in mobile Fixed Shadows on GLES 2.0 CPU performance regression in shadow rendering Alpha clip shadow issues Unmatched command buffer error message Null reference exception caused by missing resource in LWRP Issue that was causing Camera clear flags was being ignored in mobile [1.1.1-preview] - 2018-01-01 Added Added Cascade Split selection UI Added SHADER_HINT_NICE_QUALITY. If user defines this to 1 in the shader Lightweight pipeline will favor quality even on mobile platforms. Changed Shadowmap uses 16bit format instead of 32bit. Small shader performance improvements Fixed Subtractive Mode Shadow Distance does not accept negative values anymore [0.1.24] - 2018-01-01 Added Added Light abstraction layer on lightweight shader library. Added HDR global setting on pipeline asset. Added Soft Particles settings on pipeline asset. Ported particles shaders to SRP library Changed HDR RT now uses what format is configured in Tier settings. Refactored lightweight standard shaders and shader library to improve ease of use. Optimized tile LOAD op on mobile. Reduced GC pressure Reduced shader variant count by ~56% by improving fog and lightmap keywords Converted LW shader library files to use real/half when necessary. Fixed Realtime shadows on OpenGL Shader compiler errors in GLES 2.0 Issue sorting issues when BeforeTransparent custom fx was enabled. VR single pass rendering. Viewport rendering issues when rendering to backbuffer. Viewport rendering issues when rendering to with MSAA turned off. Multi-camera rendering. [0.1.23] - 2018-01-01 Added UI Improvements (Rendering features not supported by LW are hidden) Changed Shaders were ported to the new SRP shader library. Constant Buffer refactor to use new Batcher Shadow filtering and bias improved. Pipeline now updates color constants in gamma when in Gamma colorspace. Optimized ALU and CB usage on Shadows. Reduced shader variant count by ~33% by improving shadow and light classification keywords Default resources were removed from the pipeline asset. Fixed Fixed shader include path when using SRP from package manager. Fixed spot light attenuation to match Unity Built-in pipeline. Fixed depth pre-pass clearing issue. [0.1.12] - 2018-01-01 Added Standard Unlit shader now has an option to sample GI. Added Material Upgrader for stock Unity Mobile and Legacy Shaders. UI improvements Changed Realtime shadow filtering was improved. Fixed Fixed an issue that was including unreferenced shaders in the build. Fixed a null reference caused by Particle System component lights."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2DLightProperties.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2DLightProperties.html",
    "title": "Common properties of 2D Lights | mmo-rpg-unity",
    "keywords": "Common properties of 2D Lights Each 2D Light Type has various properties and options to customize their appearance and behavior. This page documents the properties that are common to all 2D Light Types. following are the common properties used by the different Light types. For properties specific to each of the available Light Types, refer to their respective sections: Freeform Sprite Spot (Note: The Point Light Type has been renamed to the Spot Light Type from URP 11 onwards.) Global Creating a Light Create a 2D Light GameObject by going to GameObject > Light > 2D and selecting one of the five available types: Freeform: You can edit the shape of this Light type with a spline editor. Sprite: You can select a Sprite to create this Light type. Spot: You can control the inner and outer radius, direction and angle of this Light type. Global: This 2D Light affects all rendered Sprites on all targeted sorting layers. The following are the common properties used by the different Light types. Property Function Light Type Select the type of Light you want the selected Light to be. The available types are Freeform, Sprite, Parametric, Spot, and Global. Color Use the color picker to set the color of the emitted light. Intensity Enter the desired brightness value of the Light. The default value is 1. Overlap Operation Select the overlap operation used by this light The operations available are Additive, and Alpha Blend. Target Sorting Layers Select the sorting layers that this Light targets and affects. Blend Style Select the blend style used by this Light. Different blend styles can be customized in the 2D Renderer Asset. Light Order (unavailable for Global Lights) Enter a value here to specify the rendering order of this Light relative to other Lights on the same sorting layer(s). Lights with lower values are rendered first, and negative values are valid. Shadow Strength Use the slider to control the amount of light that Shadow Caster 2Ds block when they obscure this Light. The value scales from 0 (no light is blocked) to 1 (all light is blocked). Volumtric Intensity Use the slider to select the opacity of the volumetric lighting. The value scales from 0 (transparent) to 1 (opaque). Volumetric Shadow Strength Use the slider to control the amount of volumetric light that Shadow Caster 2Ds block when they obscure this Light. The value scales from 0 (no light is blocked) to 1 (all light is blocked). Normal Map Quality Select either Disabled (degfault)m Accurate or Fast to adjust the accuracy of the lighting calculations used. Normal Map Distance (available when Use Normal Map quality is not disabled) Enter the desired distance (in Unity units) between the Light and the lit Sprite. This does not Transform the position of the Light in the Scene. Overlap Operation This property controls the way in the selected Light interacts with other rendered Lights. You can toggle between the two modes by enabling or disabling this property. The effects of both modes are shown in the examples below: Overlap Operation set to Additive Overlap Operation set to Alpha Blend When Overlap Operation is set to Additive, the Light is blended with other Lights additively, where the pixel values of intersecting Lights are added together. This is the default Light blending behavior. When Overlap Operation is set to Alpha Blend, Lights are blended together based on their alpha values. This can be used to completely overwrite one Light with another where they intersect, but the render order of the Lights is also dependent on the Light Order of the different Lights. Light Order The Light Order value determines the position of the Light in the Render queue relative to other Lights that target the same sorting layer(s). Lower numbered Lights are rendered first, with higher numbered Lights rendered above those below. This especially affects the appearance of blended Lights when Overlap Operation is set to Alpha Blend. Intensity Light intensity are available to all types of Lights. Color adjusts the lights color, while intensity allows this color to go above 1. This allows lights which use multiply to brighten a sprite beyond its original color. Use Normal Map All lights except for global lights can be toggled to use the normal maps in the sprites material. When enabled, Distance and Accuracy will be visible as new properties. Use Normal Map: __Disabled Use Normal Map: Enabled Distance Distance controls the distance between the light and the surface of the Sprite, changing the resulting lighting effect. This distance does not affect intensity, or transform the position of the Light in the Scene. The following examples show the effects of changing the Distance values. Distance: 0.5 Distance: 2 Distance: 8 Quality Light quality allows the developer to choose between performance and accuracy. When choosing performance, artefacts may occur. Smaller lights and larger distance values will reduce the difference between fast and accurate. Volume Opacity Volumetric lighting is available to all Light types. Use the Volume Opacity slider to control the visibility of the volumetric light. At a value of zero, no Light volume is shown while at a value of one, the Light volume appears at full opacity. Shadow Intensity The Shadow Intensity property controls the amount of light that Shadow Caster 2Ds block from the Light source which affects the intensity of their shadows. This is available on all non global Light types. Use this slider to control the amount of light that Shadow Caster 2Ds block when they interact with or block this Light. The slider ranges from 0 to 1. At 0, Shadow Caster 2Ds do not block any light coming from the Light source and they create no shadows. At the maximum value of 1, Shadow Caster 2Ds block all light from the Light source and create shadows at full intensity. Shadow Intensity = 0.0 Shadow Intensity = 0.5 Shadow Intensity = 1.0 Shadow Volume Intensity Shadow Volume Intensity determines the amount of volumetric light Shadow Caster 2Ds block from the Light source. It is available on all non global lights, and when Volume Opacity is above zero. Use this slider to control the amount of volumetric light that Shadow Caster 2Ds block when they interact with or block this Light. The slider ranges from 0 to 1. At 0, Shadow Caster 2Ds do not block any light coming from the Light source and they create no shadows. At the maximum value of 1, Shadow Caster 2Ds block all light from the Light source and create shadows at full intensity. Target Sorting Layers Lights only light up the Sprites on their targeted sorting layers. Select the desired sorting layers from the drop-down menu for the selected Light. To add or remove sorting layers, refer to the Tag Manager - Sorting Layers for more information."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2DRendererData_overview.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2DRendererData_overview.html",
    "title": "2D Renderer Data Asset | mmo-rpg-unity",
    "keywords": "2D Renderer Data Asset The 2D Renderer Data Asset contains the settings that affect the way 2D Lights are applied to lit Sprites. You can set the way Lights emulate HDR lighting with the HDR Emulation Scale, or customize your own Light Blend Styles. Refer to their respective pages for more information about their properties and options. Default Material Type Unity assigns a Material of the selected Default Material Type to Sprites when they are created. The available options have the following properties and functions. Lit: Unity assigns a Material with the Lit type (default Material: Sprite-Lit-Default). 2D Lights affect Materials of this type. Unlit: Unity assigns a Material with the Unlit type (default Material: Sprite-Lit-Default). 2D Lights do not affect Materials of this type. Custom: Unity assigns a Material with the Custom type. When you select this option, Unity shows the Default Custom Material box. Assign the desired Material to this box. Use Depth/Stencil Buffer This option is enabled by default. Clear this option to disable the Depth/Stencil Buffer. Doing so might improve your project’s performance, especially on mobile platforms. You should clear this option if you are not using any features that require the Depth/Stencil Buffer (such as Sprite Mask). Camera Sorting Layer Texture The 2D Renderer Data specifies how Unity supplies the shader variable CameraSortingLayerTexture for use in custom shaders. It is recommended that you use this data in the same frame and on the following layers, as using CameraSortingLayerTexture before it has been captured may result in unexpected results. Foremost Sorting Layer All Layers captured for use in the supplied Texture will be drawn from the very back Layer up to and including the Layer specified by Foremost Sorting Layer. Downsampling Method Downsampling reduces the Texture resolution used by CameraSortingLayerTexture. The options are: None, 2x Bilinear, 4x Box, 4x Bilinear. Renderer Features The 2D Renderer supports URP Renderer Features. The setup for the features are called before any of the 2D built-in passes are queued. Refer to the URP Renderer Features documentation for more information."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2DShadows.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2DShadows.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Shadow Caster 2D The Shadow Caster 2D component defines the shape and properties that a Light uses to determine its cast shadows. Add the Shadow Caster 2D component to a GameObject by going to menu: Component > Rendering > 2D > Shadow Caster 2D. Property Function Use Renderer Silhouette Enable this and Self Shadows to include the GameObject Renderer's silhouette as part of the shadow. Enable this and disable Self Shadows to exclude the Renderer's silhouette from the shadow. This option is only available when a valid Renderer is present. Casts Shadows Enable this to have the Renderer cast shadows. Self Shadows Enable this to have the Renderer cast shadows on itself. Use Renderer Silhouette disabled, Self Shadow disabled Use Renderer Silhouette enabled, Self Shadow disabled Use Renderer Silhouette disabled, Self Shadows enabled Use Renderer Silhouette enabled, Self Shadows enabled Composite Shadow Caster 2D The Composite Shadow Caster 2D merges the shape of multiple Shadow Caster 2Ds together as a single Shadow Caster 2D. Add the Composite Shadow Caster 2D component to a GameObject by going to menu: Component > Rendering > 2D > Composite Shadow Caster 2D, then parent GameObjects with the Shadow Caster 2D component to it. The Composite component merges all Shadow Caster 2Ds within this hierarchy, including any Shadow Caster 2Ds on the parent as well. Without Composite Shadow Caster 2D With Composite Shadow Caster 2D"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2d-customlit.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2d-customlit.html",
    "title": "Custom Lighting in 2D | mmo-rpg-unity",
    "keywords": "Custom Lighting in 2D The default lighting model in 2D renderer is meant for generic use and was design to provide some level flexibility. However, it is not infinitely flexible and may not be able to meet the needs for more custom or advance effects. You can now make your own 2D Lighting model. Sprite Custom Lit Shader Graph The new Shader Graph target \"Custom Lit Shader Graph\" provides a great starting point to create a custom lighting model shader. It does not sample the Light Textures but it does have a Normal pass and a fallback Forward pass for use in non 2D Renderer. 2D Light Texture 2D Light Textures are Render Textures created by the 2D Renderer that contain the visible lights in the scene. There are up to 4 textures each representing a blend style in the 2D Renderer Data The built in Lit shaders will sample these textures and combined them with the Sprite's textures to create the lighting effect. 2D Light Texture Node To sample the Light Texture use the new \"2D Light Texture\" node in Shader Graph. The output of the node is the same as the output of a \"Texture 2D\" and should be fed into a \"Texture Sampler\". Creating the Emissive Effect with Custom Lit Shader The emissive effect is the perfect example of utilizing the Custom Lit Shader to create a custom effect. By combining the a mask texture to identify areas of the Sprite that should not receive lighting effect. The \"Secondary Texture\" feature is a great way to load the emissive mask."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2d-index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2d-index.html",
    "title": "| mmo-rpg-unity",
    "keywords": "#2D Graphics Features 2D features included with URP are the 2D Lighting graphics pipeline which allows you to create 2D Lights and 2D lighting effects; and the 2D Pixel Perfect Camera for implementing the pixelated visual style with your projects. The following are the different 2D Light Types included in the package's Light 2D component: Freeform Sprite Spot (Note: The Point Light Type has been renamed to the Spot Light Type from URP 11 onwards.) Global Important: The Parametric Light Type is deprecated from URP 11 onwards. To convert existing Parametric lights to Freeform lights, go to Edit > Render Pipeline > Universal Render Pipeline > Upgrade Project/Scene Parametric Lights to Freeform The package includes the 2D Renderer Data Asset which contains the Blend Styles parameters, and allows you to create up to four custom Light Operations for your Project. Note: If you have the experimental 2D Renderer enabled (menu: Graphics Settings > add the 2D Renderer Asset under Scriptable Render Pipeline Settings), some of the options related to 3D rendering in the URP Asset don't have any impact on your final app or game."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2d-pixelperfect.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/2d-pixelperfect.html",
    "title": "2D Pixel Perfect | mmo-rpg-unity",
    "keywords": "2D Pixel Perfect The 2D Pixel Perfect package contains the Pixel Perfect Camera component, which ensures your pixel art remains crisp and clear at different resolutions, and stable in motion. It is a single component that makes all the calculations Unity needs to scale the viewport with resolution changes, so that you don’t need to do it manually. You can use the component settings to adjust the definition of the rendered pixel art within the camera viewport, and you can use the Run in Edit Mode feature to preview any changes immediately in the Game view. Attach the Pixel Perfect Camera component to the main Camera GameObject in the Scene, it is represented by two green bounding boxes centered on the Camera gizmo in the Scene view. The solid green bounding box shows the visible area in Game view, while the dotted bounding box shows the Reference Resolution. The Reference Resolution is the original resolution your Assets are designed for, its effect on the component's functions is detailed further in the documentation. Before using the component, first ensure your Sprites are prepared correctly for best results with the the following steps. Preparing Your Sprites After importing your textures into the project as Sprites, set all Sprites to the same Pixels Per Unit value. In the Sprites' Inspector window, set their Filter Mode to ‘Point’. Set their Compression to 'None'. Follow the steps below to correctly set the pivot for a Sprite Open the Sprite Editor for the selected Sprite. If __Sprite Mode __is set to ‘Multiple’ and there are multiple Sprite elements, then you need to set a pivot point for each individual Sprite element. Under the Sprite settings, set Pivot to ‘Custom’, then set Pivot Unit Mode to ‘Pixels’. This allows you to set the pivot point's coordinates in pixels, or drag the pivot point around freely in the Sprite Editor and have it automatically snap to pixel corners. Repeat for each Sprite element as necessary. Snap Settings To ensure the pixelated movement of Sprites are consistent with each other, follow the below steps to set the proper snap settings for your project. To open the Snap settings, go to Edit > Snap Settings. Set the Move X/Y/Z properties to 1 divided by the Pixel Perfect Camera’s Asset Pixels Per Unit (PPU) value. For example, if the Asset PPU is 100, you should set the Move X/Y/Z properties to 0.01 (1 / 100 = 0.01). Unity does not apply Snap settings retroactively. If there are any pre-existing GameObjects in the Scene, select each of them and select Snap All Axes to apply the Snap settings. Properties The component's Inspector window Property Function Asset Pixels Per Unit This is the amount of pixels that make up one unit of the Scene. Match this value to the Pixels Per Unit values of all Sprites in the Scene. Reference Resolution This is the original resolution your Assets are designed for. Crop Frame Describes what to do when there is a difference in aspect ratio. Grid Snapping Describes how to handle snapping. Current Pixel Ratio Shows the size ratio of the rendered Sprites compared to their original size. Additional Property Details Reference Resolution This is the original resolution your Assets are designed for. Scaling up Scenes and Assets from this resolution preserves your pixel art cleanly at higher resolutions. Grid Snapping Upscale Render Texture By default, the Scene is rendered at the pixel perfect resolution closest to the full screen resolution. Enable this option to have the Scene rendered to a temporary texture set as close as possible to the Reference Resolution, while maintaining the full screen aspect ratio. This temporary texture is then upscaled to fit the entire screen. The result is unaliased and unrotated pixels, which may be a desirable visual style for certain game projects. Pixel Snapping Enable this feature to snap Sprite Renderers to a grid in world space at render-time. The grid size is based on the Assets Pixels Per Unit value. Pixel Snapping prevents subpixel movement and make Sprites appear to move in pixel-by-pixel increments. This does not affect any GameObjects' Transform positions. Crop Frame Crops the viewport based on the option selected, adding black bars to match the Reference Resolution. Black bars are added to make the Game view fit the full screen resolution. Uncropped Cropped"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Building-For-Consoles.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Building-For-Consoles.html",
    "title": "Building your Project for Closed platforms | mmo-rpg-unity",
    "keywords": "Building your Project for Closed platforms If you have a license to develop games for Closed platforms that require you to meet the confidentiality and legal agreements of the platform provider, then refer to the relevant developer forums for a link to the console specific render pipeline package. Platform package installation Closed platform packages are not available in the package registry or the Package Manager. To install a Closed platform package: Download the package from the relevant platform developer forum. Use the Package Manager to install the package locally. For information on how to install packages locally, refer to Installing a local package."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/EffectList.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/EffectList.html",
    "title": "Effect List | mmo-rpg-unity",
    "keywords": "Effect List These are the post-processing effects that are available in the Universal Render Pipeline (URP): Bloom Channel Mixer Chromatic Aberration Color Adjustments Color Curves Depth of Field Film Grain Lens Distortion Lift Gamma Gain Motion Blur Panini Projection Shadows Midtones Highlights Split Toning Tonemapping Vignette White Balance Lens Flare"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/HDREmulationScale.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/HDREmulationScale.html",
    "title": "| mmo-rpg-unity",
    "keywords": "HDR emulation scale All Lights in the 2D lighting system support HDR. While a typical RGBA32 color channel has the range of zero to one, a HDR channel can go beyond one. Light RGB(1,1,1) HDR Light RGB(1,1,1) + Light RGB(2,2,2) However, not all platforms natively support HDR textures. HDR Emulation Scale allows those platforms to use HDR lighting by compressing the number of expressible colors in exchange for extra intensity range. Scale describes this extra intensity range. Increasing this value too high may cause undesirable banding to occur. Light Intensity scale examples: HDR Reference Light Intensity Scale 1 (No HDR) Light Intensity Scale 4 Light Intensity Scale 12 When choosing a value for HDR Emulation Scale, the developer should choose the combined maximum brightness for the lights in the scene as the value."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/InstallURPIntoAProject.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/InstallURPIntoAProject.html",
    "title": "Installing the Universal Render Pipeline into an existing Project | mmo-rpg-unity",
    "keywords": "Installing the Universal Render Pipeline into an existing Project You can download and install the latest version of the Universal Render Pipeline (URP) to your existing Project via the Package Manager system, and then install it into your Project. If you don’t have an existing Project, refer to documentation on how to start a new URP Project from a Template. Before you begin URP uses its own integrated post-processing solution. If you have the Post Processing Version 2 package installed in your Project, you need to delete the Post Processing Version 2 package before you install URP into your Project. When you have installed URP, you can then recreate your post-processing effects. URP does not currently support custom post-processing effects. If your Project uses custom post-processing effects, these cannot currently be recreated in URP. Custom post-processing effects will be supported in a forthcoming release of URP. Installing URP In Unity, open your Project. In the top navigation bar, select Window > Package Manager to open the Package Manager window. In the Packages menu, select Unity Registry. This shows the list of available packages for the version of Unity that you are currently running. Select Universal RP from the list of packages. In the bottom right corner of the Package Manager window, select Install. Unity installs URP directly into your Project. Configuring URP Before you can start using URP, you need to configure it. To do this, you need to create a Scriptable Render Pipeline Asset and adjust your Graphics settings. Creating the Universal Render Pipeline Asset The Universal Render Pipeline Asset (URP Asset) contains the global rendering and quality settings of your project, and creates the rendering pipeline instance. The rendering pipeline instance contains intermediate resources and the render pipeline implementation. To create a Universal Render Pipeline Asset: In the Editor, go to the Project window. Right-click in the Project window, and select Create > Rendering > URP Asset (with Universal Renderer). Alternatively, navigate to the menu bar at the top, and select Assets > Create > Rendering > URP Asset (with Universal Renderer). You can either leave the default name for the new Universal Render Pipeline Asset, or type a new one. Set URP as the active render pipeline To set URP as the active render pipeline: In your project, locate the Render Pipeline Asset that you want to use. Tip: to find all URP Assets in a project, use the following query in the search field: t:universalrenderpipelineasset. Select Edit > Project Settings > Graphics. In the Scriptable Render Pipeline Settings field, select the URP Asset. When you select the URP Asset, the available Graphics settings change immediately. Optional: Set an override URP Assets for different quality levels: Select Edit > Project Settings > Quality. Select a quality level. In the Render Pipeline Asset field, select the Render Pipeline Asset. Upgrading your shaders If your project uses the prebuilt Standard Shader, or custom Unity shaders made for the Built-in Render Pipeline, you must convert them to URP-compatible Unity shaders. For more information on this topic, refer to Upgrading your Shaders. Upgrade from the Built-in Render Pipeline When you upgrade a project from the Built-in Render Pipeline (BiRP) to the Universal Render Pipeline (URP), there are many changes which occur. These changes are wide reaching and require some work beyond the initial installation process for URP shown here. The following pages explain more about these changes and provide guidance on any additional steps required: Converting your shaders Render Pipeline Converter Upgrade custom shaders for URP compatibility Find graphics quality settings in URP Update graphics quality levels for URP"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/InstallingAndConfiguringURP.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/InstallingAndConfiguringURP.html",
    "title": "Getting started | mmo-rpg-unity",
    "keywords": "Getting started To use the Universal Render Pipeline (URP), you can start a new Project or upgrade an existing Project. You can do this in the following ways: Create a new URP Project from a Template. If you are starting a new Project from scratch, this is the best choice. When you do this, Unity automatically installs and configures URP for you. Install URP into an existing Unity Project. If you have started a Project using the Built-in Render Pipeline, you can install URP and configure your Project to use URP. When you do this, you must configure URP yourself. You will need to manually convert or recreate parts of your Project (such as lit shaders or post-processing effects) to be compatible with URP. Note: URP does not currently support custom post-processing effects. If your Project uses custom post-processing effects, these cannot currently be recreated in URP. Custom post-processing effects will be supported in a forthcoming release of URP. Note: Projects made using URP are not compatible with the High Definition Render Pipeline (HDRP) or the Built-in Render Pipeline. Before you start development, you must decide which render pipeline to use in your Project. For information on choosing a render pipeline, refer to the Render Pipelines section of the Unity Manual."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/LightBlendStyles.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/LightBlendStyles.html",
    "title": "Light Blend Styles | mmo-rpg-unity",
    "keywords": "Light Blend Styles Blend Styles determine the way a particular Light interacts with Sprites in the Scene. All Lights in the Scene must pick from one of the available Blend Styles. The Universal Render Pipeline (URP) 2D Asset can currently contain a total of four different Light Blend Styles, starting with the 'Default' Blend Style being available. Property Function Name The name that appears when choosing a Blend Style for a Light2D. Mask Texture Channel Which mask channel to use when applying this Blend Style to a Sprite. Render Texture Scale Scale for the internal render texture created for this Blend Style. Blend Mode What blending mode the Light2D uses when this Blend Style is selected. Blend Mode Blend Modes controls the way a Sprite is lit by light. The following examples show the four predefined Blend Modes: Original Sprite Multiply Additive Subtractive Custom Blend Modes All of the Blend Modes available can be expressed with Custom Blend Factors. The factors for the existing Blend Modes are as follows: Multiplicative Modulate = 1 Additive = 0 Additive Modulate = 0 Additive = 1 Subtractive Modulate = 0 Additive = -1 Mask Texture Channel Masks control where Lights can affect a Sprite. There are 4 channels to select from as the mask channel - Red, Blue, Green, and Alpha. In a mask max value means full light, min value means no light. Original Rock Color Rock with a mask Additive Light Blending Additive Light Blending with a mask Render Texture Scale Render Texture Scale adjusts the size of the internal render Texture used for a given Blend Mode. Lowering the Render Texture Scale can increase performance and decrease memory usage for Scenes that contain large Lights. Lowering the Texture Scale to too low a value may cause visual artefacts or a shimmering effect when there is motion in the Scene."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/LightTypes.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/LightTypes.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Freeform Select the Freeform Light type to create a Light from an editable polygon with a spline editor. To begin editing your shape, select the Light and find the button in its Inspector window. Select it to enable the shape editing mode. Add new control points by clicking the mouse along the inner polygon’s outline. Remove control points selecting the point and pressing the Delete key. The following additional properties are available to the Freeform Light type. Property Function Falloff Adjust the amount the blending from solid to transparent, starting from the center of the shape to its edges. Falloff Intensity Adjusts the falloff curve of the Light. Falloff Offset Sets the offset for the outer falloff shape. Freeform Light in edit mode Resulting Light Effect When creating a Freeform Light, take care to avoid self-intersection as this may cause unintended lighting results. Self-intersection may occur by creating outlines where edges cross one another, or by enlarging falloff until it overlaps itself. To prevent such issues, it is recommended to edit the shape of the Light until the conditions creating the self-intersection no longer occur. Outline self-intersection in Edit mode. Light effect with a black triangular artifact Falloff overlap in Edit mode Light effect with double lighted areas with overlapping falloff Parametric The Parametric light type has been deprecated. To convert existing Parametric lights to Freeform lights, Edit > Rendering > Lights > Upgrade Project/Scene URP Parametric Lights to Freeform Sprite Select the Sprite Light type to create a Light based on a selected Sprite by assigning the selected Sprite to the additional Sprite property. Property Function Sprite Select a Sprite as the Light source. Selected Sprite Resulting Light effect Spot Select the Spot Light type for great control over the angle and direction of the selected Light with the following additional properties. Property Function Radius Inner Set the inner radius here or with the gizmo. Light within the inner radius will be at maximum intensity. Radius Outer Set the outer radius here or with the gizmo. Light intensity decreases to zero as it approaches the outer radius. Inner / Outer Spot Angle Set the angles with this slider or with the gizmo. Light within the inner and outer angles will be at the intensity specified by inner and outer radius. Point Light in Edit mode Resulting Light effect Global Global Lights light all objects on the targeted sorting layers. Only one global Light can be used per Blend Style, and per sorting layer."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Lights-2D-intro.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Lights-2D-intro.html",
    "title": "Introduction to the 2D Lighting system | mmo-rpg-unity",
    "keywords": "Introduction to the 2D Lighting system The 2D Lighting system included with URP consists of a set of artist friendly tools and runtime components that help you quickly create a lit 2D Scene through core Unity components such as the Sprite Renderer, and 2D Light components that act as 2D counterparts to familiar 3D Light components. These tools are designed to integrate seamlessly with 2D Renderers such as the Sprite Renderer, Tilemap Renderer, and Sprite Shape Renderer. This system of tools and components are optimized for mobile systems, and for running on multiple platforms. Differences from 3D Lights There are a number of key differences between the implementation and behavior of 2D Lights and 3D Light, which consists of the following: New 2D specific components and render pass The 2D lighting systems includes its own set of 2D Light components, Shader Graph sub-targets and a custom 2D render pass that are specifically designed for 2D lighting and rendering. Editor tooling for the 2D Lights and pass configuration are also included in the package. Coplanar The 2D lighting model was designed specifically to work with 2D worlds that are coplanar and multi-layered. A 2D Light does not require depth separation between it and the object it is lighting. The 2D shadow system also works in coplanar and does not require depth separation. Not physically based The lighting calculation in 2D Lights is not physics based as it is with 3D Lights. The details of the lighting model calculation can be found here. No interoperability with 3D Lights and 3D Renderers 3D and 2D Lights can only affect 3D and 2D Renderers respectively. 2D Lighting does not work on or effect 3D Renderers such as the Mesh Renderer, while 3D Lighting will similarly have no effect on 2D Renderers such as the Sprite Renderer. Currently, to achieve a combination of 2D and 3D Lights and 2D and 3D Renderers in a single Scene, you can use multiple cameras and have one of the cameras render to a Render Texture, and sample that texture in a material rendered by another camera. Technical details of the 2D Lighting graphics pipeline The 2D Lighting graphics pipeline rendering process can be broken down into 2 distinct phases: Drawing the Light Render Textures Drawing the Renderers Light Render Textures are Render Textures that contain information about the Light’s color and shape in screen space. These two phases are only repeated for each distinctly lit set of Light Layers. In other words, if Sorting Layers 1 through 4 have the exact same set of Lights, it will only perform the above set of operations once. The default setup allows a number of batches to be drawn ahead of time before drawing the Renderers to reduce target switching. The ideal setup would allow the pipeline to render the Light Render Textures for all the batches and only then move on to draw the Renderers. This prevents loading and unloading of the color target. Refer to Optimization for more detailed information. Pre-phase: Calculate Sorting Layer batching Before proceeding with the rendering phases, the 2D Lighting graphics pipeline first analyses the Scene to assess which Layers can be batched together in a single draw operation. The following is the criteria that determine whether Layers are batched together: They are consecutive Layers. They share the exact same set of Lights. It is highly recommended to batch as many Layers as possible to minimize the number of Light Render Textures draw operations and improve performance. Phase 1: Draw Light Render Textures After the pre-phase batching, the pipeline then draws the Light Textures for that batch. This essentially draws the Light’s shape onto a Render Texture. The light’s color and shape can be blended onto the target Light Render Texture using Additive or Alpha Blended depending on the light’s setup. It is worth noting that a Light Render Texture is only created when at least one 2D Light is targeting it. For example, if all the lights of a Layer only uses Blendstyle #1, then only one Light Render Texture is created. Phase 2: Draw Renderers Once all the Light Render Textures have been drawn, the pipeline proceeds to draw the Renderers. The system will keep track of which set of Renderers are drawn by which set of Light Render Textures. They are associated during the batching process in the pre-phase. When the Renderers are being drawn, it will have access to all (one for each blend style) the available Light Render Textures. In the shader, the final color is calculated by combining the input color with colors from the Light Render Texture using the specified operation. An example of a setup with four active blend styles illustrating how multiple blend styles come together. In most cases, you would typically only need two blend styles for your desired effect. Optimization In addition to the standard optimization techniques such as reducing draw calls, culling and optimizing shaders, there are several techniques and considerations that are unique to the 2D Lighting graphics pipeline. Number of blend styles The easiest way to increase rendering performance is to reduce the number of blend styles used. Each blend style is a Render Texture that needs to be rendered and subsequently uploaded. Reducing the number of blend styles has a direct impact on the performance. For simple scenes a single blend style could suffice. It is also common to use up to 2 blend styles in a scene. Light Render Texture scale The 2D Lighting system relies on screen space Light Render Texture to capture light contribution. This means there are a lot of Render Texture drawing subsequent uploading. Choosing the right Render Texture size directly impacts the performance. By default it is set at 0.5x of screen resolution. Smaller Light Render Texture size will give better performance at the cost of visual artifact. Half screen size resolution provides a good performance with almost no noticeable artifact in most situations. Experiment and find a scale suitable for your project. Layer Batching To further reduce the number of Light Render Textures, it is crucial to make the Sorting Layer batchable. Layers that are batched together share the same set of Light Render Textures. Uniquely lit layers will have its own set thus increasing the amount of work needed. Layers can be batch together if they share the same set of lights. Pre-rendering of Light Render Texture Multiple sets of Light Render Textures can be rendered ahead of drawing the Renderers. In an ideal situation, all the Light Render Textures will be rendered upfront and only then will the pipeline proceed with drawing the Renderers onto the final color output. This reduces the need to load/unload/reload of final color output. In a very complex setup with many distinctly lit Layers, it may not be practical to pre-render all Light Render Textures. The limit can be configured in the 2D Renderer Data inspector. Normal Maps Using normal maps to simulate depth is currently a very expensive operation. If it is enabled, a full size Render Texture is created during a depth pre-pass and the Renderers are drawn onto it. This is done for each Layer batch. If the normal mapping effect to simulate depth perception is not needed, ensure that all lights have the normal map option disabled."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Channel-Mixer.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Channel-Mixer.html",
    "title": "Channel Mixer | mmo-rpg-unity",
    "keywords": "Channel Mixer The Channel Mixer effect modifies the influence of each input color channel on the overall mix of the output channel. For example, if you increase the influence of the green channel on the overall mix of the red channel, all areas of the final image that are green (including neutral/monochrome) tint to a more reddish hue. Using Channel Mixer Channel Mixer uses the Volume framework, so to enable and modify Channel Mixer properties, you must add a Channel Mixer override to a Volume in your Scene. To add Channel Mixer to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Channel Mixer. URP now applies Channel Mixer to any Camera this Volume affects. Properties Output channels Before you modify the influence of each input channel, you must select the output color channel to influence. To do this, click the button for the channel that you want to set the influence for. Property Description Red Use the slider to set the influence of the red channel on the selected output channel. Green Use the slider to set the influence of the green channel on the selected output channel. Blue Use the slider to set the influence of the blue channel on the selected output channel."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Color-Adjustments.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Color-Adjustments.html",
    "title": "Color Adjustments | mmo-rpg-unity",
    "keywords": "Color Adjustments Use this effect to tweak the overall tone, brightness, and contrast of the final rendered image. Scene without Color Adjustments effect. Scene with Color Adjustments effect. Using Color Adjustments Color Adjustments uses the Volume framework, so to enable and modify Color Adjustments properties, you must add a Color Adjustments override to a Volume in your Scene. To add Color Adjustments to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Color Adjustments. URP now applies Color Adjustments to any Camera this Volume affects. Properties Property Description Post Exposure Adjusts the overall exposure of the Scene in EV (not EV100). URP applies this after the HDR effect and before tonemapping, which means that it does not affect previous effects in the chain. Contrast Use the slider to expand or shrink the overall range of tonal values. Larger positive values expand the tonal range and lower negative values shrink the tonal range. Color Filter Use the color picker to select which color the Color Adjustment effect should use to multiply the render and tint the result. Hue Shift Use the slider to shift the hue of all colors. Saturation Use the slider to push the intensity of all colors."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Color-Curves.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Color-Curves.html",
    "title": "Color Curves | mmo-rpg-unity",
    "keywords": "Color Curves Grading curves are an advanced way to adjust specific ranges in hue, saturation, or luminosity. You can adjust the curves in eight available graphs to achieve effects such as specific hue replacement or desaturating certain luminosities. Using Color Curves Color Curves uses the Volume framework, so to enable and modify Color Curves properties, you must add a Color Curves override to a Volume in your Scene. To add Color Curves to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Color Curves. URP now applies Color Curves to any Camera this Volume affects. Properties Curve Description Master This curve affects the luminance across the whole image. The x-axis of the graph represents input luminance and the y-axis represents output luminance. You can use this to further adjust the appearance of basic attributes such as contrast and brightness across all color channels at the same time. Red This curve affects the red channel intensity across the whole image. The x-axis of the graph represents input intensity and the y-axis represents output intensity for the red channel. Green This curve affects the green channel intensity across the whole image. The x-axis of the graph represents input intensity and the y-axis represents output intensity for the green channel. Blue This curve affects the blue channel intensity across the whole image. The x-axis of the graph represents input intensity and the y-axis represents output intensity for the blue channel. Hue Vs Hue This curve shifts the input hue (x-axis) according to the output hue (y-axis). You can use this to fine tune hues of specific ranges or perform color replacement. Hue Vs Sat This curve adjusts saturation (y-axis) according to the input hue (x-axis). You can use this to tone down particularly bright areas or create artistic effects such as monochromatic except a single dominant color. Sat Vs Sat This curve adjusts saturation (y-axis) according to the input saturation (x-axis). You can use this to fine tune saturation adjustments made with Color Adjustments. Lum Vs Sat This curve adjusts saturation (y-axis) according to the input luminance (x-axis). You can use this to desaturate areas of darkness to provide an interesting visual contrast."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Film-Grain.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Film-Grain.html",
    "title": "Film Grain | mmo-rpg-unity",
    "keywords": "Film Grain Scene with Film Grain effect turned off. Scene with Film Grain effect turned on. The Film Grain effect simulates the random optical texture of photographic film, usually caused by small particles being present on the physical film. Using Film Grain Film Grain uses the Volume framework, so to enable and modify Film Grain properties, you must add a Film Grain override to a Volume in your Scene. To add Film Grain to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Film Grain. URP now applies Film Grain to any Camera this Volume affects. Properties Property Description Type Use the drop-down to select the type of grain to use. You can select from a list of presets that URP includes, or select Custom to provide your own grain Texture. Texture Assign a Texture that this effect uses as a custom grain Texture.This property is only available when Type is set to Custom. Intensity Use the slider to set the strength of the Film Grain effect. Response Use the slider to set the noisiness response curve. The higher you set this value, the less noise there is in brighter areas. Response value 1 (left), and 0 (right)."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Lens-Distortion.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Lens-Distortion.html",
    "title": "Lens Distortion | mmo-rpg-unity",
    "keywords": "Lens Distortion Scene with Lens Distortion effect turned off. Scene with Lens Distortion effect turned on. The Lens Distortion effect distorts the final rendered picture to simulate the shape of a real-world camera lens. Using Lens Distortion Lens Distortion uses the Volume framework, so to enable and modify Lens Distortion properties, you must add a Lens Distortion override to a Volume in your Scene. To add Lens Distortion to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Lens Distortion. URP now applies Lens Distortion to any Camera this Volume affects. Properties Property Description Intensity Use the slider to set the overall strength of the distortion effect. X Multiplier Use the slider to set the distortion intensity on the x-axis. This value acts as a multiplier so you can set this value to 0 to disable distortion on this axis, Y Multiplier Use the slider to set the distortion intensity on the y-axis. This value acts as a multiplier so you can set this value to 0 to disable distortion on this axis, Center Set the center point of the distortion effect on the screen. Scale Use the slider to set the value for global screen scaling. This zooms the render to hide the borders of the screen. When you use a high distortion, pixels on the borders of the screen can break because they rely on information from pixels outside the screen boundaries that don't exist. This property is useful for hiding these broken pixels around the screen border."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Lift-Gamma-Gain.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Lift-Gamma-Gain.html",
    "title": "Lift Gamma Gain | mmo-rpg-unity",
    "keywords": "Lift Gamma Gain This effect allows you to perform three-way color grading. The Lift Gamma Gain trackballs follow the ASC CDL standard. When you adjust the position of the point on the trackball, it shifts the hue of the image towards that color in the given tonal range. Use the different trackballs to affect different ranges within the image. Adjust the slider under the trackball to offset the color lightness of that range. Using Lift Gamma Gain Lift Gamma Gain uses the Volume framework, so to enable and modify the lift, gamma, or gain of the render, you must add a Lift Gamma Gain override to a Volume in your Scene. To add Lift Gamma Gain to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Lift Gamma Gain. URP now applies Lift Gamma Gain to any Camera this Volume affects. Properties Property Description Lift Use this to control the dark tones. This has a more exaggerated effect on shadows. Use the trackball to select which color URP should shift the hue of the dark tones to. Use the slider to offset the color lightness of the trackball color. Gamma Use this to control the mid-range tones with a power function. Use the trackball to select which color URP should use to shift the hue of the mid-tones to. Use the slider to offset the color lightness of the trackball color. Gain Use this to increase the signal and make highlights brighter. Use the trackball to select which color that URP uses to shift the hue of the highlights to. Use the slider to offset the color lightness of the trackball color."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Motion-Blur.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Motion-Blur.html",
    "title": "Motion Blur | mmo-rpg-unity",
    "keywords": "Motion Blur Scene with Motion Blur effect turned off. Scene with Motion Blur effect turned on. The Motion Blur effect simulates the blur that occurs in an image when a real-world camera films objects moving faster than the camera’s exposure time. This is usually due to rapidly moving objects, or a long exposure time. Universal Render Pipeline (URP) only blurs camera motions. Using Motion Blur Motion Blur uses the Volume system, so to enable and modify Motion Blur properties, you must add a Motion Blur override to a Volume in your Scene. To add Motion Blur to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing, and click on Motion Blur. URP now applies Motion Blur to any Camera this Volume affects. Properties Property Description Quality Set the quality of the effect. Lower presets give better performance, but at a lower visual quality. Intensity Set the strength of the motion blur filter to a value from 0 to 1. Higher values give a stronger blur effect, but can cause lower performance, depending on the Clamp parameter. Clamp Set the maximum length that the velocity resulting from Camera rotation can have. This limits the blur at high velocity, to avoid excessive performance costs. The value is measured as a fraction of the screen's full resolution. The value range is 0 to 0.2. The default value is 0.05. Troubleshooting performance issues To decrease the performance impact of Motion Blur, you can: Reduce the Quality. A lower quality setting gives higher performance but may exhibit more visual artifacts. Decrease the Clamp to reduce the maximum velocity that Unity takes into account. Lower values give higher performance."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Panini-Projection.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Panini-Projection.html",
    "title": "Panini Projection | mmo-rpg-unity",
    "keywords": "Panini Projection Scene with Panini Projection effect turned off. Scene with Panini Projection effect turned on. This effect helps you to render perspective views in Scenes with a very large field of view. Panini projection is a cylindrical projection, which means that it keeps vertical straight lines straight and vertical. Unlike other cylindrical projections, panini projection keeps radial lines through the center of the image straight too. For more information about panini projection, refer to PanoTools’ wiki documentation on General Panini Projection. Using Panini Projection Panini Projection uses the Volume framework, so to enable and modify Panini Projection properties, you must add a Panini Projection override to a Volume in your Scene. To add Panini Projection to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Panini Projection. URP now applies Panini Projection to any Camera this Volume affects. Properties Property Description Distance Use the slider to set the strength of the distortion. Crop to Fit Use the slider to crop the distortion to fit the screen. A value of 1 crops the distortion to the edge of the screen, but results in a loss of precision in the center if you set Distance to a high value."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Shadows-Midtones-Highlights.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Shadows-Midtones-Highlights.html",
    "title": "Shadows Midtones Highlights | mmo-rpg-unity",
    "keywords": "Shadows Midtones Highlights The Shadows Midtones Highlights effect separately controls the shadows, midtones, and highlights of the render. Unlike Lift, Gamma, Gain, you can use this effect to precisely define the tonal range for shadows, midtones, and highlights. Using Shadows Midtones Highlights Shadows Midtones Highlights uses the Volume framework, so to enable and modify the shadows, midtones, or highlights of the render, you must add a Shadows Midtones Highlights override to a Volume in your Scene. To add Shadows Midtones Highlights to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Shadows Midtones Highlights. URP now applies Shadows Midtones Highlights to any Camera this Volume affects. Properties Property Description Shadows Use this to control the shadows.Use the trackball to select the color URP should shift the hue of the shadows to.Use the slider to offset the color lightness of the trackball color. Midtones Use this to control the midtones.Use the trackball to select the color URP should shift the hue of the midtones to.Use the slider to offset the color lightness of the trackball color. Highlights Use this to control the highlights.Use the trackball to select the color URP should shift the hue of the highlights to.Use the slider to offset the color lightness of the trackball color. Graph view This graph shows the overall contribution of the Shadows (blue), Midtones (green), and Highlights (yellow). This is useful to visualize the transitions between the tonal regions. Shadow Limits Property Description Start Set the start point of the transition between the shadows and the midtones of the render. End Set the end point of the transition between the shadows and the midtones of the render. Highlight Limits Property Description Start Set the start point of the transition between the midtones and the highlights of the render. End Set the end point of the transition between the midtones and the highlights of the render."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Split-Toning.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-Split-Toning.html",
    "title": "Split Toning | mmo-rpg-unity",
    "keywords": "Split Toning This effect tints different areas of the image based on luminance values, to help you achieve a more distinctive look. You can use this to add different color tones to the shadows and highlights in your Scene. Using Split Toning Split Toning uses the Volume framework, so to enable and modify Split Toning properties, you must add a Split Toning override to a Volume in your Scene. To add Split Toning to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Split Toning. URP now applies Split Toning to any Camera this Volume affects. Properties When you adjust the color in the color picker for each property, you should only adjust the Hue and Saturation. Value also changes the overall image brightness. Property Description Shadows Use the color picker to select the color that URP uses for tinting shadows. Highlights Use the color picker to select the color that URP uses for tinting highlights. Balance Use the slider to set the balance between Shadows and Highlights. Lower values result in more pronounced shadow toning is compared to highlight toning. Higher values result in the opposite effect, with more pronounced highlight toning compared to shadow toning."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-White-Balance.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Post-Processing-White-Balance.html",
    "title": "White Balance | mmo-rpg-unity",
    "keywords": "White Balance The White Balance component applies a white balance effect that removes unrealistic color casts, so that items that would appear white in real life render as white in your final image. You can also use white balance to create an overall colder or warmer feel in the final render. Using White Balance White Balance uses the Volume framework, so to enable and modify White Balance properties, you must add a White Balance override to a Volume in your Scene. To add White Balance to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on White Balance. URP now applies White Balance to any Camera this Volume affects. Properties Property Description Temperature Use the slider to set the white balance to a custom color temperature. Higher values result in a warmer color temperature and lower values result in a colder color temperature. For more information, refer to Wikipedia: Color balance for more information about color temperature. Tint Use the slider to compensate for a green or magenta tint."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/PrepShader.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/PrepShader.html",
    "title": "Prepare and upgrade sprites and projects for lighting | mmo-rpg-unity",
    "keywords": "Prepare and upgrade sprites and projects for lighting To light a sprite with 2D lights, first go to the Sprite Renderer component of the sprite and assign a material with a Shader that reacts to 2D lights. When you drag sprites onto the scene, Unity automatically assigns the Sprite-Lit-Default material to them which enables them to interact and appear lit by 2D lights. You can also create a custom Shader that reacts to lights with the Shader Graph package. Upgrading existing materials If you are installing the URP package into an existing project with preexisting prefabs, materials or scenes, you will need to upgrade any materials used to a lighting compatible Shader if you want to use the package's 2D lighting features. Warning: The following task automatically upgrades a scene or project in a one way process. Unity can't revert upgraded scenes or projects to their previous state. Before you start this task, back up any files you don't want to lose or converted. To upgrade your project, go to Window > Rendering > Render Pipeline Converter. Enable Material Upgrade and then select Convert Assets to begin the upgrade. For information on converting assets made for a Built-in Render Pipeline project to assets compatible with 2D URP, refer to Render Pipeline Converter."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/SecondaryTextures.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/SecondaryTextures.html",
    "title": "Setting up normal map and mask Textures | mmo-rpg-unity",
    "keywords": "Setting up normal map and mask Textures 2D Lights can interact with normal map and mask Textures linked to Sprites to create advanced lighting effects, such as normal mapping. Assign these additional Textures to Sprites by using the Sprite Editor’s Secondary Textures module. First select a Sprite, and open the Sprite Editor from its Inspector window. Then select the Secondary Textures module from the drop-down menu at the top left of the editor window. Adding a Secondary Texture In the Secondary Textures editor, select a Sprite to add Secondary Textures to. With a Sprite selected, the Secondary Textures panel appears at the bottom right of the editor window. The panel displays the list of Secondary Textures currently assigned to the selected Sprite. To add a new Secondary Texture to the Sprite, select + at the bottom right of the list. This adds a new entry to the list with the ‘Name’ and ‘Texture’ boxes. Enter a custom name into the Name box, or select the arrow to the right of the Name box to open the drop-down list of suggested names. These suggested names can include suggestions from installed Unity packages, as the Secondary Textures may need to have specific names to interact correctly with the Shaders in these packages to produce their effects. The 2D Lights package suggests the names ‘MaskTex’ and ‘NormalMap’. Select the name that matches the function of the selected Texture - select ‘MaskTex’ for a masking Texture, or ‘NormalMap’ for a normal map Texture. Naming these Textures correctly allow them to interact with the 2D Lights Shaders to properly produce the various lighting effects. To select the Texture Asset for this Secondary Texture entry, drag the Texture Asset directly onto the Texture field, or open the Object Picker window by selecting the circle to the right of the Texture box. Secondary Textures are sampled with the same UV coordinates as the Texture of the selected Sprite. Align the Secondary Textures with the main Sprite Texture to ensure that additional Texture effects are displayed correctly. To preview the Secondary Texture in the Sprite Editor window, select an entry in the list. This automatically hides the Sprite’s main Texture. Click outside of the Secondary Textures list to deselect the entry, and the main Sprite Texture becomes visible again. Deleting a Secondary Texture To delete a Secondary Texture, select it from the list and then select - at the bottom right of the window. This automatically removes the entry. Applying Select Apply at the top of the editor to save your entries. Invalid entries without a Name or an assigned Texture are automatically removed when changes are applied."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Setup.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Setup.html",
    "title": "Requirements and setup | mmo-rpg-unity",
    "keywords": "Requirements and setup Install the following Editor and package versions to begin working with the 2D Renderer: Unity 2021.2.0b1 or later Universal Render Pipeline version 10 or higher (available via the Package Manager) 2D Renderer Setup Create a new Project using the 2D template. Create a new Pipeline Asset and Renderer Asset by going to the Assets menu and selecting Create > Rendering > URP Asset (with 2D Renderer). Enter the name for both the Pipeline and Renderer Assets. The name is automatically applied to both, with \"_Renderer\" appended to the name of the Renderer Asset. The Renderer Asset is automatically assigned to the Pipeline Asset. To set the graphics quality settings, there are two options: Option 1: For a single setting across all platforms Go to Edit > Project Settings and select the Graphics category. Drag the Pipeline Asset created earlier to the Scriptable Render Pipeline Settings box, and adjust the quality settings. Option 2: For settings per quality level Go to Edit > Project Settings and select the Quality category. Select the quality levels to be included in your Project. Drag the Pipeline Asset created earlier to the Rendering box. Repeat steps 2-3 for each quality level and platform included in your Project. The 2D Renderer is now set up for your Project. Note: If you use the 2D Renderer in your Project, some of the options related to 3D rendering in the Universal Render Pipeline Asset will not affect or impact on your final app or game."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/ShaderGraph.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/ShaderGraph.html",
    "title": "2D Renderer and Shader Graph | mmo-rpg-unity",
    "keywords": "2D Renderer and Shader Graph Creating a Lit Shader Create a new Asset by selecting Assets > Create > Shader Graph > URP > Sprite Lit Shader Graph. The Shader Graph Asset is then created in the Asset window. Double-click the new Asset to open the Shader Graph. Create three Sample Texture 2D Nodes by right-clicking on the Shader Graph window and selecting Create Node, then search for and select the Sample Texture 2D option. Change the Type of one of the Nodes to Normal. Attach the RGBA(4) Output Slot of the Default Type Nodes as shown below. Note that you should attach the Normal Type Node's Output Slot to the Normal(Tangent Space)(3) Input Slot. Create three Texture 2D properties by selecting the + on the Blackboard, and then select Texture 2D. Name them 'MainTex', 'MaskTex', and 'NormalMap' for this example. Drag each of the Texture 2D properties onto the editor window. Attach each of the properties to the Input Slots of the Sample Texture 2D Nodes as shown below. Note that the 'NormalMap' property must be attached to the Normal Type Node only. Select Save Asset to save the Shader. You can now apply the newly built Shader to materials."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Shadows-in-URP.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Shadows-in-URP.html",
    "title": "Shadows in the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Shadows in the Universal Render Pipeline The Universal Render Pipeline’s Lights can cast shadows from one GameObject onto another. They emphasize the position and scale of GameObjects, which adds a degree of depth and realism to a Scene that could otherwise look flat. URP uses shadow maps and shadow cascades. You can add a Screen Space Shadows Renderer Feature so the Universal Render Pipeline (URP) uses a single render texture to calculate and draw shadows from the main Directional Light, instead of multiple shadow cascade textures. Shadow map resolution The resolution of a Light’s shadow map determines the size of its shadow maps. The larger the shadow map, the more precise the shadows can be, and the better the Universal Render Pipeline can capture small details in the shadow casting geometry. Rendering shadow maps at higher resolutions make them look sharper. The number of shadow maps Universal RP renders per Light depends on the Type of the Light: A Spot Light renders one shadow map. A Point Light renders six shadow maps (the number of faces in a cubemap). A Directional Light renders one shadow map per cascade. Set the cascade count of Directional Lights from the Universal Render Pipeline Asset of your project. Universal RP will try to use the best resolution according to the number of shadow maps that are needed in the scene, and the size of the shadow atlases. Shadow atlases Universal RP renders all real-time shadows for a frame using one common shadow map atlas for all punctual light shadows (i.e shadows for Spot Lights and Point Lights), and an other shadow map atlas for Directional Light shadows. Set the size of these atlases in your Unity Project’s Universal Render Pipeline Asset. The atlas size determines the maximum resolution of shadows in your Scene. For example, an atlas of size 1024 x 1024 can fit: Four shadow maps of 512 x 512 pixels. Sixteen shadow maps of 256 x 256 pixels. Matching shadow atlas resolution to Built-In RP settings In projects that used the Built-In Render Pipeline, you controlled shadow maps resolution by selecting a shadow resolution level (\"Low\", \"Medium\", \"High\", \"Very High\") in your project's Quality Settings. For each shadow map, Unity then decided which resolution to actually use, based on the algorithm explained in the Built-In RP Manual Page about Shadow Mapping. You could then inspect in the Frame Debugger the resolution actually used for a specific shadow map. In Universal Render Pipeline, you specify the resolution of the Shadow Atlases. Therefore you can control the amount of video memory your application will allocate for shadows. If you want to make sure that the resolution Universal RP uses for a specific punctual light shadow in your project, will not go under a specific value: Consider the number of shadow maps required in the scene, and select a big enough shadow atlas resolution. For example: if your scene has four Spot Lights and one Point light ; and you want each shadow map resolution to be at least 256x256. Your scene needs to render ten shadow maps (one for each Spot Light, and six for the Point Light), each with resolution 256x256. Using a shadow atlas of size 512x512 would not be enough, because it can contain only four maps of size 256x256. Therefore, you should use a shadow atlas of size 1024x1024, that can contain up to sixteen maps of size 256x256. Shadow Bias Shadow maps are essentially textures projected from the point of view of the Light. Universal RP uses a bias in the projection so that the shadow casting geometry does not self-shadow itself. In Universal RP, each individual Light component controls its own shadow biasing using the following parameters: Depth Bias Normal Bias Near Plane Find these settings under the Shadows section. If properties are not visible, change the Bias setting from \"Use Pipeline Settings\" to \"Custom\" to expose them. Using high shadow bias values can result in light \"leaking\" through Meshes. This occurs where there is a visible gap between the shadow and its caster, and leads to shadow shapes that do not accurately represent their casters. Configure shadows for better performance Refer to Configure for better performance for more information about how to adjust shadow settings for better performance."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Universal Render Pipeline Requirements Building for Closed platforms What's new in URP Features Feature Comparison with the Built-in Render Pipeline Getting started Create a project with URP Install URP into an existing Project Package samples URP Package Samples Scene Templates Quality Settings in URP Change Quality settings with code Configure settings with the URP Config package Understand performance Configure for better performance Render Pipeline Concepts The URP Asset URP Global Settings Universal Renderer Deferred Rendering Path Forward+ Rendering Path Graphics settings window reference in URP Pre-built effects (Renderer Features) How to add a Renderer Feature Render Objects Renderer Feature Example: How to create a custom rendering effect using the Render Objects Renderer Feature Render Objects Renderer Feature reference Decal Renderer Feature Decal Renderer Feature Decal Shader Graph Screen Space Ambient Occlusion (SSAO) Renderer Feature Screen Space Shadows Renderer Feature Full Screen Pass Renderer Feature How to create a custom post-processing effect Full Screen Pass Renderer Feature reference Upgrade guides Render Pipeline Converter Upgrading to URP 14 Upgrading to URP 13 Upgrading to URP 12.0.x Upgrading to URP 11.0.x Upgrading to URP 10.1.x Upgrading to URP 10.0.x Upgrading to URP 9.0.x Upgrading to URP 8.2.0 Upgrading to URP 8.1.0 Upgrading to URP 8.0.0 Upgrading to URP 7.4.0 Upgrading to URP 7.3.0 Upgrading to URP 7.2.0 Upgrading from LWRP to URP Rendering Rendering Layers Lighting Lighting in URP Light component reference The Universal Additional Light Data component Lighting Mode Shadows in the Universal Render Pipeline Reflection probes Lens Flare Data Asset Cameras Cameras in URP Understand camera render order Camera render types Anti-aliasing in URP Use multiple cameras Understand camera stacking Set up a camera stack Add and remove cameras in a camera stack Set up split-screen rendering Apply different post processing effects to separate cameras Render a camera's output to a Render Texture Customize a camera Camera component properties Physical Camera properties Post-processing How to configure HDR Output Volumes Volume Profile Volume Overrides Effect List Ambient Occlusion Bloom Channel Mixer Chromatic Aberration Color Adjustments Color Curves Depth of Field Film Grain Lens Distortion Lift, Gamma, and Gain Motion Blur Panini Projection Shadows Midtones Highlights Split Toning Tonemapping Vignette White Balance Lens Flare Custom Post-processing How to create a custom post-processing effect Shaders and Materials Shading Models Material Variants Complex Lit Lit Simple Lit Baked Lit Unlit Terrain Lit Particles Lit Particles Simple Lit Particles Unlit Decal Upgrading shaders from Built-in Upgrade custom shaders for URP compatibility Shader stripping Writing custom shaders Creating a sample scene URP basic unlit shader URP unlit shader with color input Drawing a texture Visualizing normal vectors Reconstruct the world space positions Shader methods in URP Import a file from the URP shader library Transform positions in a custom URP shader Use the camera in a custom URP shader Use lighting in a custom URP shader Use shadows in a custom URP shader URP ShaderLab Pass tags Custom rendering and post-processing Custom render passes Custom render pass workflow in URP Scriptable Render Passes Scriptable Render Passes Write a Scriptable Render Pass Inject a pass via scripting Scriptable Renderer Features Introduction to Scriptable Renderer Features Inject a custom render pass using a Scriptable Renderer Feature Apply a Scriptable Renderer Feature to a specific camera type Example of a complete Scriptable Renderer Feature Using textures URP blit best practices Perform a full screen blit in URP Blit input and output textures Blit multiple RTHandle textures Injection points reference Scriptable Renderer Feature and Scriptable Render Pass API reference Optimization Rendering Debugger Optimize for better performance Update Quality Setting Presets for URP 2D graphic features Introduction to Lights 2D Requirements and setup Configuring the 2D Renderer Asset HDR emulation scale Light Blend Styles Preparing and upgrading Normal map and mask Textures Common Lights 2D properties Lights 2D types and specific properties 2D Shadows 2D Renderer and Shader Graph 2D Pixel Perfect Cinemachine Pixel Perfect extension Frequently asked questions (FAQ) Known issues"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/URP-Config-Package.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/URP-Config-Package.html",
    "title": "Configure settings with the URP Config package | mmo-rpg-unity",
    "keywords": "Configure settings with the URP Config package You can use the Universal Render Pipeline (URP) Config package to control some of the settings of URP. Unity automatically adds the package files in the package cache as they are a dependency of URP, but you must make a copy of them in your project before you can use the package. The URP Config Package currently only changes one setting which is the maximum number of visible lights URP renders when you use the Forward+ Rendering Path. For more information, refer to Change the maximum number of visible lights. Set up the URP Config package To create a usable copy of the URP Config package in your project, do the following: In the Project window, right-click Assets and select Show in Explorer (MacOS: Reveal in Finder). Go to /Library/PackageCache/. Copy the com.unity.render-pipelines.universal-config@[versionnumber] folder to the Packages folder. Rename the copied folder to com.unity.render-pipelines.universal-config. The URP Config package is now ready for use in your project. Configure URP with the URP Config package You can edit the ShaderConfig.cs file to configure the properties of your URP project. If you edit this file, you must also update the equivalent ShaderConfig.cs.hlsl header file so that it mirrors the definitions you set in ShaderConfig.cs. You can update the ShaderConfig.cs.hlsl file in two ways: Manually edit the ShaderConfig.cs.hlsl file to mirror the ShaderConfig.cs file. This method is faster but more likely to result in an error due to a mistake. Use the Editor to generate the ShaderConfig.cs.hlsl file from the ShaderConfig.cs file, which might take longer than a manual edit but ensures that the two files are synchronized. To use the Editor to generate the ShaderConfig.cs.hlsl file, follow these steps: In the Project window, go to Packages > Universal RP Config > Runtime and open ShaderConfig.cs. Edit the values of the properties you want to change and then save and close the file. In the Editor, select Edit > Rendering > Generate Shader Includes. Unity automatically configures your project and shaders to use the new configuration. Update the URP Config package When you use the Package Manager to update your URP package, the Package Manager downloads the latest version of the URP Config package to the /Library/PackageCache/ folder, but doesn't automatically update the files of the URP Config package in your Packages folder. Instead, you need to manually update your copy of the URP Config package in your Packages folder and reapply your changes. To do this, use the following steps: Make a copy of the com.unity.render-pipelines.universal-config from your Packages folder. You can reference this later when you reapply your changes. Delete the com.unity.render-pipelines.universal-config folder in your Packages folder. Copy the com.unity.render-pipelines.universal-config@[versionnumber] folder again from the /Library/PackageCache/ folder to your Packages folder, as shown above in the Set up the URP Config package section. Rename the copied folder to com.unity.render-pipelines.universal-config. Manually reapply your modifications to the updated copy of the URP Config package."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/VolumeOverrides.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/VolumeOverrides.html",
    "title": "Volume Overrides | mmo-rpg-unity",
    "keywords": "Volume Overrides Volume Overrides let you change or extend the default properties in a Volume Profile. URP implements post-processing effects as Volume Overrides. For example, the following image shows the Vignette post-processing effect in the URP Template SampleScene. In a the Volume Override, checkboxes to the left of each property let you enable or disable specific properties. If you disable a property, URP uses the Volume’s default value for that property instead. To turn all properties on or off, use the All or None shortcuts above the property list. How to add a Volume Override to a Volume component To add a Volume Override to a Volume component: Select a GameObject with the Volume component. In the Inspector window, click Add Override. Use the search field to search for an Override, or select an Override from the menu."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/VolumeProfile.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/VolumeProfile.html",
    "title": "| mmo-rpg-unity",
    "keywords": "#Volume Profile A Volume Profile is a Scriptable Object which contains properties that Volumes use to determine how to render the Scene environment for Cameras they affect. A Volume references a Volume Profile in its Profile field and uses values from the Volume Profile it references. A Volume Profile organizes its properties into structures which control different environment settings. These structures all have default values that you can use, but you can use Volume Overrides to override these values and customize the environment settings. ##Create and custom a Volume Profile There are multiple ways to create a Volume Profile. Unity creates, and links, a Volume Profile automatically when you create a Scene Settings GameObject (menu: Rendering > Scene Settings). You can also create a Volume Profile manually. Navigate to menu: Assets > Create > Volume Profile. Open the Volume Profile in the Inspector to edit its properties. To do this, you can either: • Select the Volume Profile in the Assets folder. • Select a GameObject with a Volume component that has a Volume Profile set in its Profile field. When you view the Volume Profile in the Inspector, you can only see values from the Volume overrides that the Volume Profile includes; the Volume Profile hides all other values. You must add Volume override components in order to edit the default properties of the Volume Profile. To add a Volume override component, click on the Add Override button, and select which Volume override you want to add to the Volume Profile. For example, click on the Add Override button and select the Motion Blur Volume override. This exposes properties relating to the Motion Blur effect in URP."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Volumes.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/Volumes.html",
    "title": "Volumes | mmo-rpg-unity",
    "keywords": "Volumes The Universal Render Pipeline (URP) uses the Volume framework. Volumes can override or extend Scene properties depending on the Camera position relative to each Volume. URP uses the Volume framework for post-processing effects. URP implements dedicated GameObjects for Volumes: Global Volume, Box Volume, Sphere Volume, Convex Mesh Volume. The Volume component contains the Mode property that defines whether the Volume is Global or Local. With Mode set to Global, Volumes affect the Camera everywhere in the Scene. With Mode set to Local, Volumes affect the Camera if the Camera is within the bounds of the Collider. For more information, refer to How to use Local Volumes. You can add a Volume component to any GameObject. A Scene can contain multiple GameObjects with Volume components. You can add multiple Volume components to a GameObject. The Volume component references a Volume Profile, which contains the Scene properties. A Volume Profile contains default values for every property and hides them by default. Volume Overrides let you change or extend the default properties in a Volume Profile. At runtime, URP goes through all of the enabled Volume components attached to active GameObjects in the Scene, and determines each Volume's contribution to the final Scene settings. URP uses the Camera position and the Volume component properties to calculate the contribution. URP interpolates values from all Volumes with a non-zero contribution to calculate the final property values. Volume component properties Volumes components contain properties that control how they affect Cameras and how they interact with other Volumes. Property Description Mode Use the drop-down to select the method that URP uses to calculate whether this Volume can affect a Camera: • Global: Makes the Volume have no boundaries and allow it to affect every Camera in the Scene. • Local: Allows you to specify boundaries for the Volume so that the Volume only affects Cameras inside the boundaries. Add a Collider to the Volume's GameObject and use that to set the boundaries. Blend Distance The furthest distance from the Volume’s Collider that URP starts blending from. A value of 0 means URP applies this Volume’s overrides immediately upon entry. This property only appears when you select Local from the Mode drop-down. Weight The amount of influence the Volume has on the Scene. URP applies this multiplier to the value it calculates using the Camera position and Blend Distance. Priority URP uses this value to determine which Volume it uses when Volumes have an equal amount of influence on the Scene. URP uses Volumes with higher priorities first. Profile A Volume Profile Asset that contains the Volume Components that store the properties URP uses to handle this Volume. Volume Profiles The Profile field stores a Volume Profile, which is an Asset that contains the properties that URP uses to render the Scene. You can edit this Volume Profile, or assign a different Volume Profile to the Profile field. You can also create a Volume Profile or clone the current one by clicking the New and Clone buttons respectively. How to use Local Volumes This section describes how to use a Local Volume to implement a location-based post-processing effect. In this example, URP applies a post-processing effect when the Camera is within a certain Box Collider. In the Scene, create a new Box Volume (GameObject > Volume > Box Volume). Select the Box Volume. In Inspector, In the Volume component, In the Profile field, click New. Unity creates the new Volume Profile and adds the Add Override button to the Volume component. If you have other Volumes in the Scene, change the value of the Priority property to ensure that the Overrides from this Volume have higher priority than those of other Volumes. Click Add Override. In the Volume Overrides dialog box, select a post-processing effect. In the Collider component, adjust the Size and the Center properties so that the Collider occupies the volume where you want the local post-processing effect to be. Ensure that the Is Trigger check box is selected. Now, when the Camera is within the bounds of the Volume's Box Collider, URP uses the Volume Overrides from the Box Volume."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/anti-aliasing.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/anti-aliasing.html",
    "title": "Anti-aliasing in the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Anti-aliasing in the Universal Render Pipeline Aliasing is a side effect that happens when a digital sampler samples real-world information and attempts to digitize it. For example, when you sample audio or video, aliasing means that the shape of the digital signal doesn't match the shape of the original signal. This means when Unity renders a line, it may appear jagged as the pixels don't align perfectly with the line's intended path across the screen. An example of the rasterization process creating aliasing. To prevent aliasing, the Universal Render Pipeline (URP) has multiple methods of anti-aliasing, each with their own effectiveness and resource intensity. The anti-aliasing methods available are: Fast Approximate Anti-aliasing (FXAA) Subpixel Morphological Anti-aliasing (SMAA) Temporal Anti-aliasing (TAA) Multisample Anti-aliasing (MSAA) Fast Approximate Anti-aliasing (FXAA) FXAA uses a full screen pass that smooths edges on a per-pixel level. This is the least resource intensive anti-aliasing technique in URP. To select FXAA for a Camera: Select the Camera in the Scene view or Hierarchy window and view it in the Inspector. Navigate to Rendering > Anti-aliasing, and select Fast Approximate Anti-aliasing (FXAA). Subpixel Morphological Anti-aliasing (SMAA) SMAA finds patterns in the borders of an image and blends the pixels on these borders according to the pattern it finds. This anti-aliasing method has much sharper results than FXAA. To select SMAA for a Camera: Select the Camera in the Scene view or Hierarchy window and view it in the Inspector. Navigate to Rendering > Anti-aliasing, and select Subpixel Morphological Anti-aliasing (SMAA). Temporal Anti-aliasing (TAA) TAA uses frames from a color history buffer to smooth edges over the course of multiple frames. This means edges in motion are smoother and there's less flickering. Because TAA calculates its effects over time, it often creates ghosting artifacts in extreme situations, such as when a GameObject moves quickly in front of a surface that contrasts with it. To select TAA for a Camera: Select the Camera in the Scene view or Hierarchy window and view it in the Inspector. Navigate to Rendering > Anti-aliasing, and select Temporal Anti-aliasing (TAA). The following features cannot be used with TAA: Multisample anti-aliasing (MSAA) Camera Stacking Dynamic Resolution Multisample Anti-aliasing (MSAA) MSAA samples the depth and stencil values of every pixel and combines these samples to produce the final pixel. Crucially, MSAA solves spatial aliasing issues and is better at solving triangle-edge aliasing issues than the other techniques. However, it does not fix shader aliasing issues such as specular or texture aliasing. MSAA is more resource intensive than other forms of anti-aliasing on most hardware. However, when run on a tiled GPU with no post-processing anti-aliasing or custom render features in use, MSAA is a cheaper option than other anti-aliasing types. MSAA is a hardware anti-aliasing method. This means you can use it with the other methods, as they are post-processing effects. However, you can't use MSAA with TAA. To enable MSAA: Open a URP Asset in the Inspector. Navigate to Quality > Anti Aliasing (MSAA) and select the level of MSAA you want. For more information on the available settings, refer to the MSAA setings in the URP Asset. Note On mobile platforms that don't support the StoreAndResolve store action, if Opaque Texture is selected in the URP Asset, Unity ignores the MSAA property at runtime (as if MSAA is set to Disabled)."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/baked-lit-shader.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/baked-lit-shader.html",
    "title": "Baked Lit Shader | mmo-rpg-unity",
    "keywords": "Baked Lit Shader In the Universal Render Pipeline (URP), use this Shader for stylised games or apps that only require baked lightingvia lightmaps and Light Probes. This shader does not use Physically Based Shading and has no real-time lighting, so all real-time relevant shader keywords and variants are stripped from the Shader code, which makes it faster to calculate. Using the Baked Lit Shader in the Editor To select and use this Shader: In your Project, create or find the Material you want to use the Shader on. Select the Material. A Material Inspector window opens. Click Shader, and select Universal Render Pipeline > Baked Lit. UI overview The Inspector window for this Shader contains these elements: Surface Options Surface Inputs Advanced Surface Options The Surface Options control how the Material is rendered on a screen. Property Description Surface Type Use this drop-down to apply an Opaque or Transparent surface type to the Material. This determines which render pass URP renders the material in. Opaque surface types are always fully visible, regardless of what’s behind them. URP renders opaque Materials first. Transparent surface types are affected by their background, and they can vary according to which type of transparent surface type you choose. URP renders transparent Materials in a separate pass after opaque objects. If you select Transparent, the Blending Mode drop-down appears. Blending Mode Select how Unity calculates the color of each pixel of a transparent Material when it blends the Material with the background. In the context of Blending Modes, Source refers to the transparent Material where the Blending Mode is set and Destination refers to anything that Material overlaps with. Alpha Alpha blending mode. Alpha uses the Material's alpha value to change how transparent an object is. 0 is fully transparent. 255 is fully opaque, this is translated to a value of 1 when used with the blending equations. The Material is always rendered in the Transparent render pass regardless of it's alpha value. Alpha equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB × (1 − SourceAlpha) Premultiply Premultiply blending mode. Premultiply first multiplies the RGB values of the transparent Material by its alpha value then applies a similar effect to the Material as Alpha. The equation for Premultiply also allows areas of the transparent Material with an alpha value of 0 to have an additive blend effect. This can help reduce artifacts that may appear at the edge of the overlap between opaque and transparent pixels. Premultiply equation: OutputRGBA = SourceRGB + DestinationRGB × (1 − SourceAlpha) Additive Additive blending mode. Additive adds the color values of the Materials together to create the blend effect. The alpha value determines the strength of the source Material's color before the blend is calculated. Additive equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB Multiply Multiply blending mode. Multiply multiplies the color of the Material with the color behind the surface. This creates a darker effect, like when you look through colored glass. This mode uses the Material’s alpha value to adjust how much the colors blend. An alpha value of 1 results in unadjusted multiplication of the colors while lower values blend the colors towards white. Multiply equation: OutputRGBA = SourceRGB × DestinationRGB Render Face Use this drop-down to determine which sides of your geometry to render. Front Face renders the front face of your geometry and culls the back face. This is the default setting. Back Face renders the back face of your geometry and culls the front face. Both makes URP render both faces of the geometry. This is good for small, flat objects, like leaves, where you might want both sides visible. Alpha Clipping Makes your Material act like a Cutout Shader. Use this to create a transparent effect with hard edges between the opaque and transparent areas. For example, to create blades of grass. To achieve this effect, URP does not render alpha values below the specified Threshold, which appears when you enable Alpha Clipping. You can set the Threshold by moving the slider, which accepts values from 0 to 1. All values above your threshold are fully opaque, and all values below your threshold are invisible. For example, a threshold of 0.1 means that URP doesn't render alpha values below 0.1. The default value is 0.5. Surface Inputs The Surface Inputs describe the surface itself. For example, you can use these properties to make your surface look wet, dry, rough, or smooth. Property Description Base Map Adds color to the surface, also known as the diffuse map. To assign a Texture to the Base Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. The color next to the setting shows the tint on top of your assigned Texture. To assign another tint, you can click this color swatch. If you select Transparent or Alpha Clipping under Surface Options, your Material uses the Texture’s alpha channel or color. Normal Map Adds a normal map to the surface. With a normal map, you can add surface details like bumps, scratches and grooves. To add the map, click the object picker next to it. The normal map picks up ambient lighting in the environment. Tiling A 2D multiplier value that scales the Texture to fit across a mesh according to the U and V axes. This is good for surfaces like floors and walls. The default value is 1, which means no scaling. Set a higher value to make the Texture repeat across your mesh. Set a lower value to stretch the Texture. Try different values until you reach your desired effect. Offset The 2D offset that positions the Texture on the mesh. To adjust the position on your mesh, move the Texture across the U or V axes. Advanced The Advanced settings affect the underlying calculations of your rendering. They do not have a visible effect on your surface. Property Description Enable GPU Instancing Makes URP render meshes with the same geometry and Material in one batch, when possible. This makes rendering faster. URP cannot render Meshes in one batch if they have different Materials or if the hardware does not support GPU instancing. Sorting Priority Use this slider to determine the chronological rendering order for a Material. URP renders Materials with lower values first. You can use this to reduce overdraw on devices by making the pipeline render Materials in front of other Materials first, so it doesn't have to render overlapping areas twice. This works similarly to the render queue in the built-in Unity render pipeline."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/birp-onboarding/quality-presets.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/birp-onboarding/quality-presets.html",
    "title": "Update graphics quality levels for URP | mmo-rpg-unity",
    "keywords": "Update graphics quality levels for URP This page provides recommended URP graphics Quality Level settings for Low and High quality level values. These settings approximately match the performance of the equivalent Low and High default presets in the Built-In Render Pipeline. URP changes the implementation of many features and settings, and as a result they often have a different performance impact to the Built-In Render Pipeline equivalent. When you upgrade a project from the Built-In Render Pipeline to URP, your existing quality levels might provide a different level of performance, and you might need to update or create new quality levels for your project. You can use the values on this page as a starting point. This page is split into the following sections: Project Settings URP Asset Note: In URP, many quality level settings have moved from the Project Settings window to the URP Asset. For more information on where to find these settings in URP projects, refer to Built-In Render Pipeline Quality Settings Reference. Project Settings You can change the following settings in Project Settings under Project Settings > Quality. Setting \"Low\" preset value \"High\" preset value Rendering Real-time Reflection Probes No Yes Resolution Scaling Fixed DPI Factor 1 1 VSync Count Don't Sync Every V Blank Textures Global Mipmap Limit Half Resolution Full Resolution Anisotropic Textures Disabled Disabled Texture Streaming No No Particles Particle Raycast Budget 16 256 Terrain Billboards Face Camera Position No Yes Shadows Shadowmask Mode Shadowmask Distance Shadowmask Async Asset Upload Time Slice 2 2 Buffer Size 16 16 Persistent Buffer Yes Yes Level of Detail LOD Bias 0.4 1 Maximum LOD level 0 0 Meshes Skin Weights 4 Bones Unlimited URP Asset You can change the following settings inside any URP Asset. Setting \"Low\" preset value \"High\" preset value Rendering Depth Texture No No Opaque Texture No No Terrain Holes Yes Yes Quality HDR Yes Yes Anti Aliasing (MSAA) Disabled 2x Render Scale 1 1 Lighting Main Light Per Pixel Per Pixel Cast Shadows No Yes Shadows Resolution N/A 2048 Additional Lights Disabled Per Pixel Per Object Limit N/A 4 Cast Shadows N/A Yes Shadow Atlas Resolution N/A 2048 Shadow Resolution Tiers N/A Low N/A 512 Medium N/A 1024 High N/A 2048 Cookie Atlas Resolution N/A 2048 Cookie Atlas Format N/A Color High Reflection Probes Probe Blending No Yes Box Projection No No Shadows Max Distance N/A 50 Cascade Count N/A 3 Split 1 N/A 12.5 Split 2 N/A 33.8 Last Border N/A 3.8 Working Unit N/A Metric Depth Bias N/A 1 Normal Bias N/A 1 Soft Shadows N/A Yes Post-processing Grading Mode Low Dynamic Range Low Dynamic Range LUT Size 16 32 Fast sRGB/Linear Conversion No No Additional resources Find Quality Settings in URP URP Asset"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/birp-onboarding/quality-settings-location.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/birp-onboarding/quality-settings-location.html",
    "title": "Find graphics quality settings in URP | mmo-rpg-unity",
    "keywords": "Find graphics quality settings in URP URP splits its quality settings between Project Settings and the URP Asset to allow for more versatility in the quality levels your project has. As a result, some settings that Built-In Render Pipeline (BiRP) listed in the Project Settings Quality section have moved or changed, or no longer exist. The following table describes all the settings that the Built-in Renderer lists in the Project Settings Quality section, and where that setting is now located within URP. BiRP Setting URP Setting Rendering Render Pipeline Asset Project Settings > Quality > Rendering > Render Pipeline Asset Pixel Light Count In URP, the maximum number of real-time lights per object depends on the render path in use. For more information, refer to Rendering Path comparison. To set the light count per object, use the following property: URP Asset > Lighting > Additional Lights > Per Pixel > Per Object Limit Anti-aliasing There are two types of anti-aliasing in URP: you control Multisample Anti-aliasing (MSAA) in the URP Asset, and other anti-aliasing types on a per camera basis. For more information refer to Anti-aliasing in the Universal Render Pipeline. To control MSAA, use the following property: URP Asset > Quality > Anti-aliasing (MSAA) To control any other type of anti-aliasing, use the following property on a per camera basis: Camera > Rendering > Anti-aliasing Real-time Reflection Probes Project Settings > Quality > Rendering > Real-time Reflection Probes Resolution Scaling Fixed DPI Factor This property remains in the same place in URP. However, URP also supports the use of Upscalers to handle resolution scaling in the URP Asset. For more information on the use of upscalers, refer to Quality in the URP Asset. To set Resolution Scaling Fixed DPI Factor, use the following property: Project Settings > Quality > Rendering > Resolution Scaling Fixed DPI Factor To set resolution scaling in the URP Asset, use the following property: URP Asset > Quality > Render Scale and Upscaling Filter VSync Count Project Settings > Quality > Rendering > VSync Count Textures Global Mipmap Limit Project Settings > Quality > Textures > Global Mipmap Limit Anisotropic Textures Project Settings > Quality > Textures > Anisotropic Textures Texture Streaming Project Settings > Quality > Textures > Texture Streaming Particles Soft Particles To enable soft particles use the shader keyword _SOFTPARTICLES_ON inside the relevant particle shaders. Particle Raycast Budget Project Settings > Quality > Particles > Particle Raycast Budget Terrain Billboards Face Camera Position Project Settings > Quality > Terrain > Billboards Face Camera Position Use Legacy Details Distribution Project Settings > Quality > Terrain > Use Legacy Details Distribution Shadows Shadowmask Mode Project Settings > Quality > Shadows > Shadowmask Mode Shadows In URP you can enable shadows from two types of light separately. One is the Main Light of a scene, and the other is all other Additional Lights. To do this, set following properties as necessary: To enable shadows cast by the Main Light, use the following property: URP Asset > Lighting > Main Light > Cast Shadows To enable shadows cast by Additional Lights, use the following property: URP Asset > Lighting > Additional Lights > Cast Shadows Note: You no longer select the type of Shadows when you enable shadows. Instead to use Soft Shadows, enable URP Asset > Shadows > Soft Shadows and select an appropriate quality level. Shadow Resolution You can set Shadow Resolution separately for the Main Light and Additional Lights. Additional Lights use a Shadow Atlas with three tiers: Low, Medium, and High. To set the shadow resolution for the Main Light, use the following property: URP Asset > Lighting > Main Light > Shadow Resolution To set the shadow resolution for Additional Lights, use the following properties: URP Asset > Lighting > Additional Lights > Shadow Atlas Resolution and Shadow Resolution Tiers Shadow Projection URP only supports Stable Fit Shadow Projection. Shadow Distance URP Asset > Shadows > Max Distance Shadow Near Plane Offset No equivalent setting, because URP's shadow system doesn't use this property. Shadow Cascades URP Asset > Shadows > Cascade Count Cascade Splits Shadow Cascade Splits are now controlled by a dynamic set of properties based on the Cascade Count. The URP Asset displays a visual representation of the Cascade Splits below the Split values as a bar with multiple segments, with each segment representing the size of a given split. You can control the size of each Shadow Cascade Split with the following properties: URP Asset > Shadows > Cascade Count > Split 1, Split 2, Split 3, and Last Border Async Asset Upload Time Slice Project Settings > Quality > Async Asset Upload > Time Slice Buffer Size Project Settings > Quality > Async Asset Upload > Buffer Size Persistent Buffer Project Settings > Quality > Async Asset Upload > Persistent Buffer Level of Detail LOD Bias Project Settings > Quality > Level of Detail > LOD Bias Maximum LOD level Project Settings > Quality > Level of Detail > Maximum LOD Level LOD Cross Fade URP Asset > Quality > LOD Cross Fade Note: URP offers two options for LOD Cross Fade: Bayer and Blue Noise. These are both different to Built-In's use of Dither. Meshes Skin Weights Project Settings > Quality > Meshes > Skin Weights Additional resources URP Quality Presets URP Asset Shadows in URP"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/camera-component-reference.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/camera-component-reference.html",
    "title": "Camera component reference | mmo-rpg-unity",
    "keywords": "Camera component reference In the Universal Render Pipeline (URP), Unity exposes different properties of the Camera component in the Inspector depending on the camera type. To change the type of the camera, select a Render Type. Base cameras expose the following properties: Projection Physical Camera Rendering Stack Environment Output Overlay cameras expose the following properties: Projection Physical Camera Rendering Environment Projection Property Description Projection Control how the camera simulates perspective. Perspective Render objects with perspective intact. Orthographic Render objects uniformly, with no sense of perspective. Field of View Axis Set the axis Unity measures the camera's field of view along. Available options: Vertical Horizontal This property is only visible when Projection is set to Perspective. Field of View Set the width of the camera's view angle, measured in degrees along the selected axis. This property is only visible when Projection is set to Perspective. Size Set the viewport size of the camera. This property is only visible when Projection is set to Orthographic. Clipping Planes Set the distances from the camera where rendering starts and stops. Near The closest point relative to the camera where drawing occurs. Far The furthest point relative to the camera where drawing occurs. Physical Camera Displays additional properties for the camera in the Inspector to simulate a physical camera. A physical camera calculates the Field of View with properties simulating real-world camera attributes: Focal Length, Sensor Size, and Shift. The Physical Camera property is only available when Projection is set to Perspective. Physical Camera The Physical Camera property adds additional properties to the camera to simulate a real-world camera. For more information, refer to the Physical Camera reference. Rendering Property Description Renderer Select which renderer this camera uses. Post Processing Enable post-processing effects. Anti-Aliasing Select the method that this camera uses for post-process anti-aliasing. A camera can still use Multisample Anti-aliasing (MSAA), which is a hardware feature, at the same time as post-process anti-aliasing unless you use Temporal Anti-aliasing. The following Anti-aliasing options are available: None: This camera can process MSAA but does not process any post-process anti-aliasing. Fast Approximate Anti-aliasing (FXAA): Performs a full screen pass which smooths edges on a per-pixel level. Subpixel Morphological Anti-aliasing (SMAA): Finds edge patterns in the image and blends the pixels on these edges according to those patterns. Temporal Anti-aliasing (TAA): Uses previous frames accumulated into a color history buffer to smooth edges over the course of multiple frames. For more information, refer to Anti-aliasing in the Universal Render Pipeline. This property is only visible when Render Type is set to Base. Quality (SMAA) Select the quality of SMAA. The difference in resource intensity is fairly small between Low and High. Available options: Low Medium High This property only appears when you select Subpixel Morphological Anti-aliasing (SMAA) from the Anti-aliasing drop-down. Quality (TAA) Select the quality of TAA. Available options: Very Low Low Medium High Very High This property only appears when you select Temporal Anti-aliasing (TAA) from the Anti-aliasing drop-down. Contrast Adaptive Sharpening Enable high quality post sharpening to reduce TAA blur. This setting is overridden when you enable either AMD FidelityFX Super Resolution (FSR) or Scalable Temporal Post-Processing (STP) upscaling in the URP Asset as they both handle sharpening as part of the upscaling process. This property only appears when you select Temporal Anti-aliasing (TAA) from the Anti-aliasing drop-down. Base Blend Factor Set how much the history buffer blends with the current frame result. Higher values mean more history contribution, which improves the anti-aliasing, but also increases the chance of ghosting. This property only appears when you select Temporal Anti-aliasing (TAA) from the Anti-aliasing drop-down and enable Show Additional Properties in the Inspector. Jitter Scale Set the scale of the jitter applied when TAA is enabled. A lower value reduces visible flickering and jittering, but also reduces the effectiveness of the anti-aliasing. This property only appears when you select Temporal Anti-aliasing (TAA) from the Anti-aliasing drop-down and enable Show Additional Properties in the Inspector. Mip Bias Set how much texture mipmap selection is biased when rendering. A positive bias makes a texture appear more blurry, while a negative bias sharpens the texture. However, a lower value also has a negative impact on performance. Note: Requires mipmaps in textures. This property only appears when you select Temporal Anti-aliasing (TAA) from the Anti-aliasing drop-down and enable Show Additional Properties in the Inspector. Variance Clamp Scale Set the size of the color volume Unity uses to find nearby pixels when the color history is incorrect or unavailable. The clamp limits how much a pixel's color can vary from the color of the surrounding pixels. Lower values can reduce ghosting, but produce more flickering. Higher values reduce flickering, but are prone to blur and ghosting. This property only appears when you select Temporal Anti-aliasing (TAA) from the Anti-aliasing drop-down and enable Show Additional Properties in the Inspector. Stop NaNs Replaces Not a Number (NaN) values with a black pixel for the camera. This stops certain effects from breaking, but is a resource-intensive process which causes a negative performance impact. Only enable this feature if you experience NaN issues you can't fix. The Stop NaNs pass executes at the start of the post-processing passes. You must enable Post Processing for the camera to use Stop NaNs. Only available when Render Type is set to Base. Dithering Enable to apply 8-bit dithering to the final render to help reduce banding on wide gradients and low light areas. This property is only visible when Render Type is set to Base. Clear Depth Enable to clear depth from previous camera on rendering. This property is only visible when Render Type is set to Overlay. Render Shadows Enable shadow rendering. Priority A camera with a higher priority is drawn on top of a camera with a lower priority. Priority has a range from -100 to 100. This property is only visible when Render Type is set to Base. Opaque Texture Control whether the camera creates a CameraOpaqueTexture, which is a copy of the rendered view. Available options: Off: Camera does not create a CameraOpaqueTexture. On: Camera creates a CameraOpaqueTexture. Use Pipeline Settings: The Render Pipeline Asset determines the value of this setting. This property is only visible when Render Type is set to Base. Depth Texture Control whether the camera creates _CameraDepthTexture, which is a copy of the rendered depth values. Available options: Off: Camera does not create a CameraDepthTexture. On: Camera creates a CameraDepthTexture. Use Pipeline Settings: The Render Pipeline Asset determines the value of this setting. Note: _CameraDepthTexture is set between the AfterRenderingSkybox and BeforeRenderingTransparents events, or at the BeforeRenderingOpaques event if you use a depth prepass. For more information on the order of events in the rendering loop, refer to Injection points. Culling Mask Select which Layers the camera renders to. Occlusion Culling Enable Occlusion Culling. Stack Note This section is only available if Render Type is set to Base A camera stack allows to composite results of several cameras together. The camera stack consists of a Base camera and any number of additional Overlay cameras. You can use the stack property add Overlay cameras to the stack and they will render in the order as defined in the stack. For more information on configuring and using camera stacks, refer to Set up a camera stack. Environment Property Description Background Type Control how to initialize the color buffer at the start of this camera's render loop. For more information, refer to the documentation on clearing. This property is only visible when Render Type is set to Base. Skybox Initializes the color buffer by clearing to a Skybox. Defaults to a background color if no Skybox is found. Solid Color Initializes the color buffer by clearing to a given color. If you select this property, Unity shows the following extra property: Background: The camera clears its color buffer to this color before rendering. Uninitialized Does not initialize the color buffer. This means that the load action for that specific RenderTarget will be DontCare instead of Load or Clear. DontCare specifies that the previous contents of the RenderTarget don't need to be preserved. Only use this option in order to optimize performance in situations where your camera or Camera Stack will draw to every pixel in the color buffer, otherwise the behaviour of pixels the camera doesn't draw is undefined. Note: The results might look different between Editor and Player, as the Editor doesn't run on Tile-Based Deferred Rendering (TBDR) GPUs (found in mobile devices). If you use this option on TBDR GPUs, it causes uninitialized tile memory and the content is undefined. Volumes The settings in this section define how Volumes affect this camera. Update Mode Select how Unity updates Volumes. Available options: Every Frame: Update Volumes with every frame Unity renders. Via Scripting: Only update volumes when triggered by a script. Use Pipeline Settings: Use the default setting for the Render Pipeline. Volume Mask Use the drop-down to set the Layer Mask that defines which Volumes affect this camera. Volume Trigger Assign a Transform that the Volume system uses to handle the position of this camera. For example, if your application uses a third person view of a character, set this property to the character's Transform. The camera then uses the post-processing and scene settings for Volumes that the character enters. If you do not assign a Transform, the camera uses its own Transform instead. Output This section is only available if you set the Render Type to Base Note When a camera's Render Type is set to Base and its Render Target is set to Texture, Unity does not show the following properties in the Inspector for the camera: Target Display HDR rendering MSAA Allow Dynamic Resolution This is because the Render Texture determines these properties. You can change them in the Render Texture Asset. Property Description Output Texture Render this camera's output to a RenderTexture if this field is assigned, otherwise render to the screen. Target Display Select which external device to render to. Target Eye Select the target eye for this camera. Available options: Both: Allows XR rendering from the selected camera. None: Disables XR rendering for the selected camera. Viewport Rect Four values that indicate where on the screen this camera view is drawn. Measured in Viewport Coordinates (values 0-1). X The beginning horizontal position Unity uses to draw the camera view. Y The beginning vertical position Unity uses to draw the camera view. W Width of the camera output on the screen. H Height of the camera output on the screen. HDR Rendering Enable High Dynamic Range rendering for this camera. MSAA Enable Multisample Anti-aliasing for this camera. Allow Dynamic Resolution Enable Dynamic Resolution rendering for this camera."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/camera-stacking.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/camera-stacking.html",
    "title": "Set up a camera stack | mmo-rpg-unity",
    "keywords": "Set up a camera stack This page describes how to use a camera stack to layer outputs from multiple cameras to the same render target. For more information on camera stacking, refer to Understand camera stacking. An example of a scene that uses camera stacking to render a red capsule with a post-processing effect, and a blue capsule with no post-processing. Follow these steps to set up a camera stack: Create a camera stack. Set up layers and culling masks. Create a camera stack Create a camera stack with a Base Camera and one or more Overlay Cameras. For more information on how to do this, refer to Add a camera to a camera stack. Set up layers and culling masks Once you create your camera stack, you must assign any GameObjects the Overlay Cameras need to render to a layer, then set the Culling Mask of each camera to match the layer. To do this use the following steps: Add as many layers as your project requires. For information on how to do this, refer to Add a new layer. For each GameObject you want an Overlay Camera to render, assign the GameObject to the appropriate layer. Select the Base Camera of your camera stack and navigate to Rendering > Culling Mask in the Inspector Window. Remove any layers you don't want the Base Camera to render, such as layers that contain objects only an Overlay Camera should render. Select the first Overlay Camera in the camera stack and navigate to Rendering > Culling Mask in the Inspector window. Remove all layers except for the layers that contain GameObjects you want this camera to render. Repeat Step 5 and Step 6 for each Overlay Camera in the camera stack. Note You don't need to configure the Culling Mask property of the cameras. However, cameras in URP render all layers by default, so rendering is faster if you remove layers that contain unneeded GameObjects."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/camera-types-and-render-type.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/camera-types-and-render-type.html",
    "title": "Camera render types | mmo-rpg-unity",
    "keywords": "Camera render types There are two types of Camera in the Universal Render Pipeline (URP): A Base Camera is a general purpose Camera that renders to a render target (a screen, or a Render Texture). An Overlay Camera renders on top of another Camera's output. You can combine the output of a Base Camera with the output of one or more Overlay Cameras. This is called Camera stacking. Use a Camera’s Render Type property to make it a Base Camera or an Overlay Camera. To change the type of a Camera in the Unity Editor: Create or select a Camera in your Scene. In the Camera Inspector, use the Render Type drop-down menu to select a different type of Camera. Select either: Base to change the Camera to a Base Camera Overlay to change the Camera to an Overlay Camera You can change a Camera’s type in a script, by setting the renderType property of the Camera's Universal Additional Camera Data component, like this: var cameraData = camera.GetUniversalAdditionalCameraData(); cameraData.renderType = CameraRenderType.Base; Base Camera Base Camera is the default type of Camera in URP. A Base Camera is a general purpose Camera that renders to a given render target. To render anything in URP, you must have at least one Base Camera in your Scene. You can have multiple Base Cameras in a Scene. You can use a Base Camera on its own, or you can use it in a Camera stack. For more information on working with multiple Cameras in URP, refer to Working with multiple cameras. When you have an active Base Camera in your Scene, this icon appears next to the Camera Gizmo in the Scene view: For information on the properties that Unity exposes in the Inspector for a Base Camera, refer to the Camera component reference. Overlay Camera An Overlay Camera is a Camera that renders its view on top of another Camera's output. You can use Overlay Cameras to create effects such as 3D objects in a 2D UI, or a cockpit in a vehicle. You must use Overlay Cameras in conjunction with one or more Base Cameras using the Camera Stacking system. You cannot use Overlay Cameras on their own. An Overlay Camera that is not part of a Camera Stack does not perform any steps of its render loop, and is known as an orphan Camera. Note In this version of URP, Overlay Cameras and Camera Stacking are supported only when using the Universal Renderer. When you have an active Overlay Camera in your Scene, this icon appears next to the Camera Gizmo in the Scene view: The Base Camera in a Camera Stack determines most of the properties of the Camera Stack. Because you can only use Overlay Cameras in a Camera Stack, URP uses only the following properties of an Overlay Camera when rendering the Scene: Projection FOV Axis Field of View Physical Camera properties Clipping plans Renderer Clear Depth Render Shadows Culling Mask Occlusion Culling Unity hides all of the other unused properties in the Inspector. You can access unused properties using a script, but any changes you make to these unused properties will not affect the visual output of any Camera Stacks that use the Overlay Camera. Note While you can apply post-processing to an individual Overlay Camera within a camera stack, the effects also apply to all the outputs the camera stack renders before the Overlay Camera. This is different to how you can apply post-processing to an individual Base Camera where the effects on only apply to the Base Camera. For information on the properties that Unity exposes in the Inspector of an Overlay Camera, refer to the Camera component reference."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras-advanced.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras-advanced.html",
    "title": "Understand camera render order | mmo-rpg-unity",
    "keywords": "Understand camera render order This page describes when a Universal Render Pipeline (URP) camera performs the following operations: Clearing the color and depth buffers Base Camera Overlay Camera Culling and rendering Rendering order optimizations. Clearing the color and depth buffers In the Universal Render Pipeline (URP), Camera clearing behavior depends on the Camera's Render Type. Base Camera Color buffer At the start of its render loop, a Camera with the Base Render Type can clear its color buffer to a Skybox, clear its color buffer to a solid color, or use an uninitialized color buffer. You can define this behavior using the Background Type property in the Camera Inspector when Render Type is set to Base. Note that the contents of the uninitialized color buffer vary by platform. On some platforms, the unitialized color buffer will contain data from the previous frame. On other platforms, the unitialized color buffer will contain unintialized memory. You should choose to use an unitialized color buffer only if your Camera draws to every pixel in the color buffer, and you do not wish to incur the cost of an unnecessary clear operation. Depth buffer A Base Camera always clears its depth buffer at the start of each render loop. Overlay Camera Color buffer At the start of its render loop, an Overlay Camera receives a color buffer containing color data from the previous Cameras in the Camera stack. It does not clear the contents of the color buffer. Depth buffer At the start of its render loop, an Overlay Camera receives a depth buffer containing depth data from the previous Cameras in the Camera Stack. You can define this behavior using the Clear Depth property in the Camera Inspector when Render Type is set to Overlay. When Clear Depth is set to true, the Overlay Camera clears the depth buffer and draws its view to the color buffer on top of any existing color data. When Clear Depth is set to false, the Overlay Camera tests against the depth buffer before drawing its view to the color buffer. Culling and rendering If your URP scene contains multiple Cameras, Unity performs their culling and rendering operations in a predictable order. Once per frame, Unity performs the following operations: Unity gets the list of all active Base Cameras in the Scene. Unity organises the active Base Cameras into 2 groups: Cameras that render their view to Render Textures, and Cameras that render their view to the screen. Unity sorts the Base Cameras that render to Render Textures into Priority order, so that Cameras with a higher Priority value are drawn last. For each Base Camera that renders to a Render Texture, Unity performs the following steps: Cull the Base Camera Render the Base Camera to the Render Texture For each Overlay Camera that is part of the Base Camera's Camera Stack, in the order defined in the Camera Stack: Cull the Overlay Camera Render the Overlay Camera to the Render Texture Unity sorts the Base Cameras that render to the screen into Priority order, so that Cameras with a higher Priority value are drawn last. For each Base Camera that renders to the screen, Unity performs the following steps: Cull the Base Camera Render the Base Camera to the screen For each Overlay Camera that is part of the Base Camera's Camera Stack, in the order defined in the Camera Stack: Cull the Overlay Camera Render the Overlay Camera to the screen Unity can render an Overlay Camera’s view multiple times during a frame - either because the Overlay Camera appears in more than one Camera Stack, or because the Overlay Camera appears in the same Camera Stack more than once. When this happens, Unity does not reuse any element of the culling or rendering operation. The operations are repeated in full, in the order detailed above. Note In this version of URP, Overlay Cameras and Camera Stacking are supported only when using the Universal Renderer. Overlay Cameras will not perform any part of their rendering loop if using the 2D Renderer. Rendering order optimizations URP performs several optimizations within a Camera, including rendering order optimizations to reduce overdraw. However, when you use a Camera Stack, you effectively define the order in which those Cameras are rendered. You must therefore be careful not to order the Cameras in a way that causes excessive overdraw. When multiple Cameras in a Camera Stack render to the same render target, Unity draws each pixel in the render target for each Camera in the Camera Stack. Additionally, if more than one Base Camera or Camera Stack renders to the same area of the same render target, Unity draws any pixels in the overlapping area again, as many times as required by each Base Camera or Camera Stack. You can use Unity's Frame Debugger, or platform-specific frame capture and debugging tools, to understand where excessive overdraw occurs in your scene. You can then optimize your Camera Stacks accordingly."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras-multiple.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras-multiple.html",
    "title": "Use multiple cameras | mmo-rpg-unity",
    "keywords": "Use multiple cameras In the Universal Render Pipeline (URP), you can use multiple cameras to work with multiple camera outputs and targets, as well as different output resolutions and post-processing effects. Note If you use multiple cameras, it might make rendering slower. An active camera runs through the entire rendering loop even if it renders nothing. An example of the effect camera stacking can produce in URP. You can combine these ways of working for more complex effects. For example, you can define two camera stacks, and then set each of those to camera stacks that render to a different area of the same render target. For information on Camera rendering order when working with multiple Cameras, refer to Understand camera render order. Page Description Understand camera stacking Learn the fundamental concepts of camera stacking. Set up a camera stack Stack cameras to layer the outputs of multiple cameras into a single combined output. Add and remove cameras in a camera stack Add, remove, and reorder cameras within a camera stack. Set up split-screen rendering Render multiple camera outputs to a single render target to create effects such as split screen rendering. Render a camera's output to a Render Texture Render to a Render Texture to create effects such as in-game CCTV monitors."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras.html",
    "title": "Cameras | mmo-rpg-unity",
    "keywords": "Cameras A Camera in Unity works like a camera in the real world: it captures a view of objects in 3-dimensional space and flattens that view to display it on a 2-dimensional surface. Page Description Cameras in URP Understand the differences between Unity's built-in camera and the URP camera. Understand camera render order Understand the order in which URP clears camera buffers and performs culling and rendering operations. Camera render types Understand the difference between the Base and Overlay camera types. Anti-aliasing in URP Apply anti-aliasing effects to a camera. Use multiple cameras Set up and use more than one camera in a scene to use in a camera stack, a split screen effect, post-processing, or output to a render texture. Customize a camera Use the Universal Additional Camera Data component to customise a camera's behavior. Camera component properties Understand how each camera property works in URP."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/add-and-remove-cameras-in-a-stack.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/add-and-remove-cameras-in-a-stack.html",
    "title": "Add and remove cameras in a camera stack | mmo-rpg-unity",
    "keywords": "Add and remove cameras in a camera stack Camera stacks contain a single Base Camera with one or more Overlay Cameras stacked on top. In the Editor, you can add, remove, and reorder these cameras as much as you like to achieve the desired effects. This page is split into the following sections: Add a camera to a camera stack Remove a camera from a camera stack Reorder cameras in a camera stack Add a camera to a camera stack To add a camera to a camera stack, use the following steps: Select a Camera in your scene with the Render Type set to Base, making it a Base Camera. If you do not have a Base Camera in your scene, create one. Create another camera in your scene, and select it. In the camera Inspector window, set the Render Type to Overlay. Select the Base Camera again. In the camera Inspector window, go to the Stack section, select Add (+), then select the name of the Overlay Camera. The Overlay Camera is now part of the Base Camera's camera stack. Unity renders the Overlay Camera's output on top of the Base Camera's output. Note When you create multiple cameras for a camera stack, consider whether the cameras are all necessary. Each camera you add makes rendering slower, because an active camera runs through the entire rendering loop even if it renders nothing. Add a camera to a camera stack with a C# script You can also add a camera to a camera stack with a C# script. Use the cameraStack property of the Base Camera's Universal Additional Camera Data component, as shown below: var cameraData = camera.GetUniversalAdditionalCameraData(); cameraData.cameraStack.Add(myOverlayCamera); Remove a camera from a camera stack To remove a camera from a camera stack, use the following steps: Create a camera stack that contains at least one Overlay Camera. For instructions, refer to Add a camera to a camera stack. Select the camera stack's Base Camera. In the camera Inspector window, go to the Stack section, select the name of the Overlay Camera you want to remove, then then select Remove (-). The Overlay Camera remains in the scene, but is no longer part of the camera stack. Remove a camera from a camera stack with a C# script You can also remove a Camera from a camera stack with a C# script. Use the cameraStack property of the Base Camera's Universal Additional Camera Data component, as shown below: var cameraData = camera.GetUniversalAdditionalCameraData(); cameraData.cameraStack.Remove(myOverlayCamera); Reorder cameras in a camera stack To reorder the cameras in a camera stack, use the following steps: Create a camera stack that contains more than one Overlay Camera. For instructions, refer to Add a camera to a camera stack. Select the Base Camera in the camera stack. In the Camera Inspector, go to the Stack section. Use the handles next to the names of the Overlay Cameras to reorder the list of Overlay Cameras. The Base Camera renders the base layer of the camera stack, and the Overlay Cameras in the stack render on top of this in the order that they are listed, from top to bottom. Reorder a camera from a camera stack with a C# script You can also reorder a camera stack with a C# script. Use the cameraStack property of the Base Camera's Universal Additional Camera Data component. The cameraStack is a List and can be reordered in the same way as any other List."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/apply-different-post-proc-to-cameras.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/apply-different-post-proc-to-cameras.html",
    "title": "Apply different post processing effects to separate cameras | mmo-rpg-unity",
    "keywords": "Apply different post processing effects to separate cameras In the Universal Render Pipeline (URP) you can apply separate post processing effects to different cameras in the same scene. The output of two cameras. Image A shows a camera with a Color Adjustment override. Image B shows the second camera with a Vignette override. Set up your scene To set up your scene for multiple post-processing effects on different cameras, use the following steps: Create multiple cameras in your scene (GameObject > Camera). Enable Post Processing on each camera. Create an empty GameObject for each separate post-processing effect you want. Add a volume component to each empty GameObject. To do this, select the GameObject and in the Inspector window select Add Component > Volume. Create a volume profile for each empty GameObject. In the GameObject's Volume component, go to the Profile property and select New. Create new layer for each post-processing effect. For more information, refer to Layers. Apply different post processing effects to each camera With the scene set up, the following steps show how to create and apply a post-processing effect to each camera in the scene. Select one of the GameObjects with a volume component and select Add Override. Choose a post-processing effect from the dropdown. Select the Layer dropdown and choose one of the layers created when you set up the scene. Select the camera you want to apply this effect to. In the Inspector window, go to Environment > Volume Mask and select the same layer that you chose for the GameObject. Repeat stpes 1-5 for each GameObject and Camera pair that your scene requires. Note Some effects apply to all cameras in a scene by default. As a result of this, you might need to add the same effect to each volume. This overrides the effects from other volumes on individual cameras with the new values that you set. Each camera now applies post-processing as assigned to it by the GameObject on the same layer as it's volume mask. Note The Scene Camera might display some post-processing effects from the Default layer. To avoid this and create a clear view of your scene, open the Effects dropdown in the View options overlay in the Scene view and turn off Post Processing."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/camera-differences-in-urp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/camera-differences-in-urp.html",
    "title": "Cameras in URP | mmo-rpg-unity",
    "keywords": "Cameras in URP Cameras in the Universal Render Pipeline (URP) are based on Unity's standard camera functionality, but with some significant differences. For example, URP cameras use the following: The Universal Additional Camera Data component, which extends the Camera component's functionality and allows URP to store additional camera-related data. The Render Type setting, which defines the two types of camera in URP: Base and Overlay. The Camera Stacking system, which allows you to layer the output of multiple Cameras into a single combined output. The Volume system, which allows you to apply post-processing effects to a camera based on the position of a Transform in your scene. The Camera component, which exposes URP-specific properties in the Inspector. For a general introduction to how cameras work in Unity, and examples of common Camera workflows, refer to the Unity manual section on Cameras."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/camera-stacking-concepts.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/camera-stacking-concepts.html",
    "title": "Understand camera stacking | mmo-rpg-unity",
    "keywords": "Understand camera stacking In the Universal Render Pipeline (URP), you use camera stacking to layer the output of multiple Cameras and create a single combined output. Camera stacking allows you to create effects such as a 3D model in a 2D UI, or the cockpit of a vehicle. A camera stack consists of a Base Camera and one or more Overlay Cameras. A camera stack overrides the output of the Base Camera with the combined output of all the cameras in the camera stack. As a result, anything you can do with the output of a Base Camera, you can do with the output of a camera stack. For example, you can render a camera stack to a render target, or apply post-processing effects. Refer to Set up a camera stack for more information. To download examples of camera stacking in URP, install the Camera Stacking samples. Camera stacking and rendering order URP performs several optimizations within a camera, including rendering order optimizations to reduce overdraw. However, when you use a camera stack, you define the order in which URP renders the cameras. You must be careful not to order the cameras in a way that causes excessive overdraw. For more information on overdraw in URP, refer to Rendering order optimizations. Camera stacking and post-processing You should only apply post-processing to the last camera in the stack, so the following applies: URP renders the post-processing effects only once, not repeatedly for each camera. The visual effects are consistent, because all the cameras in the stack receive the same post-processing. Additional resources Set up a camera stack Camera component reference"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/physical-camera-reference.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/cameras/physical-camera-reference.html",
    "title": "Physical Camera reference | mmo-rpg-unity",
    "keywords": "Physical Camera reference The physical camera properties enable the URP camera to simulate a real-world camera. These properties correspond to features of real-world cameras and work in the same way. For more information about how to use some of these properties to create the camera effect you desire, refer to Using Physical Cameras. Note When the Physical Camera is in use, Unity calcualtes the Field of View with the following properties: Sensor Size Focal Length Shift The Physical Camera properties are split into the following sections: Camera Body Lens Aperture Shape Camera Body Property Description Sensor Type Specify the real-world camera format you want the camera to simulate. When you choose a camera format, Unity sets the the Sensor Size > X and Y properties to the correct values automatically. URP offers the following camera format presets: 8mm: X: 4.8 Y: 3.5 Super 8mm: X: 5.79 Y: 4.01 16mm: X: 10.26 Y: 7.49 Super 16mm: X: 12.522 Y: 7.417 35mm 2-perf: X: 21.95 Y: 9.35 35mm Academy: X: 21.946 Y: 16.002 Super-35: X: 24.89 Y: 18.66 35mm TV Projection: X: 20.726 Y: 15.545 35mm Full Aperture: X: 24.892 Y: 18.669 35mm 1.85 Projection: X: 20.955 Y: 11.328 35mm Anamorphic: X: 21.946 Y: 18.593 65mm ALEXA: X: 54.12 Y: 25.59 70mm: X: 52.476 Y: 23.012 70mm IMAX: X: 70.41 Y: 52.63 Custom: Set the X and Y values manually If you change the Sensor Size values manually, Unity automatically sets this property to Custom. Sensor Size Set the size, in millimeters, of the camera sensor. Unity sets the X and Y values automatically when you choose the Sensor Type. X The horizontal size of the camera sensor. Y The vertical size of the camera sensor. ISO The light sensitivity of the camera sensor. Shutter Speed The amount of time the camera sensor captures light. Unit The unit of measurement for Shutter Speed. Available options: Second 1/Second Gate Fit Options for changing the size of the resolution gate (size/aspect ratio of the game view) relative to the film gate (size/aspect ratio of the Physical Camera sensor). For more information about resolution gate and film gate, refer to the documentation on Physical Cameras. Vertical Fits the resolution gate to the height of the film gate. If the sensor aspect ratio is larger than the game view aspect ratio, Unity crops the rendered image at the sides. If the sensor aspect ratio is smaller than the game view aspect ratio, Unity overscans the rendered image at the sides. When you choose this setting, any change to the sensor width (Sensor Size > X) has no effect on the rendered image. Horizontal Fits the resolution gate to the width of the film gate. If the sensor aspect ratio is larger than the game view aspect ratio, Unity overscans the rendered image on the top and bottom. If the sensor aspect ratio is smaller than the game view aspect ratio, Unity crops the rendered image on the top and bottom. When you choose this setting, any change to the sensor height (Sensor Size > Y) has no effect on the rendered image. Fill Fits the resolution gate to either the width or height of the film gate, whichever is smaller. This crops the rendered image. Overscan Fits the resolution gate to either the width or height of the film gate, whichever is larger. This overscans the rendered image. None Ignores the resolution gate and uses the film gate only. This stretches the rendered image to fit the game view aspect ratio. Lens Property Description Focal Length The distance, in millimeters, between the camera sensor and the camera lens. Lower values result in a wider Field of View, and vice versa. When you change this value, Unity automatically updates the Field of View property accordingly. Shift Shifts the lens horizontally or vertically from center. Values are multiples of the sensor size; for example, a shift of 0.5 along the X axis offsets the sensor by half its horizontal size. You can use lens shifts to correct distortion that occurs when the camera is at an angle to the subject (for example, converging parallel lines). Shift the lens along either axis to make the camera frustum oblique. X The lens's horizontal offset from the camera sensor. Y The lens's vertical offset from the camera sensor Aperture The f-stop (f-number) of the lens. A lower value gives a wider lens aperture. Focus Distance The distance from the camera where objects appear sharp when you enable Depth of Field. Note When Physical Camera properties are in use at the same time as Depth of Field post-processing, the Lens properties directly affect the Depth of Field effect. This requires you to adjust both the Depth of Field properties and the Lens properties to create the effect you want. Aperture Shape Property Description Blade Count The number of blades in the lens aperture. A higher value gives a rounder aperture shape. Curvature The curvature of the lens aperture blades. Barrel Clipping The self-occlusion of the lens. A higher value creates a cat's eye effect. Anamorphism The amount of vertical stretch of the camera sensor to make the sensor taller or shorter. A higher value increases the stretch of the sensor to simulate an anamorphic look."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/configure-for-better-performance.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/configure-for-better-performance.html",
    "title": "Configure for better performance | mmo-rpg-unity",
    "keywords": "Configure for better performance You can disable or change Universal Render Pipeline (URP) settings and features that have a large performance impact. This helps you get better performance for your project, especially on lower-end platforms. Depending on your project or the platforms you target, one or all of the following might have the biggest effect: Which rendering path you choose How much memory URP uses Processing time on the CPU Processing time on the GPU You can use the Unity Profiler or a GPU profiler such as RenderDoc or Xcode to measure the effect of each setting on the performance of your project. You might not be able to disable some features if your project needs them. Choose a rendering path Refer to Universal Renderer for more information about the three rendering paths in URP, and the performance effects and limitations of each one. Reduce how much memory URP uses You can do the following in the URP Asset: Disable Depth Texture unless you need it (for example, if you use a shader that samples scene depth), so that URP doesn't store a depth texture unless it's needed. Disable Opaque Texture, so that URP doesn't store a snapshot of the opaques in a scene unless it needs to. If you use the Deferred rendering path, disable Use Rendering Layers so that URP doesn't create an extra render target. Disable High Dynamic Range (HDR) if you don't need it, so that URP doesn't do HDR calculations. If you need HDR, set HDR Precision to 32 Bit. Reduce Main Light > Shadow Resolution, to lower the resolution of the shadow map for the main light. If you use additional lights, reduce Additional Lights > Shadow Atlas Resolution, to lower the resolution of the shadow map for additional lights. Disable Light Cookies if you don't need them, or reduce Cookie Atlas Resolution and Cookie Atlas Format. On lower-end mobile platforms, set Store Actions to Auto or Discard, so that URP doesn't use memory bandwidth to copy the render targets from each pass into and out of memory. In the Universal Renderer asset, you can set Intermediate Texture to Auto, so that Unity only renders using an intermediate texture when necessary. This might also reduce how much GPU memory bandwidth URP uses. Use the Frame Debugger to check if URP removes the intermediate texture when you change this setting. You can also do the following: Minimize the use of the Decal Renderer Feature, because URP creates an additional render pass to render decals. This also reduces processing time on the CPU and GPU. Refer to Decal Renderer Feature for more information. Strip shader variants for features you don't use. Reduce processing time on the CPU You can do the following in the URP Asset: Set Volume Update Mode to Via Scripting, so that URP doesn't update volumes every frame. You need to update volumes manually using an API such as UpdateVolumeStack. On lower-end mobile platforms, if you use Reflection Probes, disable Probe Blending and Box Projection. In the Shadows section, reduce Max Distance so that URP processes fewer objects in the shadow pass. This also reduces processing time on the GPU. In the Shadows section, reduce Cascade Count to reduce the number of render passes. This also reduces processing time on the GPU. In the Additional Lights section, disable Cast Shadows. This also reduces processing time on the GPU and how much memory URP uses. Each camera in the Scene requires resources for URP culling and rendering. To optimize URP for better performance, minimize the number of cameras you use. This also reduces processing time on the GPU. Reduce processing time on the GPU You can do the following in the URP Asset: Reduce or disable Anti-aliasing (MSAA), so that URP doesn't use memory bandwidth to copy frame buffer attachments into and out of memory. This also reduces how much memory URP uses. Disable Terrain Holes. Enable SRP Batcher, so that URP reduces the GPU setup between draw calls and makes material data persistent in GPU memory. Check your shaders are compatible with the SRP Batcher first. This also reduces processing time on the CPU. On lower-end mobile platforms, disable LOD Cross Fade, so that URP doesn't use alpha testing to fade level of detail (LOD) meshes in and out. Set Additional Lights to Disabled, or Per Vertex if you use the Forward rendering path. This reduces the work URP does to calculate lighting. This also reduces processing time on the CPU if you set to Disabled. Disable Soft Shadows, or enable Soft Shadows but reduce Quality. You can do the following in the Universal Renderer asset: Enable Native RenderPass if you use Vulkan, Metal or DirectX 12 graphics APIs, so that URP automatically reduces how often it copies render textures into and out of memory. This also reduces how much memory URP uses. If you use the Forward or Forward+ rendering path, set Depth Priming Mode to Auto or Forced for PC and console platforms, or Disabled for mobile platforms. On PC and console platforms, this makes URP create and use depth textures to avoid running pixel shaders on obscured pixels. Set Depth Texture Mode to After Transparents, so that URP avoids switching render targets between the opaque pass and the transparent pass. You can also do the following: Avoid use of the Complex Lit shader, which has complex lighting calculations. If you use the Complex Lit shader, disable Clear Coat. On lower-end mobile platforms, use the Baked Lit shader for static objects and the Simple Lit shader for dynamic objects. If you use Screen Space Ambient Occlusion (SSAO), refer to Ambient Occlusion for more information about settings that have a large performance impact. Additional resources Understand performance in URP Optimize for better performance Introduction to the Universal Render Pipeline for advanced Unity creators Performance optimization for high-end graphics on PC and console Making Alba: How to build a performant open-world game Post-processing in URP for mobile devices. Optimizing lighting for a healthy frame rate Refer to the following for more information on the settings: Deferred Rendering Path in URP Forward+ Rendering Path Universal Render Pipeline Asset Universal Renderer"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/containers/create-custom-renderer-feature-1.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/containers/create-custom-renderer-feature-1.html",
    "title": "Example of a complete Scriptable Renderer Feature | mmo-rpg-unity",
    "keywords": "Example of a complete Scriptable Renderer Feature This section describes how to create a complete Scriptable Renderer Feature for a URP Renderer. This walkthrough contains the following sections: Overview of this example implementation Create example Scene and GameObjects Create a scriptable Renderer Feature and add it to the Universal Renderer Add the Renderer Feature to the the Universal Renderer asset Create the scriptable Render Pass Implement the settings for the custom render pass Enqueue the render pass in the custom renderer feature Implement the volume component Complete code for the scripts in this example Custom Renderer Feature code Custom render pass code Volume Component code The custom shader for the blur effect Overview of this example implementation The example workflow on this page implements a custom Renderer Feature that uses custom Render Passes to add a blur effect to the camera output. The implementation consists of the following parts: A ScriptableRendererFeature instance that enqueues a ScriptableRenderPass instance every frame. A ScriptableRenderPass instance that performs the following steps: Creates a temporary render texture using the RenderTextureDescriptor API. Applies two passes of the custom shader to the camera output using the RTHandle and the Blit API. Create example Scene and GameObjects To set your project up for this example workflow: Create a new Scene. Create two GameObjects: a Cube GameObject called Cube, and a Sphere GameObject called Sphere. Create two Materials with a shader that lets you specify the base color (for example, the Universal Render Pipeline/Lit shader). Call the Materials Blue and Red, and set the base colors of the Materials to blue and red respectively. Assign the Red Material to the cube and the Blue Material to the sphere. Position the camera so that it has the cube and the sphere in its view. The sample scene should look like the following image: Create a scriptable Renderer Feature and add it to the Universal Renderer Create a new C# script and name it BlurRendererFeature.cs. In the script, remove the code that Unity inserted in the BlurRendererFeature class. Add the following using directive: using UnityEngine.Rendering.Universal; Create the BlurRendererFeature class that inherits from the ScriptableRendererFeature class. public class BlurRendererFeature : ScriptableRendererFeature In the BlurRendererFeature class, implement the following methods: Create: Unity calls this method on the following events: When the Renderer Feature loads the first time. When you enable or disable the Renderer Feature. When you change a property in the inspector of the Renderer Feature. AddRenderPasses: Unity calls this method every frame, once for each camera. This method lets you inject ScriptableRenderPass instances into the scriptable Renderer. Now you have the custom BlurRendererFeature Renderer Feature with its main methods. Below is the complete code for this step. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.Rendering.Universal; public class BlurRendererFeature : ScriptableRendererFeature { public override void Create() { } public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { } } Add the Renderer Feature to the the Universal Renderer asset Add the Renderer Feature you created to the the Universal Renderer asset. For information on how to do this, refer to the page How to add a Renderer Feature to a Renderer. Create the scriptable Render Pass This section demonstrates how to create a scriptable Render Pass and enqueue its instance into the scriptable Renderer. Create a new C# script and name it BlurRenderPass.cs. In the script, remove the code that Unity inserted in the BlurRenderPass class. Add the following using directive: using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; Create the BlurRenderPass class that inherits from the ScriptableRenderPass class. public class BlurRenderPass : ScriptableRenderPass Add the Execute method to the class. Unity calls this method every frame, once for each camera. This method lets you implement the rendering logic of the scriptable Render Pass. public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { } Below is the complete code for the BlurRenderPass.cs file from this section. using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class BlurRenderPass : ScriptableRenderPass { public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { } } Implement the settings for the custom render pass This section demonstrates how to implement the settings for the custom blur render pass. The Renderer Feature in this example uses the shader that performs the blur horizontally in one pass, and vertically in another pass. To let users control the blur value for each pass, add the following BlurSettings class to the BlurRendererFeature.cs script. [Serializable] public class BlurSettings { [Range(0,0.4f)] public float horizontalBlur; [Range(0,0.4f)] public float verticalBlur; } In the BlurRendererFeature class, declare the following fields: [SerializeField] private BlurSettings settings; [SerializeField] private Shader shader; private Material material; private BlurRenderPass blurRenderPass; In the BlurRenderPass class, add the fields for the settings, the Material, and the constructor that uses those fields. private BlurSettings defaultSettings; private Material material; public BlurRenderPass(Material material, BlurSettings defaultSettings) { this.material = material; this.defaultSettings = defaultSettings; } In the BlurRenderPass class, add the RenderTextureDescriptor field and initialize it in the constructor: using UnityEngine; private RenderTextureDescriptor blurTextureDescriptor; public BlurRenderPass(Material material, BlurSettings defaultSettings) { this.material = material; this.defaultSettings = defaultSettings; blurTextureDescriptor = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0); } In the BlurRenderPass class, declare the RTHandle field to store the reference to the temporary blur texture. private RTHandle blurTextureHandle; In the BlurRenderPass class, implement the Configure method. Unity calls this method before executing the render pass. public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) { //Set the blur texture size to be the same as the camera target size. blurTextureDescriptor.width = cameraTextureDescriptor.width; blurTextureDescriptor.height = cameraTextureDescriptor.height; //Check if the descriptor has changed, and reallocate the RTHandle if necessary. RenderingUtils.ReAllocateIfNeeded(ref blurTextureHandle, blurTextureDescriptor); } In the BlurRenderPass class, implement the UpdateBlurSettings method that updates the shader values. Use the Blit method to apply the two passes from the custom shader to the camera output. private static readonly int horizontalBlurId = Shader.PropertyToID(\"_HorizontalBlur\"); private static readonly int verticalBlurId = Shader.PropertyToID(\"_VerticalBlur\"); ... private void UpdateBlurSettings() { if (material == null) return; material.SetFloat(horizontalBlurId, defaultSettings.horizontalBlur); material.SetFloat(verticalBlurId, defaultSettings.verticalBlur); } Call the UpdateBlurSettings method in the Execute method. public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { //Get a CommandBuffer from pool. CommandBuffer cmd = CommandBufferPool.Get(); RTHandle cameraTargetHandle = renderingData.cameraData.renderer.cameraColorTargetHandle; UpdateBlurSettings(); // Blit from the camera target to the temporary render texture, // using the first shader pass. Blit(cmd, cameraTargetHandle, blurTextureHandle, material, 0); // Blit from the temporary render texture to the camera target, // using the second shader pass. Blit(cmd, blurTextureHandle, cameraTargetHandle, material, 1); //Execute the command buffer and release it back to the pool. context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } Implement the Dispose method that destroys the Material and the temporary render texture after the render pass execution. public void Dispose() { #if UNITY_EDITOR if (EditorApplication.isPlaying) { Object.Destroy(material); } else { Object.DestroyImmediate(material); } #else Object.Destroy(material); #endif if (blurTextureHandle != null) blurTextureHandle.Release(); } The complete code for this part is in section Custom render pass code. Enqueue the render pass in the custom renderer feature In this section, you instantiate the render pass in the Create method of the BlurRendererFeature class, and enqueue it in the AddRenderPasses method. In the Create method of the BlurRendererFeature class, instantiate the BlurRenderPass class. In the method, use the renderPassEvent field to specify when to execute the render pass. public override void Create() { if (shader == null) { return; } material = new Material(shader); blurRenderPass = new BlurRenderPass(material, settings); renderPassEvent = RenderPassEvent.AfterRenderingSkybox; } In the AddRenderPasses method of the BlurRendererFeature class, enqueue the render pass with the EnqueuePass method. public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { if (renderingData.cameraData.cameraType == CameraType.Game) { renderer.EnqueuePass(blurRenderPass); } } Implement the Dispose method that destroys the material instance that the Renderer Feature creates. The method also calls the Dispose method from the render pass class. protected override void Dispose(bool disposing) { blurRenderPass.Dispose(); #if UNITY_EDITOR if (EditorApplication.isPlaying) { Destroy(material); } else { DestroyImmediate(material); } #else Destroy(material); #endif } For the complete Renderer Feature code, refer to section Custom Renderer Feature code. The Scriptable Renderer Feature is now complete. The following image shows the effect of the feature in the Game view and the example settings. The effect of the Scriptable Renderer Feature in the Game view. Implement the volume component This section shows how to implement a volume component that lets you control the input values for the custom renderer feature. Create a new C# script and name it CustomVolumeComponent.cs. Inherit the CustomVolumeComponent class from the VolumeComponent class, add the [Serializable] attribute to the class. Add the using UnityEngine.Rendering; directive. using System; using UnityEngine.Rendering; [Serializable] public class CustomVolumeComponent : VolumeComponent { } Add the BoolParameter field to the CustomVolumeComponent class. This field lets you enable or disable the custom renderer feature. public class BlurVolumeComponent : VolumeComponent { public BoolParameter isActive = new BoolParameter(true); } Add the fields to control the blur settings defined in the custom renderer feature. [Serializable] public class CustomVolumeComponent : VolumeComponent { public BoolParameter isActive = new BoolParameter(true); public ClampedFloatParameter horizontalBlur = new ClampedFloatParameter(0.05f, 0, 0.5f); public ClampedFloatParameter verticalBlur = new ClampedFloatParameter(0.05f, 0, 0.5f); } In the BlurRenderPass script, change the UpdateBlurSettings method so that it uses the settings defined in a Volume or the default settings if no Volume is set. private void UpdateBlurSettings() { if (material == null) return; // Use the Volume settings or the default settings if no Volume is set. var volumeComponent = VolumeManager.instance.stack.GetComponent<CustomVolumeComponent>(); float horizontalBlur = volumeComponent.horizontalBlur.overrideState ? volumeComponent.horizontalBlur.value : defaultSettings.horizontalBlur; float verticalBlur = volumeComponent.verticalBlur.overrideState ? volumeComponent.verticalBlur.value : defaultSettings.verticalBlur; material.SetFloat(horizontalBlurId, horizontalBlur); material.SetFloat(verticalBlurId, verticalBlur); } In the Unity scene, create a local Box Volume. If a Volume Profile is missing, create a new one by clicking New next to the Profile property. Add the Custom Volume Component override to the Volume. Enable the settings in the Custom Volume Component override and set the values for this Volume. Move the Volume so that the camera is inside it. The settings from the Volume override the default settings from the custom renderer feature. All complete code for the scripts in this example This section contains the complete code for all the scripts in this example. Custom Renderer Feature code Below is the complete code for the custom Renderer Feature script. using System; using UnityEditor; using UnityEngine; using UnityEngine.Rendering.Universal; public class BlurRendererFeature : ScriptableRendererFeature { [SerializeField] private BlurSettings settings; [SerializeField] private Shader shader; private Material material; private BlurRenderPass blurRenderPass; public override void Create() { if (shader == null) { return; } material = new Material(shader); blurRenderPass = new BlurRenderPass(material, settings); blurRenderPass.renderPassEvent = RenderPassEvent.AfterRenderingSkybox; } public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { if (renderingData.cameraData.cameraType == CameraType.Game) { renderer.EnqueuePass(blurRenderPass); } } protected override void Dispose(bool disposing) { blurRenderPass.Dispose(); #if UNITY_EDITOR if (EditorApplication.isPlaying) { Destroy(material); } else { DestroyImmediate(material); } #else Destroy(material); #endif } } [Serializable] public class BlurSettings { [Range(0, 0.4f)] public float horizontalBlur; [Range(0, 0.4f)] public float verticalBlur; } Custom render pass code Below is the complete code for the custom Render Pass script. using UnityEditor; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class BlurRenderPass : ScriptableRenderPass { private static readonly int horizontalBlurId = Shader.PropertyToID(\"_HorizontalBlur\"); private static readonly int verticalBlurId = Shader.PropertyToID(\"_VerticalBlur\"); private BlurSettings defaultSettings; private Material material; private RenderTextureDescriptor blurTextureDescriptor; private RTHandle blurTextureHandle; public BlurRenderPass(Material material, BlurSettings defaultSettings) { this.material = material; this.defaultSettings = defaultSettings; blurTextureDescriptor = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0); } public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) { // Set the blur texture size to be the same as the camera target size. blurTextureDescriptor.width = cameraTextureDescriptor.width; blurTextureDescriptor.height = cameraTextureDescriptor.height; // Check if the descriptor has changed, and reallocate the RTHandle if necessary RenderingUtils.ReAllocateIfNeeded(ref blurTextureHandle, blurTextureDescriptor); } private void UpdateBlurSettings() { if (material == null) return; // Use the Volume settings or the default settings if no Volume is set. var volumeComponent = VolumeManager.instance.stack.GetComponent<CustomVolumeComponent>(); float horizontalBlur = volumeComponent.horizontalBlur.overrideState ? volumeComponent.horizontalBlur.value : defaultSettings.horizontalBlur; float verticalBlur = volumeComponent.verticalBlur.overrideState ? volumeComponent.verticalBlur.value : defaultSettings.verticalBlur; material.SetFloat(horizontalBlurId, horizontalBlur); material.SetFloat(verticalBlurId, verticalBlur); } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { //Get a CommandBuffer from pool. CommandBuffer cmd = CommandBufferPool.Get(); RTHandle cameraTargetHandle = renderingData.cameraData.renderer.cameraColorTargetHandle; UpdateBlurSettings(); // Blit from the camera target to the temporary render texture, // using the first shader pass. Blit(cmd, cameraTargetHandle, blurTextureHandle, material, 0); // Blit from the temporary render texture to the camera target, // using the second shader pass. Blit(cmd, blurTextureHandle, cameraTargetHandle, material, 1); //Execute the command buffer and release it back to the pool. context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } public void Dispose() { #if UNITY_EDITOR if (EditorApplication.isPlaying) { Object.Destroy(material); } else { Object.DestroyImmediate(material); } #else Object.Destroy(material); #endif if (blurTextureHandle != null) blurTextureHandle.Release(); } } Volume Component code Below is the complete code for the Volume Component script. using System; using UnityEngine.Rendering; [Serializable] public class CustomVolumeComponent : VolumeComponent { public BoolParameter isActive = new BoolParameter(true); public ClampedFloatParameter horizontalBlur = new ClampedFloatParameter(0.05f, 0, 0.5f); public ClampedFloatParameter verticalBlur = new ClampedFloatParameter(0.05f, 0, 0.5f); } The custom shader for the blur effect This section contains the code for the custom shader that implements the blur effect. Shader \"CustomEffects/Blur\" { HLSLINCLUDE #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" // The Blit.hlsl file provides the vertex shader (Vert), // the input structure (Attributes), and the output structure (Varyings) #include \"Packages/com.unity.render-pipelines.core/Runtime/Utilities/Blit.hlsl\" float _VerticalBlur; float _HorizontalBlur; float4 _BlitTexture_TexelSize; float4 BlurVertical (Varyings input) : SV_Target { const float BLUR_SAMPLES = 64; const float BLUR_SAMPLES_RANGE = BLUR_SAMPLES / 2; float3 color = 0; float blurPixels = _VerticalBlur * _ScreenParams.y; for(float i = -BLUR_SAMPLES_RANGE; i <= BLUR_SAMPLES_RANGE; i++) { float2 sampleOffset = float2 (0, (blurPixels / _BlitTexture_TexelSize.w) * (i / BLUR_SAMPLES_RANGE)); color += SAMPLE_TEXTURE2D(_BlitTexture, sampler_LinearClamp, input.texcoord + sampleOffset).rgb; } return float4(color.rgb / (BLUR_SAMPLES + 1), 1); } float4 BlurHorizontal (Varyings input) : SV_Target { const float BLUR_SAMPLES = 64; const float BLUR_SAMPLES_RANGE = BLUR_SAMPLES / 2; UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(input); float3 color = 0; float blurPixels = _HorizontalBlur * _ScreenParams.x; for(float i = -BLUR_SAMPLES_RANGE; i <= BLUR_SAMPLES_RANGE; i++) { float2 sampleOffset = float2 ((blurPixels / _BlitTexture_TexelSize.z) * (i / BLUR_SAMPLES_RANGE), 0); color += SAMPLE_TEXTURE2D(_BlitTexture, sampler_LinearClamp, input.texcoord + sampleOffset).rgb; } return float4(color / (BLUR_SAMPLES + 1), 1); } ENDHLSL SubShader { Tags { \"RenderType\"=\"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\"} LOD 100 ZWrite Off Cull Off Pass { Name \"BlurPassVertical\" HLSLPROGRAM #pragma vertex Vert #pragma fragment BlurVertical ENDHLSL } Pass { Name \"BlurPassHorizontal\" HLSLPROGRAM #pragma vertex Vert #pragma fragment BlurHorizontal ENDHLSL } } }"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/containers/how-to-custom-effect-render-objects.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/containers/how-to-custom-effect-render-objects.html",
    "title": "Example: How to create a custom rendering effect using the Render Objects Renderer Feature | mmo-rpg-unity",
    "keywords": "Example: How to create a custom rendering effect using the Render Objects Renderer Feature URP draws objects in the DrawOpaqueObjects and DrawTransparentObjects passes. You might need to draw objects at a different point in the frame rendering, or interpret and write rendering data (like depth and stencil) in alternate ways. The Render Objects Renderer Feature lets you do such customizations by letting you draw objects on a certain layer, at a certain time, with specific overrides. The example on this page describes how to create a custom rendering effect with the Render Objects Renderer Feature. Example overview The example on this page demonstrates how to implement the following effect: There is a character in the Scene. When the character goes behind GameObjects, Unity draws the character silhouette with a different Material. Prerequisites This example requires the following: A Unity project with the URP package installed. The Scriptable Render Pipeline Settings property refers to a URP asset (Project Settings > Graphics > Scriptable Render Pipeline Settings). Create example Scene and GameObjects To follow the steps in this example, create a new Scene with the following GameObjects: Create a Cube. Set its Scale values so that it looks like a wall. Create a Material and assign it the Universal Render Pipeline/Lit shader. Select the base color (for example, red). Call the Material Character. Create a basic character and assign it the Character Material. In this example, the character consists of three capsules: the big capsule in the center represents the body, and the two smaller capsules represent the hands. To make it easier to manipulate the character in the Scene, add the three Capsules as child GameObjects under the Character GameObject. Create a Material and assign it the Universal Render Pipeline/Unlit shader. Select the base color that you would like the character to have when it's behind GameObjects (for example, blue). Call the Material CharacterBehindObjects. Now you have the setup necessary to follow the steps in this example. Example implementation This section assumes that you created a Scene as described in section Example Scene and GameObjects. The example implementation uses two Render Objects Renderer Features: one to draw parts of the character that are behind other GameObjects, and another one to draw the parts of the character that are in front of other GameObjects. Create a Renderer Feature to draw the character behind GameObjects Follow these steps to create a Renderer Feature to draw the character behind GameObjects. Select a URP Renderer. In the Inspector, click Add Renderer Feature and select Render Objects. Select the Name field and enter the name of the new Renderer Feature, for example, DrawCharacterBehind. This example uses Layers to filter the GameObjects to render. Create a new Layer and call it Character. Select the Character GameObject and assign it to the Character Layer. To do this, open the Layer drop down and select Character. In the DrawCharacterBehind Renderer Feature, in Filters > Layer Mask, select Character. With this setting, this Renderer Feature renders GameObjects only in the Layer Character. In Overrides > Material, select the CharacterBehindObjects Material. The Renderer Feature overrides the Material of a GameObject with the selected Material. The intended behavior is that the Renderer Feature renders the character with the CharacterBehindObjects Material only when the character is behind other GameObjects. To achieve this, select the Depth check box, and set the Depth Test property to Greater. With these settings, Unity renders the character with the CharacterBehindObjects Material only when the character is behind another GameObject. However, Unity also renders parts of the character using the CharacterBehindObjects Material, because some parts of the character occlude the character itself. Create an extra Renderer Feature to avoid the self see-through effect The settings in the previous section result in the self see-through effect for the following reason: When performing the Opaque rendering pass of the URP Renderer, Unity renders all GameObjects belonging to the character with the Character Material and writes depth values to the Depth buffer. This happens before Unity starts executing the DrawCharacterBehind Renderer Feature, because, by default, new Render Objects Renderer Features have the value AfterRenderingOpaques in the Event property. The Event property defines the injection point where Unity injects Render Passes from the Render Objects Renderer Feature. The event when URP Renderer draws GameObjects in the Opaque Layer Mask is the BeforeRenderingOpaques event. When executing the DrawCharacterBehind Renderer Feature, Unity performs the depth test using the condition specified in the Depth Test property. In the following screenshot, a bigger capsule occludes part of the smaller capsule, and the depth test passes for that part of the smaller capsule. The Renderer Feature overrides the Material for that part. The following steps describe how to avoid such behavior and ensure that Unity draws all parts of the character with proper Materials. In the URP asset, in Filtering > Opaque Layer Mask, clear the check mark next to the Character Layer. Now Unity does not render the character unless it's behind a GameObject. Add a new Render Objects Renderer Feature, and call it Character. In the Character Renderer Feature, in Filters > Layer Mask, select the Character Layer. Now Unity renders the character with the Character Material even when the character is behind GameObjects. This happens because the DrawCharacterBehind Renderer Feature writes values to the depth buffer. When Unity executes the Character Renderer Feature, the pixels on the character appear to be in front of the pixels that Unity has drawn previously, and Unity draws on top of those pixels. In the DrawCharacterBehind Renderer Feature, In Overrides > Depth, clear the Write Depth check box. With this setting, the DrawCharacterBehind Renderer Feature does not make changes to the depth buffer and the Character Renderer Feature does not draw the character when it's behind GameObjects. The example is complete. When the character goes behind GameObjects, Unity draws the character silhouette with the CharacterBehindObjects Material. With the extra Character Renderer Feature, Unity renders GameObjects as follows: URP Renderer does not render the Character GameObject in the BeforeRenderingOpaques event, because the Character Layer is excluded from the Opaque Layer Mask list. The DrawCharacterBehind Renderer Feature draws parts of the character that are behind other GameObjects. This happens in the AfterRenderingOpaques event. The Character Renderer Feature draws parts of the character that are in front of other GameObjects. This happens in the AfterRenderingOpaques event, and after executing the DrawCharacterBehind Renderer Feature."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/containers/post-processing-custom-effect-low-code.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/containers/post-processing-custom-effect-low-code.html",
    "title": "How to create a custom post-processing effect | mmo-rpg-unity",
    "keywords": "How to create a custom post-processing effect The example on this page shows how to use a Full Screen Render Pass to create a grayscale custom post-processing effect. Prerequisites This example requires the following: A Unity project with the URP package installed. The Scriptable Render Pipeline Settings property refers to a URP asset (Project Settings > Graphics > Scriptable Render Pipeline Settings). Create a Fullscreen Shader Graph You must create a Fullscreen Shader Graph to create a custom post-processing effect. Create a new Shader Graph in your Project. To do this right-click in the Project window and select Create > Shader Graph > URP > Fullscreen Shader Graph. Add a URP Sample Buffer node. To do this right-click in the Shader Graph window, and select Create Node. Then locate and select URP Sample Buffer. In the URP Sample Buffer node's Source Buffer dropdown menu, select BlitSource. Add a Vector 3 node. Assign the Vector 3 node the following values: X = 0.2126 Y = 0.7152 Z = 0.0722 Add a Dot Product node. Connect the nodes as shown below. Node Connection URP Sample Buffer Output to Dot Product A Vector 3 Out to Dot Product B Dot Product Out to Fragment Base Color Save your Shader Graph. Create a new Material in your Project. To do this right-click in the Project window and select Create > Material. Apply the Shader Graph shader to the Material. To do this, open the Material in the Inspector and select Shader > Shader Graphs, then select the Shader Graph you created in the previous steps. Use the Material in a Full Screen Pass Renderer Feature Once you've created a compatible Shader Graph and Material, you can use the Material with a Full Screen Pass Renderer Feature to create a custom post-processing effect. In the Project window, select a URP Renderer. In the Inspector, click Add Renderer Feature and select Full Screen Pass Renderer Feature. For more information on adding Renderer Features refer to How to add a Renderer Feature to a Renderer. Set the Post Process Material to the Material you created with the Fullscreen Shader Graph. Set Injection Point to After Rendering Post Processing. Set Requirements to Color. You should now see the effect in both Scene view and Game view. Example scene with a grayscale custom post-processing effect."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/creating-a-new-project-with-urp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/creating-a-new-project-with-urp.html",
    "title": "Create a project with URP | mmo-rpg-unity",
    "keywords": "Create a project with URP The Unity Hub contains the following templates that let you create a pre-configured Universal Render Pipeline (URP) project. Template Description 2D URP This is an empty project for 2D applications. URP is pre-configured with 2D renderer. 3D (URP) This is an empty project for 3D applications. URP is pre-configured with 3D renderer. 3D Sample Scenes (URP) This sample contains four environments that showcase the versatility, scalability, and customizability of URP. The project demonstrates different art styles, rendering paths, and scene complexities. Each scene shows you how to tailor a project to different platforms, from mobile and untethered devices to high-end PCs and consoles. To create a new project using a URP template: Open the Unity Hub. Select the Projects tab, then select New project. Select one of the URP templates. Fill in the Project settings fields and select Create project. Unity creates a new pre-configured URP project."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/blit-multiple-rthandles.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/blit-multiple-rthandles.html",
    "title": "Blit multiple RTHandle textures and draw them on the screen | mmo-rpg-unity",
    "keywords": "Blit multiple RTHandle textures and draw them on the screen This page describes a blit operation that involves multiple RTHandle textures and a custom shader effect. The description uses the DistortTunnel scene from the URP package samples as an example. The code samples on the page are from the following Scene from the URP Package Samples: * Assets > Samples > Universal RP > 14.0.9 > URP Package Samples > RendererFeatures > DistortTunnel The sample Scene uses the following assets to perform the blit operation: A scriptable Renderer Feature enqueues three render passes for execution. Two render passes create intermediate textures. The final render pass binds the textures and performs the blit operation. Import URP Package Samples to access the complete source code and the Scene. For general information on the blit operation, refer to URP blit best practices. Define the render passes in the Scriptable Renderer Feature The Renderer Feature defines the render passes necessary for rendering the intermediate textures and for the blit operation. private DistortTunnelPass_CopyColor m_CopyColorPass; private DistortTunnelPass_Tunnel m_TunnelPass; private DistortTunnelPass_Distort m_DistortPass; The RTHandle variables Each of three render passes and the renderer feature declare the RTHandle variables to create and process the textures for the sample effect. For example, the DistortTunnelRendererFeature class declares the RTHandle variables, which it first passes as arguments to the render passes, and then uses the resulting textures in the final render pass (DistortTunnelPass_Distort). The Distort shader, which the example uses for the final effect, uses the textures from the following code sample. private RTHandle m_CopyColorTexHandle; private const string k_CopyColorTexName = \"_TunnelDistortBgTexture\"; private RTHandle m_TunnelTexHandle; private const string k_TunnelTexName = \"_TunnelDistortTexture\"; To create temporary render textures within the RTHandle system, the SetupRenderPasses method in the Renderer Feature uses the ReAllocateIfNeeded method: RenderingUtils.ReAllocateIfNeeded(ref m_CopyColorTexHandle, desc, FilterMode.Bilinear, TextureWrapMode.Clamp, name: k_CopyColorTexName ); RenderingUtils.ReAllocateIfNeeded(ref m_TunnelTexHandle, desc, FilterMode.Bilinear, TextureWrapMode.Clamp, name: k_TunnelTexName ); Configure the input and output textures In this example, the SetRTHandles methods in render passes contain code for configuring the input and output textures. For example, here is the SetRTHandles method from the DistortTunnelPass_Distort render pass: public void SetRTHandles(ref RTHandle copyColorRT, ref RTHandle tunnelRT, RTHandle dest) { if (m_Material == null) return; m_OutputHandle = dest; m_Material.SetTexture(copyColorRT.name,copyColorRT); m_Material.SetTexture(tunnelRT.name,tunnelRT); } Perform the blit operation There are two blit operations in this example. The first example blit operation is in the DistortTunnelPass_CopyColor render pass. The pass blits the texture rendered by the camera to the RTHandle texture called _TunnelDistortBgTexture. using (new ProfilingScope(cmd, m_ProfilingSampler)) { Blitter.BlitCameraTexture(cmd, m_Source, m_OutputHandle, 0); } The second example blit operation is the DistortTunnelPass_Distort render pass. Before performing the blit, the pass binds two source textures directly to the Material in the SetRTHandles method: m_Material.SetTexture(copyColorRT.name,copyColorRT); m_Material.SetTexture(tunnelRT.name,tunnelRT); And then the pass performs the blit operation: using (new ProfilingScope(cmd, m_ProfilingSampler)) { Blitter.BlitCameraTexture(cmd, m_OutputHandle, m_OutputHandle, m_Material, 0); } Additional resources Perform a full screen blit in URP This page describes a basic blit operation and provides a complete step-by-step description of the implementation."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/blit-overview.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/blit-overview.html",
    "title": "URP blit best practices | mmo-rpg-unity",
    "keywords": "URP blit best practices A blit operation is a process of copying a source texture to a destination texture. This page provides an overview of different ways to perform a blit operation in URP and best practices to follow when writing custom render passes. The legacy CommandBuffer.Blit API Avoid using the CommandBuffer.Blit API in URP projects. The CommandBuffer.Blit API is the legacy API. It implicitly runs extra operations related to changing states, binding textures, and setting render targets. Those operations happen under the hood in SRP projects and are not transparent to the user. The API has compatibility issues with the URP XR integration. Using cmd.Blit might implicitly enable or disable XR shader keywords, which breaks XR SPI rendering. The CommandBuffer.Blit API is not compatible with NativeRenderPass and RenderGraph. Similar considerations apply to any utilities or wrappers relying on cmd.Blit internally, RenderingUtils.Blit is one such example. SRP Blitter API Use the Blitter API in URP projects. This API does not rely on legacy logic, and is compatible with XR, native Render Passes, and other SRP APIs. Custom full-screen blit example The How to perform a full screen blit in URP example shows how to create a custom Renderer Feature that performs a full screen blit. The example works in XR and is compatible with SRP APIs."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/blit-to-rthandle.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/blit-to-rthandle.html",
    "title": "Blit Camera color texture to RTHandle | mmo-rpg-unity",
    "keywords": "Blit Camera color texture to RTHandle This page describes the operation of blitting a camera color texture to an output texture, and setting the output texture as a global property. The shaders in the Scene use the global texture. The description uses the BlitToRTHandle scene from the URP package samples. The code samples on the page are from the following Scene from the URP Package Samples: * Assets > Samples > Universal RP > 14.0.9 > URP Package Samples > RendererFeatures > BlitToRTHandle The sample Scene uses the following assets to perform the blit operation: A scriptable Renderer Feature that enqueues a render pass for execution. A render pass that blits a camera color texture to an output texture, and sets the output texture as a global property. Import URP Package Samples to access the complete source code and the Scene. For general information on the blit operation, refer to URP blit best practices. Define RTHandles in a render pass The ScriptableRenderPass in the sample implementation defines the RTHandle variables for storing the input and the output textures. private RTHandle m_InputHandle; private RTHandle m_OutputHandle; Configure the input and output textures This section describes how the sample uses the RTHandle variables to configure the input and output textures. Input texture In this example, the Renderer Feature uses the SetInput method in the render pass to set the input texture: public void SetInput(RTHandle src) { // The Renderer Feature uses this variable to set the input RTHandle. m_InputHandle = src; } The Renderer Feature calls the SetInput method in the SetupRenderPasses method: public override void SetupRenderPasses(ScriptableRenderer renderer, in RenderingData renderingData) { if (renderingData.cameraData.cameraType != CameraType.Game) return; m_CopyColorPass.SetInput(renderer.cameraColorTargetHandle); } Note To set the m_InputHandle variable directly in the render pass, without calling the SetInput method, use the following code in the Execute method: m_InputHandle = renderingData.cameraData.renderer.cameraColorTargetHandle; Output texture The Configure method configures the output texture for the blit operation. The ReAllocateIfNeeded method creates a temporary render texture within the RTHandle system. public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) { // Configure the custom RTHandle var desc = cameraTextureDescriptor; desc.depthBufferBits = 0; desc.msaaSamples = 1; RenderingUtils.ReAllocateIfNeeded(ref m_OutputHandle, desc, FilterMode.Bilinear, TextureWrapMode.Clamp, name: k_OutputName ); // Set the RTHandle as the output target ConfigureTarget(m_OutputHandle); } Bind a source texture with the Blitter API By default, the Blitter API binds a source texture with the name _BlitTexture in the Blitter.BlitCameraTexture method. The example uses this texture for the m_InputHandle variable. The Shader Graph for the Material that the Renderer Feature uses contains the _BlitTexture property: _BlitTexture property in Shader Graph Note In this particular example, you can achieve the same effect by using the URP Sample Buffer node instead of the Sample Texture 2D node. In the URP Sample Buffer node, set Source Buffer to BlitSource, and the input value to Default. Note If you want to perform a direct copy of the input texture without applying any effects, it's not necessary to provide a Material as a parameter to the BlitCameraTexture method. You can use the following code instead of the Blitter.BlitCameraTexture line in the sample: Blitter.BlitCameraTexture(cmd, m_InputHandle, m_OutputHandle, 0, true); Refer to the following page for more information on the Blitter API: UnityEngine.Rendering.Blitter. Perform the blit operation In the render pass, the BlitCameraTexture method from the Blitter API performs the blit operation. using (new ProfilingScope(cmd, m_ProfilingSampler)) { // Blit the input RTHandle to the output one Blitter.BlitCameraTexture(cmd, m_InputHandle, m_OutputHandle, m_Material, 0); // Make the output texture available for the shaders in the scene cmd.SetGlobalTexture(m_OutputId, m_OutputHandle.nameID); } Additional resources Perform a full screen blit in URP This page describes a basic blit operation and provides a complete step-by-step description of the implementation. Blit multiple RTHandle textures and draw them on the screen This page describes a more complex blit operation that uses multiple textures defined as RTHandle."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/custom-pass-injection-points.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/custom-pass-injection-points.html",
    "title": "Injection points | mmo-rpg-unity",
    "keywords": "Injection points URP contains multiple injection points that let you inject render passes into the frame rendering loop and execute them upon different events. Injection points give a custom render pass access to URP buffers. A render pass has read and write access to all buffers at each injection point. Unity provides the following events in the rendering loop. You can use these events to inject your custom passes. Injection point Description BeforeRendering Executes a ScriptableRenderPass instance before rendering any other passes in the pipeline for the current Camera. Camera matrices and stereo rendering are not setup at this point. You can use this injection point to draw to custom input textures used later in the pipeline, for example, LUT textures. BeforeRenderingShadows Executes a ScriptableRenderPass instance before rendering shadow maps (MainLightShadow, AdditionalLightsShadow passes). Camera matrices and stereo rendering are not set up at this point. AfterRenderingShadows Executes a ScriptableRenderPass instance after rendering shadow maps (MainLightShadow, AdditionalLightsShadow passes). Camera matrices and stereo rendering are not set up this point. BeforeRenderingPrePasses Executes a ScriptableRenderPass instance before rendering prepasses (DepthPrepass, DepthNormalPrepass passes). Camera matrices and stereo rendering are already set up at this point. AfterRenderingPrePasses Executes a ScriptableRenderPass instance after rendering prepasses (DepthPrepass, DepthNormalPrepass passes). Camera matrices and stereo rendering are set up at this point. BeforeRenderingGbuffer Executes a ScriptableRenderPass instance before rendering the GBuffer pass. AfterRenderingGbuffer Executes a ScriptableRenderPass instance after rendering the GBuffer pass. BeforeRenderingDeferredLights Executes a ScriptableRenderPass instance before rendering the Deferred pass. AfterRenderingDeferredLights Executes a ScriptableRenderPass instance after rendering the Deferred pass. BeforeRenderingOpaques Executes a ScriptableRenderPass instance before rendering opaque objects (DrawOpaqueObjects pass). AfterRenderingOpaques Executes a ScriptableRenderPass instance after rendering opaque objects (DrawOpaqueObjects pass). BeforeRenderingSkybox Executes a ScriptableRenderPass instance before rendering the skybox (Camera.RenderSkybox pass). AfterRenderingSkybox Executes a ScriptableRenderPass instance after rendering the skybox (Camera.RenderSkybox pass). BeforeRenderingTransparents Executes a ScriptableRenderPass instance before rendering transparent objects (DrawTransparentObjects pass). AfterRenderingTransparents Executes a ScriptableRenderPass instance after rendering transparent objects (DrawTransparentObjects pass). BeforeRenderingPostProcessing Executes a ScriptableRenderPass instance before rendering post-processing effects (Render PostProcessing Effects pass). AfterRenderingPostProcessing Executes a ScriptableRenderPass instance after rendering post-processing effects but before the final blit, post-processing anti-aliasing effects, and color grading. AfterRendering Executes ScriptableRenderPass instance after rendering all other passes. The following diagram shows the passes and the flow of frame resources in a URP frame:"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/inject-render-pass-via-script.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customize/inject-render-pass-via-script.html",
    "title": "Inject a render pass via scripting | mmo-rpg-unity",
    "keywords": "Inject a render pass via scripting Unity raises a beginCameraRendering event before it renders each active Camera in every frame. If a Camera is inactive (for example, if the Camera component checkbox is cleared on a Camera GameObject), Unity does not raise a beginCameraRendering event for this Camera. When you subscribe a method to this event, you can execute custom logic before Unity renders the Camera. Examples of custom logic include rendering extra Cameras to Render Textures, and using those Textures for effects like planar reflections or surveillance camera views. Other events in the RenderPipelineManager class provide more ways to customize URP. You can also use the principles described in this article with those events. Use the RenderPipelineManager API Subscribe a method to one of the events in the RenderPipelineManager class. In the subscribed method, use the EnqueuePass method of a ScriptableRenderer instance to inject a custom render pass into the URP frame rendering. Example code: public class EnqueuePass : MonoBehaviour { [SerializeField] private BlurSettings settings; private BlurRenderPass blurRenderPass; private void OnEnable() { ... blurRenderPass = new BlurRenderPass(settings); // Subscribe the OnBeginCamera method to the beginCameraRendering event. RenderPipelineManager.beginCameraRendering += OnBeginCamera; } private void OnDisable() { RenderPipelineManager.beginCameraRendering -= OnBeginCamera; blurRenderPass.Dispose(); ... } private void OnBeginCamera(ScriptableRenderContext context, Camera cam) { ... // Use the EnqueuePass method to inject a custom render pass cam.GetUniversalAdditionalCameraData() .scriptableRenderer.EnqueuePass(blurRenderPass); } } Example This example demonstrates how to subscribe a method to the beginCameraRendering event. To follow the steps in this example, create a new Unity project using the Universal Project Template In the scene, create a Cube. Name it Example Cube. In your Project, create a C# script. Call it URPCallbackExample. Copy and paste the following code into the script. using UnityEngine; using UnityEngine.Rendering; public class URPCallbackExample : MonoBehaviour { // Unity calls this method automatically when it enables this component private void OnEnable() { // Add WriteLogMessage as a delegate of the RenderPipelineManager.beginCameraRendering event RenderPipelineManager.beginCameraRendering += WriteLogMessage; } // Unity calls this method automatically when it disables this component private void OnDisable() { // Remove WriteLogMessage as a delegate of the RenderPipelineManager.beginCameraRendering event RenderPipelineManager.beginCameraRendering -= WriteLogMessage; } // When this method is a delegate of RenderPipeline.beginCameraRendering event, Unity calls this method every time it raises the beginCameraRendering event void WriteLogMessage(ScriptableRenderContext context, Camera camera) { // Write text to the console Debug.Log($\"Beginning rendering the camera: {camera.name}\"); } } Note: When you subscribe to an event, your handler method (in this example, WriteLogMessage) must accept the parameters defined in the event delegate. In this example, the event delegate is RenderPipeline.BeginCameraRendering, which expects the following parameters: <ScriptableRenderContext, Camera>. Attach the URPCallbackExample script to Example Cube. Select Play. Unity prints the message from the script in the Console window each time Unity raises the beginCameraRendering event. To raise a call to the OnDisable() method: In the Play mode, select Example Cube and clear the checkbox next to the script component title. Unity unsubscribes WriteLogMessage from the RenderPipelineManager.beginCameraRendering event and stops printing the message in the Console window."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customizing-urp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/customizing-urp.html",
    "title": "Custom rendering and post-processing | mmo-rpg-unity",
    "keywords": "Custom rendering and post-processing Customize and extend the rendering process in the Universal Render Pipeline (URP). URP uses Renderer Features to implement certain effects. URP includes a selection of pre-built Renderer Features and the ability to create customized Renderer Features known as Scriptable Renderer Features. Page Description Custom render passes Create a custom render pass in a C# script and inject it into the URP frame rendering loop. Injection points reference The injection points you can use to inject render passes into the frame rendering loop. Scriptable Renderer Feature and Scriptable Render Pass API reference Common methods you can use to write Scriptable Renderer Passes and Scriptable Renderer Features. Additional resources Pre-built effects (Renderer Features) How to create a custom post-processing effect"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/decal-shader.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/decal-shader.html",
    "title": "Decal Shader Graph | mmo-rpg-unity",
    "keywords": "Decal Shader Graph The Decal Projector component can project a Material as a decal if the Material uses a Shader Graph with the Decal Material type. Shader Graph with the Decal Material type URP contains the pre-built Decal Shader (Shader Graphs/Decal). Decal Material properties and advanced options. You can assign a Material that uses a Decal Shader Graph to a GameObject directly. For example, you can use a Quad as the Decal GameObject. The pre-built Decal Shader has the following properties: Base Map: the Base texture of the Material. Normal Map: the normal texture of the Material. Normal Blend: this property defines the proportion in which the the normal texture selected in the Normal Map property blends with the normal map of the Material that the decal is projected on. 0: the decal does not affect the Material it's projected on. 1: the normal map of the decal replaces the normal map of the Material it's projected on. You can create your own Shader Graphs that render decals in a way that suits your project best. The Decal Material properties above are defined in the pre-built Shader Graph. Custom decal Material properties depend on a custom Shader Graph. The following table describes the properties in the Advanced Options section. These properties are common for all decal shaders. Property Description Enable GPU Instancing Enabling this option lets URP render meshes with the same geometry and Material in one batch, when possible. This makes rendering faster. URP cannot render Meshes in one batch if they have different Materials or if the hardware does not support GPU instancing. Priority This property defines the order in which URP draws decals in the Scene. URP draws decals with lower Priority values first, and draws decals with higher Priority values on top of those with lower values. If there are multiple Decal Materials with the same Priority in the Scene, URP renders them in the order in which the Materials were created. Mesh Bias Type Select the Mesh bias type. The Mesh bias lets you prevent z-fighting between the Decal GameObject and the GameObject it overlaps. This property is only applicable for GameObjects with a Decal Material type assigned directly. View Bias A world-space bias (in meters). When drawing the Decal GameObject, Unity shifts each pixel of the GameObject by this value along the view vector. A positive value shifts pixels closer to the Camera, so that Unity draws the Decal GameObject on top of the overlapping Mesh, which prevents z-fighting. Decal Projectors ignore this property. Depth Bias When drawing the Decal GameObject, Unity changes the depth value of each pixel of the GameObject by this value. A negative value shifts pixels closer to the Camera, so that Unity draws the Decal GameObject on top of the overlapping Mesh, which prevents z-fighting. Decal Projectors ignore this property. Create custom Decal shaders The pre-built Shader Graphs/Decal shader serves as a simple example. You can create your own decal shaders that render decals in a way that suits your project best. To create a custom decal Shader Graph, select the Decal value in Material property of the shader target. Enabling one of the following properties override the equivalent Lit Shader property on the surface of the Material. Property Description Affect BaseColor When enabled, the shader affects the base color. Most decals make use of this option. An exception is a surface damage effect, were you might want to manipulate other properties, such as normals. From left to right: shader affecting only the color, affecting all properties, affecting all properties but color. Affect Normal When enabled, the shader affects normals. Use cases: adding damage effects to materials, for example, bullet holes or cracks. Use the Blend property to blend the normals of the decal with the normals of the surface it's projected to. If the Blend property is disabled, the decal overrides the normals all over the surface it's projected to. From left to right: Affect Normal is off; Affect Normal is on, Blend is off; Affect Normal and Blend are on. Affect MAOS MOAS stands for Metallic, Ambient Occlusion, and Smoothness. These properties are grouped together to save memory. You can change values of each property separately in the shader, but all properties are blended with a single common alpha value. Use cases: Override smoothness to highlight puddles or wet paint. Override metallic values with lower values to render rust. Override AO to give the decal more depth. Left: the decal does not affect MAOS. Right: the decal affects MAOS. Affect Emission Use cases: you can affect the emission values to make surfaces seem like they are emitting light, or to make surfaces seem like they are being lit by light. Left: Affect Emission is off. Right: Affect Emission is on. To improve performance, pack data for different surface properties into a single texture. This way the shader performs fewer samples and Unity stores fewer textures. For example, the following Shader Graph uses a normal map and a mask map to drive all properties in the shader. This decal is used for the damaged tarmac effect, and a hardcoded roughness value of 0 suites the use case. The shader samples the mask and uses the color for setting the Ambient Occlusion values (Red channel), smoothness values (Green channel), Emission intensity values (Blue channel), and alpha values for the entire decal. Decals are often blended using single alpha values for all properties. The following image shows the mask map for the example tarmac cracks: Example of mask map that packs Ambient Occlusion, Smoothness, Emission, and alpha values of a decal atlas into a single texture."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/faq.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/faq.html",
    "title": "Frequently asked questions (FAQ) | mmo-rpg-unity",
    "keywords": "Frequently asked questions (FAQ) This section answers some frequently asked questions about the Universal Render Pipeline (URP). These questions come from the General Graphics section on our forums, from the Unity Discord channel, and from our support teams. For information about the High Definition Render Pipeline (HDRP), refer to the HDRP documentation. Can I use URP and HDRP at the same time? No. They're both built with the Scriptable Render Pipeline (SRP), but their render paths and light models are different. Can I convert from one pipeline to the other? You can convert from the Built-in Render Pipeline to URP. To do so, you'll have to re-write your Assets and redo the lighting in your game or app. Refer to this upgrade guide on installing URP into an existing Project. You can use our upgrader to upgrade Built-in Shaders to the URP Shaders. For custom Shaders, you'll have to upgrade them manually. You should not swap pipeline Assets from one pipeline to another at run time, and there's no upgrader between URP and HDRP. How do I update the Universal Render Pipeline package? You should update via the Package Manager. In the Unity Editor, go to Unity > Window > Package Manager, and find the Universal RP package. If you’ve added SRP code or Shader Graph manually via Github, make sure to upgrade them to the same package version as URP in your manifest file. Where has Dynamic Batching gone? The Dynamic Batching checkbox has moved from the Player Settings to the URP Asset. How do I enable Double Sided Global Illumination in the Editor? In the Material Inspector, find Render Face, and select Both. This means that both sides of your geometry contribute to global illumination, because URP doesn’t cull either side. Is this render pipeline usable for desktop apps and games? Yes. The graphics quality and performance is scalable across platforms, so you can create apps for PCs and consoles as well as mobile devices. A certain feature from the Built-in Render Pipeline is not supported in URP. Will URP support it? To see which features URP currently supports, check the comparison table. URP will not support features marked as Not Supported. Does URP have a public roadmap? Yes. You can check it here. You can add suggestions as well. To do so, you’ll have to enter your email address, but you won’t have to make an account. I’ve found a bug. How do I report it? You can open bugs by using the bug reporter system. URP bugs go through the same process as all other Unity bugs. You can also check the active list of bugs for URP in the issue tracker. I’ve upgraded my Project from the Built-in render pipeline to URP, but it’s not running faster. Why? URP and the Built-in Render Pipeline have different quality settings. While the Built-in Render Pipeline configures many settings in different places like the Quality Settings, Graphics Settings, and Player Settings, all URP settings are stored in the URP Asset. The first thing to do is to check whether your URP Asset settings match the settings your Built-in render pipeline Project. For example, if you disabled MSAA or HDR in your Built-in render pipeline Project, make sure they are disabled in the URP Asset in your URP Project. For advice on configuring URP Assets, refer to documentation on the URP Asset. If, after comparing the settings, you still experience worse performance with URP, please open a bug report and attach your Project. URP doesn’t run on device X or platform Y. Is this expected? No. Please open a bug report. My Project takes a long time to build. Is this expected? We are looking into how to strip Shader keywords more aggressively. You can help the Shader stripper by disabling features you don’t require for your game in the URP Asset. For more information on settings that affect shader variants and build time, refer to the shader stripping documentation. How do I set Camera clear flags in URP? You can set the Background Type in the Camera Inspector to control how a Camera's color buffer is initialized. What rendering space does URP work in? By default, URP uses a linear color space while rendering. You can also use a gamma color space, which is non-linear. To do so, toggle it in the Player Settings."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/features/rendering-debugger.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/features/rendering-debugger.html",
    "title": "Rendering Debugger | mmo-rpg-unity",
    "keywords": "Rendering Debugger The Rendering Debugger window lets you visualize various lighting, rendering, and Material properties. The visualizations help you identify rendering issues and optimize Scenes and rendering configurations. This section contains the following topics: How to access the Rendering Debugger. Information on how to access the Rendering Debugger window in the Editor, in the Play mode, and at runtime in Development builds. Navigation at runtime How to navigate the Rendering Debugger interface at runtime. Rendering Debugger window sections Descriptions of the elements and properties in the Rendering Debugger window. How to access the Rendering Debugger The Rendering Debugger window is available in the following modes: Mode Platform Availability How to Open the Rendering Debugger Editor All Yes (window in the Editor) Select Window > Analysis > Rendering Debugger Play mode All Yes (overlay in the Game view) On a desktop or laptop computer, press LeftCtrl+Backspace (LeftCtrl+Delete on macOS) On a console controller, press L3 and R3 (Left Stick and Right Stick) Runtime Desktop/Laptop Yes (only in Development builds) Press LeftCtrl+Backspace (LeftCtrl+Delete on macOS) Runtime Console Yes (only in Development builds) Press L3 and R3 (Left Stick and Right Stick) Runtime Mobile Yes (only in Development builds) Use a three-finger double tap To enable all the sections of the Rendering Debugger in your built application, disable Strip Debug Variants in Project Settings > Graphics > URP Global Settings. Otherwise, you can only use the Display Stats section. To disable the runtime UI, use the enableRuntimeUI property. Note When using the Rendering Debugger window in the Development build, clear the Strip Debug Variants check box in Project Settings > Graphics > URP Global Settings. Navigation at runtime Keyboard Action Control Change the current active item Use the arrow keys Change the current tab Use the Page up and Page down keys (Fn + Up and Fn + Down keys respectively for MacOS) Display the current active item independently of the debug window Press the right Shift key Xbox Controller Action Control Change the current active item Use the Directional pad (D-Pad) Change the current tab Use the Left Bumper and Right Bumper Display the current active item independently of the debug window Press the X button PlayStation Controller Action Control Change the current active item Use the Directional buttons Change the current tab Use the L1 button and R1 button Display the current active item independently of the debug window Press the Square button Rendering Debugger window sections The Rendering Debugger window contains the following sections: Display Stats Frequently Used Material Lighting Rendering The following illustration shows the Rendering Debugger window in the Scene view. Display Stats The Display Stats panel shows statistics relevant to debugging performance issues in your project. You can only view this section of the Rendering Debugger in Play mode. Use the [runtime shortcuts](#Navigation at runtime) to open the Display stats window in the scene view at runtime. Frame Stats The Frame Stats section displays the average, minimum, and maximum value of each property. HDRP calculates each Frame Stat value over the 30 most recent frames. Property Description Frame Rate The frame rate (in frames per second) for the current camera view. Frame Time The total frame time for the current camera view. CPU Main Thread Frame The total time (in milliseconds) between the start of the frame and the time when the Main Thread finished the job. CPU Render Thread Frame The time (in milliseconds) between the start of the work on the Render Thread and the time Unity waits to render the present frame (Gfx.PresentFrame). CPU Present Wait The time (in milliseconds) that the CPU spent waiting for Unity to render the present frame (Gfx.PresentFrame) during the last frame. GPU Frame The amount of time (in milliseconds) the GPU takes to render a given frame. Debug XR Layout Display debug information for XR passes. This mode is only available in editor and development builds. Bottlenecks A bottleneck is a condition that occurs when one process performs significantly slower than other components, and other components depend on it. The Bottlenecks section describes the distribution of the last 60 frames across the CPU and GPU. You can only see the Bottleneck information when you build your player on a device. Note: Vsync limits the Frame Rate based on the refresh rate of your device’s screen. This means when you enable Vsync, the Present Limited category is 100% in most cases. To turn Vsync off, go to Edit > Project settings > Quality > Current Active Quality Level and set the Vsync Count set to Don't Sync. Bottleneck categories Category Description CPU The percentage of the last 60 frames in which the CPU limited the frame time. GPU The percentage of the last 60 frames in which the GPU limited the frame time. Present limited The percentage of the last 60 frames in which the frame time was limited by the following presentation constraints: • Vertical Sync (Vsync): Vsync synchronizes rendering to the refresh rate of your display. •Target framerate: A function that you can use to manually limit the frame rate of an application. If a frame is ready before the time you specify in targetFrameRate, Unity waits before presenting the frame. Balanced This percentage of the last 60 frames in which the frame time was not limited by any of the above categories. A frame that is 100% balanced indicates the processing time for both CPU and GPU is approximately equal. Bottleneck example If Vsync limited 20 of the 60 most recent frames, the Bottleneck section might appear as follows: CPU 0.0%: This indicates that HDRP did not render any of the last 60 frames on the CPU. GPU 66.6%: This indicates that the GPU limited 66.6% of the 60 most recent frames rendered by HDRP. Present Limited 33.3%: This indicates that presentation constraints (Vsync or the target framerate) limited 33.3% of the last 60 frames. Balanced 0.0%: This indicates that in the last 60 frames, there were 0 frames where the CPU processing time and GPU processing time were the same. In this example, the bottleneck is the GPU. Detailed Stats The Detailed Stats section displays the amount of time in milliseconds that each rendering step takes on the CPU and GPU. HDRP updates these values once every frame based on the previous frame. Property Description Update every second with average Calculate average values over one second and update every second. Hide empty scopes Hide profiling scopes that use 0.00ms of processing time on the CPU and GPU. Debug XR Layout Enable to display debug information for XR passes. This mode only appears in the editor and development builds. Frequently Used This section contains a selection of properties that users use often. The properties are from the other sections in the Rendering Debugger window. For information about the properties, refer to the sections Material, Lighting, and Rendering. Material The properties in this section let you visualize different Material properties. Material Filters Property Description Material Override Select a Material property to visualize on every GameObject on screen. The available options are: Albedo Specular Alpha Smoothness AmbientOcclusion Emission NormalWorldSpace NormalTangentSpace LightingComplexity Metallic SpriteMask With the LightingComplexity value selected, Unity shows how many Lights affect areas of the screen space. Vertex Attribute Select a vertex attribute of GameObjects to visualize on screen. The available options are: Texcoord0 Texcoord1 Texcoord2 Texcoord3 Color Tangent Normal Material Validation Property Description Material Validation Mode Select which Material properties to visualize: Albedo, or Metallic. Selecting one of the properties shows the new context menu. Validation Mode: Albedo Selecting Albedo in the Material Validation Mode property shows the Albedo Settings section with the following properties: Validation Preset: Select a pre-configured material, or Default Luminance to visualize luminance ranges. Min Luminance: Unity draws pixels where the luminance is lower than this value with red color. Max Luminance: Unity draws pixels where the luminance is higher than this value with blue color. Hue Tolerance: available only when you select a pre-set material. Unity adds the hue tolerance to the minimum and maximum luminance values. Saturation Tolerance: available only when you select a pre-set material. Unity adds the saturation tolerance to the minimum and maximum luminance values. Validation Mode: Metallic Selecting Metallic in the Material Validation Mode property shows the Metallic Settings section with the following properties: Min Value: Unity draws pixels where the metallic value is lower than this value with red color. Max Value: Unity draws pixels where the metallic value is higher than this value with blue color. Lighting The properties in this section let you visualize different settings and elements related to the lighting system, such as shadow cascades, reflections, contributions of the Main and the Additional Lights, and so on. Lighting Debug Modes Property Description Lighting Debug Mode Specifies which lighting and shadow information to overlay on-screen to debug. The options are: None: Renders the scene normally without a debug overlay. Shadow Cascades: Overlays shadow cascade information so you can see which shadow cascade each pixel uses. Use this to debug shadow cascade distances. For information on which color represents which shadow cascade, refer to the Shadows section of the URP Asset. Lighting Without Normal Maps: Renders the scene to visualize lighting. This mode uses neutral materials and disables normal maps. This and the Lighting With Normal Maps mode are useful for debugging lighting issues caused by normal maps. Lighting With Normal Maps: Renders the scene to visualize lighting. This mode uses neutral materials and allows normal maps. Reflections: Renders the scene to visualize reflections. This mode applies perfectly smooth, reflective materials to every Mesh Renderer. Reflections With Smoothness: Renders the scene to visualize reflections. This mode applies reflective materials without an overridden smoothness to every GameObject. Lighting Features Specifies flags for which lighting features contribute to the final lighting result. Use this to view and debug specific lighting features in your scene. The options are: Nothing: Shortcut to disable all flags. Everything: Shortcut to enable all flags. Global Illumination: Indicates whether to render global illumination. Main Light: Indicates whether the main directional Light contributes to lighting. Additional Lights: Indicates whether lights other than the main directional light contribute to lighting. Vertex Lighting: Indicates whether additional lights that use per-vertex lighting contribute to lighting. Emission: Indicates whether emissive materials contribute to lighting. Ambient Occlusion: Indicates whether ambient occlusion contributes to lighting. Rendering The properties in this section let you visualize different rendering features. Rendering Debug Property Description Map Overlays Specifies which render pipeline texture to overlay on the screen. The options are: None: Renders the scene normally without a texture overlay. Depth: Overlays the camera's depth texture on the screen. Additional Lights Shadow Map: Overlays the shadow map that contains shadows cast by lights other than the main directional light. Main Light Shadow Map: Overlays the shadow map that contains shadows cast by the main directional light. ** Map Size** The width and height of the overlay texture as a percentage of the view window URP displays it in. For example, a value of 50 fills up a quarter of the screen (50% of the width and 50% of the height). HDR Indicates whether to use high dynamic range (HDR) to render the scene. Enabling this property only has an effect if you enable HDR in your URP Asset. MSAA Indicates whether to use Multisample Anti-aliasing (MSAA) to render the scene. Enabling this property only has an effect if: You set Anti Aliasing (MSAA) to a value other than Disabled in your URP Asset. You use the Game View. MSAA has no effect in the Scene View. Post-processing Specifies how URP applies post-processing. The options are: Disabled: Disables post-processing. Auto: Unity enables or disables post-processing depending on the currently active debug modes. If color changes from post-processing would change the meaning of a debug mode's pixel, Unity disables post-processing. If no debug modes are active, or if color changes from post-processing don't change the meaning of the active debug modes' pixels, Unity enables post-processing. Enabled: Applies post-processing to the image that the camera captures. Additional Wireframe Modes Specifies whether and how to render wireframes for meshes in your scene. The options are: None: Doesn't render wireframes. Wireframe: Exclusively renders edges for meshes in your scene. In this mode, you can see the wireframe for meshes through the wireframe for closer meshes. Solid Wireframe: Exclusively renders edges and faces for meshes in your scene. In this mode, the faces of each wireframe mesh hide edges behind them. Shaded Wireframe: Renders edges for meshes as an overlay. In this mode, Unity renders the scene in color and overlays the wireframe over the top. Overdraw Indicates whether to render the overdraw debug view. This is useful to see where Unity draws pixels over one other. Pixel Validation The Pixel Validation subsection. Property Description Pixel Validation Mode Specifies which mode Unity uses to validate pixel color values. The options are: None: Renders the scene normally and doesn't validate any pixels. Highlight NaN, Inf and Negative Values: Highlights pixels that have color values that are NaN, Inf, or negative. Highlight Values Outside Range: Highlights pixels that have color values outside a particular range. Use Value Range Min and Value Range Max. ** Channels** Specifies which value to use for the pixel value range validation. The options are: RGB: Validates the pixel using the luminance value calculated from the red, green, and blue color channels. R: Validates the pixel using the value from the red color channel. G: Validates the pixel using the value from the green color channel. B: Validates the pixel using the value from the blue color channel. A: Validates the pixel using the value from the alpha channel. This property only appears if you set Pixel Validation Mode to Highlight Values Outside Range. ** Value Range Min** The minimum valid color value. Unity highlights color values that are less than this value. This property only appears if you set Pixel Validation Mode to Highlight Values Outside Range. ** Value Range Max** The maximum valid color value. Unity highlights color values that are greater than this value. This property only appears if you set Pixel Validation Mode to Highlight Values Outside Range."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/features/rendering-layers.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/features/rendering-layers.html",
    "title": "Rendering Layers | mmo-rpg-unity",
    "keywords": "Rendering Layers The Rendering Layers feature lets you configure certain Lights to affect only specific GameObjects. For example, in the following illustration, Light A affects Sphere D, but not Sphere C. Light B affects Sphere C, but not Sphere D. To read how to implement this example, refer to How to use Rendering Layers. Enable Rendering Layers for Lights To enable Rendering Layers for Lights in your project: In the URP Asset, in the Lighting section, click the vertical ellipsis icon (⋮) and select Show Additional Properties In the URP Asset, in the Lighting section, select Use Rendering Layers. URP Asset > Lighting > Use Rendering Layers Enable Rendering Layers for Decals To enable Rendering Layers for decals in your project: In the Decal Renderer Feature, enable Use Rendering Layers. Decal Renderer Feature, Inspector view. When you enable Rendering Layers for Decals, Unity shows the Rendering Layers property on each Decal Projector: How to edit Rendering Layer names To edit the names of Rendering Layers: Go to Project Settings > Graphics > URP Global Settings. Edit the Rendering Layer names in the Rendering Layers (3D) section. Graphics > URP Global Settings > Rendering Layers (3D) How to use Rendering Layers with Lights This section describes how to configure the following application example: The Scene contains two Point Lights (marked A and B in the illustration) and two Sphere GameObjects (C and D in the illustration). Light A affects Sphere D, but not Sphere C. Light B affects Sphere C, but not Sphere D. The following illustration shows the example: Light A affects Sphere D, but not Sphere C. Light B affects Sphere C, but not Sphere D. To implement the example: Enable Rendering Layers in your project. Create two Point Lights (call them A, and B) and two Spheres (call them C, and D). Position the objects so that both Spheres are within the emission range of Lights. Go to Project Settings > Graphics > URP Global Settings. Rename Rendering Layer 1 to Red, and Layer 2 to Green. Select Light A, change its color to green. Select Light B, change its color to red. With this setup, both Lights affect both Spheres. Make the following settings on Lights and Spheres: Light A: in the property Light > Rendering > Rendering Layers, clear all options, and select Green. Light B: in the property Light > Rendering > Rendering Layers, clear all options, and select Red. Sphere C: in the property Mesh Renderer > Additional Settings > Rendering Layer Mask, select all options, clear Green. Sphere D: in the property Mesh Renderer > Additional Settings > Rendering Layer Mask, select all options, clear Red. Now Point Light A affects Sphere D, but not Sphere C. Point Light B affects Sphere C, but not Sphere D. How to use Custom Shadow Layers In the illustration above, Light A does not affect Sphere C, and the Sphere does not cast shadow from Light A. The Custom Shadow Layers property lets you configure the Scene so that Sphere C casts the shadow from Light A. Select Light A. In Light > Shadows, select the Custom Shadow Layers property. Unity shows the Layer property. In the Layer property, select the Rendering Layer that Sphere C belongs to. Now Light A does not affect Sphere C, but Sphere C casts shadow from Light A. The following illustrations show the Scene with the Custom Shadow Layers property off and on. How to use Rendering Layers with Decals This section describes how to configure the following application example: The Scene contains a Decal Projector. The Decal Projector projects a decal on the wall and the ground, but not on the paint bucket. The following illustration shows the example: In image 1, the paint bucket has the Receive decals layer selected. In image 2 it does not, so the Decal Projector does not project on the bucket. To implement the example: Enable Rendering Layers for Decals in your project. Create a Decal Projector in the Scene. Go to Project Settings > Graphics > URP Global Settings. Add a Rendering Layer called Receive decals. Select the Decal Projector. In the Rendering Layers property, select Receive decals. Select the paint bucket GameObject. In the Rendering Layer Mask field, clear the Receive decals layer. Now the Decal Projector does not affect this GameObject. Performance This section contains information related to the impact of Rendering Layers on performance. Keep the Rendering Layer count as small as possible. Avoid creating Rendering Layers that you don't use in the project. When using Rendering Layers for decals, increasing the layer count increases the required memory bandwidth and decreases the performance. When using Rendering Layers only for Lights in the Forward Rendering Path, the performance impact is insignificant. Performance impact grows more significantly when the Rendering Layer count exceeds a multiple of 8. For example: increasing the layer count from 8 to 9 layers has a bigger relative impact than increasing the layer count from 9 to 10 layers."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/features/rp-converter.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/features/rp-converter.html",
    "title": "Render Pipeline Converter | mmo-rpg-unity",
    "keywords": "Render Pipeline Converter The Render Pipeline Converter converts assets made for a Built-in Render Pipeline project to assets compatible with URP. NOTE: The conversion process makes irreversible changes to the project. Back up your project before the conversion. How to use the Render Pipeline Converter To convert project assets: Select Window > Rendering > Render Pipeline Converter. Unity opens the Render Pipeline Converter window. Select the conversion type. Depending on the conversion type, the dialog shows the available converters. Select or clear the check boxes next to converter names to enable or disable the converters. For the list of available converters, refer to the section Converters. Click Initialize Converters. The Render Pipeline Converter preprocesses the assets in the project and shows the list of elements to convert. Select or clear check boxes next to assets to include or exclude them from the conversion process. The following illustration shows initialized converters. Click a converter to see the list of items that a converter is about to convert. Yellow icon: a yellow icon next to an element indicates that a user action might be required to run the conversion. Hover the mouse pointer over the icon to see the description of the issue. Click Convert Assets to start the conversion process. NOTE: The conversion process makes irreversible changes to the project. Back up your project before the conversion. When the conversion process finishes, the window shows the status of each converter. Green check mark: the conversion went without issues. Yellow icon: the conversion finished with warnings and might require user action. Red icon: the conversion failed. Click a converter to see the list of processed items in that converter. After reviewing the converted project, close the Render Pipeline Converter window. Conversion types and converters The Render Pipeline Converter let's you select one of the following conversion types: Built-in Render Pipeline to URP Built-in Render Pipeline 2D to URP 2D Upgrade 2D URP Assets When you select on of the conversion types, the tool shows you the available converters. The following sections describe the converters available for each conversion type. Built-in Render Pipeline to URP This conversion type converts project elements from the Built-in Render Pipeline to URP. Available converters: Rendering Settings This converter creates the URP Asset and Renderer assets. Then the converter evaluates the settings in the Built-in Render Pipeline project and converts them into equivalent properties in the URP assets. Material Upgrade This converter converts the Materials. The converter works on pre-built Materials that are supplied by Unity, it does not support Materials with custom shaders. Animation Clip Converter This converter converts the animation clips. It runs after the Material Upgrade converter finishes. NOTE: This converter is available only if the project contains animations that affect the properties of Materials, or Post-processing Stack v2 properties. Read-only Material Converter This converter converts the pre-built read-only Materials, where the Material Upgrade converter cannot replace the shader. This converter indexes the project and creates a temporary .index file, which might take a significant time. Examples of read-only Materials: Default-Diffuse, Default-Line, Dafault-Terrain-Diffuse, etc. Post-Processing Stack v2 Converter This converter converts PPv2 Volumes, Profiles, and Layers to URP Volumes, Profiles, and Cameras. This converter indexes the project and creates a temporary .index file, which might take a significant time. Built-in Render Pipeline 2D to URP 2D This conversion type converts elements of a project from Built-in Render Pipeline 2D to URP 2D. Available converters: Material and Material Reference Upgrade This converter converts all Materials and Material references from Built-in Render Pipeline 2D to URP 2D. Upgrade 2D URP Assets This conversion type upgrades assets of a 2D project from an earlier URP version to the current URP version. Available converters: Parametric to Freeform Light Upgrade This converter converts all parametric lights to freeform lights. Run conversion using API or CLI The Render Pipeline Converter implements the Converters class with RunInBatchMode methods that let you run the conversion process from a command line. For example, the following script initializes and executes the converters Material Upgrade, and Read-only Material Converter. using System.Collections; using System.Collections.Generic; using UnityEditor; using UnityEditor.Rendering.Universal; using UnityEngine; public class MyUpgradeScript : MonoBehaviour { public static void ConvertBuiltinToURPMaterials() { Converters.RunInBatchMode( ConverterContainerId.BuiltInToURP , new List<ConverterId> { ConverterId.Material, ConverterId.ReadonlyMaterial } , ConverterFilter.Inclusive ); EditorApplication.Exit(0); } } To run the example conversion from the command line, use the following command: \"<path to Unity application> -projectPath <project path> -batchmode -executeMethod MyUpgradeScript.ConvertBuiltinToURPMaterials For more information, refer to: Unity Editor command line arguments."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/index.html",
    "title": "Universal Render Pipeline overview | mmo-rpg-unity",
    "keywords": "Universal Render Pipeline overview The Universal Render Pipeline (URP) is a prebuilt Scriptable Render Pipeline, made by Unity. URP provides artist-friendly workflows that let you quickly and easily create optimized graphics across a range of platforms, from mobile to high-end consoles and PCs. Requirements For information about requirements and compatibility, refer to the Requirements section. What's new in URP For information on what's new in the latest version of URP, refer to What's new in URP. Getting started with URP For information on starting a new URP Project from scratch, or about installing URP in an existing Unity Project, refer to Getting started. Upgrading For information on upgrading from a previous version of URP to the current version, or for information about upgrading from the Lightweight Render Pipeline (LWRP) to URP, refer to the Upgrade guides."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/inside-universalrp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/inside-universalrp.html",
    "title": "Insid the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Insid the Universal Render Pipeline In the following sections, you can read more about the technology inside the Universal Render Pipeline (URP): The URP Asset Shader stripping Built-in Render Pipeline/URP comparison Shading Models in URP"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/integration-with-post-processing.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/integration-with-post-processing.html",
    "title": "Post-processing in the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Post-processing in the Universal Render Pipeline The Universal Render Pipeline (URP) includes an integrated implementation of post-processing effects. If you use URP, it's not necessary to install an extra package for post-processing effects. URP is not compatible with the Post Processing Stack v2 package. URP uses the Volume framework for post-processing effects. The images below show a Scene with and without URP post-processing. Without post-processing: With post-processing: Note: URP does not support Post-processing on OpenGL ES 2.0. How to configure post-processing effects in URP This section describes how to configure Post-processing in URP. Using post-processing in the URP Template Scene Post-processing is preconfigured in the SampleScene Scene in URP Template. To see the preconfigured effects, select Post-process Volume in the Scene. To add extra effects, add Volume Overrides to the Volume. To configure location-based post-processing effects, refer to How to use Local Volumes. Configuring post-processing in a new URP Scene To configure post-processing in a new Scene: Select a Camera, and select the Post Processing check box. Add a GameObject with a Volume component in the Scene. This instruction adds a Global Volume. Select GameObject > Volume > Global Volume. Select the Global Volume GameObject. In the Volume component, create a new Profile by clicking New button on the right side of the Profile property. Add post-processing effects to the Camera by adding Volume Overrides to the Volume component. Now you can use the Volume Override to enable and adjust the settings for the post-processing effect. Note The GameObject which contains the volume and the camera you wish to apply post-processing to must be on the same Layer. Refer to Understand Volumes for more information. Post-processing in URP for mobile devices Post-processing effects can take up a lot of frame time. If you’re using URP for mobile devices, these effects are the most “mobile-friendly” by default: Bloom (with High Quality Filtering disabled) Chromatic Aberration Color Grading Lens Distortion Vignette Note: For depth-of field, Unity recommends that you use Gaussian Depth of Field for lower-end devices. For console and desktop platforms, use Bokeh Depth of Field. Note: For anti-aliasing on mobile platforms, Unity recommends that you use FXAA. Post-processing in URP for VR In VR apps and games, certain post-processing effects can cause nausea and disorientation. To reduce motion sickness in fast-paced or high-speed apps, use the Vignette effect for VR, and avoid the effects Lens Distortion, Chromatic Aberration, and Motion Blur for VR."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/known-issues.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/known-issues.html",
    "title": "Known issues | mmo-rpg-unity",
    "keywords": "Known issues This page contains information on known issues you may encounter when using URP. Long build times when using the Forward+ Rendering Path Due to the wide variety of use cases, target platforms, renderers, and features used in projects, certain URP configurations can result in a large number of shader variants. That can lead to long compilation times. Long shader compilation time affects both player build time and the time for a scene to render in the Editor. The per-camera visible light limit value affects the compilation time for each Lit and Complex Lit shader variant. In the Forward+ Rendering Path, on desktop platforms, that limit is 256. Refer to the following page to learn how to reduce the build time in the Forward+ Rendering Path by reducing the maximum number of visible lights: Reduce build time in Forward+ Rendering Path When importing the URP package samples, Unity does not set the necessary URP asset in Quality > Render Pipeline Asset When importing the URP package samples, Unity does not set the necessary URP asset in Quality > Render Pipeline Asset, and certain sample rendering effects do not work. To fix this issue: In Project Settings > Quality > Render Pipeline Asset, select SamplesPipelineAsset. Renaming a URP Renderer asset to a name matching one of the Renderer Feature names causes erroneous behavior If a URP Renderer asset has any Renderer Features assigned, renaming the Renderer asset to a name matching one of the Renderer Feature names causes erroneous behavior: the URP Renderer and the Renderer Feature switch places. The following scenario shows how the error occurs: Let's assume that the URP Renderer in your project is called UniversalRenderer. The Renderer has a Renderer Feature called NewRenderObjects assigned. Renaming UniversalRenderer to NewRenderObjects causes erroneous behavior: The Renderer switches places with the Renderer Feature and does not behave correctly. To avoid the issue, do not give the URP Renderer asset the same name as the Renderer Feature asset. To see updates on this issue, refer to the Unity Issue Tracker. Warning about _AdditionalLights property when upgrading the URP package In certain cases, you might see the following warning when upgrading the URP package to a newer version: Property (_AdditionalLights<...>) exceeds previous array size (256 vs 16). Cap to previous size. This warning does not cause issues with the project, the warning disappears if you restart the Editor."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/light-component.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/light-component.html",
    "title": "Light component reference | mmo-rpg-unity",
    "keywords": "Light component reference Lights determine the shading of an object and the shadows it casts. This page contains information on Light components in the Universal Render Pipeline (URP). For a general introduction to lighting in Unity and examples of common lighting workflows, refer to the Lighting section of the Unity Manual. Properties The Light Inspector includes the following groups of properties: General Shape Emission Rendering Shadows General Property: Function: Type The current type of light. Possible values are Directional, Point, Spot and Area. Mode Specify the Light Mode used to determine if and how a light is \"baked\". Options: Realtime Mixed Baked Note: If Type is set to Area, this property is automatically set to Baked. Shape Property: Function: Inner/Outer Spot Angle The inner and outer angles (in degrees) at the base of a spot light’s cone. This property is only available when Type is set to Spot. Shape The shape of the area light. Available options: Rectangle Disc This property is only available when Type is set to Area. Width The width of the area light. Note: This property is only available if Shape is set to Rectangle. Height The height of the area light. Note: This property is only available if Shape is set to Rectangle. Radius The radius of the area light Note: This property is only available if Shape is set to Disc. Emission Property: Function: Light Appearance Select the method used to create the color of the light. Available options: Color Filter and Temperature Color The color of the emitted light. Set this property with the color slider. Note: This property is only available if Light Apperance is set to Color. Filter The color of the tint for the light source. Set this property with the color slider. Note: This property is only available if Light Apperance is set to Filter and Temperature. Temperature The temperature (in Kelvin) of the light. Set this property with the slider or enter a specific value. Note: This property is only available if Light Apperance is set to Filter and Temperature. Intensity Set the brightness of the light. The default value for a Directional light is 0.5. The default value for a Point, Spot or Area light is 1. Indirect Multiplier Use this value to vary the intensity of indirect light. Indirect light is light that has bounced from one object to another. The Indirect Multiplier defines the brightness of bounced light calculated by the global illumination (GI) system. If you set Indirect Multiplier to a value lower than 1, the bounced light becomes dimmer with every bounce. A value higher than 1 makes light brighter with each bounce. This is useful, for example, when a dark surface in shadow (such as the interior of a cave) needs to be brighter in order to make detail visible. Range Define how far the light emitted from the center of the object travels (Point and Spot lights only). Cookie The RGB texture this Light projects into the scene. Use cookies to create silhouettes or patterned illumination. The texture format to use depends on the type of Light: • Directional: 2D texture • Spot: 2D texture • Point: cubemap texture Note: URP doesn't support light cookies for Area lights. For more information about light cookies, refer to Cookies. Cookie Size The per-axis scale Unity applies to the cookie texture. Use this property to set the size of the cookie. Note: This property is available only if you set Type to Directional and assign a texture to Cookie. Cookie Offset The per-axis offset Unity applies to the cookie texture. Use this property to move the cookie without moving the light itself. You can also animate this property to scroll the cookie. Note: This property is available only if you set Type to Directional and assign a texture to Cookie. Rendering Property: Function: Culling Mask Use this to selectively exclude groups of objects from being affected by the Light. For more information, refer to Layers. Shadows Property: Function: Shadow Type Determine whether this Light casts Hard Shadows, Soft Shadows, or no shadows at all. For information on hard and soft shadows, refer to documentation on Lights. Baked Shadow Angle If Type is set to Directional and Shadow Type is set to Soft Shadows, this property adds some artificial softening to the edges of shadows and gives them a more natural look. Note: This property is only available if Mode is set to Mixed or Baked. Baked Shadow Radius If Type is set to Point or Spot and Shadow Type is set to Soft Shadows, this property adds some artificial softening to the edges of shadows and gives them a more natural look. Note: This property is only available if Mode is set to Mixed or Baked. Realtime Shadows These properties are available when Shadow Type is set to Hard Shadows or Soft Shadows. Use these properties to control real-time shadow rendering settings. Strength Use the slider to control how dark the shadows cast by this Light are, represented by a value between 0 and 1. This is set to 1 by default. Bias Controls whether to use shadow bias settings from the URP Asset, or whether to define custom shadow bias settings for this Light. Possible values are Use Pipeline Settings or Custom. Depth Controls the distance at which the shadows will be pushed away from the light. Useful for avoiding false self-shadowing artifacts. This property is visible only when Bias is set to Custom. Normal Controls the distance at which the shadow casting surfaces will be shrunk along the surface normal. Useful for avoiding false self-shadowing artifacts. This property is visible only when Bias is set to Custom. Near Plane Use the slider to control the value for the near clip plane when rendering shadows, defined as a value between 0.1 and 10. This value is clamped to 0.1 units or 1% of the light’s Range property, whichever is lower. This is set to 0.2 by default. Soft Shadows Quality Select the soft shadows quality. With the Use Pipeline Settings option selected Unity uses the value from the URP Asset. Options Low, Medium, and High let you specify the soft shadow quality value for this Light. For more information on the values, refer to the Soft Shadows section. Preset When using Preset of Light Component, only a subset of properties are supported. Unsupported properties are hidden."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/lighting.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/lighting.html",
    "title": "Lighting in the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Lighting in the Universal Render Pipeline Using the Universal Render Pipeline (URP), you can achieve realistic lighting that is suitable for a range of art styles. Page Description Lighting in URP Understand the differences between Unity's common lighting functionality and the lighting functionality in URP. Light component reference Understand how each lighting property works in URP. The Universal Additional Light Data component Use the Universal Additional Light Data component to override lighting settings in URP. Lighting Mode Understand which lighting modes URP supports. Shadows in the URP How to work with shadows in URP. Reflection Probes Configure the URP-specific behavior of Reflection Probes. Lens Flare Data Asset Understand how to use the Lens Flare Data Asset in URP. Configure lighting for better performance Refer to Configure for better performance for more information about how to adjust lighting settings for better performance. Additional resources Universal Render Pipeline for advanced Unity creators Shedding some light on the Universal Render Pipeline Optimize your Unity project with URP Creating Believable Visuals Creative Core: Lighting"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/lighting/lighting-in-urp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/lighting/lighting-in-urp.html",
    "title": "Lighting in the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Lighting in the Universal Render Pipeline All of Unity's render pipelines share common lighting functionality, but each render pipeline has some important differences. Areas where the Universal Render Pipeline (URP) differs from Unity's common lighting functionality are: The Light component inspector, which displays some URP-specific controls. The Universal Additional Light Data component, which allows Unity to store Light-related data that is specific to URP. For a full comparison of lighting features between Unity's Built-in Render Pipeline and URP, and an up to date list of lighting features that are currently under research, check the Render pipeline feature comparison. For a general introduction to lighting in Unity and examples of common lighting workflows, refer to the Lighting section of the Unity Manual."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/lighting/reflection-probes.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/lighting/reflection-probes.html",
    "title": "Reflection probes | mmo-rpg-unity",
    "keywords": "Reflection probes This page describes URP-specific behavior of reflection probes. For general information on reflection probes, refer to the page Reflection Probes. For examples of how to use reflection probes, refer to the Lighting samples in URP Package Samples. Configuring reflection probe settings To configure settings related to reflection probes, in a URP Asset, select Lighting > Reflection Probes. Reflection probe settings. The Reflection Probes section contains the following properties: Property Description Probe Blending Select this property to enable reflection probe blending. On lower-end mobile platforms, disable this property to decrease processing time on the CPU. Box Projection Select this property to enable reflection probe box projection. On lower-end mobile platforms, disable this property to decrease processing time on the CPU. Reflection probe blending Reflection probe blending lets you avoid a situation where a reflection suddenly appears on an object when it enters the probe box volume. When reflection probe blending is enabled, Unity gradually fades probe cubemaps in and out as the reflective object passes from one volume to the other. URP supports reflection probe blending in all Rendering Paths. Reflection probe volume Each reflection probe has a box volume. A reflection probe only affects parts of a GameObject that are inside the box volume. When a pixel of an object is outside of any reflection probe volume, Unity uses the skybox reflection. In URP, Unity evaluates the contribution of each probe for each individual pixel, depending on the position of the pixel relative to the boundary of the probe volume. This behavior is different from the Built-in Render Pipeline, where Unity evaluates the contribution of a probe for the whole object. Blend Distance Each reflection probe has the Blend Distance property. This property is the distance from the face of a reflection box volume towards the center of the box volume. Unity uses the Blend Distance property to determine the contribution of a reflection probe. When a pixel of an object is on the face of a reflection probe volume, that pixel gets 0% of reflections from the probe. When a pixel is inside the reflection probe volume and its distance from each face exceeds the Blend Distance value, the pixel gets 100% of reflections. If the Blend Distance value is more than half of the distance between faces of the reflection probe volume, the reflection probe cannot provide 100% contribution to any pixel within the volume. Which probes affect a GameObject When a GameObject is within multiple reflection probe volumes, maximum two of the probes can affect the GameObject. Unity selects which probes affect the GameObject using the following criteria: The Importance property of a reflection probe. Unity selects two probes with higher Importance values and ignores the others. If the Importance values are the same, Unity selects probes which have the smallest box volumes. If the Importance values and the box volumes are the same, Unity determines which two reflection probe volumes contain larger surface areas of a GameObject, and picks the probes of those volumes. When two reflection probes affect a GameObject, for each pixel, Unity calculates the weight of each probe depending on the distance of this pixel from the faces of the probe box volumes and the values of the Blend Distance properties. If the pixel is relatively close to faces of both box volumes and the sum of weights of both probes is less than 1, Unity assigns the remaining weight to the _GlossyEnvironmentCubeMap. This cube map contains the reflection from the lighting source set in the Lighting window under Environment Lighting > Source. In most cases this source is the skybox. If the pixel is within both box volumes and farther than the Blend Distance values from faces of both volumes: If the Importance properties of the reflection probes are the same, Unity blends reflections from the probes with equal weights. If the Importance property of one of the probes is higher, Unity applies the reflections only from that probe. Box projection For the box projection to work: Select the Box Projection check box on the URP asset. Select the Box Projection property on the reflection probe."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/lit-shader.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/lit-shader.html",
    "title": "Lit Shader | mmo-rpg-unity",
    "keywords": "Lit Shader The Lit Shader lets you render real-world surfaces like stone, wood, glass, plastic, and metals in photo-realistic quality. Your light levels and reflections look lifelike and react properly across various lighting conditions, for example bright sunlight, or a dark cave. This Shader uses the most computationally heavy shading model in the Universal Render Pipeline (URP). For examples of how to use the Lit Shader, refer to the Shaders samples in URP Package Samples. Using the Lit Shader in the Editor To select and use this Shader: In your Project, create or find the Material you want to use the Shader on. Select the Material. A Material Inspector window opens. Click Shader, and select Universal Render Pipeline > Lit. UI overview The Inspector window for this Shader contains these elements: Surface Options Surface Inputs Advanced Surface Options The Surface Options control how URP renders the Material on a screen. Property Description Workflow Mode Use this drop-down menu to choose a workflow that fits your Textures, either Metallic and Specular. When you have made your choice, the main Texture options in the rest of the Inspector now follow your chosen workflow. For information on metallic or specular workflows, refer to this Manual page for the Standard built-in Shader in Unity. Surface Type Use this drop-down to apply an Opaque or Transparent surface type to the Material. This determines which render pass URP renders the material in. Opaque surface types are always fully visible, regardless of what’s behind them. URP renders opaque Materials first. Transparent surface types are affected by their background, and they can vary according to which type of transparent surface type you choose. URP renders transparent Materials in a separate pass after opaque objects. If you select Transparent, the Blending Mode drop-down appears. Blending Mode Select how Unity calculates the color of each pixel of a transparent Material when it blends the Material with the background. In the context of Blending Modes, Source refers to the transparent Material where the Blending Mode is set and Destination refers to anything that Material overlaps with. Alpha Alpha blending mode. Alpha uses the Material's alpha value to change how transparent an object is. 0 is fully transparent. 255 is fully opaque, this is translated to a value of 1 when used with the blending equations. The Material is always rendered in the Transparent render pass regardless of it's alpha value. This mode lets you use the Preserve Specular Lighting property. Alpha equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB × (1 − SourceAlpha) Premultiply Premultiply blending mode. Premultiply first multiplies the RGB values of the transparent Material by its alpha value then applies a similar effect to the Material as Alpha. The equation for Premultiply also allows areas of the transparent Material with an alpha value of 0 to have an additive blend effect. This can help reduce artifacts that may appear at the edge of the overlap between opaque and transparent pixels. Premultiply equation: OutputRGBA = SourceRGB + DestinationRGB × (1 − SourceAlpha) Additive Additive blending mode. Additive adds the color values of the Materials together to create the blend effect. The alpha value determines the strength of the source Material's color before the blend is calculated. This mode lets you use the Preserve Specular Lighting property. Additive equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB Multiply Multiply blending mode. Multiply multiplies the color of the Material with the color behind the surface. This creates a darker effect, like when you look through colored glass. This mode uses the Material’s alpha value to adjust how much the colors blend. An alpha value of 1 results in unadjusted multiplication of the colors while lower values blend the colors towards white. Multiply equation: OutputRGBA = SourceRGB × DestinationRGB Preserve Specular Lighting Indicates whether Unity preserves specular highlights on a GameObject or not. This applies even when your surface is transparent which means that only the reflected light is visible. This property only appears when the Surface Type is set to Transparent and Blending Mode is set to either Alpha or Additive. Material with Preserve Specular Lighting disabled. Material with Preserve Specular Lighting enabled. Render Face Use this drop-down to determine which sides of your geometry to render. Front Face renders the front face of your geometry and culls the back face. This is the default setting. Back Face renders the front face of your geometry and culls the front face. Both makes URP render both faces of the geometry. This is good for small, flat objects, like leaves, where you might want both sides visible. Alpha Clipping Makes your Material act like a Cutout Shader. Use this to create a transparent effect with hard edges between the opaque and transparent areas. For example, to create blades of grass. To achieve this effect, URP does not render alpha values below the specified Threshold, which appears when you enable Alpha Clipping. You can set the Threshold by moving the slider, which accepts values from 0 to 1. All values above your threshold are fully opaque, and all values below your threshold are invisible. For example, a threshold of 0.1 means that URP doesn't render alpha values below 0.1. The default value is 0.5. Receive Shadows Tick this box to enable your GameObject to have shadows cast upon it by other objects. If you untick this box, the GameObject will not have shadows on it. Surface Inputs The Surface Inputs describe the surface itself. For example, you can use these properties to make your surface look wet, dry, rough, or smooth. Note: If you are used to the Standard Shader in the built-in Unity render pipeline, these options are similar to the Main Maps settings in the Material Editor. Property Description Base Map Adds color to the surface, also known as the diffuse map. To assign a Texture to the Base Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. The color next to the setting shows the tint on top of your assigned Texture. To assign another tint, you can click this color swatch. If you select Transparent or Alpha Clipping under Surface Options, your Material uses the Texture’s alpha channel or color. Metallic / Specular Map Shows a map input for your chosen Workflow Mode in the Surface Options. For the Metallic Map workflow, the map gets the color from the Base Map assigned above. Use the slider to control how metallic the surface appears. 1 is fully metallic, like silver or copper, and 0 is fully dielectric, like plastic or wood. You can generally use values in between 0 and 1 for dirty or corroded metals. For the Specular Map setting, you can assign a texture to it by clicking the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. For both workflows, you can use the Smoothness slider to control the spread of highlights on the surface. 0 gives a wide, rough highlight. 1 gives a small, sharp highlight like glass. Values in between produce semi-glossy looks. For example, 0.5 produces a plastic-like glossiness. Use the Source drop-down menu to select where the shader samples a smoothness map from. Options are: Metallic Alpha (alpha channel from the metallic map), and Albedo Alpha (alpha channel from the base map). The default value is Metallic Alpha. If the selected source has the alpha channel, the shader samples the channel and multiplies each sample by the Smoothness value. Normal Map Adds a normal map to the surface. With a normal map, you can add surface details like bumps, scratches and grooves. To add the map, click the object picker next to it. The normal map picks up ambient lighting in the environment. The float value next to the setting is a multiplier for the effect of the Normal Map. Low values decrease the effect of the normal map. High values create stronger effects. Height Map URP implements the parallax mapping technique which uses the height map to achieve surface-level occlusion effect by shifting the areas of the visible surface texture. To add the map, click the object picker next to it. The float value next to the setting is a multiplier for the effect of the Height Map. Low values decrease the effect of the height map. High values create stronger effects. Occlusion Map Select an occlusion map. This simulates shadows from ambient light and reflection, which makes lighting look more realistic as less light reaches corners and crevices of objects. To select the occlusion map, click the object picker next to it. Emission Makes the surface look like it emits lights. When enabled, the Emission Map and Emission Color settings appear. To assign an Emission Map, click the object picture next to it. This opens the Asset Browser, where you can select from the textures in your Project. For Emission Color, you can use the color picker to assign a tint on top of the color. This can be more than 100% white, which is useful for effects like lava, that shines brighter than white while still being another color. If you have not assigned an Emission Map, the Emission setting only uses the tint you’ve assigned in Emission Color. If you do not enable Emission, URP sets the emission to black and does not calculate emission. Tiling A 2D multiplier value that scales the Texture to fit across a mesh according to the U and V axes. This is good for surfaces like floors and walls. The default value is 1, which means no scaling. Set a higher value to make the Texture repeat across your mesh. Set a lower value to stretch the Texture. Try different values until you reach your desired effect. Offset The 2D offset that positions the Texture on the mesh. To adjust the position on your mesh, move the Texture across the U or V axes. Detail Inputs Use the Detail Inputs settings to add extra details to the surface. Requirement: GPU supporting shader model 2.5 or higher. Property Description Mask Select a texture that defines areas where Unity overlays the Detail maps over the Surface Inputs maps. The mask uses the alpha channel of the selected texture. The Tiling and Offset settings have no effect on the mask. Base Map Select the texture containing the surface details. Unity blends this map with the Surface Base Map using the overlay mode. Normal Map Select the texture containing the normal vector data. Use a normal map to add surface details like bumps, scratches and grooves. Use the slider next to the setting to change the intensity of the effect of the map. The default value is 1. Tiling Use this setting to scale the Base Map and the Normal Map on the mesh along the U and V axes, so that the maps fit the mesh best. The default value is 1. Select a value higher than one to make the maps repeat themselves across the mesh. Set a value lower than 1 to stretch the maps. Offset The offset that moves the Base Map and the Normal Map on the mesh along the U and V axes. Advanced The Advanced settings affect the underlying calculations of your rendering. They do not have a visible effect on your surface. Property Description Specular Highlights Enable this to allow your Material to have specular highlights from direct lighting, for example Directional, Point, and Spot lights. This means that your Material reflects the shine from these light sources. Disable this to leave out these highlight calculations, so your Shader renders faster. By default, this feature is enabled. Environment Reflections Sample reflections using the nearest Reflection Probe, or, if you have set one in the Lighting window, the Lighting Probe. If you disable this, you will have fewer Shader calculations, but this also means that your surface has no reflections. Enable GPU Instancing Makes URP render meshes with the same geometry and Material in one batch, when possible. This makes rendering faster. URP cannot render Meshes in one batch if they have different Materials or if the hardware does not support GPU instancing. Sorting Priority Use this slider to determine the chronological rendering order for a Material. URP renders Materials with lower values first. You can use this to reduce overdraw on devices by making the pipeline render Materials in front of other Materials first, so it doesn't have to render overlapping areas twice. This works similarly to the render queue in the built-in Unity render pipeline. Channel packing This Shader uses channel packing, so you can use a single RGBA texture for the metallic, smoothness and occlusion properties. When you use texture packing, you only have to load one texture into memory instead of three separate ones. When you write your texture maps in a program like Substance or Photoshop, you can pack the maps like this: Channel Property Red Metallic Green Occlusion Blue None Alpha Smoothness"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/materialvariant-URP.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/materialvariant-URP.html",
    "title": "Material Variants | mmo-rpg-unity",
    "keywords": "Material Variants Many of the materials in a game may be variations on a source—outfits with a variety of color schemes, damaged and undamaged versions of scenery, shiny and weathered instances of props. To help you manage and maintain these materials, Material Variants address specific shortcomings of copied materials. To learn more about this functionality, refer to Material Variants."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/optimize-for-better-performance.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/optimize-for-better-performance.html",
    "title": "Optimize for better performance | mmo-rpg-unity",
    "keywords": "Optimize for better performance If the performance of your Universal Render Pipeline (URP) project seems slow, you can analyze your project and adjust settings to increase performance. Use the Unity Profiler to analyze your project You can use the Unity Profiler to get data on the performance of your project in areas such as the CPU and memory. Profiler markers The following table lists markers that appear in the Unity Profiler for a URP frame and have a significant effect on performance. The table doesn't include a marker if it's deep in the Profiler hierarchy, or the label already describes what URP does. Marker Sub-marker Description Inl_UniversalRenderPipeline. RenderSingleCameraInternal URP builds a list of rendering commands in the ScriptableRenderContext, for a single camera. URP only records rendering commands in this marker, but doesn't yet execute them. The marker includes the camera name, for example Main Camera. Inl_ScriptableRenderer.Setup URP prepares for rendering, for example preparing render textures for the camera and shadow maps. CullScriptable URP generates a list of GameObjects and lights to render, and culls (excludes) any that are outside the camera's view. The time this takes depends on the number of GameObjects and lights in your scene. Inl_ScriptableRenderContext.Submit URP submits the list of commands in the ScriptableRenderContext to the graphics API. This marker might appear more than once if URP submits commands more than once per frame, or you call ScriptableRenderContext.Submit in your own code. MainLightShadow URP renders a shadow map for the main Directional Light. AdditionalLightsShadow URP renders shadow maps for other lights. UberPostProcess URP renders post-processing effects you enable. This marker contains separate markers for some post-processing effects. RenderLoop.DrawSRPBatcher URP uses the Scriptable Render Pipeline Batcher to render one or more batches of objects. CopyColor URP copies the color buffer from one render texture to another. You can disable Opaque Texture in the URP Asset, so that URP only copies the color buffer if it needs to. CopyDepth URP copies the depth buffer from one render texture to another. You can disable Depth Texture in the URP Asset unless you need the depth texture (for example, if you use a shader that uses scene depth). FinalBlit URP copies a render texture to the current camera render target. Use a GPU profiler to analyze your project You can use a platform GPU profiler such as Xcode to get data on the performance of the GPU during rendering. You can also use a profiler such as RenderDoc, but it might provide less accurate performance data. Data from a GPU profiler includes URP markers for rendering events, such as different render passes. Use other tools to analyze your project You can also use the following tools to analyze the performance of your project: Scene view View Options Rendering Debugger Frame Debugger Adjust settings Based on your analysis, you can adjust the following settings in the Universal Render Pipeline (URP) Asset or the Universal Renderer asset to improve the performance of your project. Depending on your project or the platforms you target, some settings might not have a significant effect. There might also be other settings that have an effect on performance in your project. Setting Where the setting is What to do for better performance Accurate G-buffer normals Universal Renderer > Rendering Disable if you use the Deferred rendering path Additional Lights > Cast Shadows URP Asset > Lighting Disable Additional Lights > Cookie Atlas Format URP Asset > Lighting Set to Color Low Additional Lights > Cookie Atlas Resolution URP Asset > Lighting Set to the lowest you can accept Additional Lights > Per Object Limit URP Asset > Lighting Set to the lowest you can accept. This setting has no effect if you use the Deferred or Forward+ rendering paths. Additional Lights > Shadow Atlas Resolution URP Asset > Lighting Set to the lowest you can accept Additional Lights > Shadow Resolution URP Asset > Lighting Set to the lowest you can accept Cascade Count URP Asset > Shadows Set to the lowest you can accept Conservative Enclosing Sphere URP Asset > Shadows Enable Technique Decal Renderer Feature Set to Screen Space, and set Normal Blend to Low or Medium Fast sRGB/Linear conversion URP Asset > Post Processing Enable Grading Mode URP Asset > Post Processing Set to Low Dynamic Range LOD Cross Fade Dither URP Asset > Quality Set to Bayer Matrix LUT size URP Asset > Post Processing Set to the lowest you can accept Main Light > Cast Shadows URP Asset > Lighting Disable Max Distance URP Asset > Shadows Reduce Opaque Downsampling URP Asset > Rendering If Opaque Texture is enabled in the URP Asset, set to 4x Bilinear Render Scale URP Asset > Quality Set to below 1.0 Soft Shadows URP Asset > Shadows Disable, or set to Low Upscaling Filter URP Asset > Quality Set to Bilinear or Nearest-Neighbor Refer to the following for more information on the settings: Deferred Rendering Path in URP Forward+ Rendering Path Decal Renderer Feature Universal Render Pipeline Asset Universal Renderer Additional resources Understand performance in URP Configure for better performance Graphics performance and profiling Best practices for profiling game performance Tools for profiling and debugging Native CPU profiling: Tips to optimize your game performance"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/package-sample-urp-package-samples.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/package-sample-urp-package-samples.html",
    "title": "URP Package Samples | mmo-rpg-unity",
    "keywords": "URP Package Samples URP Package Samples is a package sample for the Universal Render Pipeline (URP). It contains example shaders, C# scripts, and other assets you can build upon, use to learn how to use a feature, or use directly in your application. For information on how to import URP Package Samples into your project, refer to Importing package samples. Each example uses its own URP Asset so, if you want to build an example scene, add the example's URP Asset to your Graphics settings. If you don't do this, Unity might strip shaders or render passes that the example uses. Camera Stacking The URP Package Samples/CameraStacking folder contains examples for Camera Stacking. The following table describes each Camera Stacking example in this folder. Example Description Mixed field of view The example in CameraStacking/MixedFOV demonstrates how to use Camera Stacking in a first-person application to prevent the character's equipped items from clipping into the environment. This setup also makes it possible to have different fields of view for the environment camera and the equipped items camera. Split screen The example in CameraStacking/SplitScreenPPUI demonstrates how to create a split-screen camera setup where each screen has its own Camera Stack. It also demonstrates how to apply post-processing on world-space and screen-space camera UI. 3D skybox The example in CameraStacking/3D Skybox uses Camera Stacking to transform a miniature environment into a skybox. One overlay camera renders a miniature city and another renders miniature planets. The overlay cameras render to pixels that the main camera did not draw to. With some additional scripted translation, this makes the miniature environment appear full size in the background of the main camera's view. Decals The URP Package Samples/Decals folder contains examples for decals. The following table describes each decal example in this folder. Example Description Blob shadows The example in Decals/BlobShadow uses the Decal Projector component to cast a shadow under a character. This method of shadow rendering is less resource-intensive than shadow maps and is suitable for use on low-end devices. Paint splat The example in Decals/PaintSplat uses a WorldSpaceUV Sub Graph and the Simple Noise Shader Graph node to create procedural decals. The noise in each paint splat uses the world position of the Decal Projector component. Proxy lighting The example in Decals/ProxyLighting builds on the Blob shadows example and uses Decal Projectors to add proxy spotlights. These decals modify the emission of surfaces inside the projector's volume. Note: To demonstrate the extent of its lighting simulation, this example disables normal real-time lighting. Lens Flares The URP Package Samples/LensFlares folder contains lens flare examples. The following table describes each lens flare example in this folder. Example Description Sun flare The LensFlares/SunFlare example demonstrates how to use the Lens Flare component to add a lens flare effect to the main directional light in the scene. Lens flare showroom The LensFlares/LensFlareShowroom example helps you to author lens flares. To use it: 1. In the Hierarchy window, select the Lens Flare GameObject. 2. In the Lens Flare component, assign a LensFlareDataSRP asset to the Lens Flare Data property. 3. Change the Lens Flare component and data properties and view the lens flare in the Game View. Note: If the text box is in the way, disable the Canvas in the scene. Lighting The URP Package Samples/Lighting folder contains examples for lighting. The following table describes each lighting example in this folder. Example Description Reflection probes The example in Lighting/Reflection Probes uses reflection probes to create reflection maps for a reflective sphere GameObject. This sample shows how the Probe Blending and Box Projection settings can change the reflection within a scene that uses reflection probes. Renderer Features The URP Package Samples/RendererFeatures folder contains examples for Renderer Features. The following table describes each Renderer Feature example in this folder. Example Description Ambient occlusion The example in RendererFeatures/AmbientOcclusion uses a Renderer Feature to add screen space ambient occlusion (SSAO) to URP. See the SSAO_Renderer asset for an example of how to set up this effect. Blit to RTHandle This example describes the operation of blitting a camera color texture to an output texture, and setting the output texture as a global property. The shaders in the Scene use the global texture. Refer to the page Blit Camera color texture to RTHandle to read the example description. Depth Blit This sample uses a custom renderer feature to copy or render the depth texture to an RTHandle and then perform a full screen blit to screen to achieve the fading effect. Distort Tunnel This example describes the blit operation involving multiple RTHandle textures and a custom shader effect. Refer to the page Blit multiple RTHandle textures to read the example description. Glitch effect The example in RendererFeatures/GlitchEffect uses the Render Objects Render Feature and the Scene Color Shader Graph node to draw some GameObjects with a glitchy effect. See the Glitch_Renderer asset for an example of how to set up this effect. Keep frame The example in RendererFeatures/KeepFrame uses a custom Renderer Feature to preserve frame color between frames. The example uses this to create a swirl effect from a simple particle system. Note: The effect is only visible in Play Mode. Occlusion effect The example in RendererFeatures/OcclusionEffect uses the Render Objects Renderer Feature to draw occluded geometry. The example achieves this effect without any code and sets everything up in the OcclusionEffect_Renderer asset. Trail effect The example in RendererFeatures/TrailEffect uses the Renderer Feature from the Keep frame example on an additional camera to create a trail map. To do this, the additional camera draws depth to a RenderTexture. The Sand_Graph shader samples the map and displaces vertices on the ground. Shaders The URP Package Samples/Shaders folder contains examples for shaders. The following table describes each shader example in this folder. Example Description Lit The example in Shaders/Lit demonstrates how different properties of the Lit shader affect the surface of some geometry. You can use the materials and textures as guidelines on how to set up materials in URP."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/package-samples.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/package-samples.html",
    "title": "Package samples | mmo-rpg-unity",
    "keywords": "Package samples The Universal Render Pipeline (URP) comes with a set of samples to help you get started. A sample is a set of assets that you can import into your Unity project and use as a base to build upon or learn how to use a feature. A package sample can contain anything from a single C# script to multiple scenes. Importing package samples Before you import any package samples for URP, be aware that they require your project to be URP-compatible. A project is URP-compatible if you created it from a template or manually installed and set up URP in it. If the project is not URP-compatible, errors can occur when you import a package sample. To import package samples, use the Unity Package Manager window: Go to Window > Package Manager and, in the packages list view, select Universal RP. In the package details view, find the Samples section. Find the sample you want to import and click the Import button next to it. Unity imports URP package samples into Assets/Samples/Universal RP/<package version>/<sample name>. Opening package samples To open a package sample: Go to Assets/Samples/Universal RP/<package version>/. Here there is a folder for each URP package sample you have imported. Find the folder that contains the package sample you want and open it. The folder has the same name that the package sample has in the Unity Package Manager window. Package samples list The package samples that URP provides are: URP Package Samples: A collection of example shaders, C# scripts, and other assets you can build upon or use in your application. For more information, refer to URP Package Samples."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/particles-lit-shader.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/particles-lit-shader.html",
    "title": "Particles Lit Shader | mmo-rpg-unity",
    "keywords": "Particles Lit Shader In the Universal Render Pipeline (URP), use this Shader to make particles appear almost photorealistic, for example for camp fire particles, rain drops or torch smoke. This Shader produces lifelike visuals but uses the most computationally heavy shading model in URP, which can impact performance. Using the Particles Lit Shader in the Editor To select and use this Shader: In your Project, create or find the Material you want to use the Shader on. Select the Material. A Material Inspector window opens. Click Shader, and select Universal Render Pipeline > Particles > Lit. UI overview The Inspector window for this Shader contains these elements: Surface Options Surface Inputs Advanced Surface Options The Surface Options control how URP renders the Material on a screen. Property Description Surface Type Use this drop-down to apply an Opaque or Transparent surface type to the Material. This determines which render pass URP renders the Material in. Opaque surface types are always fully visible, regardless of what’s behind them. URP renders opaque Materials first. Transparent surface types are affected by their background, and they can vary according to which type of transparent surface type you choose. URP renders transparent Materials in a separate pass after opaque Materials. If you select Transparent, the Blending Mode drop-down appears. Blending Mode Select how Unity calculates the color of each pixel of a transparent Material when it blends the Material with the background. In the context of Blending Modes, Source refers to the transparent Material where the Blending Mode is set and Destination refers to anything that Material overlaps with. Alpha Alpha blending mode. Alpha uses the Material's alpha value to change how transparent an object is. 0 is fully transparent. 255 is fully opaque, this is translated to a value of 1 when used with the blending equations. The Material is always rendered in the Transparent render pass regardless of it's alpha value. This mode lets you use the Preserve Specular Lighting property. Alpha equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB × (1 − SourceAlpha) Premultiply Premultiply blending mode. Premultiply first multiplies the RGB values of the transparent Material by its alpha value then applies a similar effect to the Material as Alpha. The equation for Premultiply also allows areas of the transparent Material with an alpha value of 0 to have an additive blend effect. This can help reduce artifacts that may appear at the edge of the overlap between opaque and transparent pixels. Premultiply equation: OutputRGBA = SourceRGB + DestinationRGB × (1 − SourceAlpha) Additive Additive blending mode. Additive adds the color values of the Materials together to create the blend effect. The alpha value determines the strength of the source Material's color before the blend is calculated. This mode lets you use the Preserve Specular Lighting property. Additive equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB Multiply Multiply blending mode. Multiply multiplies the color of the Material with the color behind the surface. This creates a darker effect, like when you look through colored glass. This mode uses the Material’s alpha value to adjust how much the colors blend. An alpha value of 1 results in unadjusted multiplication of the colors while lower values blend the colors towards white. Multiply equation: OutputRGBA = SourceRGB × DestinationRGB Preserve Specular Lighting Indicates whether Unity preserves specular highlights on a GameObject or not. This applies even when your surface is transparent which means that only the reflected light is visible. This property only appears when the Surface Type is set to Transparent and Blending Mode is set to either Alpha or Additive. Material with Preserve Specular Lighting disabled. Material with Preserve Specular Lighting enabled. Render Face Use this drop-down to determine which sides of your geometry to render. Front Face renders the front face of your geometry and culls the back face. This is the default setting. Back Face renders the front face of your geometry and culls the front face. Both makes URP render both faces of the geometry. This is good for small, flat objects, like leaves, where you might want both sides visible. Alpha Clipping Makes your Material act like a Cutout Shader. Use this to create a transparent effect with hard edges between the opaque and transparent areas. For example, to create blades of grass. To achieve this effect, URP does not render alpha values below the specified Threshold, which appears when you enable Alpha Clipping. You can set the Threshold by moving the slider, which accepts values from 0 to 1. All values above your threshold are fully opaque, and all values below your threshold are invisible. For example, a threshold of 0.1 means that URP doesn't render alpha values below 0.1. The default value is 0.5. Color Mode Use this drop-down to determine how the particle color and the Material color blend together. Multiply produces a darker final color by multiplying the two colors. Additive produces a brighter final colour by adding the two colours together.</br/>Subtractive subtracts the particle color from the base color of the Material. This creates an overall dark effect in the pixel itself, with less brightness. Overlay blends the particle color over the base color of the Material. This creates a brighter color at values over 0.5 and darker colors at values under 0.5. Color uses the particle color to colorize the Material color, while keeping the value and saturation of the base color of the Material. This is good for adding splashes of color to monochrome Scenes. Difference returns the difference between both color values. This is good for blending particle and Material colors that are similar to each other. Surface Inputs The Surface Inputs describe the surface itself. For example, you can use these properties to make your surface look wet, dry, rough, or smooth. Property Description Base Map Adds color to the surface. To assign a Texture to the Base Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. The color next to the setting shows the tint on top of your assigned Texture. To assign another tint, you can click this color swatch. If you select Transparent or Alpha Clipping under Surface Options, your Material uses the Texture’s alpha channel or color. The Base Map is also known as a diffuse map. Metallic Map Shows the map input for the metallic highlights and reflections from direct lighting, for example Directional, Point, and Spot lights. You can use the Smoothness slider to control the spread of highlights on the surface. 0 gives a wide, rough highlight. 1 gives a small, sharp highlight like glass. Values in between 0 and 1 produce semi-glossy looks. For example, 0.5 produces a plastic-like glossiness. Normal Map Adds a normal map to the surface. With a normal map, you can add surface details like bumps, scratches and grooves. To add the map, click the object picker next to it. The normal map picks up ambient lighting in the environment. The float value next to the setting is a multiplier for the effect of the Normal Map. Low values decrease the effect of the normal map. High values create stronger effects. Emission Makes the surface look like it emits lights. When enabled, the Emission Map and Emission Color settings appear. To assign an Emission Map, click the object picture next to it. This opens the Asset Browser, where you can select from the textures in your Project. For Emission Color, you can use the color picker to assign a tint on top of the color. This can be more than 100% white, which is useful for effects like lava, that shines brighter than white while still being another color. If you have not assigned an Emission Map, the Emission setting only uses the tint you’ve assigned in Emission Color. If you do not enable Emission, URP sets the emission to black and does not calculate emission. Advanced The Advanced settings affect behind-the-scenes rendering. They do not have a visible effect on your surface, but on underlying calculations that impact performance. Property Description Flip-Book Blending Tick this box to blend flip-book frames together. This is useful in texture sheet animations with limited frames, because it makes animations smoother. If you have performance issues, try turning this off. Vertex Streams This list shows the vertex streams that this Material requires in order to work properly. If the vertex streams aren’t correctly assigned, the Fix Now button appears. Click this button to apply the correct setup of vertex streams to the Particle System that this Material is assigned to. Sorting Priority Use this slider to determine the chronological rendering order for a Material. URP renders Materials with lower values first. You can use this to reduce overdraw on devices by making the pipeline render Materials in front of other Materials first, so it doesn't have to render overlapping areas twice. This works similarly to the render queue in the built-in Unity render pipeline. Transparent surface type If you’ve chosen a Transparent surface type under Surface Options, these options appear: Property Description Soft Particles Tick this box to make particles fade out when they get close to intersecting with the surface of other geometry written into the depth buffer. When you enable this feature, the Surface Fade settings appear: Near sets the distance from the other surface where the particle is completely transparent. This is where the particle appears to fade out completely. Far sets the distance from the other surface where the particle is completely opaque. The particle appears solid here. Distances are measured in world units. Only usable for transparent surface types. Note: This setting uses the CameraDepthTexture that is created by URP. To use this setting, enable Depth Texture in the URP Asset or for the Camera that is rendering the particles. Camera Fading Tick this box to make particles fade out when they get close to the camera. When you enable this feature, the Distance settings appear: Near sets the distance from the camera where the particle is completely transparent. This is where the particle appears to fade out completely. Far sets the distance from the camera where the particle is completely opaque. The particle appears solid here. Distances are measured in world units. Note: This uses the CameraDepthTexture that is created by URP. To use this setting, enable Depth Texture in the URP Asset or for the Camera that is rendering the particles. Distortion Creates a distortion effect by making particles perform refraction with the objects drawn before them. This is useful for creating a heat wave effect or for warping objects behind the particles. When you enable this feature, these settings appear: Strength controls how much the Particle distorts the background. Negative values have the opposite effect of positive values. So if something was offset to the right with a positive value, the equal negative value offsets it to the left. Blend controls how visible the distortion is. At 0, there is no visible distortion. At 1, only the distortion effect is visible. Note: This uses the CameraOpaqueTexture that is created by URP. To use this setting, enable Opaque Texture in the URP Asset or for the Camera that is rendering the particles."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/particles-simple-lit-shader.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/particles-simple-lit-shader.html",
    "title": "Particles Simple Lit Shader | mmo-rpg-unity",
    "keywords": "Particles Simple Lit Shader In the Universal Render Pipeline (URP), use this Shader for particles where performance is more important than photorealism. This Shader uses a simple approximation for lighting. Because this Shader does not calculate for physical correctness and energy conservation, it renders quickly. Using the Particles Simple Lit Shader in the Editor To select and use this Shader: In your Project, create or find the Material you want to use the Shader on. Select the Material. A Material Inspector window opens. Click Shader, and select Universal Render Pipeline > Particles > Simple Lit. UI overview The Inspector window for this Shader contains these elements: Surface Options Surface Inputs Advanced Surface Options The Surface Options control how URP renders the Material on a screen. Property Description Surface Type Use this drop-down to apply an Opaque or Transparent surface type to the Material. This determines which render pass URP renders the material in. Opaque surface types are always fully visible, regardless of what’s behind them. URP renders opaque Materials first. Transparent surface types are affected by their background, and they can vary according to which type of transparent surface type you choose. URP renders transparent Materials in a separate pass after opaque objects. If you select Transparent, the Blending Mode drop-down appears. Blending Mode Use this drop-down to determine how URP calculates the color of each pixel of the transparent Material by blending the Material with the background pixels. Alpha uses the Material’s alpha value to change how transparent an object is. 0 is fully transparent. 1 appears fully opaque, but the Material is still rendered during the Transparent render pass. This is useful for visuals that you want to be fully visible but to also fade over time, like clouds. Premultiply applies a similar effect to the Material as Alpha, but preserves reflections and highlights, even when your surface is transparent. This means that only the reflected light is visible. For example, imagine transparent glass. Additive adds an extra layer to the Material, on top of another surface. This is good for holograms. Multiply multiplies the color of the Material with the color behind the surface. This creates a darker effect, like when you look through colored glass. Render Face Use this drop-down to determine which sides of your geometry to render. Front Face renders the front face of your geometry and culls the back face. This is the default setting. Back Face renders the front face of your geometry and culls the front face. Both makes URP render both faces of the geometry. This is good for small, flat objects, like leaves, where you might want both sides visible. Alpha Clipping Makes your Material act like a Cutout Shader. Use this to create a transparent effect with hard edges between the opaque and transparent areas. For example, to create blades of grass. To achieve this effect, URP does not render alpha values below the specified Threshold, which appears when you enable Alpha Clipping. You can set the Threshold by moving the slider, which accepts values from 0 to 1. All values above your threshold are fully opaque, and all values below your threshold are invisible. For example, a threshold of 0.1 means that URP doesn't render alpha values below 0.1. The default value is 0.5. Color Mode Use this drop-down to determine how the particle color and the Material color blend together. Multiply produces a darker final color by multiplying the two colors. Additive produces a brighter final colour by adding the two colours together.</br/>Subtractive subtracts the particle color from the base color of the Material. This creates an overall dark effect in the pixel itself, with less brightness. Overlay blends the particle color over the base color of the Material. This creates a brighter color at values over 0.5 and darker colors at values under 0.5. Color uses the particle color to colorize the Material color, while keeping the value and saturation of the base color of the Material. This is good for adding splashes of color to monochrome Scenes. Difference returns the difference between both color values. This is good for blending Particle and Material colors that are similar to each other. Surface Inputs The Surface Inputs describe the surface itself. For example, you can use these properties to make your surface look wet, dry, rough, or smooth. Property Description Base Map Adds color to the surface. To assign a Texture to the Base Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. The color next to the setting shows the tint on top of your assigned Texture. To assign another tint, you can click this color swatch. If you select Transparent or Alpha Clipping under Surface Options, your Material uses the Texture’s alpha channel or color. The Base Map is also known as a diffuse map. Specular Map Controls the color of your specular highlights from direct lighting, for example Directional, Point, and Spot lights. To assign a Texture to the Specular Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. In__ Source__, you can select a Texture in your Project to act as a source for the smoothness. By default, the source is the alpha channel for this Texture. You can use the Smoothness slider to control the spread of highlights on the surface. 0 gives a wide, rough highlight. 1 gives a small, sharp highlight like glass. Values in between 0 and 1 produce semi-glossy looks. For example, 0.5 produces a plastic-like glossiness. Note: If this setting appears greyed out, check if Specular Highlights are enabled under the Advanced settings. Normal Map Adds a normal map to the surface. With a normal map, you can add surface details like bumps, scratches and grooves. To add the map, click the object picker next to it. The normal map picks up ambient lighting in the environment. Emission Makes the surface look like it emits lights. When enabled, the Emission Map and Emission Color settings appear. To assign an Emission Map, click the object picture next to it. This opens the Asset Browser, where you can select from the textures in your Project. For Emission Color, you can use the color picker to assign a tint on top of the color. This can be more than 100% white, which is useful for effects like lava, that shines brighter than white while still being another color. If you have not assigned an Emission Map, the Emission setting only uses the tint you’ve assigned in Emission Color. If you do not enable Emission, URP sets the emission to black and does not calculate emission. Advanced The Advanced settings affect behind-the-scenes rendering. They do not have a visible effect on your surface, but on underlying calculations that impact performance. Property Description Flip-Book Blending Tick this box to blend flip-book frames together. This is useful in texture sheet animations with limited frames, because it makes animations smoother. If you have performance issues, try turning this off. Specular Highlights When enabled, your particles have specular highlights from direct lighting, for example Directional, Point, and Spot lights. This means that each particle reflects the shine from these light sources. When disabled, these highlight calculations are not part of the Shader, which can make the Shader render faster. By default, this feature is enabled. Vertex Streams This list shows the vertex streams that this Material requires in order to work properly. If the vertex streams aren’t correctly assigned, the Fix Now button appears. Click this button to apply the correct setup of vertex streams to the Particle System that this Material is assigned to. Sorting Priority Use this slider to determine the chronological rendering order for a Material. URP renders Materials with lower values first. You can use this to reduce overdraw on devices by making the pipeline render Materials in front of other Materials first, so it doesn't have to render overlapping areas twice. This works similarly to the render queue in the built-in Unity render pipeline. Transparent surface type If you’ve chosen a Transparent surface type under Surface Options, these options appear: Property Description Soft Particles Tick this box to make particles fade out when they get close to intersecting with the surface of other geometry written into the depth buffer. When you enable this feature, the Surface Fade settings appear: Near sets the distance from the other surface where the particle is completely transparent. This is where the particle appears to fade out completely. Far sets the distance from the other surface where the particle is completely opaque. The particle appears solid here. Distances are measured in world units. Only usable for transparent surface types. Note: This setting uses the CameraDepthTexture that is created by URP. To use this setting, enable Depth Texture in the URP Asset or for the Camera that is rendering the particles. Camera Fading Tick this box to make particles fade out when they get close to the camera. When you enable this feature, the Distance settings appear: Near sets the distance from the camera where the particle is completely transparent. This is where the particle appears to fade out completely. Far sets the distance from the camera where the particle is completely opaque. The particle appears solid here. Distances are measured in world units. Note: This uses the CameraDepthTexture that is created by URP. To use this setting, enable Depth Texture in the URP Asset or for the Camera that is rendering the particles. Distortion Creates a distortion effect by making particles perform refraction with the objects drawn before them. This is useful for creating a heat wave effect or for warping objects behind the particles. When you enable this feature, these settings appear: Strength controls how much the Particle distorts the background. Negative values have the opposite effect of positive values. So if something was offset to the right with a positive value, the equal negative value offsets it to the left. Blend controls how visible the distortion is. At 0, there is no visible distortion. At 1, only the distortion effect is visible. Note: This uses the CameraOpaqueTexture that is created by URP. To use this setting, enable Opaque Texture in the URP Asset or for the Camera that is rendering the particles."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/particles-unlit-shader.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/particles-unlit-shader.html",
    "title": "Particles Unlit Shader | mmo-rpg-unity",
    "keywords": "Particles Unlit Shader Use this Shader for Particles that don’t need lighting. Because there are no time-consuming lighting calculations or lookups, this Shader is optimal for lower-end hardware. The Unlit Shader uses the most simple shading model in the Universal Render Pipeline (URP). Using the Particles Unlit Shader in the Editor To select and use this Shader: In your Project, create or find the Material you want to use the Shader on. Select the Material. A Material Inspector window opens. Click Shader, and select Universal Render Pipeline > Particles > Unlit. UI overview The Inspector window for this Shader contains these elements: Surface Options Surface Inputs Advanced Surface Options The Surface Options control how URP renders the Material on a screen. Property Description Surface Type Use this drop-down to apply an Opaque or Transparent surface type to the Material. This determines which render pass URP renders the Material in. Opaque surface types are always fully visible, regardless of what’s behind them. URP renders opaque Materials first. Transparent surface types are affected by their background, and they can vary according to which type of transparent surface type you choose. URP renders transparent Materials in a separate pass after opaque Materials. If you select Transparent, the Blending Mode drop-down appears. Blending Mode Use this drop-down to determine how URP calculates the color of each pixel of the transparent Material by blending the Material with the background pixels. Alpha uses the Material’s alpha value to change how transparent a surface is. 0 is fully transparent. 1 appears fully opaque, but the Material is still rendered during the Transparent render pass. This is useful for visuals that you want to be fully visible but to also fade over time, like clouds. Premultiply applies a similar effect to the Material as Alpha, but preserves reflections and highlights, even when your surface is transparent. This means that only the reflected light is visible. For example, imagine transparent glass. Additive adds an extra layer to the Material, on top of another surface. This is good for holograms. Multiply multiplies the color of the Material with the color behind the surface. This creates a darker effect, like when you view an through tinted glass. Render Face Use this drop-down to determine which sides of your geometry to render. Front Face renders the front face of your geometry and culls the back face. This is the default setting. Back Face renders the front face of your geometry and culls the front face. Both makes URP render both faces of the geometry. This is good for small, flat objects, like leaves, where you might want both sides visible. Alpha Clipping Makes your Material act like a Cutout Shader. Use this to create a transparent effect with hard edges between the opaque and transparent areas. For example, to create blades of grass. To achieve this effect, URP does not render alpha values below the specified Threshold, which appears when you enable Alpha Clipping. You can set the Threshold by moving the slider, which accepts values from 0 to 1. All values above your threshold are fully opaque, and all values below your threshold are invisible. For example, a threshold of 0.1 means that URP doesn't render alpha values below 0.1. The default value is 0.5. Color Mode Use this drop-down to determine how the particle color and the Material color blend together. Multiply produces a darker final color by multiplying the two colors. Additive produces a brighter final colour by adding the two colours together.</br/>Subtractive subtracts the particle color from the base color of the Material. This creates an overall dark effect in the pixel itself, with less brightness. Overlay blends the particle color over the base color of the Material. This creates a brighter color at values over 0.5 and darker colors at values under 0.5. Color uses the particle color to colorize the Material color, while keeping the value and saturation of the base color of the Material. This is good for adding splashes of color to monochrome Scenes. Difference returns the difference between both color values. This is good for blending particle and Material colors that are similar to each other. Surface Inputs The Surface Inputs describe the surface itself. For example, you can use these properties to make your surface look wet, dry, rough, or smooth. Property Description Base Map Adds color to the surface. To assign a Texture to the Base Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. The color next to the setting shows the tint on top of your assigned Texture. To assign another tint, you can click this color swatch. If you select Transparent or Alpha Clipping under Surface Options, your Material uses the Texture’s alpha channel or color. The Base Map is also known as a diffuse map. Normal Map Adds a normal map to the surface. With a normal map, you can add surface details like bumps, scratches and grooves. To add the map, click the object picker next to it. The normal map picks up ambient lighting in the environment. Emission Makes the surface look like it emits lights. When enabled, the Emission Map and Emission Color settings appear. To assign an Emission Map, click the object picture next to it. This opens the Asset Browser, where you can select from the textures in your Project. For Emission Color, you can use the color picker to assign a tint on top of the color. This can be more than 100% white, which is useful for effects like lava, that shines brighter than white while still being another color. If you have not assigned an Emission Map, the Emission setting only uses the tint you’ve assigned in Emission Color. If you do not enable Emission, URP sets the emission to black and does not calculate emission. Advanced The Advanced settings affect behind-the-scenes rendering. They do not have a visible effect on your surface, but on underlying calculations that impact performance. Property Description Flip-Book Blending Tick this box to blend flip-book frames together. This is useful in texture sheet animations with limited frames, because it makes animations smoother. If you have performance issues, try turning this off. Vertex Streams This list shows the vertex streams that this Material requires in order to work properly. If the vertex streams aren’t correctly assigned, the Fix Now button appears. Click this button to apply the correct setup of vertex streams to the Particle System that this Material is assigned to. Sorting Priority Use this slider to determine the chronological rendering order for a Material. URP renders Materials with lower values first. You can use this to reduce overdraw on devices by making the pipeline render Materials in front of other Materials first, so it doesn't have to render overlapping areas twice. This works similarly to the render queue in the built-in Unity render pipeline. Transparent surface type If you’ve chosen a Transparent surface type under Surface Options, these options appear: Property Description Soft Particles Tick this box to make particles fade out when they get close to intersecting with the surface of other geometry written into the depth buffer. When you enable this feature, the Surface Fade settings appear: Near sets the distance from the other surface where the particle is completely transparent. This is where the particle appears to fade out completely. Far sets the distance from the other surface where the particle is completely opaque. The particle appears solid here. Distances are measured in world units. Only usable for transparent surface types. Note: This setting uses the CameraDepthTexture that is created by URP. To use this setting, enable Depth Texture in the URP Asset or for the Camera that is rendering the particles. Camera Fading Tick this box to make particles fade out when they get close to the camera. When you enable this feature, the Distance settings appear: Near sets the distance from the camera where the particle is completely transparent. This is where the particle appears to fade out completely. Far sets the distance from the camera where the particle is completely opaque. The particle appears solid here. Distances are measured in world units. Note: This uses the CameraDepthTexture that is created by Universal RP. To use this setting, enable Depth Texture in the URP Asset or for the Camera that is rendering the particles. Distortion Creates a distortion effect by making particles perform refraction with the objects drawn before them. This is useful for creating a heat wave effect or for warping objects behind the particles. When you enable this feature, these settings appear: Strength controls how much the Particle distorts the background. Negative values have the opposite effect of positive values. So if something was offset to the right with a positive value, the equal negative value offsets it to the left. Blend controls how visible the distortion is. At 0, there is no visible distortion. At 1, only the distortion effect is visible. Note: This uses the CameraOpaqueTexture that is created by URP. To use this setting, enable Opaque Texture in the URP Asset or for the Camera that is rendering the particles."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/pixel-cinemachine.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/pixel-cinemachine.html",
    "title": "Using the Cinemachine Pixel Perfect extension | mmo-rpg-unity",
    "keywords": "Using the Cinemachine Pixel Perfect extension Both the Pixel Perfect Camera and Cinemachine modify the Camera’s orthographic size. Using these two systems together in a single Scene would cause them to fight for control over the Camera and produce unwanted results. The Cinemachine Pixel Perfect extension solves this incompatibility. Cinemachine Pixel Perfect is an extension for the Cinemachine Virtual Camera that alters the orthographic size of the virtual camera. The extension detects the presence of the Pixel Perfect Camera component, and uses the component settings to calculate for the correct orthographic size of the virtual camera that best retains the Sprites in a pixel-perfect resolution. To add this extension to your virtual cameras, use the Add Extension dropdown menu on the Cinemachine Virtual Camera Inspector window. Add this extension to each virtual camera in your Project. For each virtual camera attached with this extension, the Pixel Perfect Camera component then calculates a pixel-perfect orthographic size that best matches the original size of the virtual camera during __Play Mode __ or when Run In Edit Mode is enabled. This is done to match the original framing of each virtual camera as close as possible when the pixel-perfect calculations are implemented. When the Cinemachine Brain component blends between multiple virtual cameras, the rendered image is temporarily not pixel-perfect during the transition between cameras. The image becomes pixel-perfect once the view fully transitions to a single virtual camera. The following are the current limitations of the extension: When a virtual camera with the Pixel Perfect extension is set to follow a Target Group, there may be visible choppiness when the virtual camera is positioned with the Framing Transposer component. If the Upscale Render Texture option is enabled on the Pixel Perfect Camera, there are less possible pixel-perfect resolutions that match the original orthographic size of the virtual cameras. This may cause the framing of the virtual cameras to be off by quite a large margin after the pixel-perfect calculations."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-bloom.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-bloom.html",
    "title": "Bloom | mmo-rpg-unity",
    "keywords": "Bloom Scene with Bloom effect turned off. Scene with Bloom effect turned on. The Bloom effect creates fringes of light extending from the borders of bright areas in an image. This creates the illusion of extremely bright light overwhelming the Camera. The Bloom effect also has a Lens Dirt feature, which you can use to apply a full-screen layer of smudges or dust to diffract the Bloom effect. Using Bloom Bloom uses the Volume system, so to enable and modify Bloom properties, you must add a Bloom override to a Volume in your Scene. To add Bloom to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing, and click on Bloom. Universal Render Pipeline applies Bloom to any Camera this Volume affects. Properties Bloom Property Description Threshold Set the gamma space brightness value at which URP applies Bloom. URP does not apply Bloom to any pixels in the Scene that have a brightness lower than this value. The minimum value is 0, where nothing is filtered. The default value is 0.9. There is no maximum value. Intensity Set the strength of the Bloom filter, in a range from 0 to 1. The default is 0, which means that the Bloom effect is disabled. Scatter Set the radius of the bloom effect in a range from 0 to 1. Higher values give a larger radius. The default value is 0.7. Tint Use the color picker to select a color for the Bloom effect to tint to. Clamp Set the maximum intensity that Unity uses to calculate Bloom. If pixels in your Scene are more intense than this, URP renders them at their current intensity, but uses this intensity value for the purposes of Bloom calculations. The default value is 65472. High Quality Filtering Enable this to use high quality sampling. This reduces flickering and improves the overall smoothness, but is more resource-intensive and can affect performance. Downscale Set the initial resolution scale for the effect. The lower this value is, the fewer system resources the initial blur effect consumes. Max Iterations The size of the rendered image determines the number of iterations. Use this setting to define the maximum number of iterations. Decreasing this value reduces processing load and increases performance, especially on mobile devices with high DPI screens. The default value is 6. Lens Dirt Property Description Texture Assign a Texture to apply the effect of dirt (such as smudges or dust) to the lens. Intensity Set the strength of the Lens Dirt effect. Troubleshooting performance issues There are multiple ways to improve the performance impact of Bloom. Listed in order of effectiveness, you can: Disable High Quality Filtering. Bloom then uses bilinear filtering instead of bicubic. This reduces the overall smoothness of the Bloom effect, but greatly improves performance, especially on lower-end hardware and platforms. In some extreme cases, you might see blocky graphical artifacts in your Scene. Set Downscale to Quarter starting resolution to make the initial cost of Bloom much lower. Use a lower resolution Lens Dirt Texture to reduce memory pressure and speed up blending across volumes."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-chromatic-aberration.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-chromatic-aberration.html",
    "title": "Chromatic Aberration | mmo-rpg-unity",
    "keywords": "Chromatic Aberration Scene with Chromatic Aberration effect turned off. Scene with Chromatic Aberration effect turned on. Chromatic Aberration creates fringes of color along boundaries that separate dark and light parts of the image. It mimics the color distortion that a real-world camera produces when its lens fails to join all colors to the same point. For more information, refer to Wikipedia: Chromatic aberration. Using Chromatic Aberration Chromatic Aberration uses the Volume system, so to enable and modify Chromatic Aberration properties, you must add a Chromatic Aberration override to a Volume in your Scene. To add Chromatic Aberration to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Chromatic Aberration. Universal Render Pipeline applies Chromatic Aberration to any Camera this Volume affects. Properties Property Description Intensity Set the strength of the Chromatic Aberration effect. Values range between 0 and 1. The higher the value, the more intense the effect is. The default value is 0, which disables the effect."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-depth-of-field.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-depth-of-field.html",
    "title": "Depth Of Field | mmo-rpg-unity",
    "keywords": "Depth Of Field The Depth Of Field component applies a depth of field effect, which simulates the focus properties of a camera lens. In real life, a camera can only focus sharply on an object at a specific distance. Objects nearer or farther from the camera are out of focus. The blurring gives a visual cue about an object’s distance, and introduces “bokeh”, which refers to visual artifacts that appear around bright areas of the image as they fall out of focus. To read more about bokeh, refer to the Wikipedia article on Bokeh. The Universal Render Pipeline (URP) has two depth of field modes: Gaussian: this mode approximates camera-like effects, but doesn’t imitate them completely. It has a limited blur radius and only does far-field blurring. This mode is the fastest, and is the best mode for lower-end platforms. Bokeh: a slower but higher quality mode that closely imitates the effects of a real-life camera. It can do both near & far-field blurring, and generates bokeh on areas with high luminosity intensity, also known as hot spots. Using Depth Of Field Depth Of Field uses the Volume system, so to enable and modify Depth Of Field properties, you must add a Depth Of Field override to a Volume in your Scene. To add Depth Of Field to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing, and click on Depth Of Field. Universal Render Pipeline applies Depth Of Field to any Camera this Volume affects. Properties Property Description Mode Use this drop-down to select the mode that URP uses to set the focus for the depth of field effect. Off: Select this option to disable depth of field. Gaussian: Select this option to use the faster but more limited depth of field mode. Bokeh: Select this option to use the Bokeh-based depth of field mode. Gaussian Depth of Field Property Description Start Set the distance from the Camera at which the far field starts blurring. End Set the distance from the Camera at which the far field blur reaches its maximum blur radius. Max Radius Set the maximum radius the far blur can reach. The default value is 1. Note: Values above 1 can cause visual under-sampling artifacts to appear in your Scene. If your blur effects are not smooth or appear to have static noise in them, try decreasing the value back to 1 or lower. High Quality Sampling Use higher quality sampling to reduce flickering and improve the overall blur smoothness. This can cause some performance cost. Bokeh Depth of Field The Bokeh Depth of Field mode closely imitates the effect of a real-life camera. For this reason, the settings are based on real-life camera settings, and offer a number of properties to adjust the diaphragm blades on the Camera. For an introduction to diaphragm blades and how they affect the visual quality of your Camera output, refer to Improve Photography’s guide Aperture Blades: How many is best?. Property Description Focus Distance Set the distance from the Camera to the focus point. Focal Length Set the distance, in millimeters, between the Camera sensor and the Camera lens. The larger the value is, the shallower the depth of field. Aperture Set the ratio of aperture (known as f-stop or f-number). The smaller the value is, the shallower the depth of field is. Blade Count Use the slider to set the number of diaphragm blades the Camera uses to form the aperture. The more blades you use, the rounder the bokeh appears. Blade Count from left to right: 3, 4, 5, and 6. Blade Curvature Use the slider to set the curvature of diaphragm blades the Camera uses to form the aperture. The smaller the value is, the more visible aperture blades are. A value of 1 makes the bokeh perfectly circular. Blade Curvature value of 1 (left), and 0 (right). Blade Rotation Use the slider to set the rotation of diaphragm blades in degrees."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-ssao.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-ssao.html",
    "title": "Ambient Occlusion | mmo-rpg-unity",
    "keywords": "Ambient Occlusion The Ambient Occlusion effect darkens creases, holes, intersections and surfaces that are close to each other in real-time. In the real world, such areas tend to block out or occlude ambient light, so they appear darker. URP implements the Screen Space Ambient Occlusion (SSAO) effect as a Renderer Feature. It works with every shader that the Universal Render Pipeline (URP) provides as well as any custom opaque Shader Graphs you create. Note: The SSAO effect is a Renderer Feature and works independently from the post-processing effects in URP. This effect does not depend on or interact with Volumes. The following images show a scene with the Ambient Occlusion effect turned off, on, and only the Ambient Occlusion texture. Scene with Ambient Occlusion effect turned off. Scene with Ambient Occlusion effect turned on. Scene with only the Ambient Occlusion texture. Add the SSAO Renderer Feature to a Renderer URP implements the Ambient Occlusion effect as a Renderer Feature. To use the SSAO effect in your project follow the instructions on How to add a Renderer Feature to a Renderer and add the Screen Space Ambient Occlusion Renderer Feature. This causes any Cameras that use the Renderer with the SSAO Renderer Feature to have the SSAO effect. Properties This section describes the properties of the SSAO Renderer Feature. Method This property defines the type of noise the SSAO effect uses. Available Options: Interleaved Gradient Noise: Uses interleaved gradient noise to generate static SSAO. Blue Noise: Uses a selection of blue noise textures to generate dynamic SSAO. This creates an animated effect as the texture changes with every frame, as a result the SSAO effect is more subtle when the camera is in motion. Performance impact: Insignificant. Intensity This property defines the intensity of the darkening effect. Performance impact: Insignificant. Radius When Unity calculates the Ambient Occlusion value, the SSAO effect takes samples of the normal texture within this radius from the current pixel. Performance impact: High. A lower Radius value improves performance, because the SSAO Renderer Feature samples pixels closer to the source pixel. This makes caching more efficient. Calculating the Ambient Occlusion Pass on objects closer to the Camera takes longer than on objects further from the Camera. This is because the Radius property scales with the object. Falloff Distance SSAO does not apply to objects farther than this distance from the Camera. A lower value increases performance in scenes that contain many distant objects. The performance improvement is smaller in smaller scenes with fewer objects. Performance impact: Depends on the application. Direct Lighting Strength This property defines how visible the effect is in areas exposed to direct lighting. These images show how the Direct Lighting Strength value changes the SSAO effect depending on whether they are in the shadow or not. Direct Lighting Strength: 0.2. Direct Lighting Strength: 0.9. A. Shows the effect of Direct Lighting Strength on the SSAO effect in lit areas. B. Shows the effect of Direct Lighting Strength on the SSAO effect in areas one or more shadows cover. Performance impact: Insignificant. Quality Source Select the source of the normal vector values. The SSAO Renderer Feature uses normal vectors for calculating how exposed each point on a surface is to ambient lighting. Available options: Depth Normals: SSAO uses the normal texture generated by the DepthNormals Pass. This option lets Unity make use of a more accurate normal texture. Depth: SSAO does not use the DepthNormals Pass to generate the normal texture. SSAO reconstructs the normal vectors using the depth texture instead. Use this option only if you want to avoid using the DepthNormals Pass block in your custom shaders. Selecting this option enables the Normal Quality property. Performance impact: Depends on the application. When you switch between the options Depth Normals and Depth, there might be a variation in performance, which depends on the target platform and the application. In a wide range of applications the difference in performance is small. In most cases, Depth Normals produce a better visual look. For more information on the Source property, refer to the section Implementation details. Normal Quality This property becomes active when you select the option Depth in the Source property. Higher quality of the normal vectors produces smoother SSAO effect. Available options: Low Medium High Performance impact: Medium. In some scenarios, the Depth option produces results comparable with the Depth Normals option. But in certain cases, the Depth Normals option provides a significant increase in quality. The following images show an example of such case. Source: Depth. Normal Quality: Low. Source: Depth. Normal Quality: Medium. Source: Depth. Normal Quality: High. Source: Depth Normals. For more information, refer to the section Implementation details. Downsample Selecting this check box reduces the resolution of the Pass that calculates the Ambient Occlusion effect by a factor of two. The reduction in resolution of the Ambient Occlusion Pass by a factor of two reduces the pixel count to process by a factor of four. This reduces the load on the GPU significantly, but makes the effect less detailed. Performance impact: Very high. After Opaque When you enable After Opaque, Unity calculates and applies the SSAO effect after the opaque render pass. This can increase performance when used with Depth as the Source for normal vector values as Unity does not perform the skips depth prepass to calculate SSAO and instead uses the existing depth values. After Opaque can also increase performance on mobile devices that use tile-based rendering. Performance impact: Medium. Blur Quality This property defines the quality of blur that Unity applies to the SSAO effect. Higher quality blur creates a smoother, higher fidelity effect but requires more processing power. Available options: High (Bilateral): Bilateral blur, takes three passes to process. Medium (Gaussian): Gaussian blur, takes two passes to process. Low (Kawase): Kawase blur, takes a single pass to process. Performance impact: Very high. Samples For each pixel, the SSAO Render Feature takes the selected number of samples within the specified radius to calculate the Ambient Occlusion value. A higher value makes the effect smoother and more detailed, but also reduces performance. Available options: High: 12 Samples Medium: 8 Samples Low: 4 Samples Performance impact: High. An increase in the Sample Count value from 4 to 8 doubles the computational load on the GPU. Implementation details The SSAO Renderer Feature uses normal vectors for calculating how exposed each point on a surface is to ambient lighting. URP 10.0 implements the DepthNormals Pass block that generates the the normal texture _CameraNormalsTexture for the current frame. By default, the SSAO Renderer Feature uses this texture to calculate Ambient Occlusion values. If you implement your custom SRP and if you do not want to implement the DepthNormals Pass block in your shaders, you can use the SSAO Renderer Feature and set its Source property to Depth. In this case, Unity does not use the DepthNormals Pass to generate the normal vectors, it reconstructs the normal vectors using the depth texture instead. Selecting the option Depth in the Source property enables the Normal Quality property. The options in this property (Low, Medium, and High) determine the number of samples of the depth texture that Unity takes when reconstructing the normal vector from the depth texture. The number of samples per quality level: Low: 1, Medium: 5, High: 9."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-tonemapping.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-tonemapping.html",
    "title": "Tonemapping | mmo-rpg-unity",
    "keywords": "Tonemapping Tonemapping is the process of remapping the HDR values of an image to a new range of values. Its most common purpose is to make an image with a low dynamic range appear to have a higher range. For more information, refer to Wikipedia: Tone mapping. Using Tonemapping Tonemapping uses the Volume system, so to enable and modify Tonemapping properties, you must add a Tonemapping override to a Volume in your Scene. To add Tonemapping to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing, and click on Tonemapping. The Universal Render Pipeline applies Tonemapping to any Camera this Volume affects. Properties Property Description Mode Select a tonemapping algorithm to use for color grading. The options are: None: Use this option if you do not want to apply tonemapping. Neutral: Use this option if you only want range-remapping with minimal impact on color hue & saturation. It is generally a good starting point for extensive color grading. ACES: Use this option to apply a close approximation of the reference ACES tonemapper, for a more cinematic look. It is more contrasted than Neutral, and has an effect on actual color hue & saturation. If you use this tonemapper, Unity does all the grading operations in the ACES color spaces, for optimal precision and results. Note: ACES HDR tonemapping is not supported on Android devices with Adreno 300 series GPU."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-vignette.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing-vignette.html",
    "title": "Vignette | mmo-rpg-unity",
    "keywords": "Vignette In photography, vignetting is the term for the darkening and/or desaturating towards the edges of an image compared to the center. In real life, thick or stacked filters, secondary lenses, and improper lens hoods are usually the cause of this effect. You can use vignetting to draw focus to the center of an image. Using Vignette Vignette uses the Volume system, so to enable and modify Vignette properties, you must add a Vignette override to a Volume in your Scene. To add Vignette to a Volume: In the Scene or Hierarchy view, select a GameObject that contains a Volume component to view it in the Inspector. In the Inspector, navigate to Add Override > Post-processing and click on Vignette. Universal Render Pipeline applies Vignette to any Camera this Volume affects. Properties Property Description Color Use the color picker to set the color of the vignette. Center Set the vignette center point. For reference, the screen center is [0.5, 0.5]. Intensity Set the strength of the vignette effect. Smoothness Use the slider to set the smoothness of the vignette borders. Values range between 0.01 and 1. The higher the value, the smoother the vignette border. The default value is 0.2. Rounded When enabled, the vignette is perfectly round. When disabled, the vignette matches the shape on the current aspect ratio."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing/custom-post-processing.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing/custom-post-processing.html",
    "title": "Custom post-processing | mmo-rpg-unity",
    "keywords": "Custom post-processing The Universal Render Pipeline (URP) provides a variety of pre-built post-processing effects that you can adjust to create a particular visual effect or style. URP also lets you create custom post-processing effects using the Full Screen Pass Renderer Feature. For example, you can implement a grayscale effect to indicate when a player has run out of health. Scene with no post-processing effects. Scene with grayscale custom post-processing effect. The following page describes how to create a custom post-processing effect using the Full Screen Pass Renderer Feature. How to create a custom post-processing effect."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing/hdr-output.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing/hdr-output.html",
    "title": "High Dynamic Range (HDR) Output | mmo-rpg-unity",
    "keywords": "High Dynamic Range (HDR) Output High Dynamic Range content has a wider color gamut and greater luminosity range than standard definition content. URP can output HDR content for displays which support that functionality. How to enable HDR Output To activate HDR output, follow these steps. Locate the URP Asset in the Project window under Assets > Settings. Navigate to Quality > HDR and enable the checkbox to enable HDR. Navigate to Edit > Project Settings > Player > Other Settings and enable the following settings: Allow HDR Display Output Use HDR Display Output Note: Only enable Use HDR Display Output if you need the main display to use HDR Output. If you switch to a URP Asset that does not have HDR enabled, URP disables HDR Output until you change to a URP Asset with HDR enabled. Note: If HDR Output is active, the grading mode falls back to HDR, even if there is a different Color Grading Mode active in the URP Asset. HDR tone mapping in URP After you enable Allow HDR Display Output, you must configure Tonemapping settings for your HDR input. In order to configure these settings effectively, you need to understand how certain values related to tone mapping determine the visual characteristics of your HDR output. Important tone mapping values To properly make use of the capabilities of HDR displays, your Tonemapping configuration must take into account the capabilities of the target display, specifically these three values (in nits): Minimum supported brightness. Maximum supported brightness. Paper White value: This value represents the brightness of a paper-white surface represented on the display, which determines the display's brightness overall. Note: Low Dynamic Range (LDR) and High Dynamic Range (HDR) content do not appear equally bright on displays with the same Paper White value. This is because displays apply extra processing to low dynamic range content that bumps its brightness levels up. For this reason, it is best practice to implement a calibration menu for your application. Usable user interfaces depend on accurate Paper White values Unlit materials do not respond to lighting changes, so it is standard practice to use an Unlit material for user interfaces. Calculations for Unlit material rendering define brightness with values between 0 and 1 when you are not specifically targeting HDR displays. In this context, a value of 1 corresponds to white, and a value of 0 corresponds to black. However, in HDR mode, URP uses Paper White values to determine the brightness of Unlit materials. This is because HDR values can exceed the 0 to 1 range. As a result, Paper White values determine the brightness of UI elements in HDR mode, especially white elements, whose brightness matches Paper White values. Configure HDR Tone Mapping settings You can select and adjust Tonemapping modes in the Volume component settings. You can also adjust some aspects of your HDR Tonemapping configuration with a script (refer to the HDROutputSettings API). After you enable Allow HDR Display Output, HDR Tonemapping options become visible in the Volume component. Tone mapping modes URP provides two Tonemapping modes: Neutral and ACES. Each Tonemapping mode has some unique properties. Neutral mode is especially suitable for situations where you do not want the tone mapper to color grade your content. ACES mode uses the ACES reference color space for feature films. It produces a cinematic, contrasty result. Neutral Property Description Neutral HDR Range Reduction Mode The curve that the Player uses for tone mapping. The options are: BT2390: The default. Defined by the BT.2390 broadcasting recommendations. Reinhard: A simple Tone Mapping operator. This option is only available when you enable Show Additional Properties. Hue Shift Amount The value determines the extent to which your content retains its original hue after you apply HDR settings. When this value is 0, the tonemapper attempts to preserve the hue of your content as much as possible by only tonemapping luminance. Detect Paper White Enable this property if you want URP to use the Paper White value that the display communicates to the Unity Engine. In some cases, the value the display communicates may not be accurate. Implement a calibration menu for your application so that users can display your content correctly on displays that communicate inaccurate values. Paper White The Paper White value of the display. If you do not enable Detect Paper White, you must specify a value here. Detect Brightness Limits Enable this property if you want URP to use the minimum and maximum nit values that the display communicates. In some cases, the value the display communicates may not be accurate. It is best practice to implement a calibration menu for your application to allow for these situations. Min Nits The minimum brightness value of the display. If you do not enable Detect Brightness Limits, you must specify a value here and in Max Nits. Max Nits The maximum brightness value of the display. If you do not enable Detect Brightness Limits, you must specify a value here and in Min Nits. Misuse of Hue Shift Amount Creators might author some content with the intention to use Hue Shift Amount to produce special effects. In the illustration below, the Hue Shift Amount is 0 for Image A and 1 for Image B. The flames image B appear more intense because of the hue shift effect. It is preferable not to author content in this way, because settings optimized for special effects can have undesirable effects on other content in the Scene. Image A: Output when Hue Shift Amount is 0. Image B: Output when Hue Shift Amount is 1. ACES This mode has fixed presets to target 1000, 2000, and 4000 nit displays. It is best practice to implement a calibration menu for your application to ensure that the user can select the right preset. Property Description ACES Preset The tone mapper preset to use. The options are: ACES 1000 Nits: The default. This curve targets 1000 nits displays. ACES 2000 Nits: Curve that targets 2000 nits displays. ACES 4000 Nits: Curve that targets 4000 nits displays. Detect Paper White Enable this property if you want URP to use the Paper White value that the display communicates to the Unity Engine. In some cases, the value the display communicates may not be accurate. Implement a calibration menu for your application so that users can display your content correctly on displays that communicate inaccurate values. Paper White The Paper White value of the display. If you do not enable Detect Paper White, you must specify a value here. The HDROutputSettings API The HDROutputSettings API makes it possible to enable and disable HDR mode, as well as query certain values (such as Paper White). Offscreen Rendering When using offscreen rendering techniques, not all cameras in a scene output directly to the display. For example, when Unity is rendering the output to a Render Texture. In these situations, you use the output of the camera before rendering post-processing. Unity does not apply HDR Output processing to the output of cameras which use offscreen rendering techniques. This prevents HDR Output processing being applied twice to the camera's output. SDR Rendering HDR Output relies on HDR Rendering to provide pixel values in the correct format for tone mapping and color encoding. The values after HDR tone mapping are in nits and exceed 1. This differs from SDR Rendering where the pixel values are between 0 and 1. As a result of this, the use of SDR Rendering with HDR Output can cause the rendered image to look underexposed or oversaturated. You can use SDR Rendering on a per-camera basis when you have HDR Output enabled, this can be useful for cameras that only render unlit materials, for example, for mini-map rendering. However, the use of SDR Rendering with HDR Output imposes some limitations. To ensure correct rendering when you use SDR Rendering with HDR Output, you must avoid any render passes that occur after post-processing. This includes URP's built-in effects which insert render passes after post-processing. As a result, SDR Rendering with HDR Output is incompatible with the following features: Upscaling FXAA HDR Debug Views Custom passes which occur after post-processing 2D Renderer To use SDR Rendering with HDR Output on the 2D Renderer, you must ensure post-processing is turned off. HDR Debug Views URP offers three debug views for HDR rendering. To access them, navigate to Window > Analysis > Render Pipeline Debugger > Lighting > HDR Debug Mode. Gamut View The triangles in this debug view indicate which parts of three specific color gamuts this scene covers. The small triangle displays the Rec709 gamut values, the medium triangle displays the P3-D65 gamut values, and the large triangle displays the Rec2020 gamut values. This enables you to check color plot changes while color grading. It can also help you ensure that you benefit from the wider color gamut available in HDR. Gamut Clip This debug view indicates the relationship between scene values and specific color gamuts. Areas of the screen with values within the Rec709 gamut are green, areas outside of the Rec709 gamut but inside the P3-D65 gamut are blue, and areas outside of both are red. Values exceeding Paper White This debug view uses a color coded gradient to indicate parts of the Scene that exceed the Paper White value. The gradient ranges from yellow to red. Yellow corresponds to Paper White +1, and red corresponds to Max Nits. Platform Compatibility URP only supports HDR Output on the following platforms: Windows with DirectX 11, DirectX 12 or Vulkan MacOS with Metal Consoles XR devices with HDR support Note: DirectX 11 only supports HDR Output in the Player, it does not support HDR Output in the Editor."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing/post-processing-custom-effect-low-code.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/post-processing/post-processing-custom-effect-low-code.html",
    "title": "How to create a custom post-processing effect | mmo-rpg-unity",
    "keywords": "How to create a custom post-processing effect The example on this page shows how to use a Full Screen Render Pass to create a grayscale custom post-processing effect. Prerequisites This example requires the following: A Unity project with the URP package installed. The Scriptable Render Pipeline Settings property refers to a URP asset (Project Settings > Graphics > Scriptable Render Pipeline Settings). Create a Fullscreen Shader Graph You must create a Fullscreen Shader Graph to create a custom post-processing effect. Create a new Shader Graph in your Project. To do this right-click in the Project window and select Create > Shader Graph > URP > Fullscreen Shader Graph. Add a URP Sample Buffer node. To do this right-click in the Shader Graph window, and select Create Node. Then locate and select URP Sample Buffer. In the URP Sample Buffer node's Source Buffer dropdown menu, select BlitSource. Add a Vector 3 node. Assign the Vector 3 node the following values: X = 0.2126 Y = 0.7152 Z = 0.0722 Add a Dot Product node. Connect the nodes as shown below. Node Connection URP Sample Buffer Output to Dot Product A Vector 3 Out to Dot Product B Dot Product Out to Fragment Base Color Save your Shader Graph. Create a new Material in your Project. To do this right-click in the Project window and select Create > Material. Apply the Shader Graph shader to the Material. To do this, open the Material in the Inspector and select Shader > Shader Graphs, then select the Shader Graph you created in the previous steps. Use the Material in a Full Screen Pass Renderer Feature Once you've created a compatible Shader Graph and Material, you can use the Material with a Full Screen Pass Renderer Feature to create a custom post-processing effect. In the Project window, select a URP Renderer. In the Inspector, click Add Renderer Feature and select Full Screen Pass Renderer Feature. For more information on adding Renderer Features refer to How to add a Renderer Feature to a Renderer. Set the Post Process Material to the Material you created with the Fullscreen Shader Graph. Set Injection Point to After Rendering Post Processing. Set Requirements to Color. You should now see the effect in both Scene view and Game view. Example scene with a grayscale custom post-processing effect."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/quality/quality-settings-through-code.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/quality/quality-settings-through-code.html",
    "title": "Control URP Quality settings through code | mmo-rpg-unity",
    "keywords": "Control URP Quality settings through code Unity has several preset levels of Quality settings and you might add more to your project. To accommodate different hardware specifications, you can switch between these levels and the associated URP Asset from C# scripts. The following examples show how to use API to change Quality setting levels and the active URP Asset, and how to change specific settings in the URP Asset at runtime. Note: You should only change Quality settings and URP Asset settings at runtime at points where performance is not essential, such as during loading screens or on static menus. This is because these changes cause a temporary but significant performance impact. Change URP Asset at runtime Each quality level uses a URP Asset to control many of the specific graphics settings. You can assigning different URP Assets to each quality level and switch between them at runtime. Configure Project Quality settings To use Quality settings to switch between URP Assets, ensure that the quality levels of your project are configured to use different URP Assets. The URP 3D Sample scene has this configuration by default. Create a URP Asset for each quality level. To do this, right-click in the Project window and select Create > Rendering > URP Asset (with Universal Renderer). Note: These instructions are also valid for URP Assets that use the 2D Renderer. Configure and name the new URP Assets as necessary. Open the Quality section in the Project Settings (Edit > Project Settings > Quality). Assign each URP Asset to a quality level. To do this, select a quality level from the Levels list, then go to Rendering > Render Pipeline Asset and choose the URP Asset you created for this quality level. Do this for each quality level. The quality levels of your project are now ready to be used to change between URP Assets at runtime. Change Quality Level You can change the quality level Unity uses at runtime through the QualitySettings API. With the quality levels setup as shown previously, this enables you to switch between URP Assets as well as Quality settings presets. In the following simple example, the C# script uses the system's total Graphics Memory to determine the appropriate quality level without any input from the user when they open the built project. Create a new C# script with the name QualityControls. Open the QualityControls script and add the SwitchQualityLevel method to the QualityControls class. using System.Collections; using System.Collections.Generic; using UnityEngine; public class QualityControls : MonoBehaviour { void Start() { } private void SwitchQualityLevel() { } } Add a switch statement in the SwitchQualityLevel method to select the quality level with the QualitySettings.SetQualityLevel() method as shown below. Note: Each Quality level has an index that matches the level's position in the list in the Quality section of the Project Settings window. The quality level at the top of the list has an index of 0. This index only counts quality levels which you specified as enabled for the target platform of any built version of your project. using System.Collections; using System.Collections.Generic; using UnityEngine; public class QualityControls : MonoBehaviour { void Start() { } private void SwitchQualityLevel() { // Select Quality settings level (URP Asset) based on the size of the device's graphics memory switch (SystemInfo.graphicsMemorySize) { case <= 2048: QualitySettings.SetQualityLevel(1); break; case <= 4096: QualitySettings.SetQualityLevel(2); break; default: QualitySettings.SetQualityLevel(0); break; } } } Add a call to the SwitchQualityLevel method in the Start method. This ensures that the quality level only changes when the scene first loads. using System.Collections; using System.Collections.Generic; using UnityEngine; public class QualityControls : MonoBehaviour { void Start() { SwitchQualityLevel(); } private void SwitchQualityLevel() { // Select Quality settings level (URP Asset) based on the size of the device's graphics memory switch (SystemInfo.graphicsMemorySize) { case <= 2048: QualitySettings.SetQualityLevel(1); break; case <= 4096: QualitySettings.SetQualityLevel(2); break; default: QualitySettings.SetQualityLevel(0); break; } } } Open the first scene that your built project loads on startup. Create an empty GameObject and call it QualityController. To do this, right-click in the Hierarchy Window and select Create Empty. Open the QualityController object in the Inspector. Add the QualityControls script to the QualityController as a component. Now when this scene loads, Unity runs the SwitchQualityLevel method in the QualityControls script which detects the system's total graphics memory and sets the quality level. The quality level sets the URP Asset as the active Render Pipeline Asset. You can create more complex systems and sequences of checks to determine which quality level to use, but the fundamental process remains the same. When the project starts, run a script which uses QualitySettings.SetQualityLevel to select a quality level and through that select the URP Asset for the project to use at runtime. Change URP Asset settings You can change some properties of the URP Asset at runtime with C# scripts. This can help fine tune performance on devices with hardware that doesn't perfectly match any of the quality levels in your project. Note: To change a property of the URP Asset with a C# script, the property must have a set method. For more information on these properties refer to Accessible Properties. The following example uses the QualityControls script and QualityController object from the Change Quality Level through code section, and extends the functionality to locate the active URP Asset and change some of its properties to fit the performance level of the hardware. Open the QualityControls script. At the top of the script add using UnityEngine.Rendering and using UnityEngine.Rendering.Universal. Add a method with the name ChangeAssetProperties and the type void to the QualityControls class as shown below. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class QualityController : MonoBehaviour { void Start() { // Select the appropriate Quality Level first SwitchQualityLevel(); } private void SwitchQualityLevel() { // Code from previous example } private void ChangeAssetProperties() { // New code is added to this method } } Retrieve the active Render Pipeline Asset with GraphicsSettings.currentRenderPipeline as shown below. Note: You must use the as keyword to cast the Render Pipeline Asset as the UniversalRenderPipelineAsset type for the script to work correctly. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class QualityController : MonoBehaviour { void Start() { // Select the appropriate Quality Level first SwitchQualityLevel(); } private void SwitchQualityLevel() { // Code from previous example } private void ChangeAssetProperties() { // Locate the current URP Asset UniversalRenderPipelineAsset data = GraphicsSettings.currentRenderPipeline as UniversalRenderPipelineAsset; // Do nothing if Unity can't locate the URP Asset if (!data) return; } } Add a switch statement in the ChangeAssetProperties method to set the value of the URP Asset properties. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class QualityController : MonoBehaviour { void Start() { // Select the appropriate Quality Level first SwitchQualityLevel(); } private void SwitchQualityLevel() { // Code from previous example } private void ChangeAssetProperties() { // Locate the current URP Asset UniversalRenderPipelineAsset data = GraphicsSettings.currentRenderPipeline as UniversalRenderPipelineAsset; // Do nothing if Unity can't locate the URP Asset if (!data) return; // Change URP Asset settings based on the size of the device's graphics memory switch (SystemInfo.graphicsMemorySize) { case <= 1024: data.renderScale = 0.7f; data.shadowDistance = 50.0f; break; case <= 3072: data.renderScale = 0.9f; data.shadowDistance = 150.0f; break; default: data.renderScale = 0.7f; data.shadowDistance = 25.0f; break; } } } Add a call to the ChangeAssetProperties method in the Start method. This ensures that the URP Asset only changes when the scene first loads. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class QualityController : MonoBehaviour { void Start() { // Select the appropriate Quality Level first SwitchQualityLevel(); // Fine tune performance with specific URP Asset properties ChangeAssetProperties(); } private void SwitchQualityLevel() { // Code from previous example } private void ChangeAssetProperties() { // Locate the current URP Asset UniversalRenderPipelineAsset data = GraphicsSettings.currentRenderPipeline as UniversalRenderPipelineAsset; // Do nothing if Unity can't locate the URP Asset if (!data) return; // Change URP Asset settings based on the size of the device's graphics memory switch (SystemInfo.graphicsMemorySize) { case <= 1024: data.renderScale = 0.7f; data.shadowDistance = 50.0f; break; case <= 3072: data.renderScale = 0.9f; data.shadowDistance = 150.0f; break; default: data.renderScale = 0.7f; data.shadowDistance = 25.0f; break; } } } Now when this scene loads, Unity detects the system's total graphics memory and sets the URP Asset properties accordingly. You can use this method of changing particular URP Asset properties in conjunction with changing quality levels to fine tune the performance of your project for different systems without the need to create a quality level for every target hardware configuration. Accessible Properties You can access and change any properties of the URP Asset which have a set method through a C# script at runtime. The following properties of the URP Asset have a set method: cascadeBorder colorGradingLutSize colorGradingMode conservativeEnclosingSphere fsrOverrideSharpness fsrSharpness hdrColorBufferPrecision maxAdditionalLightsCount msaaSampleCount numIterationsEnclosingSphere renderScale shadowCascadeCount shadowDepthBias shadowDistance shadowNormalBias storeActionsOptimization supportsCameraDepthTexture supportsCameraOpaqueTexture supportsDynamicBatching supportsHDR upscalingFilter useAdaptivePerformance useSRPBatcher For more information on these properties, refer to Universal Render Pipeline Asset API."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/realtime-lighting-in-universalrp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/realtime-lighting-in-universalrp.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Important: This page is still a work in progress. To read our most current documentation, open the TableOfContents.md file to see the linked pages."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-feature-decal-landing.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-feature-decal-landing.html",
    "title": "Decal Renderer Feature | mmo-rpg-unity",
    "keywords": "Decal Renderer Feature A Decal Renderer Features projects specific materials (decals) onto other objects in the scene. Decals interact with the scene's lighting and wrap around meshes. Page Description Decal Renderer Feature Use a Decal Renderer Feature in your scene. Decal Shader Graph Project a material as a decal if the material uses a Shader Graph with the Decal Material type."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-feature-decal.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-feature-decal.html",
    "title": "Decal Renderer Feature | mmo-rpg-unity",
    "keywords": "Decal Renderer Feature With the Decal Renderer Feature, Unity can project specific Materials (decals) onto other objects in the Scene. The decals interact with the Scene's lighting and wrap around Meshes. Sample scene without decals Sample scene with decals. The decals hide the seams between materials and add artistic details. For examples of how to use Decals, refer to the Decals samples in URP Package Samples. How to use the feature To add decals to your Scene: Add the Decal Renderer Feature to the URP Renderer. Create a Material, and assign it the Shader Graphs/Decal shader. In the Material, select the Base Map and the Normal Map. Create a new Decal Projector GameObject, or add a Decal Projector component to an existing GameObject. The following illustration shows a Decal Projector in the Scene. For more information, refer to Decal Projector component. An alternative way to add decals to a Scene: Create a Quad GameObject. Assign a Decal Material to the GameObject. Position the Quad on the surface where you want the decal to be. If necessary, adjust the mesh bias value to prevent z-fighting. Limitations This feature has the following limitations: The decal projection does not work on transparent surfaces. Decal Renderer Feature properties This section describes the properties of the Decal Renderer Feature. Decal Renderer Feature, Inspector view. Technique Select the rendering technique for the Renderer Feature. This section describes the options in this property. Automatic Unity selects the rendering technique automatically based on the build platform. The Accurate G-buffer normals option is also taken into account, as it prevents normal blending from working correctly without the D-Buffer technique. DBuffer Unity renders decals into the Decal buffer (DBuffer). Unity overlays the content of the DBuffer on top of the opaque objects during the opaque rendering. Selecting this technique reveals the Surface Data property. The Surface Data property lets you specify which surface properties of decals Unity blends with the underlying meshes. The Surface Data property has the following options: Albedo: decals affect the base color and the emission color. Albedo Normal: decals affect the base color, the emission color, and the normals. Albedo Normal MAOS: decals affect the base color, the emission color, the normals, the metallic values, the smoothness values, and the ambient occlusion values. Limitations: This technique requires the DepthNormal prepass, which makes the technique less efficient on GPUs that implement tile-based rendering. This technique does not work on particles and terrain details. Screen Space Unity renders decals after the opaque objects using normals that Unity reconstructs from the depth texture, or from the G-Buffer when using the Deferred rendering path. Unity renders decals as meshes on top of the opaque meshes. This technique supports only the normal blending. When using the Deferred rendering path with Accurate G-buffer normals, blending of normals is not supported, and will yield incorrect results. Screen space decals are recommended for mobile platforms that use tile-based rendering, because URP doesn't create a DepthNormal prepass unless you enable Use Rendering Layers. Selecting this technique reveals the following properties. Property Description Normal Blend The options in this property (Low, Medium, and High) determine the number of samples of the depth texture that Unity takes when reconstructing the normal vector from the depth texture. The higher the quality, the more accurate the reconstructed normals are, and the higher the performance impact is. Low Unity takes one depth sample when reconstructing normals. Medium Unity takes three depth samples when reconstructing normals. High Unity takes five depth samples when reconstructing normals. Max Draw Distance The maximum distance from the Camera at which Unity renders decals. Use Rendering Layers Select this check box to enable the Rendering Layers functionality. If you enable Use Rendering Layers, URP creates a DepthNormal prepass. This makes decals less efficient on GPUs that implement tile-based rendering. Decal Projector component The Decal Projector component lets Unity project decals onto other objects in the Scene. A Decal Projector component must use a Material with the Decal Shader Graph assigned (Shader Graphs/Decal). For more information on how to use the Decal Projector, refer to How to use the feature. The Decal Projector component contains the Scene view editing tools and the Decal Projector properties. Decal Projector component in the Inspector. NOTE: If you assign a Decal Material to a GameObject directly (not via a Decal Projector component), then Decal Projectors do not project decals on such GameObject. Decal Scene view editing tools When you select a Decal Projector, Unity shows its bounds and the projection direction. The Decal Projector draws the decal Material on every Mesh inside the bounding box. The white arrow shows the projection direction. The base of the arrow is the pivot point. The Decal Projector component provides the following Scene view editing tools. Icon Action Description Scale Select to scale the projector box and the decal. This tool changes the UVs of the Material to match the size of the projector box. The tool does not affect the pivot point. Crop Select to crop or tile the decal with the projector box. This tool changes the size of the projector box but not the UVs of the Material. The tool does not affect the pivot point. Pivot / UV Select to move the pivot point of the decal without moving the projection box. This tool changes the transform position. This tool also affects the UV coordinates of the projected texture. Decal Projector component properties This section describes the Decal Projector component properties. Property Description Scale Mode Select whether this Decal Projector inherits the Scale values from the Transform component of the root GameObject. Options: • Scale Invariant: Unity uses the scaling values (Width, Height, etc.) only in this component, and ignores the values in the root GameObject. • Inherit from Hierarchy: Unity evaluates the scaling values for the decal by multiplying the lossy Scale values of the Transform of the root GameObject by the Decal Projector's scale values. Note: since the Decal Projector uses the orthogonal projection, if the root GameObject is skewed, the decal does not scale correctly. Width The width of the projector bounding box. The projector scales the decal to match this value along the local X axis. Height The height of the projector bounding box. The projector scales the decal to match this value along the local Y axis. Projection Depth The depth of the projector bounding box. The projector projects decals along the local Z axis. Pivot The offset position of the center of the projector bounding box relative to the origin of the root GameObject. Material The Material to project. The Material must use a Shader Graph that has the Decal Material type. For more information, refer to the page Decal Shader Graph. Tiling The tiling values for the decal Material along its UV axes. Offset The offset values for the decal Material along its UV axes. Opacity This property lets you specify the opacity value. A value of 0 makes the decal fully transparent, a value of 1 makes the decal as opaque as defined by the Material. Draw Distance The distance from the Camera to the Decal at which this projector stops projecting the decal and URP no longer renders the decal. Start Fade Use the slider to set the distance from the Camera at which the projector begins to fade out the decal. Values from 0 to 1 represent a fraction of the Draw Distance. With a value of 0.9, Unity starts fading the decal out at 90% of the Draw Distance and finishes fading it out at the Draw Distance. Angle Fade Use the slider to set the fade out range of the decal based on the angle between the decal's backward direction and the vertex normal of the receiving surface. Performance Decals do not support the SRP Batcher by design because they use Material property blocks. To reduce the number of draw calls, decals can be batched together using GPU instancing. If the decals in your Scene use the same Material, and if the Material has the Enable GPU Instancing property turned on, Unity instances the Materials and reduces the number of draw calls. To reduce the number of Materials necessary for decals, put multiple decal textures into one texture (atlas). Use the UV offset properties on the decal projector to determine which part of the atlas to display. The following image shows an example of a decal atlas. left: decal atlas with four decals. Right: a decal projector is projecting one of them. If the decal Material has GPU instancing enabled, any instance of the four decals is rendered in a single instanced draw call."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-feature-screen-space-shadows.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-feature-screen-space-shadows.html",
    "title": "Screen Space Shadows Renderer Feature | mmo-rpg-unity",
    "keywords": "Screen Space Shadows Renderer Feature Screen-space shadows in a sample scene. You can add a Screen Space Shadows Renderer Feature to a Universal Render Pipeline (URP) renderer. This makes URP use a single render texture to calculate and draw shadows from the main Directional Light, instead of multiple shadow cascade textures. The Screen Space Shadows Renderer Feature doesn't affect how shadows look. If your project uses the Forward Renderer, screen-space shadows might make rendering faster, because the Universal Render Pipeline (URP) doesn't need to access multiple shadow cascade textures. Screen-space shadows have the following limitations: URP adds a depth prepass so it can sample the depth texture. This might reduce performance on mobile platforms that use tile-based rendering. Refer to Depth Priming Mode for more information about the depth prepass. URP creates a screen-space shadows texture, which uses more memory. The screen-space shadows texture for the previous image. Enable screen-space shadows To add screen-space shadows to your project, add the Screen Space Shadows Renderer Feature. Refer to Add a renderer feature. URP doesn't calculate or draw screen-space shadows for transparent objects. URP uses shadow maps for transparent objects instead. View screen-space shadows Use the Frame Debugger to view the render passes that draw shadows. Check the following render passes: ScreenSpaceShadows, which creates the screen-space shadows texture. MainLightShadow, which creates shadow map textures. Check the DrawOpaqueObjects render pass to check which shadow texture URP uses to draw shadows on each object. The Frame Debugger with screen-space shadows enabled. The objects in the DrawOpaqueObjects render pass use _ScreenSpaceShadowmapTexture. The Frame Debugger with screen-space shadows disabled. The objects in the DrawOpaqueObjects render pass use TempBuffer 398 2048x1024 and TempBuffer 399 2048x2048, which are shadow map textures from the MainLightShadow render pass."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/create-custom-renderer-feature.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/create-custom-renderer-feature.html",
    "title": "Example of a complete Scriptable Renderer Feature | mmo-rpg-unity",
    "keywords": "Example of a complete Scriptable Renderer Feature This section describes how to create a complete Scriptable Renderer Feature for a URP Renderer. This walkthrough contains the following sections: Overview of this example implementation Create example Scene and GameObjects Create a scriptable Renderer Feature and add it to the Universal Renderer Add the Renderer Feature to the the Universal Renderer asset Create the scriptable Render Pass Implement the settings for the custom render pass Enqueue the render pass in the custom renderer feature Implement the volume component Complete code for the scripts in this example Custom Renderer Feature code Custom render pass code Volume Component code The custom shader for the blur effect Overview of this example implementation The example workflow on this page implements a custom Renderer Feature that uses custom Render Passes to add a blur effect to the camera output. The implementation consists of the following parts: A ScriptableRendererFeature instance that enqueues a ScriptableRenderPass instance every frame. A ScriptableRenderPass instance that performs the following steps: Creates a temporary render texture using the RenderTextureDescriptor API. Applies two passes of the custom shader to the camera output using the RTHandle and the Blit API. Create example Scene and GameObjects To set your project up for this example workflow: Create a new Scene. Create two GameObjects: a Cube GameObject called Cube, and a Sphere GameObject called Sphere. Create two Materials with a shader that lets you specify the base color (for example, the Universal Render Pipeline/Lit shader). Call the Materials Blue and Red, and set the base colors of the Materials to blue and red respectively. Assign the Red Material to the cube and the Blue Material to the sphere. Position the camera so that it has the cube and the sphere in its view. The sample scene should look like the following image: Create a scriptable Renderer Feature and add it to the Universal Renderer Create a new C# script and name it BlurRendererFeature.cs. In the script, remove the code that Unity inserted in the BlurRendererFeature class. Add the following using directive: using UnityEngine.Rendering.Universal; Create the BlurRendererFeature class that inherits from the ScriptableRendererFeature class. public class BlurRendererFeature : ScriptableRendererFeature In the BlurRendererFeature class, implement the following methods: Create: Unity calls this method on the following events: When the Renderer Feature loads the first time. When you enable or disable the Renderer Feature. When you change a property in the inspector of the Renderer Feature. AddRenderPasses: Unity calls this method every frame, once for each camera. This method lets you inject ScriptableRenderPass instances into the scriptable Renderer. Now you have the custom BlurRendererFeature Renderer Feature with its main methods. Below is the complete code for this step. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.Rendering.Universal; public class BlurRendererFeature : ScriptableRendererFeature { public override void Create() { } public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { } } Add the Renderer Feature to the the Universal Renderer asset Add the Renderer Feature you created to the the Universal Renderer asset. For information on how to do this, refer to the page How to add a Renderer Feature to a Renderer. Create the scriptable Render Pass This section demonstrates how to create a scriptable Render Pass and enqueue its instance into the scriptable Renderer. Create a new C# script and name it BlurRenderPass.cs. In the script, remove the code that Unity inserted in the BlurRenderPass class. Add the following using directive: using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; Create the BlurRenderPass class that inherits from the ScriptableRenderPass class. public class BlurRenderPass : ScriptableRenderPass Add the Execute method to the class. Unity calls this method every frame, once for each camera. This method lets you implement the rendering logic of the scriptable Render Pass. public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { } Below is the complete code for the BlurRenderPass.cs file from this section. using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class BlurRenderPass : ScriptableRenderPass { public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { } } Implement the settings for the custom render pass This section demonstrates how to implement the settings for the custom blur render pass. The Renderer Feature in this example uses the shader that performs the blur horizontally in one pass, and vertically in another pass. To let users control the blur value for each pass, add the following BlurSettings class to the BlurRendererFeature.cs script. [Serializable] public class BlurSettings { [Range(0,0.4f)] public float horizontalBlur; [Range(0,0.4f)] public float verticalBlur; } In the BlurRendererFeature class, declare the following fields: [SerializeField] private BlurSettings settings; [SerializeField] private Shader shader; private Material material; private BlurRenderPass blurRenderPass; In the BlurRenderPass class, add the fields for the settings, the Material, and the constructor that uses those fields. private BlurSettings defaultSettings; private Material material; public BlurRenderPass(Material material, BlurSettings defaultSettings) { this.material = material; this.defaultSettings = defaultSettings; } In the BlurRenderPass class, add the RenderTextureDescriptor field and initialize it in the constructor: using UnityEngine; private RenderTextureDescriptor blurTextureDescriptor; public BlurRenderPass(Material material, BlurSettings defaultSettings) { this.material = material; this.defaultSettings = defaultSettings; blurTextureDescriptor = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0); } In the BlurRenderPass class, declare the RTHandle field to store the reference to the temporary blur texture. private RTHandle blurTextureHandle; In the BlurRenderPass class, implement the Configure method. Unity calls this method before executing the render pass. public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) { //Set the blur texture size to be the same as the camera target size. blurTextureDescriptor.width = cameraTextureDescriptor.width; blurTextureDescriptor.height = cameraTextureDescriptor.height; //Check if the descriptor has changed, and reallocate the RTHandle if necessary. RenderingUtils.ReAllocateIfNeeded(ref blurTextureHandle, blurTextureDescriptor); } In the BlurRenderPass class, implement the UpdateBlurSettings method that updates the shader values. Use the Blit method to apply the two passes from the custom shader to the camera output. private static readonly int horizontalBlurId = Shader.PropertyToID(\"_HorizontalBlur\"); private static readonly int verticalBlurId = Shader.PropertyToID(\"_VerticalBlur\"); ... private void UpdateBlurSettings() { if (material == null) return; material.SetFloat(horizontalBlurId, defaultSettings.horizontalBlur); material.SetFloat(verticalBlurId, defaultSettings.verticalBlur); } Call the UpdateBlurSettings method in the Execute method. public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { //Get a CommandBuffer from pool. CommandBuffer cmd = CommandBufferPool.Get(); RTHandle cameraTargetHandle = renderingData.cameraData.renderer.cameraColorTargetHandle; UpdateBlurSettings(); // Blit from the camera target to the temporary render texture, // using the first shader pass. Blit(cmd, cameraTargetHandle, blurTextureHandle, material, 0); // Blit from the temporary render texture to the camera target, // using the second shader pass. Blit(cmd, blurTextureHandle, cameraTargetHandle, material, 1); //Execute the command buffer and release it back to the pool. context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } Implement the Dispose method that destroys the Material and the temporary render texture after the render pass execution. public void Dispose() { #if UNITY_EDITOR if (EditorApplication.isPlaying) { Object.Destroy(material); } else { Object.DestroyImmediate(material); } #else Object.Destroy(material); #endif if (blurTextureHandle != null) blurTextureHandle.Release(); } The complete code for this part is in section Custom render pass code. Enqueue the render pass in the custom renderer feature In this section, you instantiate the render pass in the Create method of the BlurRendererFeature class, and enqueue it in the AddRenderPasses method. In the Create method of the BlurRendererFeature class, instantiate the BlurRenderPass class. In the method, use the renderPassEvent field to specify when to execute the render pass. public override void Create() { if (shader == null) { return; } material = new Material(shader); blurRenderPass = new BlurRenderPass(material, settings); renderPassEvent = RenderPassEvent.AfterRenderingSkybox; } In the AddRenderPasses method of the BlurRendererFeature class, enqueue the render pass with the EnqueuePass method. public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { if (renderingData.cameraData.cameraType == CameraType.Game) { renderer.EnqueuePass(blurRenderPass); } } Implement the Dispose method that destroys the material instance that the Renderer Feature creates. The method also calls the Dispose method from the render pass class. protected override void Dispose(bool disposing) { blurRenderPass.Dispose(); #if UNITY_EDITOR if (EditorApplication.isPlaying) { Destroy(material); } else { DestroyImmediate(material); } #else Destroy(material); #endif } For the complete Renderer Feature code, refer to section Custom Renderer Feature code. The Scriptable Renderer Feature is now complete. The following image shows the effect of the feature in the Game view and the example settings. The effect of the Scriptable Renderer Feature in the Game view. Implement the volume component This section shows how to implement a volume component that lets you control the input values for the custom renderer feature. Create a new C# script and name it CustomVolumeComponent.cs. Inherit the CustomVolumeComponent class from the VolumeComponent class, add the [Serializable] attribute to the class. Add the using UnityEngine.Rendering; directive. using System; using UnityEngine.Rendering; [Serializable] public class CustomVolumeComponent : VolumeComponent { } Add the BoolParameter field to the CustomVolumeComponent class. This field lets you enable or disable the custom renderer feature. public class BlurVolumeComponent : VolumeComponent { public BoolParameter isActive = new BoolParameter(true); } Add the fields to control the blur settings defined in the custom renderer feature. [Serializable] public class CustomVolumeComponent : VolumeComponent { public BoolParameter isActive = new BoolParameter(true); public ClampedFloatParameter horizontalBlur = new ClampedFloatParameter(0.05f, 0, 0.5f); public ClampedFloatParameter verticalBlur = new ClampedFloatParameter(0.05f, 0, 0.5f); } In the BlurRenderPass script, change the UpdateBlurSettings method so that it uses the settings defined in a Volume or the default settings if no Volume is set. private void UpdateBlurSettings() { if (material == null) return; // Use the Volume settings or the default settings if no Volume is set. var volumeComponent = VolumeManager.instance.stack.GetComponent<CustomVolumeComponent>(); float horizontalBlur = volumeComponent.horizontalBlur.overrideState ? volumeComponent.horizontalBlur.value : defaultSettings.horizontalBlur; float verticalBlur = volumeComponent.verticalBlur.overrideState ? volumeComponent.verticalBlur.value : defaultSettings.verticalBlur; material.SetFloat(horizontalBlurId, horizontalBlur); material.SetFloat(verticalBlurId, verticalBlur); } In the Unity scene, create a local Box Volume. If a Volume Profile is missing, create a new one by clicking New next to the Profile property. Add the Custom Volume Component override to the Volume. Enable the settings in the Custom Volume Component override and set the values for this Volume. Move the Volume so that the camera is inside it. The settings from the Volume override the default settings from the custom renderer feature. All complete code for the scripts in this example This section contains the complete code for all the scripts in this example. Custom Renderer Feature code Below is the complete code for the custom Renderer Feature script. using System; using UnityEditor; using UnityEngine; using UnityEngine.Rendering.Universal; public class BlurRendererFeature : ScriptableRendererFeature { [SerializeField] private BlurSettings settings; [SerializeField] private Shader shader; private Material material; private BlurRenderPass blurRenderPass; public override void Create() { if (shader == null) { return; } material = new Material(shader); blurRenderPass = new BlurRenderPass(material, settings); blurRenderPass.renderPassEvent = RenderPassEvent.AfterRenderingSkybox; } public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { if (renderingData.cameraData.cameraType == CameraType.Game) { renderer.EnqueuePass(blurRenderPass); } } protected override void Dispose(bool disposing) { blurRenderPass.Dispose(); #if UNITY_EDITOR if (EditorApplication.isPlaying) { Destroy(material); } else { DestroyImmediate(material); } #else Destroy(material); #endif } } [Serializable] public class BlurSettings { [Range(0, 0.4f)] public float horizontalBlur; [Range(0, 0.4f)] public float verticalBlur; } Custom render pass code Below is the complete code for the custom Render Pass script. using UnityEditor; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class BlurRenderPass : ScriptableRenderPass { private static readonly int horizontalBlurId = Shader.PropertyToID(\"_HorizontalBlur\"); private static readonly int verticalBlurId = Shader.PropertyToID(\"_VerticalBlur\"); private BlurSettings defaultSettings; private Material material; private RenderTextureDescriptor blurTextureDescriptor; private RTHandle blurTextureHandle; public BlurRenderPass(Material material, BlurSettings defaultSettings) { this.material = material; this.defaultSettings = defaultSettings; blurTextureDescriptor = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0); } public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) { // Set the blur texture size to be the same as the camera target size. blurTextureDescriptor.width = cameraTextureDescriptor.width; blurTextureDescriptor.height = cameraTextureDescriptor.height; // Check if the descriptor has changed, and reallocate the RTHandle if necessary RenderingUtils.ReAllocateIfNeeded(ref blurTextureHandle, blurTextureDescriptor); } private void UpdateBlurSettings() { if (material == null) return; // Use the Volume settings or the default settings if no Volume is set. var volumeComponent = VolumeManager.instance.stack.GetComponent<CustomVolumeComponent>(); float horizontalBlur = volumeComponent.horizontalBlur.overrideState ? volumeComponent.horizontalBlur.value : defaultSettings.horizontalBlur; float verticalBlur = volumeComponent.verticalBlur.overrideState ? volumeComponent.verticalBlur.value : defaultSettings.verticalBlur; material.SetFloat(horizontalBlurId, horizontalBlur); material.SetFloat(verticalBlurId, verticalBlur); } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { //Get a CommandBuffer from pool. CommandBuffer cmd = CommandBufferPool.Get(); RTHandle cameraTargetHandle = renderingData.cameraData.renderer.cameraColorTargetHandle; UpdateBlurSettings(); // Blit from the camera target to the temporary render texture, // using the first shader pass. Blit(cmd, cameraTargetHandle, blurTextureHandle, material, 0); // Blit from the temporary render texture to the camera target, // using the second shader pass. Blit(cmd, blurTextureHandle, cameraTargetHandle, material, 1); //Execute the command buffer and release it back to the pool. context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } public void Dispose() { #if UNITY_EDITOR if (EditorApplication.isPlaying) { Object.Destroy(material); } else { Object.DestroyImmediate(material); } #else Object.Destroy(material); #endif if (blurTextureHandle != null) blurTextureHandle.Release(); } } Volume Component code Below is the complete code for the Volume Component script. using System; using UnityEngine.Rendering; [Serializable] public class CustomVolumeComponent : VolumeComponent { public BoolParameter isActive = new BoolParameter(true); public ClampedFloatParameter horizontalBlur = new ClampedFloatParameter(0.05f, 0, 0.5f); public ClampedFloatParameter verticalBlur = new ClampedFloatParameter(0.05f, 0, 0.5f); } The custom shader for the blur effect This section contains the code for the custom shader that implements the blur effect. Shader \"CustomEffects/Blur\" { HLSLINCLUDE #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" // The Blit.hlsl file provides the vertex shader (Vert), // the input structure (Attributes), and the output structure (Varyings) #include \"Packages/com.unity.render-pipelines.core/Runtime/Utilities/Blit.hlsl\" float _VerticalBlur; float _HorizontalBlur; float4 _BlitTexture_TexelSize; float4 BlurVertical (Varyings input) : SV_Target { const float BLUR_SAMPLES = 64; const float BLUR_SAMPLES_RANGE = BLUR_SAMPLES / 2; float3 color = 0; float blurPixels = _VerticalBlur * _ScreenParams.y; for(float i = -BLUR_SAMPLES_RANGE; i <= BLUR_SAMPLES_RANGE; i++) { float2 sampleOffset = float2 (0, (blurPixels / _BlitTexture_TexelSize.w) * (i / BLUR_SAMPLES_RANGE)); color += SAMPLE_TEXTURE2D(_BlitTexture, sampler_LinearClamp, input.texcoord + sampleOffset).rgb; } return float4(color.rgb / (BLUR_SAMPLES + 1), 1); } float4 BlurHorizontal (Varyings input) : SV_Target { const float BLUR_SAMPLES = 64; const float BLUR_SAMPLES_RANGE = BLUR_SAMPLES / 2; UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(input); float3 color = 0; float blurPixels = _HorizontalBlur * _ScreenParams.x; for(float i = -BLUR_SAMPLES_RANGE; i <= BLUR_SAMPLES_RANGE; i++) { float2 sampleOffset = float2 ((blurPixels / _BlitTexture_TexelSize.z) * (i / BLUR_SAMPLES_RANGE), 0); color += SAMPLE_TEXTURE2D(_BlitTexture, sampler_LinearClamp, input.texcoord + sampleOffset).rgb; } return float4(color / (BLUR_SAMPLES + 1), 1); } ENDHLSL SubShader { Tags { \"RenderType\"=\"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\"} LOD 100 ZWrite Off Cull Off Pass { Name \"BlurPassVertical\" HLSLPROGRAM #pragma vertex Vert #pragma fragment BlurVertical ENDHLSL } Pass { Name \"BlurPassHorizontal\" HLSLPROGRAM #pragma vertex Vert #pragma fragment BlurHorizontal ENDHLSL } } }"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/custom-rendering-pass-workflow-in-urp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/custom-rendering-pass-workflow-in-urp.html",
    "title": "Custom render pass workflow in URP | mmo-rpg-unity",
    "keywords": "Custom render pass workflow in URP A custom render pass is a way to change how the Universal Render Pipeline (URP) renders a scene or the objects within a scene. A custom render pass contains your own rendering code, which you add to the rendering pipeline at an injection point. To add a custom render pass, complete the following tasks: Create the code for a custom render pass using the Scriptable Render Pass API. Inject the custom render pass using the RenderPipelineManager API, or by creating a Scriptable Renderer Feature that you add to the URP Renderer. Create the code for a custom render pass Use the ScriptableRenderPass to create the code for a custom render pass. Refer to Write a Scriptable Render Pass for more information. Inject the custom render pass using the RenderPipelineManager API Unity raises a beginCameraRendering event before it renders each active Camera in every frame. You can subscribe a method to this event, to execute your custom render pass before Unity renders the Camera. Refer to Inject a render pass via scripting for more information. Create a Scriptable Renderer Feature Scriptable Renderer Features control when and how the Scriptable Render Passes apply to a particular renderer or camera, and can also manage multiple Scriptable Render Passes at once. To create a Scriptable Renderer Feature, you do the following: Create a Scriptable Renderer Feature using the API. Add the Scriptable Renderer Feature to the Universal Renderer asset, so it's included in the rendering pipeline. Enqueue your custom render pass in the Scriptable Renderer Feature. Refer to Inject a pass using a Scriptable Renderer Feature for more information."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/custom-rendering-passes.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/custom-rendering-passes.html",
    "title": "Custom render passes | mmo-rpg-unity",
    "keywords": "Custom render passes Create a custom render pass in a C# script and inject it into the Universal Render Pipeline (URP) frame rendering loop. Page Description Custom render pass workflow in URP Add and inject a custom render pass to change how URP renders a scene or the objects within a scene. Scriptable Render Passes Use the Scriptable Render Pass API to create a custom render pass. Scriptable Renderer Features Use the Scriptable Renderer Feature API to inject a custom render pass into a URP renderer. Working with textures How to access and use textures in a custom render pass, including how to blit."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/how-to-custom-effect-render-objects.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/how-to-custom-effect-render-objects.html",
    "title": "Example: How to create a custom rendering effect using the Render Objects Renderer Feature | mmo-rpg-unity",
    "keywords": "Example: How to create a custom rendering effect using the Render Objects Renderer Feature URP draws objects in the DrawOpaqueObjects and DrawTransparentObjects passes. You might need to draw objects at a different point in the frame rendering, or interpret and write rendering data (like depth and stencil) in alternate ways. The Render Objects Renderer Feature lets you do such customizations by letting you draw objects on a certain layer, at a certain time, with specific overrides. The example on this page describes how to create a custom rendering effect with the Render Objects Renderer Feature. Example overview The example on this page demonstrates how to implement the following effect: There is a character in the Scene. When the character goes behind GameObjects, Unity draws the character silhouette with a different Material. Prerequisites This example requires the following: A Unity project with the URP package installed. The Scriptable Render Pipeline Settings property refers to a URP asset (Project Settings > Graphics > Scriptable Render Pipeline Settings). Create example Scene and GameObjects To follow the steps in this example, create a new Scene with the following GameObjects: Create a Cube. Set its Scale values so that it looks like a wall. Create a Material and assign it the Universal Render Pipeline/Lit shader. Select the base color (for example, red). Call the Material Character. Create a basic character and assign it the Character Material. In this example, the character consists of three capsules: the big capsule in the center represents the body, and the two smaller capsules represent the hands. To make it easier to manipulate the character in the Scene, add the three Capsules as child GameObjects under the Character GameObject. Create a Material and assign it the Universal Render Pipeline/Unlit shader. Select the base color that you would like the character to have when it's behind GameObjects (for example, blue). Call the Material CharacterBehindObjects. Now you have the setup necessary to follow the steps in this example. Example implementation This section assumes that you created a Scene as described in section Example Scene and GameObjects. The example implementation uses two Render Objects Renderer Features: one to draw parts of the character that are behind other GameObjects, and another one to draw the parts of the character that are in front of other GameObjects. Create a Renderer Feature to draw the character behind GameObjects Follow these steps to create a Renderer Feature to draw the character behind GameObjects. Select a URP Renderer. In the Inspector, click Add Renderer Feature and select Render Objects. Select the Name field and enter the name of the new Renderer Feature, for example, DrawCharacterBehind. This example uses Layers to filter the GameObjects to render. Create a new Layer and call it Character. Select the Character GameObject and assign it to the Character Layer. To do this, open the Layer drop down and select Character. In the DrawCharacterBehind Renderer Feature, in Filters > Layer Mask, select Character. With this setting, this Renderer Feature renders GameObjects only in the Layer Character. In Overrides > Material, select the CharacterBehindObjects Material. The Renderer Feature overrides the Material of a GameObject with the selected Material. The intended behavior is that the Renderer Feature renders the character with the CharacterBehindObjects Material only when the character is behind other GameObjects. To achieve this, select the Depth check box, and set the Depth Test property to Greater. With these settings, Unity renders the character with the CharacterBehindObjects Material only when the character is behind another GameObject. However, Unity also renders parts of the character using the CharacterBehindObjects Material, because some parts of the character occlude the character itself. Create an extra Renderer Feature to avoid the self see-through effect The settings in the previous section result in the self see-through effect for the following reason: When performing the Opaque rendering pass of the URP Renderer, Unity renders all GameObjects belonging to the character with the Character Material and writes depth values to the Depth buffer. This happens before Unity starts executing the DrawCharacterBehind Renderer Feature, because, by default, new Render Objects Renderer Features have the value AfterRenderingOpaques in the Event property. The Event property defines the injection point where Unity injects Render Passes from the Render Objects Renderer Feature. The event when URP Renderer draws GameObjects in the Opaque Layer Mask is the BeforeRenderingOpaques event. When executing the DrawCharacterBehind Renderer Feature, Unity performs the depth test using the condition specified in the Depth Test property. In the following screenshot, a bigger capsule occludes part of the smaller capsule, and the depth test passes for that part of the smaller capsule. The Renderer Feature overrides the Material for that part. The following steps describe how to avoid such behavior and ensure that Unity draws all parts of the character with proper Materials. In the URP asset, in Filtering > Opaque Layer Mask, clear the check mark next to the Character Layer. Now Unity does not render the character unless it's behind a GameObject. Add a new Render Objects Renderer Feature, and call it Character. In the Character Renderer Feature, in Filters > Layer Mask, select the Character Layer. Now Unity renders the character with the Character Material even when the character is behind GameObjects. This happens because the DrawCharacterBehind Renderer Feature writes values to the depth buffer. When Unity executes the Character Renderer Feature, the pixels on the character appear to be in front of the pixels that Unity has drawn previously, and Unity draws on top of those pixels. In the DrawCharacterBehind Renderer Feature, In Overrides > Depth, clear the Write Depth check box. With this setting, the DrawCharacterBehind Renderer Feature does not make changes to the depth buffer and the Character Renderer Feature does not draw the character when it's behind GameObjects. The example is complete. When the character goes behind GameObjects, Unity draws the character silhouette with the CharacterBehindObjects Material. With the extra Character Renderer Feature, Unity renders GameObjects as follows: URP Renderer does not render the Character GameObject in the BeforeRenderingOpaques event, because the Character Layer is excluded from the Opaque Layer Mask list. The DrawCharacterBehind Renderer Feature draws parts of the character that are behind other GameObjects. This happens in the AfterRenderingOpaques event. The Character Renderer Feature draws parts of the character that are in front of other GameObjects. This happens in the AfterRenderingOpaques event, and after executing the DrawCharacterBehind Renderer Feature."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/how-to-fullscreen-blit.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/how-to-fullscreen-blit.html",
    "title": "Perform a full screen blit in URP | mmo-rpg-unity",
    "keywords": "Perform a full screen blit in URP The example on this page describes how to create a custom Renderer Feature that performs a full screen blit. Example overview This example implements the following solution: A custom Renderer Feature calls a custom Render Pass. The Render Pass blits the Opaque Texture to the the Camera color target for the current renderer. The render pass uses the command buffer to draw a full screen mesh for both eyes. The example includes the shader that performs the GPU side of the rendering. The shader samples the color buffer using XR sampler macros. Prerequisites This example requires the following: The Scriptable Render Pipeline Settings property refers to a URP asset (Project Settings > Graphics > Scriptable Render Pipeline Settings). Create example Scene and GameObjects To follow the steps in this example, create a new Scene with the following GameObjects: Create a Cube. Ensure that the Cube is clearly visible from the main Camera. Now you have the Scene necessary to follow the steps in this example. Example implementation This section assumes that you created a Scene as described in section Create example Scene and GameObjects. Follow these steps to create a custom Renderer Feature with a custom Render Pass. Create a new C# script. Call it ColorBlitRendererFeature.cs. This script implements the custom Renderer Feature. using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; internal class ColorBlitRendererFeature : ScriptableRendererFeature { public Shader m_Shader; public float m_Intensity; Material m_Material; ColorBlitPass m_RenderPass = null; public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { if (renderingData.cameraData.cameraType == CameraType.Game) renderer.EnqueuePass(m_RenderPass); } public override void SetupRenderPasses(ScriptableRenderer renderer, in RenderingData renderingData) { if (renderingData.cameraData.cameraType == CameraType.Game) { // Calling ConfigureInput with the ScriptableRenderPassInput.Color argument // ensures that the opaque texture is available to the Render Pass. m_RenderPass.ConfigureInput(ScriptableRenderPassInput.Color); m_RenderPass.SetTarget(renderer.cameraColorTargetHandle, m_Intensity); } } public override void Create() { m_Material = CoreUtils.CreateEngineMaterial(m_Shader); m_RenderPass = new ColorBlitPass(m_Material); } protected override void Dispose(bool disposing) { CoreUtils.Destroy(m_Material); } } Create a new C# script. Call it ColorBlitPass.cs. This script implements the custom Render Pass that performs the custom blit draw call. This Render Pass uses the Blitter.BlitCameraTexture method to draw a full-screen quad and perform the blit operation. NOTE: Do not use the cmd.Blit method in URP XR projects because that method has compatibility issues with the URP XR integration. Using cmd.Blit might implicitly enable or disable XR shader keywords, which breaks XR SPI rendering. using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; internal class ColorBlitPass : ScriptableRenderPass { ProfilingSampler m_ProfilingSampler = new ProfilingSampler(\"ColorBlit\"); Material m_Material; RTHandle m_CameraColorTarget; float m_Intensity; public ColorBlitPass(Material material) { m_Material = material; renderPassEvent = RenderPassEvent.BeforeRenderingPostProcessing; } public void SetTarget(RTHandle colorHandle, float intensity) { m_CameraColorTarget = colorHandle; m_Intensity = intensity; } public override void OnCameraSetup(CommandBuffer cmd, ref RenderingData renderingData) { ConfigureTarget(m_CameraColorTarget); } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { var cameraData = renderingData.cameraData; if (cameraData.camera.cameraType != CameraType.Game) return; if (m_Material == null) return; CommandBuffer cmd = CommandBufferPool.Get(); using (new ProfilingScope(cmd, m_ProfilingSampler)) { m_Material.SetFloat(\"_Intensity\", m_Intensity); Blitter.BlitCameraTexture(cmd, m_CameraColorTarget, m_CameraColorTarget, m_Material, 0); } context.ExecuteCommandBuffer(cmd); cmd.Clear(); CommandBufferPool.Release(cmd); } } Create the shader that performs the blit operation. Call the shader file ColorBlit.shader. The vertex function outputs the full-screen quad position. The fragment function samples the color buffer and returns the color * float4(0, _Intensity, 0, 1) value to the render target. Shader \"ColorBlit\" { SubShader { Tags { \"RenderType\"=\"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\"} LOD 100 ZWrite Off Cull Off Pass { Name \"ColorBlitPass\" HLSLPROGRAM #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" // The Blit.hlsl file provides the vertex shader (Vert), // input structure (Attributes) and output strucutre (Varyings) #include \"Packages/com.unity.render-pipelines.core/Runtime/Utilities/Blit.hlsl\" #pragma vertex Vert #pragma fragment frag TEXTURE2D_X(_CameraOpaqueTexture); SAMPLER(sampler_CameraOpaqueTexture); float _Intensity; half4 frag (Varyings input) : SV_Target { UNITY_SETUP_STEREO_EYE_INDEX_POST_VERTEX(input); float4 color = SAMPLE_TEXTURE2D_X(_CameraOpaqueTexture, sampler_CameraOpaqueTexture, input.texcoord); return color * float4(0, _Intensity, 0, 1); } ENDHLSL } } } Add the ColorBlitRendererFeature to the Universal Renderer asset. For information on how to add a Renderer Feature, refer to the page How to add a Renderer Feature to a Renderer. For this example, set the Intensity property to 1.5. Unity shows the following views: NOTE: To visualize the example in XR, configure the project to use XR SDK. Add the MockHMD XR Plugin to the project. Set the Render Mode property to Single Pass Instanced. The example is complete. Additional resources Blit Camera color texture to RTHandle This page describes how to blit a camera color texture to an output texture, and set the output texture as a global property. Blit multiple RTHandle textures and draw them on the screen This page describes a more complex blit operation that uses multiple textures defined as RTHandle."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/intro-to-scriptable-render-passes.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/intro-to-scriptable-render-passes.html",
    "title": "Introduction to Scriptable Render Passes | mmo-rpg-unity",
    "keywords": "Introduction to Scriptable Render Passes Scriptable Render Passes are a way to alter how Unity renders a scene or the objects within a scene. They allow you to fine tune how Unity renders each scene in your project on a scene-by-scene basis. The following sections explain the fundamentals of Scriptable Render Passes: What is a Scriptable Render Pass? Scriptable Render Passes in Scenes You can use Scriptable Renderer Features to inject Scriptable Render Passes into a renderer. For more information, refer to Scriptable Render Passes in Scenes. What is a Scriptable Render Pass? You inject a Scriptable Render Pass into the render pipeline to achieve a custom visual effect. To do this, you add the Scriptable Render Pass via a MonoBehavior script with the EnqueuePass method and add this script as a component to a renderer, camera, or GameObject. A Scriptable Render Pass lets you to do the following: Change the properties of materials in your scene. Change the order that Unity renders GameObjects in. Lets Unity read camera buffers and use them in shaders. For example, you can use a Scriptable Render Pass to blur a camera’s view when showing the in-game menu. Unity injects Scriptable Render Passes at certain points during the URP render loop. These points are called injection points. You can change the injection point Unity inserts your pass at to control how the Scriptable Render Pass affects the appearance of your scene. For more information on injection points, refer to Injection Points. Scriptable Render Passes in Scenes You can inject a Scriptable Render Pass into a scene via any GameObject present in the scene. This gives you more precise control over when the render pass is active. But this means you must have a GameObject inject the render pass at every point you want to use it. As a result, it's better to inject any common effects in your project via a Scriptable Renderer Feature instead. When you inject a Scriptable Render Pass into a scene via any GameObject, it's important to consider how URP uses this script. The first Camera to render the Scriptable Render Pass uses up the render pass, and is the only Camera the render pass applies to. Any Cameras that the Scriptable Render Pass would apply that render after the first Camera don't render the effect. For example, if you have two Cameras and you add the Scriptable Render Pass in the Update method, only the first Camera to render uses the Scriptable Render Pass effect. This is because the first camera uses up the instance of the effect. As the second Camera renders before the next call of the Update method, a second instance of the Scriptable Render Pass isn't available to use. As a result, the second Camera doesn't apply the effect from the Scriptable Render Pass to its output. Additional resources How to create a Custom Renderer Feature Scriptable Renderer Feature Reference How to inject a Custom Render Pass via scripting"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/renderer-feature-full-screen-pass-landing.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/renderer-feature-full-screen-pass-landing.html",
    "title": "Full Screen Pass Renderer Feature | mmo-rpg-unity",
    "keywords": "Full Screen Pass Renderer Feature A Full Screen Pass Renderer Feature lets you render a full screen effect, such as a vignette or a blur, using a Material. Page Description How to create a custom post-processing effect An example of using the Full Screen Pass Renderer Feature to create a grayscale custom post-processing effect.. Full Screen Pass Renderer Feature reference Reference for the Full Screen Pass Renderer Feature."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/renderer-feature-full-screen-pass.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/renderer-feature-full-screen-pass.html",
    "title": "Full Screen Pass Renderer Feature reference | mmo-rpg-unity",
    "keywords": "Full Screen Pass Renderer Feature reference Refer to How to create a custom post-processing effect for information on how to create a full screen effect using the Full Screen Pass Renderer Feature. Properties The Full Screen Pass Renderer Feature contains the following properties. Property Description Name Name of the Full Screen Pass Renderer Feature. Pass Material The Material the Renderer Feature uses to render the effect. Injection Point Select when the effect is rendered: Before Rendering Transparents: Add the effect after the skybox pass and before the transparents pass. Before Rendering Post Processing: Add the effect after the transparents pass and before the post-processing pass. After Rendering Post Processing: Add the effect after the post-processing pass and before AfterRendering pass. After Rendering Post Processing is the default setting. Requirements Select one or more of the following passes for the Renderer Feature to use: None: Add no additional passes. Everything: Adds all additional passes available (Depth, Normal, Color, and Motion). Depth: Adds a depth prepass to enable the use of depth values. Normal: Enables the use of normal vector data. Color: Copies color data of a screen to the _BlitTexture texture inside the shader. Motion: Enables the use of motion vectors. Color is the default setting. Pass Index Select a specific pass inside the Pass Material's shader for the Pass Material to use. This option is hidden by default. To access this option, click ⋮ in the Renderer Feature section of the Inspector and select Show Additional Properties."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/renderer-feature-render-objects-landing.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/renderer-feature-render-objects-landing.html",
    "title": "Render Objects Renderer Feature | mmo-rpg-unity",
    "keywords": "Render Objects Renderer Feature Use a Render Objects Renderer Feature to draw objects on a certain layer, at a certain time, with specific overrides. Page Description Example: How to create a custom rendering effect using the Render Objects Renderer Feature An example that draws a silhouette when a character goes behind other objects. Render Objects Renderer Feature reference Properties that configure the behaviour of a Render Objects Renderer Feature."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/renderer-feature-render-objects.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/renderer-feature-render-objects.html",
    "title": "Render Objects Renderer Feature reference | mmo-rpg-unity",
    "keywords": "Render Objects Renderer Feature reference URP draws objects in the DrawOpaqueObjects and DrawTransparentObjects passes. You might need to draw objects at a different point in the frame rendering, or interpret and write rendering data (like depth and stencil) in alternate ways. The Render Objects Renderer Feature lets you do such customizations by letting you draw objects on a certain layer, at a certain time, with specific overrides. How to use the Render Objects Renderer Feature For more information, refer to: How to use the Render Objects Renderer Feature. Properties The Render Objects Renderer Feature contains the following properties. Property Description Name Use this field to edit the name of the feature. Event The event in the URP queue when Unity executes this Renderer Feature. Filters Settings that let you configure which objects this Renderer Feature renders. Queue Select whether the feature renders opaque or transparent objects. Layer Mask The Renderer Feature renders objects from layers you select in this property. Pass Names If a Pass in a shader has the LightMode Pass Tag, this Renderer Feature processes only the shaders where the value of the LightMode Pass Tag equals one of the values in the Pass Names property. Overrides Settings in this section let you configure overrides for certain properties when rendering with this Renderer Feature. Override Mode Specify the material override mode. Material (Override Mode is set to Material) When rendering an object, Unity replaces the Material assigned to it with this Material. This will override all material properties with this material Shader (Override Mode is set to Shader) When rendering an object, Unity replaces the material assigned to it with this shader. This maintains all material properties and allows the override shader to access these properties. This is currently not SRPBatcher compatible and less performant. Depth Selecting this option lets you specify how this Renderer Feature affects or uses the Depth buffer. This option contains the following items: Write Depth: this option defines whether the Renderer Feature updates the Depth buffer when rendering objects. Depth Test: the condition which determines when this Renderer Feature renders pixels of a given object. Stencil With this check box selected, the Renderer processes the Stencil buffer values. For more information on how Unity works with the Stencil buffer, refer to ShaderLab: Stencil. Camera Selecting this option lets you override the following Camera properties: Field of View: when rendering objects, the Renderer Feature uses this Field of View instead of the value specified on the Camera. Position Offset: when rendering objects, the Renderer Feature moves them by this offset. Restore: with this option selected, the Renderer Feature restores the original Camera matrices after executing the render passes in this Renderer Feature."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-render-passes.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-render-passes.html",
    "title": "Scriptable Render Passes | mmo-rpg-unity",
    "keywords": "Scriptable Render Passes Use the ScriptableRenderPass API to write a custom render pass. You can then inject the pass into the Universal Render Pipeline (URP) frame rendering loop using the RenderPipelineManager API or a Scriptable Renderer Feature. Page Description Introduction to Scriptable Render Passes What a Scriptable Render Pass is, and how you can inject it into a scene. Write a Scriptable Render Pass An example of a ScriptableRenderPass instance that uses Blit to create a red tint effect. Inject a pass via scripting Use the RenderPipelineManager API to inject a render pass, without using a Scriptable Renderer Feature. Additional resources Inject a pass using a Scriptable Renderer Feature"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/apply-scriptable-feature-to-specific-camera.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/apply-scriptable-feature-to-specific-camera.html",
    "title": "Apply a Scriptable Renderer Feature to a specific camera type | mmo-rpg-unity",
    "keywords": "Apply a Scriptable Renderer Feature to a specific camera type This guide covers how to apply a Scriptable Renderer Feature to a specific camera type. This method allows you to control which cameras the effect of a Scriptable Renderer Feature applies to. This is particularly relevant when a project uses additional cameras to render elements such as reflections where the use of the Scriptable Renderer Feature could lead to unexpected results. You can add logic to the Scriptable Renderer Feature script to check for a specific camera type, before the Scriptable Renderer Feature applies the effect. This guide is split into the following sections: Prerequisites Apply Scriptable Renderer Feature to a specific Camera Prerequisites This guide assumes that you already have a complete Scriptable Renderer Feature to work with. If you do not, refer to How to Create a Custom Renderer Feature. Apply Scriptable Renderer Feature to Game Cameras This script applies the Scriptable Renderer Feature to a specific camera type. In this example, it applies the feature only to Game cameras. Open the C# script of the Scriptable Renderer Feature you want to apply to the cameras. In the AddRenderPasses method, add the following if statement: if (renderingData.cameraData.cameraType == CameraType.Game) Add the necessary render passes from the Scriptable Renderer Feature to the renderer with the EnqueuePass method as shown below. if (renderingData.cameraData.cameraType == CameraType.Game) { renderer.EnqueuePass(yourRenderPass); } This Scriptable Renderer Feature now only applies to Cameras with the Game camera type. Note: Be aware that URP calls the AddRenderPasses method at least once per camera per frame so it is best to minimise complexity here to avoid performance issues. Additional resources Introduction to Scriptable Renderer Features Introduction to Scriptable Render Passes How to create a Custom Renderer Feature"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/inject-a-pass-using-a-scriptable-renderer-feature.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/inject-a-pass-using-a-scriptable-renderer-feature.html",
    "title": "Inject a pass using a Scriptable Renderer Feature | mmo-rpg-unity",
    "keywords": "Inject a pass using a Scriptable Renderer Feature This section describes how to create a Scriptable Renderer Feature for a URP Renderer. A Scriptable Renderer Feature enqueues a ScriptableRenderPass instance every frame. You need to write a Scriptable Render Pass first. This walkthrough contains the following sections: Create a scriptable Renderer Feature Add the Renderer Feature to the the Universal Renderer asset Enqueue the render pass in the custom renderer feature Complete code for the scripts in this example Create a scriptable Renderer Feature Create a new C# script and name it MyRendererFeature.cs. In the script, remove the code that Unity inserted in the MyRendererFeature class. Add the following using directive: using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; Create the MyRendererFeature class that inherits from the ScriptableRendererFeature class. public class MyRendererFeature : ScriptableRendererFeature In the MyRendererFeature class, implement the following methods: Create: Unity calls this method on the following events: When the Renderer Feature loads the first time. When you enable or disable the Renderer Feature. When you change a property in the inspector of the Renderer Feature. AddRenderPasses: Unity calls this method every frame, once for each camera. This method lets you inject ScriptableRenderPass instances into the scriptable Renderer. Now you have the custom MyRendererFeature Renderer Feature with its main methods. Below is the complete code for this step. using System.Collections; using System.Collections.Generic; using UnityEngine; using UnityEngine.Rendering.Universal; public class MyRendererFeature : ScriptableRendererFeature { public override void Create() { } public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { } } Add the Renderer Feature to the Universal Renderer asset Add the Renderer Feature you created to the the Universal Renderer asset. For information on how to do this, refer to the page How to add a Renderer Feature to a Renderer. Enqueue a render pass in the custom renderer feature In this section, you instantiate a render pass in the Create method of the MyRendererFeature class, and enqueue it in the AddRenderPasses method. This section uses the example RedTintRenderPass Scriptable Render Pass from the Write a Scriptable Render Pass page. Declare the following fields: [SerializeField] private Shader shader; private Material material; private RedTintRenderPass redTintRenderPass; In the Create method, instantiate the RedTintRenderPass class. In the method, use the renderPassEvent field to specify when to execute the render pass. public override void Create() { if (shader == null) { return; } material = CoreUtils.CreateEngineMaterial(shader); redTintRenderPass = new RedTintRenderPass(material); renderPassEvent = RenderPassEvent.AfterRenderingSkybox; } In the AddRenderPasses method, enqueue the render pass with the EnqueuePass method. public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { if (renderingData.cameraData.cameraType == CameraType.Game) { renderer.EnqueuePass(redTintRenderPass); } } Custom Renderer Feature code Below is the complete code for the custom Renderer Feature script. using System; using UnityEditor; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class MyRendererFeature : ScriptableRendererFeature { [SerializeField] private Shader shader; private Material material; private RedTintRenderPass redTintRenderPass; public override void Create() { if (shader == null) { return; } material = CoreUtils.CreateEngineMaterial(shader); redTintRenderPass = new RedTintRenderPass(material); redTintRenderPass.renderPassEvent = RenderPassEvent.AfterRenderingSkybox; } public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { if (renderingData.cameraData.cameraType == CameraType.Game) { renderer.EnqueuePass(redTintRenderPass); } } public override void Dispose(bool disposing) { CoreUtils.Destroy(material); } }"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/intro-to-scriptable-renderer-features.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/intro-to-scriptable-renderer-features.html",
    "title": "Introduction to Scriptable Renderer Features | mmo-rpg-unity",
    "keywords": "Introduction to Scriptable Renderer Features Scriptable Renderer Features are components you can add to a renderer to alter how URP renders a project. The following sections explain the fundamentals of Scriptable Renderer Features: What is a Scriptable Renderer Feature? Scriptable Renderer Feature or Scriptable Render Pass? Scriptable Render Passes are a fundamental part of Scriptable Renderer Features. For more information, refer to Scriptable Render Pass Fundamentals. What is a Scriptable Renderer Feature A Scriptable Renderer Feature is a customizable type of Renderer Feature, which is a scriptable component you can add to a renderer to alter how Unity renders a scene or the objects within a scene. The Scriptable Renderer Feature manages and applies Scriptable Render Passes to create custom effects. Scriptable Renderer Features control when and how the Scriptable Render Passes apply to a particular renderer or camera, and can also manage multiple Scriptable Render Passes at once. This makes it easier to create complex effects which require multiple render passes with a Scriptable Renderer Feature than by injecting individual Scriptable Render Passes. Scriptable Renderer Feature or Scriptable Render Pass? Scriptable Renderer Features and Scriptable Render Passes can both achieve similar outcomes but some scenarios suit the use of one over the other. The key difference is in the workflow for the two methods, a Scriptable Renderer Feature must be added to a renderer in order to run, while Scriptable Render Passes offer more flexibility but require additional work to apply across multiple scenes. Scriptable Renderer Features are useful for effects you want to apply to multiple cameras, scenes, or across your entire project. When you add the Scriptable Renderer Feature to a renderer, everything that uses that renderer uses the Scriptable Renderer Feature. This means you can make a change to the Scriptable Renderer Feature once and apply it everywhere that effect is in use. Alternately, the injection of individual Scriptable Render Passes offers the ability to add an effect at a single point within a scene or project. This avoids the need for complex scripts such as a renderer feature that works with volumes, and also helps to minimize the possible performance impact of adding such effects. For more information on this, refer to Scriptable Render Passes in Scenes. Additional resources Introduction to Scriptable Render Passes How to create a Custom Renderer Feature"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/scriptable-renderer-feature-reference.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/scriptable-renderer-feature-reference.html",
    "title": "Scriptable Renderer Feature Reference | mmo-rpg-unity",
    "keywords": "Scriptable Renderer Feature Reference When working with Scriptable Renderer Features and Scriptable Render Passes there are predefined methods that you need to implement for URP to call at specific points in the pipeline. The following sections summarize the common methods used to write Scriptable Renderer Features and Scriptable Render Passes: Scriptable Renderer Feature Methods Scriptable Render Pass Methods Scriptable Renderer Feature Methods You can use the following methods within a Scriptable Renderer Feature to handle its core functions. For more information on Scriptable Renderer Feature scripting and further details on the methods listed below, refer to ScriptableRendererFeature. Method Description AddRenderPasses Use this method to add one or more Render Passes into the rendering sequence of the renderer with the EnqueuePass method. By default this method applies the render passes to all cameras. To change this, add logic to return early in the method when a specific camera or camera type is detected. Note: URP calls this method once per camera when the renderer is set up, for this reason you should not create or instantiate any resources within this function. Create Use this method to initialize any resources the Scriptable Renderer Feature needs such as Materials and Render Pass instances. Dispose Use this method to clean up the resources allocated to the Scriptable Renderer Feature such as Materials. SetupRenderPasses Use this method to run any setup the Scriptable Render Passes require. For example, you can set the initial values of properties, or run custom setup methods from your Scriptable Render Passes. If your Scriptable Renderer Feature accesses camera targets to set up its Scriptable Render Passes, do it in this method instead of in the AddRenderPasses method. Scriptable Render Pass Methods You can use the following methods within a Scriptable Renderer Pass to handle its core functions. For further information on Scriptable Render Pass scripting and further details on the methods listed below, refer to ScriptableRenderPass. Method Description Execute Use this method to implement the rendering logic for the Scriptable Renderer Feature. Note: You must not call ScriptableRenderContext.Submit on a command buffer provided by URP. The render pipeline handles this at specific points in the pipeline. OnCameraCleanup Use this method to clean up any resources that were allocated during the render pass. OnCameraSetup Use this method to configure render targets and their clear state. You can also use it to create temporary render target textures. Note: When this method is empty, the render pass will render to the active camera render target. Additional resources Introduction to Scriptable Renderer Features Introduction to Scriptable Render Passes How to create a Custom Renderer Feature"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/scriptable-renderer-features-landing.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/scriptable-renderer-features/scriptable-renderer-features-landing.html",
    "title": "Scriptable Renderer Features | mmo-rpg-unity",
    "keywords": "Scriptable Renderer Features Scriptable Renderer Features are components you can add to a renderer to alter how URP renders a project. Page Description Introduction to Scriptable Renderer Features What a Scriptable Renderer Feature is, and how a Scriptable Renderer Feature relates to a Scriptable Render Pass. Inject a custom pass using a Scriptable Renderer Feature Create a Scriptable Renderer Feature, add it to the Universal Renderer, and enqueue a render pass. Apply a Scriptable Renderer Feature to a specific camera type Control which cameras the effect of a Scriptable Renderer Feature applies to. Example of a complete Scriptable Renderer Feature An example of a complete Scriptable Renderer Feature with a Scriptable Render Pass that creates a blur effect."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/write-a-scriptable-render-pass.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/renderer-features/write-a-scriptable-render-pass.html",
    "title": "Write a Scriptable Render Pass | mmo-rpg-unity",
    "keywords": "Write a Scriptable Render Pass The following example is a ScriptableRenderPass instance that performs the following steps: Creates a temporary render texture using the RenderTextureDescriptor API. Applies two passes of the custom shader to the camera output using the RTHandle and the Blit API. After you write a Scriptable Render Pass, you can inject the pass using one of the following methods: Use the RenderPipelineManager API Use a Scriptable Renderer Feature Create the scriptable Render Pass This section demonstrates how to create a scriptable Render Pass. Create a new C# script and name it RedTintRenderPass.cs. In the script, remove the code that Unity inserted in the RedTintRenderPass class. Add the following using directive: using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; Create the RedTintRenderPass class that inherits from the ScriptableRenderPass class. public class RedTintRenderPass : ScriptableRenderPass Add the Execute method to the class. Unity calls this method every frame, once for each camera. This method lets you implement the rendering logic of the scriptable Render Pass. public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { } Below is the complete code for the RedTintRenderPass.cs file from this section. using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class RedTintRenderPass : ScriptableRenderPass { public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { } } Implement the settings for the custom render pass Add a field for the Material, and the constructor that uses the field. private Material material; public RedTintRenderPass(Material material) { this.material = material; } Add the RenderTextureDescriptor field and initialize it in the constructor: using UnityEngine; private RenderTextureDescriptor textureDescriptor; public RedTintRenderPass(Material material) { this.material = material; textureDescriptor = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0); } Declare the RTHandle field to store the reference to the temporary red tint texture. private RTHandle textureHandle; Implement the Configure method. Unity calls this method before executing the render pass. public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) { //Set the red tint texture size to be the same as the camera target size. textureDescriptor.width = cameraTextureDescriptor.width; textureDescriptor.height = cameraTextureDescriptor.height; //Check if the descriptor has changed, and reallocate the RTHandle if necessary. RenderingUtils.ReAllocateIfNeeded(ref textureHandle, textureDescriptor); } Use the Blit method to apply the two passes from the custom shader to the camera output. public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { //Get a CommandBuffer from pool. CommandBuffer cmd = CommandBufferPool.Get(); RTHandle cameraTargetHandle = renderingData.cameraData.renderer.cameraColorTargetHandle; // Blit from the camera target to the temporary render texture, // using the first shader pass. Blit(cmd, cameraTargetHandle, textureHandle, material, 0); // Blit from the temporary render texture to the camera target, // using the second shader pass. Blit(cmd, textureHandle, cameraTargetHandle, material, 1); //Execute the command buffer and release it back to the pool. context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } Implement the Dispose method that destroys the Material and the temporary render texture after the render pass execution. public void Dispose() { #if UNITY_EDITOR if (EditorApplication.isPlaying) { Object.Destroy(material); } else { Object.DestroyImmediate(material); } #else Object.Destroy(material); #endif if (textureHandle != null) textureHandle.Release(); } Custom render pass code Below is the complete code for the custom Render Pass script. using UnityEditor; using UnityEngine; using UnityEngine.Rendering; using UnityEngine.Rendering.Universal; public class RedTintRenderPass : ScriptableRenderPass { private Material material; private RenderTextureDescriptor textureDescriptor; private RTHandle textureHandle; public RedTintRenderPass(Material material) { this.material = material; textureDescriptor = new RenderTextureDescriptor(Screen.width, Screen.height, RenderTextureFormat.Default, 0); } public override void Configure(CommandBuffer cmd, RenderTextureDescriptor cameraTextureDescriptor) { // Set the texture size to be the same as the camera target size. textureDescriptor.width = cameraTextureDescriptor.width; textureDescriptor.height = cameraTextureDescriptor.height; // Check if the descriptor has changed, and reallocate the RTHandle if necessary RenderingUtils.ReAllocateIfNeeded(ref textureHandle, textureDescriptor); } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { //Get a CommandBuffer from pool. CommandBuffer cmd = CommandBufferPool.Get(); RTHandle cameraTargetHandle = renderingData.cameraData.renderer.cameraColorTargetHandle; // Blit from the camera target to the temporary render texture, // using the first shader pass. Blit(cmd, cameraTargetHandle, textureHandle, material, 0); // Blit from the temporary render texture to the camera target, // using the second shader pass. Blit(cmd, textureHandle, cameraTargetHandle, material, 1); //Execute the command buffer and release it back to the pool. context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } public void Dispose() { #if UNITY_EDITOR if (EditorApplication.isPlaying) { Object.Destroy(material); } else { Object.DestroyImmediate(material); } #else Object.Destroy(material); #endif if (textureHandle != null) textureHandle.Release(); } } The custom shader for the red tint effect This section contains the code for the custom shader that implements the red tint effect. Shader \"CustomEffects/RedTint\" { HLSLINCLUDE #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" // The Blit.hlsl file provides the vertex shader (Vert), // the input structure (Attributes), and the output structure (Varyings) #include \"Packages/com.unity.render-pipelines.core/Runtime/Utilities/Blit.hlsl\" float4 RedTint (Varyings input) : SV_Target { float3 color = SAMPLE_TEXTURE2D(_BlitTexture, sampler_LinearClamp, input.texcoord).rgb; return float4(1, color.gb, 1); } float4 SimpleBlit (Varyings input) : SV_Target { float3 color = SAMPLE_TEXTURE2D(_BlitTexture, sampler_LinearClamp, input.texcoord).rgb; return float4(color.rgb, 1); } ENDHLSL SubShader { Tags { \"RenderType\"=\"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\"} LOD 100 ZTest Always ZWrite Off Cull Off Pass { Name \"RedTint\" HLSLPROGRAM #pragma vertex Vert #pragma fragment RedTint ENDHLSL } Pass { Name \"SimpleBlit\" HLSLPROGRAM #pragma vertex Vert #pragma fragment SimpleBlit ENDHLSL } } }"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering-in-universalrp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering-in-universalrp.html",
    "title": "Rendering in the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Rendering in the Universal Render Pipeline The Universal Render Pipeline (URP) renders Scenes using the following components: URP Renderer. URP contains the following Renderers: Universal Renderer. 2D Renderer. Shading models for shaders shipped with URP Camera URP Asset The following illustration shows the frame rendering loop of the URP Universal Renderer. When the render pipeline is active in Graphics Settings, Unity uses URP to render all Cameras in your Project, including game and Scene view cameras, Reflection Probes, and the preview windows in your Inspectors. The URP renderer executes a Camera loop for each Camera, which performs the following steps: Culls rendered objects in your Scene Builds data for the renderer Executes a renderer that outputs an image to the framebuffer. For more information about each step, refer to Camera loop. In the RenderPipelineManager class, URP provides events that you can use to execute code before and after rendering a frame, and before and after rendering each Camera loop. The events are: beginCameraRendering beginFrameRendering endCameraRendering endFrameRendering For the example of how to use the beginCameraRendering event, refer to Inject a render pass via scripting. Camera loop The Camera loop performs the following steps: Step Description Setup Culling Parameters Configures parameters that determine how the culling system culls Lights and shadows. You can override this part of the render pipeline with a custom renderer. Culling Uses the culling parameters from the previous step to compute a list of visible renderers, shadow casters, and Lights that are visible to the Camera. Culling parameters and Camera layer distances affect culling and rendering performance. Build Rendering Data Catches information based on the culling output, quality settings from the URP Asset, Camera, and the current running platform to build the RenderingData. The rendering data tells the renderer the amount of rendering work and quality required for the Camera and the currently chosen platform. Setup Renderer Builds a list of render passes, and queues them for execution according to the rendering data. You can override this part of the render pipeline with a custom renderer. Execute Renderer Executes each render pass in the queue. The renderer outputs the Camera image to the framebuffer."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering-to-a-render-texture.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering-to-a-render-texture.html",
    "title": "Render a camera's output to a Render Texture | mmo-rpg-unity",
    "keywords": "Render a camera's output to a Render Texture In the Universal Render Pipeline (URP), a Camera can render to the screen or to a Render Texture. Rendering to a screen is the default and is the most common use case, but rendering to a Render Texture allows you to create effects such as CCTV camera monitors. If you have a Camera that is rendering to a Render Texture, you must have a second Camera that then renders that Render Texture to the screen. In URP, all Cameras that render to Render Textures perform their render loops before all Cameras that render to the screen. This ensures that the Render Textures are ready to render to the screen. For more information on Camera rendering order in URP, refer to Rendering order and overdraw. Render to a Render Texture that renders to the screen Create a Render Texture Asset in your project. To do this select Assets > Create > Render Texture. Create a Quad game object in your scene. Create a material in your Project. In the Inspector, drag the Render Texture to the material's Base Map field. In the Scene view, drag the material on to the quad. Create a camera in your scene. Select the Base Camera and in the Inspector, drag the Render Texture on to the Output Texture property. Create another camera in your scene. Place the quad within the view of the new Base Camera. The first Camera now renders its view to the Render Texture. The second Camera renders the scene including the Render Texture to the screen. You can set the output target for a camera in a script by setting the targetTexture property of the camera: myCamera.targetTexture = myRenderTexture;"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering-to-the-same-render-target.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering-to-the-same-render-target.html",
    "title": "Set up split-screen rendering | mmo-rpg-unity",
    "keywords": "Set up split-screen rendering In the Universal Render Pipeline (URP), multiple Base Cameras or Camera Stacks can render to the same render target. This allows you to create effects such as split screen rendering. If more than one Base Camera or Camera Stack renders to the same area of a render target, Unity draws each pixel in the overlapping area multiple times. Unity draws the Base Camera or Camera Stack with the highest priority last, on top of the previously drawn pixels. For more information on the camera render order optimization, refer to Understand camera render order. You use the Base Camera's Viewport Rect property to define the area of the render target to render to. For more information on viewport coordinates, refer to the Unity Manual and API documentation. Setting up split screen rendering Create a Camera in your scene. Its Render Mode defaults to Base, making it a Base Camera. Select the Camera. In the Inspector, scroll to the Output section. Change the values for Viewport rect to the following: X: 0 Y: 0 W: 0.5 H: 1 Create another Camera in your scene. Its Render Mode defaults to Base, making it a Base Camera. Select the Camera. In the Inspector, scroll to the Output section. Change the values for Viewport rect to the following: X: 0.5 Y: 0 W: 0.5 H: 1 Unity renders the first Camera to the left-hand side of the screen, and the second Camera to the right-hand side of the screen. You can change the Viewport rect for a Camera in a script by setting its rect property, like this: myUniversalAdditionalCameraData.rect = new Rect(0.5f, 0f, 0.5f, 0f);"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering/deferred-rendering-path.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering/deferred-rendering-path.html",
    "title": "Deferred Rendering Path in URP | mmo-rpg-unity",
    "keywords": "Deferred Rendering Path in URP URP Universal Renderer supports the following Rendering Paths: Forward Forward+ Deferred For information on differences between the rendering paths, refer to Rendering Path comparison. This section describes the Deferred Rendering Path. Sample Scene rendered with the Deferred Rendering Path. This section contains the following topics: How to select the Deferred Rendering Path Unity Player system requirements Implementation details Relevant code files ShaderLab Pass tags Limitations and performance How to select the Deferred Rendering Path To select the Rendering Path, use the property Lighting > Rendering Path in the URP Universal Renderer asset. When you select the Deferred Rendering Path, Unity shows the Accurate G-buffer normals property. The Accurate G-buffer normals property lets you configure how Unity encodes the normals when storing them in the geometry buffer (G-buffer). Accurate G-buffer normals off: This option increases performance, especially on mobile GPUs, but might lead to color banding artifacts on smooth surfaces. Accurate G-buffer normals on: Unity uses the octahedron encoding to store values of normal vectors in the RGB channel of a normal texture. With this encoding, values of normal vectors are more accurate, but the encoding and decoding operations put extra load on the GPU. This option does not support decal normal blending when used with the Screen Space decal technique. For more information about this setting, refer to the section Encoding of normals in G-buffer. Unity Player system requirements The Deferred Rendering Path has the following requirements and limitations on top of the general system requirements for the Unity Player. Minimum Shader Model: Shader Model 4.5. Deferred Rendering Path does not support the OpenGL and OpenGL ES API. If a project with the Deferred Rendering Path is built for platforms using those API, the application falls back to the Forward Rendering Path. Implementation details This section describes the implementation details of this feature, and technical details about how this feature functions. G-buffer layout This section describes how Unity stores material attributes in the G-buffer in the Deferred Rendering Path. The following illustration shows the data structure for each pixel of the render targets that Unity uses in the Deferred Rendering Path. The data structure consists of the following components. Albedo (sRGB) This field contains the albedo color in sRGB format, 24 bits. MaterialFlags This field is a bit field that contains Material flags: Bit 0, ReceiveShadowsOff: if set, the pixel does not receive dynamic shadows. Bit 1, SpecularHighlightsOff: if set, the pixel does not receive specular highlights. Bit 2, SubtractiveMixedLighting: if set, the pixel uses subtractive mixed lighting. Bit 3, SpecularSetup: if set, the Material uses the specular workflow. Bits 4-7 are reserved for future use. For more technical details, refer to the file /ShaderLibrary/UnityGBuffer.hlsl. Specular This field contains the following values: SimpleLit Material: RGB specular color stored in 24 bits. Lit Material with metallic workflow: reflectivity stored in 8 bits, 16 bits are not used. Lit Material with specular workflow: RGB specular color stored in 24 bits. Occlusion This field contains the baked occlusion value from the baked lighting. For real-time lighting, Unity calculates the ambient occlusion value by combining the baked occlusion value with the SSAO value. Normal This field contains the world space normals encoded in 24 bits. For information on the encoding of normals, refer to Encoding of normals in G-buffer. Smoothness This field stores the smoothness value for the SimpleLit and Lit materials. Emissive/GI/Lighting This render target contains the Material emissive output and baked lighting. Unity fills this field during the G-buffer Pass. During the deferred shading pass, Unity stores lighting results in this render target. Render target format: B10G11R11_UFloatPack32, unless one of the following conditions is true: In URP Asset, the setting Quality > HDR is turned on, and the target Player platform does not support HDR. In Player Settings, the setting PreserveFramebufferAlpha is true. R16G6B16A16_SFloat, if Unity cannot use B10G11R11_UFloatPack32 because of the project settings. If Unity cannot use one of the other formats in the list, it uses what the following method returns: SystemInfo.GetGraphicsFormat(DefaultFormat.HDR). ShadowMask Unity adds this render target to the G-buffer layout when Lighting Mode is set to Subtractive or Shadow mask. The Subtractive and the Shadow mask modes are optimized for the Forward Rendering Path, and are less efficient in the Deferred Rendering Path. In the Deferred Rendering Path, avoid using these modes and use the Baked Indirect mode instead to improve GPU performance. Rendering Layer Mask Unity adds this render target to the G-buffer layout when the Use Rendering Layers option is enabled (URP Asset, Lighting > Use Rendering Layers). Using Rendering Layers might have an impact on the GPU performance. For more information, refer to the page Rendering Layers. Depth as Color Unity adds this render target to the G-buffer layout when Native Render Pass is enabled on platforms that support it. Unity renders depth as a color into this render target. This render target has the following purpose: Improves performance on Vulkan devices. Lets Unity get the depth buffer on Metal API, which does not allow fetching the depth from the DepthStencil buffer within the same render pass. The format of the Depth as Color render target is GraphicsFormat.R32_SFloat. DepthStencil Unity reserves the four highest bits of this render target to mark the Material type. For more information, refer to URP Pass tags: UniversalMaterialType. For this render target, Unity selects either the D32F_S8 format, or the D24S8 format depending on the platform. Encoding of normals in G-buffer In the Deferred Rendering Path, Unity stores normals in the G-buffer. Unity encodes each normal as a 24 bit value. When you select the Deferred option in the Rendering Path property in the URP Universal Renderer asset, Unity shows the Accurate G-buffer normals property. The Accurate G-buffer normals property lets you configure how Unity encodes the normals. Accurate G-buffer normals off: Unity stores values of normal vectors in the G-buffer in the RGB channel of a normal texture, 8 bit per value (x, y, z). The values are quantized with the loss of accuracy. This option increases performance, especially on mobile GPUs, but might lead to color banding artifacts on smooth surfaces. Accurate G-buffer normals on: Unity uses the octahedron encoding to store values of normal vectors in the RGB channel of a normal texture. With this encoding, values of normal vectors are more accurate, but the encoding and decoding operations put extra load on the GPU. This option does not support decal normal blending when used with the Screen Space decal technique. The precision of the encoded normal vectors is similar to the precision of the sampled values in the Forward Rendering Path. The following illustration shows the visual difference between the two options when the Camera is very close to the GameObject: Performance considerations With Accurate G-buffer normals option turned on, there is extra load on the GPU because of the encoding and decoding operations. This load is insignificant for desktop platforms and consoles, but might be considerable for mobile GPUs. Turning the option on does not increase the memory footprint. To store the normals, Unity uses the same RGB channel in the normal texture regardless of the encoding. Deferred Rendering Path render Passes The following table shows the sequence of Render Pass events in the Deferred Rendering Path. Render Pass events Deferred Rendering Path Passes SSAO Renderer Feature Passes BeforeRendering BeforeRenderingShadows AfterRenderingShadows BeforeRenderingPrePasses Depth, or depth and normal prepass (Forward only materials) AfterRenderingPrePasses BeforeRenderingGbuffer G-buffer Pass (GBufferPass) Copy G-buffer depth texture AfterRenderingGbuffer SSAO (optional) BeforeRenderingDeferredLights Deferred rendering (stencil) AfterRenderingDeferredLights BeforeRenderingOpaques Opaque Forward-only Materials AfterRenderingOpaques SSAO and blending (optional) BeforeRenderingSkybox AfterRenderingSkybox BeforeRenderingTransparents AfterRenderingTransparents BeforeRenderingPostProcessing AfterRenderingPostProcessing AfterRendering The following sections describe the Deferred Rendering Path render Passes. Depth, or depth and normal prepass In the Deferred Rendering Path, in the depth prepass or depth and normal prepass, Unity renders only the Materials that do not support the deferred rendering model. For example, Materials using the Complex Lit shader are such Materials. In the Deferred Rendering Path, Unity does not use the depth prepass to generate a copy of the depth buffer (this behavior is different in the Forward Rendering Path). If the Universal Renderer has the SSAO Renderer Feature, Unity executes the depth and normal prepass. SSAO uses the screen-space depth and normal buffers to calculate ambient occlusion. Optional passes: SSAO, SSAO with blending If the Universal Renderer has the SSAO Renderer Feature, and the After Opaque option is disabled (the option is disabled by default), Unity executes the SSAO Pass at the AfterRenderingGbuffer event. The SSAO Renderer Feature calculates the SSAO texture. Unity samples this texture in the Deferred rendering Pass and in the Pass that renders Forward-only Materials. Using this Pass order, Unity can combine the baked occlusion with the real-time occlusion from the SSAO Renderer Feature, and avoid double-darkening from the baked and the real-time ambient occlusion. When the After Opaque option is enabled, Unity executes the SSAO and blending Pass at the AfterRenderingOpaques event, after rendering the Forward-only Materials. Unity then executes an extra full screen Pass to overlay the SSAO texture onto the Emissive/GI/Lighting buffer. This causes over-darkening of the areas that receive baked occlusion and real-time occlusion. Performance considerations On mobile platforms with TBDR architecture, with the After Opaque option is disabled, Unity requires an extra render target for load and store operations. This has a significant performance impact. Enabling the After Opaque option on mobile platforms improves GPU performance. On mobile platforms with TBDR architecture, enabling this option avoids extra render target load and store operations. Forward-only Pass Certain Unity shaders use lighting models that Unity cannot render in the Deferred Rendering Path. Examples of such shaders: Complex Lit: the Lighting model of this shader (for example, the Clear Coat effect) is too complex and extra Material properties cannot fit into the G-buffer. Baked Lit and Unlit: these shaders do not calculate real-time lighting, that's why Unity renders them into the Emissive/GI/Lighting buffer directly during the Forward-only pass. This is faster than evaluating the shaders in the Deferred rendering (stencil) pass. Custom shaders: Unity renders the shaders that do not declare the Pass tags required by the Deferred Rendering Path as Forward-only. The required Pass tags are: LightMode, and UniversalMaterialType. For more information, refer to URP Pass tags. Unity renders Materials with such shaders in the Forward Rendering Path. For the SSAO Renderer Feature to be able to calculate ambient occlusion for the Materials using the Complex Lit shader, Unity must render such Materials in the depth and normal prepass first. This is because Unity does not render those Materials in the G-buffer pass (GBufferPass). For more information, refer to URP Pass tags. General implementation notes For maximum platform compatibility, the URP Deferred Rendering Path uses the light stencil volume technique to render light volumes and apply deferred shading. Relevant code files This section contains the list of files that contain the code related to the Deferred Rendering Path. The main class that handles the Deferred Rendering Path: com.unity.render-pipelines.universal\\Runtime\\DeferredLights.cs ScriptableRenderPass for the G-Buffer pass: com.unity.render-pipelines.universal\\Runtime\\Passes\\GBufferPass.cs ScriptableRenderPass for the deferred shading pass: com.unity.render-pipelines.universal\\Runtime\\Passes\\DeferredPass.cs Shader asset for the deferred shading: com.unity.render-pipelines.universal\\Shaders\\Utils\\StencilDeferred.shader Utility functions for the deferred shading: com.unity.render-pipelines.universal\\Shaders\\Utils\\Deferred.hlsl Utility functions for storing and loading the Material properties from the G-buffer: com.unity.render-pipelines.universal\\Shaders\\Utils\\UnityGBuffer.hlsl ShaderLab Pass tags To enable Unity to render a shader in the Deferred Rendering Path, the shader must have a Pass with the following tag definition: \"LightMode\" = \"UniversalGBuffer\" Unity executes the shader with such LightMode tag during the G-buffer Pass. To indicate that Unity must render a certain Material in the Forward-only Pass in the Deferred Rendering Path, add the following tags to a shader Pass: \"LightMode\" = \"UniversalForwardOnly\" \"LightMode\" = \"DepthNormalsOnly\" To specify the shader lighting model (Lit, SimpleLit), use the UniversalMaterialType tag. For more information, refer to the section URP Pass tags: LightMode. Limitations and performance This section describes the limitations of the Deferred Rendering Path. Terrain blending When blending more than four Terrain layers, the Deferred Rendering Path generates slightly different results from the Forward Rendering Path. This happens because in the Forward Rendering Path, Unity processes the first four layers separately from the next four layers using multi-pass rendering. In the Forward Rendering Path, Unity merges Material properties and calculates lighting for the combined properties of four layers at once. Unity then processes the next four layers in the same way and alpha-blends the lighting results. In the Deferred Rendering Path, Unity combines Terrain layers in the G-buffer pass, four layers at a time, and then calculates lighting only once during the deferred rendering pass. This difference with the Forward Rendering Path leads to visually different outcomes. Unity combines the Material properties in the G-buffer using hardware blending (four layers at a time), which limits how correct the combination of property values is. For example, pixel normals cannot be correctly combined using the alpha blend equation alone, because one Terrain layer might contain coarse Terrain detail while another layer might contain fine detail. Averaging or summing normals results in loss of accuracy. NOTE: Turning the setting Accurate G-buffer normals on breaks Terrain blending. With this setting turned on, Unity encodes normals using octahedron encoding. Normals in different layers encoded this way cannot be blended together because of the bitwise nature of the encoding (2 x 12 bits). If your application requires more than four Terrain layers, turn the Accurate G-buffer normals setting off. The following illustration shows the visual difference when rendering Terrain layers with different Rendering Paths. Terrain layers rendered with the Forward Rendering Path Terrain layers rendered with the Deferred Rendering Path Baked Global Illumination and Lighting Modes When Baked Global Illumination is enabled, the Subtractive and the Shadowmask Lighting modes put extra load on the GPU in the Deferred Rendering Path. The Deferred Rendering Path supports the Subtractive and the Shadowmask Lighting modes for compatibility reasons, but, unlike the case with the Forward Rendering Path, these modes do not provide any improvements in performance. In the Deferred Rendering Path, Unity processes all meshes using the same Lighting algorithm and stores the extra Lighting properties required by Subtractive and the Shadowmask modes in the ShadowMask render target. In the Deferred Rendering Path, the Baked Indirect Lighting mode provides better performance, since it does not require the ShadowMask render target. Rendering layers URP implements the Rendering Layers feature that lets you configure which Lights in a Scene affect specific meshes. Lights assigned to a specific Rendering Layer only affect the meshes assigned to the same Rendering Layer. For more information on Rendering Layers, refer to the page Rendering Layers. Performance impact The Rendering Layers feature requires an extra G-buffer render target to store the rendering layer mask (32 bits). The extra render target is likely to have a negative impact on GPU performance. Implementation notes In the Forward Rendering Path, the Layers feature lets you tell Unity to render specific meshes with a specific set of Lights. The Layers feature uses the culling mask system. The Deferred Rendering Path cannot use the layer system with light culling masks, because the shading is deferred to a later stage in the rendering loop (refer to the Deferred rendering (stencil) step in the Deferred Rendering Path render Passes table.)"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering/forward-plus-rendering-path.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/rendering/forward-plus-rendering-path.html",
    "title": "Forward+ Rendering Path | mmo-rpg-unity",
    "keywords": "Forward+ Rendering Path The Forward+ Rendering Path lets you avoid the per object limit of the Forward Rendering Path. The Forward+ Rendering Path has the following advantages compared with the Forward Rendering Path: There is no per-object limit for the number of Lights that affect GameObjects, the per-Camera limit still applies. This implementation lets you avoid splitting big meshes when more than 8 lights affect them. Blending of more than 2 reflection probes. Support for multiple Lights when using Unity Entity Component System (ECS). More flexibility with procedural draws. For more information, refer to: Rendering Path comparison. How to select the Forward+ Rendering Path To select the Forward+ Rendering Path, use the property Rendering > Rendering Path in the URP Universal Renderer asset. When you set the Rendering Path to Forward+, Unity ignores the values in the following properties in URP Asset, Lighting section: Main Light. With Forward+ the value of this property is Per Pixel regardless of the value you select. Additional Lights. With Forward+ the value of this property is Per Pixel regardless of the value you select. Additional Lights > Per Object Limit. Unity ignores this property. Reflection Probes > Probe Blending. Reflection probe blending is always on. Limitations The Forward+ Rendering Path has no limitations compared with the Forward Rendering Path. Reduce build time Due to the wide variety of use cases, target platforms, renderers, and features used in projects, certain URP configurations can result in a large number of shader variants. That can lead to long compilation times. Long shader compilation time affects both player build time and the time for a scene to render in the Editor. The per-camera visible light limit value affects the compilation time for each Lit and Complex Lit shader variant. In the Forward+ Rendering Path, on desktop platforms, that limit is 256. This section describes how to reduce the shader compilation time by changing the default maximum per-camera visible light count. Change the maximum number of visible lights Note This instruction describes a workaround for a limitation in the URP design. This limitation will be mitigated in one of the future Unity versions. The Universal Render Pipeline Config package contains the settings that define the number of maximum visible light. The following instructions describe how to change those settings. Note If you upgrade the Unity version of your project, repeat this procedure. In your project folder, copy the URP Config Package folder from /Library/PackageCache/com.unity.render-pipelines.universal-config@[versionnumber] to /Packages/com.unity.render-pipelines.universal-config@[versionnumber]. Open the file /com.unity.render-pipelines.universal-config@[versionnumber]/Runtime/ShaderConfig.cs.hlsl. The file contains multiple definitions that start with MAX_VISIBLE_LIGHT_COUNT and end with the target platform name. Change the value in brackets to a suitable maximum in-frustum per-camera light count for your project, for example, MAX_VISIBLE_LIGHT_COUNT_DESKTOP (32). For the Forward+ Rendering Path, the value includes the Main Light. For the Forward Rendering Path, the value does not include the Main Light. Open the file /com.unity.render-pipelines.universal-config@[versionnumber]/Runtime/ShaderConfig.cs. The file contains multiple definitions that start with k_MaxVisibleLightCount and end with the platform name. Change the value so that it matches the value set in the ShaderConfig.cs.hlsl file, for example k_MaxVisibleLightCountDesktop = 32;. Save the edited files and restart the Unity Editor. Unity automatically configures your project and shaders to use the new configuration. Now the Player build time should be shorter due to the reduced compilation time for each shader variant."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/requirements.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/requirements.html",
    "title": "Requirements and compatibility | mmo-rpg-unity",
    "keywords": "Requirements and compatibility This page contains information on system requirements and compatibility of this package. Unity Editor compatibility The following table shows the compatibility of URP package versions with different Unity Editor versions. Package version Minimum Unity version Maximum Unity version 16.0.x 2023.2 2023.x 15.0.x 2023.1 2023.1 14.0.x 2022.2 2022.x 13.x.x 2022.1 2022.1 12.0.x 2021.2 2021.3 11.0.0 2021.1 2021.1 10.x 2020.2 2020.3 9.x-preview 2020.1 2020.2 8.x 2020.1 2020.1 7.x 2019.3 2019.4 Since the release of Unity 2021.1, graphics packages are core Unity packages. For each release of Unity (alpha, beta, patch release), the main Unity installer contains the up-to-date versions of the following graphics packages: SRP Core, URP, HDRP, Shader Graph, VFX Graph. Since the release of Unity 2021.1, the Package Manager shows only the major revisions of the graphics packages (version 11.0.0 for all Unity 2021.1.x releases, version 12.0.0 for all Unity 2021.2.x releases). You can install a different version of a graphics package from disk using the Package Manager, or by modifying the manifest.json file. Render pipeline compatibility Projects made using URP are not compatible with the High Definition Render Pipeline (HDRP) or the Built-in Render Pipeline. Before you start development, you must decide which render pipeline to use in your Project. For information on choosing a render pipeline, refer to the Render Pipelines section of the Unity Manual. Unity Player system requirements This package does not add any extra platform-specific requirements. General system requirements for the Unity Player apply. For more information on Unity system requirements, refer to System requirements for Unity."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/scene-templates.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/scene-templates.html",
    "title": "Universal Render Pipeline Scene Templates | mmo-rpg-unity",
    "keywords": "Universal Render Pipeline Scene Templates You can use Scene Templates to quickly create scenes that include pre-configured URP-specific settings and post-processing effects. For information on how to create a new scene from a Scene Template, refer to Creating a new scene from the New Scene dialog. The New Scene dialog displaying Scene Templates. The following Scene Templates are available for URP: Basic (URP): A scene that contains a Camera and a Light. This is the URP equivalent of Unity's default scene. Standard (URP): A scene that contains a Camera, a Light, and a global Volume with various post-processing effects. Note: If you create a scene using the Standard (URP) Scene Template, Unity creates a new Volume Profile to store the post-processing effects."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shader-complex-lit.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shader-complex-lit.html",
    "title": "Complex Lit Shader | mmo-rpg-unity",
    "keywords": "Complex Lit Shader The Complex Lit Shader contains all the functionality of the Lit shader and adds advanced material features. Some features in this shader might be considerably more resource-intensive and require Unity Shader Model 4.5 hardware. In the Deferred Rendering Path, URP renders objects that have the Complex Lit shader using the Forward Rendering Path. If the hardware of the target platform does not support features in the Complex Lit shader, URP uses the Lit shader instead. If you need to reduce processing time on the GPU (for example, on lower-end platforms), avoid use of the Complex Lit shader. Instead, use the Baked Lit shader for static objects and the Simple Lit shader for dynamic objects. If you use the Complex Lit shader, disable Clear Coat. Using the Complex Lit Shader in the Editor To select and use this Shader: In your Project, create or find the Material you want to use the Shader on. Select the Material. A Material Inspector window opens. Click Shader, and select Universal Render Pipeline > Complex Lit. UI overview The Inspector window for this Shader contains these elements: Surface Options Surface Inputs Advanced Surface Options The Surface Options control how URP renders the Material on a screen. Property Description Workflow Mode Use this drop-down menu to choose a workflow that fits your Textures, either Metallic and Specular. When you have made your choice, the main Texture options in the rest of the Inspector now follow your chosen workflow. For information on metallic or specular workflows, refer to this Manual page for the Standard built-in Shader in Unity. Surface Type Use this drop-down to apply an Opaque or Transparent surface type to the Material. This determines which render pass URP renders the material in. Opaque surface types are always fully visible, regardless of what’s behind them. URP renders opaque Materials first. Transparent surface types are affected by their background, and they can vary according to which type of transparent surface type you choose. URP renders transparent Materials in a separate pass after opaque objects. If you select Transparent, the Blending Mode drop-down appears. Blending Mode Select how Unity calculates the color of each pixel of a transparent Material when it blends the Material with the background. In the context of Blending Modes, Source refers to the transparent Material where the Blending Mode is set and Destination refers to anything that Material overlaps with. Alpha Alpha blending mode. Alpha uses the Material's alpha value to change how transparent an object is. 0 is fully transparent. 255 is fully opaque, this is translated to a value of 1 when used with the blending equations. The Material is always rendered in the Transparent render pass regardless of it's alpha value. This mode lets you use the Preserve Specular Lighting property. Alpha equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB × (1 − SourceAlpha) Premultiply Premultiply blending mode. Premultiply first multiplies the RGB values of the transparent Material by its alpha value then applies a similar effect to the Material as Alpha. The equation for Premultiply also allows areas of the transparent Material with an alpha value of 0 to have an additive blend effect. This can help reduce artifacts that may appear at the edge of the overlap between opaque and transparent pixels. Premultiply equation: OutputRGBA = SourceRGB + DestinationRGB × (1 − SourceAlpha) Additive Additive blending mode. Additive adds the color values of the Materials together to create the blend effect. The alpha value determines the strength of the source Material's color before the blend is calculated. This mode lets you use the Preserve Specular Lighting property. Additive equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB Multiply Multiply blending mode. Multiply multiplies the color of the Material with the color behind the surface. This creates a darker effect, like when you look through colored glass. This mode uses the Material’s alpha value to adjust how much the colors blend. An alpha value of 1 results in unadjusted multiplication of the colors while lower values blend the colors towards white. Multiply equation: OutputRGBA = SourceRGB × DestinationRGB Preserve Specular Lighting Indicates whether Unity preserves specular highlights on a GameObject or not. This applies even when your surface is transparent which means that only the reflected light is visible. This property only appears when the Surface Type is set to Transparent and Blending Mode is set to either Alpha or Additive. Material with Preserve Specular Lighting disabled. Material with Preserve Specular Lighting enabled. Render Face Use this drop-down to determine which sides of your geometry to render. Front Face renders the front face of your geometry and culls the back face. This is the default setting. Back Face renders the front face of your geometry and culls the front face. Both makes URP render both faces of the geometry. This is good for small, flat objects, like leaves, where you might want both sides visible. Alpha Clipping Makes your Material act like a Cutout Shader. Use this to create a transparent effect with hard edges between the opaque and transparent areas. For example, to create blades of grass. To achieve this effect, URP does not render alpha values below the specified Threshold, which appears when you enable Alpha Clipping. You can set the Threshold by moving the slider, which accepts values from 0 to 1. All values above your threshold are fully opaque, and all values below your threshold are invisible. For example, a threshold of 0.1 means that URP doesn't render alpha values below 0.1. The default value is 0.5. Receive Shadows Tick this box to enable your GameObject to have shadows cast upon it by other objects. If you untick this box, the GameObject will not have shadows on it. Surface Inputs The Surface Inputs describe the surface itself. For example, you can use these properties to make your surface look wet, dry, rough, or smooth. Note: If you are used to the Standard Shader in the built-in Unity render pipeline, these options are similar to the Main Maps settings in the Material Editor. Property Description Base Map Adds color to the surface, also known as the diffuse map. To assign a Texture to the Base Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. The color next to the setting shows the tint on top of your assigned Texture. To assign another tint, you can click this color swatch. If you select Transparent or Alpha Clipping under Surface Options, your Material uses the Texture’s alpha channel or color. Metallic / Specular Map Shows a map input for your chosen Workflow Mode in the Surface Options. For the Metallic Map workflow, the map gets the color from the Base Map assigned above. Use the slider to control how metallic the surface appears. 1 is fully metallic, like silver or copper, and 0 is fully dielectric, like plastic or wood. You can generally use values in between 0 and 1 for dirty or corroded metals. For the Specular Map setting, you can assign a texture to it by clicking the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. For both workflows, you can use the Smoothness slider to control the spread of highlights on the surface. 0 gives a wide, rough highlight. 1 gives a small, sharp highlight like glass. Values in between produce semi-glossy looks. For example, 0.5 produces a plastic-like glossiness. Use the Source drop-down menu to select where the shader samples a smoothness map from. Options are: Metallic Alpha (alpha channel from the metallic map), and Albedo Alpha (alpha channel from the base map). The default value is Metallic Alpha. If the selected source has the alpha channel, the shader samples the channel and multiplies each sample by the Smoothness value. Normal Map Adds a normal map to the surface. With a normal map, you can add surface details like bumps, scratches and grooves. To add the map, click the object picker next to it. The normal map picks up ambient lighting in the environment. The float value next to the setting is a multiplier for the effect of the Normal Map. Low values decrease the effect of the normal map. High values create stronger effects. Height Map URP implements the parallax mapping technique which uses the height map to achieve surface-level occlusion effect by shifting the areas of the visible surface texture. To add the map, click the object picker next to it. The float value next to the setting is a multiplier for the effect of the Height Map. Low values decrease the effect of the height map. High values create stronger effects. Occlusion Map Select an occlusion map. This simulates shadows from ambient light and reflection, which makes lighting look more realistic as less light reaches corners and crevices of objects. To select the occlusion map, click the object picker next to it. Clear Coat Select this check box to enable the Clear Coat feature. The feature adds an extra Material layer which simulates a transparent and thin coating on top of the base Material. The feature affects the color and the Smoothness values of the underlying base material slightly. The index of refraction (IOR) of the Clear Coat is 1.5. Performance impact: Rendering Clear Coat has roughly twice the cost of rendering a base material, because the lighting is evaluated once per layer. Mask: This property defines the intensity of the effect: 0 - no effect, 1 - maximum effect. Setting the Mask value to 0 does not disable the feature. Smoothness: This property defines the spread of highlights on the surface. 0 gives wide, rough highlights. 1 gives sharp, glasslike highlights. There is the Clear Coat map property to the left of the Mask property. The channels have the following mapping: Red: the Mask property. Green: the Smoothness property. If a Clear Coat map is present, URP multiplies the map's pixel values by value of the Mask property. Emission Makes the surface look like it emits lights. When enabled, the Emission Map and Emission Color settings appear. To assign an Emission Map, click the object picture next to it. This opens the Asset Browser, where you can select from the textures in your Project. For Emission Color, you can use the color picker to assign a tint on top of the color. This can be more than 100% white, which is useful for effects like lava, that shines brighter than white while still being another color. If you have not assigned an Emission Map, the Emission setting only uses the tint you’ve assigned in Emission Color. If you do not enable Emission, URP sets the emission to black and does not calculate emission. Tiling A 2D multiplier value that scales the Texture to fit across a mesh according to the U and V axes. This is good for surfaces like floors and walls. The default value is 1, which means no scaling. Set a higher value to make the Texture repeat across your mesh. Set a lower value to stretch the Texture. Try different values until you reach your desired effect. Offset The 2D offset that positions the Texture on the mesh. To adjust the position on your mesh, move the Texture across the U or V axes. Detail Inputs Use the Detail Inputs settings to add extra details to the surface. Requirement: GPU supporting shader model 2.5 or higher. Property Description Mask Select a texture that defines areas where Unity overlays the Detail maps over the Surface Inputs maps. The mask uses the alpha channel of the selected texture. The Tiling and Offset settings have no effect on the mask. Base Map Select the texture containing the surface details. Unity blends this map with the Surface Base Map using the overlay mode. Normal Map Select the texture containing the normal vector data. Use a normal map to add surface details like bumps, scratches and grooves. Use the slider next to the setting to change the intensity of the effect of the map. The default value is 1. Tiling Use this setting to scale the Base Map and the Normal Map on the mesh along the U and V axes, so that the maps fit the mesh best. The default value is 1. Select a value higher than one to make the maps repeat themselves across the mesh. Set a value lower than 1 to stretch the maps. Offset The offset that moves the Base Map and the Normal Map on the mesh along the U and V axes. Advanced The Advanced settings affect the underlying calculations of your rendering. They do not have a visible effect on your surface. Property Description Specular Highlights Enable this to allow your Material to have specular highlights from direct lighting, for example Directional, Point, and Spot lights. This means that your Material reflects the shine from these light sources. Disable this to leave out these highlight calculations, so your Shader renders faster. By default, this feature is enabled. Environment Reflections Sample reflections using the nearest Reflection Probe, or, if you have set one in the Lighting window, the Lighting Probe. If you disable this, you will have fewer Shader calculations, but this also means that your surface has no reflections. Enable GPU Instancing Makes URP render meshes with the same geometry and Material in one batch, when possible. This makes rendering faster. URP cannot render Meshes in one batch if they have different Materials or if the hardware does not support GPU instancing. Priority Use this slider to determine the chronological rendering order for a Material. URP renders Materials with lower values first. You can use this to reduce overdraw on devices by making the pipeline render Materials in front of other Materials first, so it doesn't have to render overlapping areas twice. This works similarly to the render queue in the built-in Unity render pipeline. Channel packing This Shader uses channel packing, so you can use a single RGBA texture for the metallic, smoothness and occlusion properties. When you use texture packing, you only have to load one texture into memory instead of three separate ones. When you write your texture maps in a program like Substance or Photoshop, you can pack the maps like this: Base Map Channel Property Red Metallic Green Occlusion Blue None Alpha Smoothness Clear Coat Map Channel Property Red Mask Green Smoothness Blue None Alpha None"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shader-stripping.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shader-stripping.html",
    "title": "Shader Stripping | mmo-rpg-unity",
    "keywords": "Shader Stripping The shaders in the Universal Render Pipeline (URP) use shader keywords to support many different features, which can mean Unity compiles a lot of shader variants. If you disable features in the URP Asset, URP automatically excludes ('strips') the related shader variants. This speeds up builds, and reduces memory usage and file sizes. For example, if your project doesn't use shadows for directional lights, by default Unity still includes variants that support directional light shadows in your build. If you disable Cast Shadows in the URP Asset, URP strips these variants. If you want to examine the code that strips shaders in URP, refer to the Editor/ShaderPreprocessor.cs file. The file uses the IPreprocessShaders API. For more information on stripping shader variants, refer to the following pages: Check how many shader variants you have. Standard guidance about shader stripping, which applies to all render pipelines. Strip feature shader variants By default, URP compiles variants where a feature is enabled, and variants where a feature is disabled. To reduce the number of variants, you can enable Strip Unused Variants in the URP Global Settings and do the following: Disable a feature in all URP Assets in your build, so URP keeps only variants where the feature is disabled. Enable a feature in all URP Assets in your build, so URP keeps only variants where the feature is enabled. If you disable the Strip Unused Variants setting, URP can't strip variants where the feature is disabled. This might increase the number of variants. Disable a feature To let Unity strip variants related to a feature, make sure you disable it in all the URP Assets in your build. Unity includes the following URP Assets in your build: The URP Asset you set as the default render pipeline asset in Graphics Settings. Any URP Asset you set as a Render Pipeline Asset in a Quality Settings level you enable for the current build target. Avoid including URP Assets in your build that use different rendering paths because this causes Unity to create two sets of variants for each keyword. Feature How to disable the feature Shader keywords this turns off Rendering Path Accurate G-buffer normals Disable Accurate G-buffer normals in the URP Asset. This has no effect on platforms that use the Vulkan graphics API. _GBUFFER_NORMALS_OCT Deferred Additional lights In the URP Asset, in the Lighting section, disable Additional Lights. _ADDITIONAL_LIGHTS, _ADDITIONAL_LIGHTS_VERTEX Forward Ambient occlusion Remove the Ambient Occlusion Renderer Feature in all Renderers that URP Assets use. _SCREEN_SPACE_OCCLUSION Forward and Deferred Decals Remove the Decals Renderer Feature in all Renderers that URP Assets use. _DBUFFER_MRT1, _DBUFFER_MRT2, _DBUFFER_MRT3, _DECAL_NORMAL_BLEND_LOW, _DECAL_NORMAL_BLEND_MEDIUM, _DECAL_NORMAL_BLEND_HIGH, _DECAL_LAYERS Forward and Deferred Fast sRGB to linear conversion In the URP Asset, in the Post-processing section, disable Fast sRGB/Linear conversions. _USE_FAST_SRGB_LINEAR_CONVERSION Forward and Deferred Holes in terrain In the URP Asset, in the Rendering section, disable Terrain Holes. _ALPHATEST_ON Forward Light cookies Remove Cookie textures from all the lights in your project. _LIGHT_COOKIES Forward and Deferred Rendering Layers for lights Disable Rendering Layers for Lights. _LIGHT_LAYERS Forward and Deferred Reflection Probe blending Disable Probe Blending. _REFLECTION_PROBE_BLENDING Forward and Deferred Reflection Probe box projection Disable Box Projection. _REFLECTION_PROBE_BOX_PROJECTION Forward and Deferred Render Pass Disable Native Render in all Renderers that URP Assets use. _RENDER_PASS_ENABLED Forward and Deferred Shadows from additional lights In the URP Asset, in the Additional Lights section, disable Cast Shadows. _ADDITIONAL_LIGHT_SHADOWS Forward and Deferred Shadows from the main light In the URP Asset, in the Main Light section, disable Cast Shadows. The keywords Unity removes might depend on your settings. _MAIN_LIGHT_SHADOWS, _MAIN_LIGHT_SHADOWS_CASCADE, _MAIN_LIGHT_SHADOWS_SCREEN Forward and Deferred Soft shadows In the URP Asset, in the Shadows section, disable Soft shadows. _SHADOWS_SOFT Forward and Deferred Strip post-processing shader variants Enable Strip Unused Post Processing Variants in URP Global Settings to strip shader variants for Volume Overrides you don't use. For example if your project uses only the Bloom effect, URP keeps Bloom variants but strips all other post-processing variants. Unity checks for Volume Overrides in all scenes, so you can't strip variants by removing a Scene from your build but keeping it in your project. Volume Override removed Shader keywords this turns off Bloom _BLOOM_HQ, BLOOM_HQ_DIRT, _BLOOM_LQ, BLOOM_LQ_DIRT Chromatic Aberration _CHROMATIC_ABERRATION Film Grain _FILM_GRAIN HDR Grading _HDR_GRADING Lens Distortion _DISTORTION Tonemapping _TONEMAP_ACES, _TONEMAP_NEUTRAL, _TONEMAP_GRADING You should also enable Strip Screen Coord Override Variants in URP Global Settings, unless you override screen coordinates to support post processing on large numbers of multiple displays ('cluster' displays). Strip XR and VR shader variants If you don't use XR or VR, you can disable the XR and VR modules. This allows URP to strip XR and VR related shader variants from its standard shaders. Remove variants if you use a custom Renderer Feature If you create a custom Renderer Feature, you can use the FilterAttribute API to remove shader variants when you enable or disable settings in the URP Asset. For example, you can do the following: Use [SerializeField] to add a Boolean variable to the custom Renderer Feature and add it as a checkbox in the URP Asset Inspector. Use ShaderKeywordFilter.RemoveIf to remove shader variants when you enable the checkbox."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shader-terrain-lit.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shader-terrain-lit.html",
    "title": "Terrain Lit shader | mmo-rpg-unity",
    "keywords": "Terrain Lit shader URP uses the Terrain Lit shader for Unity Terrain. This shader is a simpler version of the Lit shader. A Terrain can use a Terrain Lit Material with up to eight Terrain Layers. A Terrain GameObject rendered with the Terrain Lit shader. Terrain Lit Material properties A Terrain Lit shader has the following properties. Property Description Enable Height-based Blend Enable to have Unity take the height values from the blue channel of the Mask Map Texture. If you do not enable this property, Unity blends the Terrain Layers based on the weights painted in the splatmap Textures. When you disable this property and the Terrain Lit Shader Material is assigned to a Terrain, URP adds an additional option Opacity as Density Blend for each Terrain Layer that is added to that Terrain in the Paint Texture Tool Inspector. Note: Unity ignores this option when more than four Terrain Layers are on the Terrain. Height Transition Select the size in world units of the smooth transition area between Terrain Layers. Enable Per-pixel Normal Enable to have Unity sample the normal map Texture on a per-pixel level, preserving more geometry details for distant terrain parts. Unity generates a geometry normal map at runtime from the heightmap, rather than the Mesh geometry. This means you can have high-resolution Mesh normals, even if your Mesh is low resolution. Note: This option only works if you enable Draw Instanced on the Terrain. Create a Terrain Lit Material To create a Material compatible with a Terrain GameObject: Create a new Material (Assets > Create > Material). Select the new Material. In the Inspector, click the Shader drop-down, and select Universal Render Pipeline > Terrain > Lit. Assign a Terrain Lit Material to a Terrain GameObject To assign a Terrain Lit Material to a Terrain GameObject: Select a Terrain GameObject. In the Inspector, click the gear icon on the right side of the Terrain Inspector toolbar to open the Terrain Settings section. In the Material property, select a Terrain Lit Material. Either use the Object picker (circle icon), or drag and drop the Material onto the property. Using the Paint Holes Tool To use the Paint Holes tool on a Terrain, ensure that the Terrain Holes check box in your project's URP Asset is checked. Otherwise, the Terrain holes are absent when you build the application."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shaders-in-universalrp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shaders-in-universalrp.html",
    "title": "Shaders and Materials | mmo-rpg-unity",
    "keywords": "Shaders and Materials URP provides the following Shaders for the most common use case scenarios: Complex Lit Lit Simple Lit Baked Lit Unlit Terrain Lit Particles Lit Particles Simple Lit Particles Unlit SpeedTree Decal Autodesk Interactive Autodesk Interactive Transparent Autodesk Interactive Masked Shader compatibility Lit and custom Lit shaders written for the Built-in Render Pipeline are not compatible with URP. Unlit shaders written for the Built-in Render Pipeline are compatible with URP. For information on converting shaders written for the Built-in Render Pipeline to URP shaders, refer to the page Converting your shaders. Choosing a shader The Universal Render Pipeline implements Physically Based Rendering (PBR). The pipeline provides pre-built shaders that can simulate real world materials. PBR materials provide a set of parameters that let artists achieve consistency between different material types and under different lighting conditions. The URP Lit shader is suitable for modeling most of the real world materials. The Complex Lit shader is suitable for simulating advanced materials that require more complex lighting evaluation, such as the clear coat effect. URP provides the Simple Lit shader as a helper to convert non-PBR projects made with the Built-in Render Pipeline to URP. This shader is non-PBR and is not supported by Shader Graph. If you don’t need real-time lighting, or would rather only use baked lighting and sample global illumination, choose a Baked Lit Shader. If you don’t need lighting on a Material at all, you can choose the Unlit Shader. SRP Batcher compatibility To ensure that a Shader is SRP Batcher compatible: Declare all Material properties in a single CBUFFER called UnityPerMaterial. Declare all built-in engine properties, such as unity_ObjectToWorld or unity_WorldTransformParams, in a single CBUFFER called UnityPerDraw. For more information on the SRP Batcher, refer to the page Scriptable Render Pipeline (SRP) Batcher."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shading-model.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shading-model.html",
    "title": "Shading models in Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Shading models in Universal Render Pipeline A shading model defines how a Material’s color varies depending on factors such as surface orientation, viewer direction, and lighting. Your choice of a shading model depends on the artistic direction and performance budget of your application. Universal Render Pipeline (URP) provides Shaders with the following shading models: Physically Based Shading Simple Shading Baked Lit Shading No lighting Physically Based Shading Physically Based Shading (PBS) simulates how objects look in real life by computing the amount of light reflected from the surface based on physics principles. This lets you create photo-realistic objects and surfaces. This PBS model follows two principles: Energy conservation - Surfaces never reflect more light than the total incoming light. The only exception to this is when an object emits light. For example, a neon sign. Microgeometry - Surfaces have geometry at a microscopic level. Some objects have smooth microgeometry, which gives them a mirror-like appearance. Other objects have rough microgeometry, which makes them look more dull. In URP, you can mimic the level of smoothness of a rendered object’s surface. When light hits a a rendered object's surface, part of the light is reflected and part is refracted. The reflected light is called specular reflection. This varies depending on the camera direction and the point at which the light hits a surface, also called the angle of incidence. In this shading model, the shape of specular highlight is approximated with a GGX function. For metal objects, the surface absorbs and changes the light. For non-metallic objects, also called dielectric objects, the surface reflects parts of the light. Light attenuation is only affected by the light intensity. This means that you don’t have to increase the range of your light to control the attenuation. The following URP Shaders use Physically Based Shading: Lit Particles Lit Note: This shading model is not suitable for low-end mobile hardware. If you’re targeting this hardware, use Shaders with a Simple Shading model. To read more about Physically Based Rendering, refer to this walkthrough by Joe Wilson on Marmoset. Simple shading This shading model is suitable for stylized visuals or for games that run on less powerful platforms. With this shading model, Materials are not truly photorealistic. The Shaders do not conserve energy. This shading model is based on the Blinn-Phong model. In this Simple shading model, Materials reflect diffuse and specular light, and there’s no correlation between the two. The amount of diffuse and specular light reflected from Materials depends on the properties you select for the Material and the total reflected light can therefore exceed the total incoming light. Specular reflection varies only with camera direction. Light attenuation is only affected by the light intensity. The following URP Shaders use Simple Shading: Simple Lit Particles Simple Lit Baked Lit shading The Baked Lit shading model doesn’t have real-time lighting. Materials can receive baked lighting from either lightmaps or Light Probes. This adds some depth to your Scenes at a small performance cost. Games with this shading model can run on less powerful platforms. The URP Baked Lit shader is the only shader that uses the Baked Lit shading model. Shaders with no lighting URP comes with some unlit-type shaders. Materials with unlit-type shaders are not affected by neither real-time, nor baked lighting. Unlit shaders let you create unique visual look of the objects in your scene. Unlit shaders have significantly faster compilation speed compared with lit shaders. The following URP Shaders have no lighting: Unlit Particles Unlit"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shared/lens-flare/lens-flare-asset.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shared/lens-flare/lens-flare-asset.html",
    "title": "Lens Flare (SRP) Data Asset | mmo-rpg-unity",
    "keywords": "Lens Flare (SRP) Data Asset Unity’s Scriptable Render Pipeline (SRP) includes the Lens Flare Data asset. You can use this asset to control the appearance of Lens Flares in your scene. This is the SRP equivalent of the Built-in Render Pipeline's Flare asset, which is incompatible with SRPs. For examples of how to use Lens Flares, refer to the Lens Flare samples in URP Package Samples. To create a Lens Flare Data asset, select Assets > Create > Lens Flare (SRP). To use this asset, assign it to the Lens Flare Data property of a Lens Flare (SRP) component. Properties The Lens Flare Element asset has the following properties: Type Image Circle Polygon Color Transform AxisTransform Distortion Multiple Elements Uniform Curve Random Type Property Description Type Select the type of Lens Flare Element this asset creates: • Image • Circle • Polygon Image Property Description Flare Texture The Texture this lens flare element uses. Preserve Aspect Ratio Fixes the width and height (aspect ratio) of the Flare Texture. You can use Distortion to change this property. Circle Property Description Gradient Controls the offset of the circular flare's gradient. This value ranges from 0 to 1. Falloff Controls the falloff of the circular flare's gradient. This value ranges from 0 to 1, where 0 has no falloff between the tones and 1 creates a falloff that is spread evenly across the circle. Inverse Enable this property to reverse the direction of the gradient. Polygon Property Description Gradient Controls the offset of the polygon flare's gradient. This value ranges from 0 to 1. Falloff Controls the falloff of the polygon flare's gradient. This value ranges from 0 to 1, where 0 has no falloff between the tones and 1 creates a falloff that is spread evenly across the polygon. Side Count Determines how many sides the polygon flare has. Roundness Defines how smooth the edges of the polygon flare are. This value ranges from 0 to 1, where 0 is a sharp polygon and 1 is a circle. Inverse Enable this property to reverse the direction of the gradient Color Property Description Tint Changes the tint of the lens flare. If this asset is attached to the light, this property is based on the light tint. Modulate By Light Color Allows light color to affect this Lens Flare Element. This only applies when the asset is used in a Lens Flare (SRP) component that is attached to a point, spot, or area light. Intensity Controls the intensity of this element. Blend Mode Select the blend mode of the Lens Flare Element this asset creates: • Additive • Screen • Premultiplied • Lerp Transform Property Description Position Offset Defines the offset of the lens flare's position in screen space, relative to its source. Auto Rotate Enable this property to automatically rotate the Lens Flare Texture relative to its angle on the screen. Unity uses the Auto Rotate angle to override the Rotation parameter. To ensure the Lens Flare can rotate, assign a value greater than 0 to the Starting Position property. Rotation Rotates the lens flare. This value operates in degrees of rotation. Size Use this to adjust the scale of this lens flare element. This property is not available when the Type is set to Image and Preserve Aspect Ratio is enabled. Scale The size of this lens flare element in world space. AxisTransform Property Description Starting Position Defines the starting position of the lens flare relative to its source. This value operates in screen space. Angular Offset Controls the angular offset of the lens flare, relative to its current position. This value operates in degrees of rotation. Translation Scale Limits the size of the lens flare offset. For example, values of (1, 0) create a horizontal lens flare, and (0, 1) create a vertical lens flare. You can also use this property to control how quickly the lens flare appears to move. For example, values of (0.5, 0.5) make the lens flare element appear to move at half the speed. Distortion Property Description Enable Set this property to True to enable distortion. Radial Edge Size Controls the size of the distortion effect from the edge of the screen. Radial Edge Curve Blends the distortion effect along a curve from the center of the screen to the edges of the screen. Relative To Center Set this value to True to make distortion relative to the center of the screen. Otherwise, distortion is relative to the screen position of the lens flare. Multiple Elements Property Description Enable Enable this to allow multiple lens flare elements in your scene. Count Determines the number of identical lens flare elements Unity generates. A value of 1 appears the same as a single lens flare element. Distribution Select the method that Unity uses to generate multiple lens flare elements: •Uniform •Curve •Random Length Spread Controls how spread out multiple lens flare elements appear. Relative To Center If true the distortion is relative to center of the screen otherwise relative to lensFlare source screen position. Uniform Property Description Colors The range of colors that this asset applies to the lens flares. Rotation The angle of rotation (in degrees) applied to each element incrementally. Curve Property Description Colors The range of colors that this asset applies to the lens flares. You can use the Position Spacing curve to determine how this range affects each lens flare. Position Variation Adjust this curve to change the placement of the lens flare elements in the Lens Spread. Rotation The uniform angle of rotation (in degrees) applied to each element distributed along the curve. This value ranges from -180° to 180°. Scale Adjust this curve to control the size range of the lens flare elements. Random Property Description Seed The base value that this asset uses to generate randomness. Intensity Variation Controls the variation of brightness across the lens flare elements. A high value can make some elements might invisible. Colors The range of colors that this asset applies to the lens flares. This property is based on the Seed value. Position Variation Controls the position of the lens flares. The X value is spread along the same axis as Length Spread. A value of 0 means there is no change in the lens flare position. The Y value is spread along the vertical screen space axis based on the Seed value. Rotation Variation Controls the rotation variation of the lens flares, based on the Seed value. The Rotation and Auto Rotate parameters inherit from this property. Scale Variation Controls the scale of the lens flares based on the Seed value."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shared/lens-flare/lens-flare-component.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/shared/lens-flare/lens-flare-component.html",
    "title": "Lens Flare (SRP) component | mmo-rpg-unity",
    "keywords": "Lens Flare (SRP) component Unity’s Scriptable Render Pipeline (SRP) includes the Lens Flare (SRP) component which renders a lens flare in your scene. This is the SRP equivalent of the Built-in Render Pipeline's Lens Flare component, which is incompatible with SRPs. You can attach a Lens Flare (SRP) component to any GameObject, but some properties only appear when you attach a Lens Flare (SRP) component to a light. Creating lens flares in SRP The Lens Flare (SRP) component controls where the lens flare is as well as properties such as attenuation and whether the lens flare considers occlusion. For properties that define how the lens flare looks, SRP uses the Lens Flare (SRP) Data asset. Each Lens Flare (SRP) component must reference a Lens Flare (SRP) data asset to display a lens flare on-screen. To create a lens flare in a scene: Create or select a GameObject to attach the lens flare too. In the Inspector, click Add Component. Select Rendering > Lens Flare (SRP). Currently, the lens flare doesn't render in the scene because the component doesn't reference a Lens Flare (SRP) Data asset in its Lens Flare Data property. Create a new Lens Flare (SRP) Data asset (menu: Assets > Create > Lens Flare (SRP)). In the Lens Flare (SRP) component Inspector, assign the new Lens Flare (SRP) Data asset to the Lens Flare Data property. Select the Lens Flare (SRP) Data asset and, in the Inspector, add a new element to the Elements list. A default white lens flare now renders at the position of the Lens Flare (SRP) component. For information on how to customize how the lens flare looks, refer to Lens Flare (SRP) Data. Properties General Property Description Lens Flare Data Select the Lens Flare (SRP) Data asset this component controls. Intensity Multiplies the intensity of the lens flare. Scale Multiplies the scale of the lens flare. Attenuation by Light Shape Enable this property to automatically change the appearance of the lens flare based on the type of light you attached this component to. For example, if this component is attached to a spot light and the camera is looking at this light from behind, the lens flare will not be visible. This property is only available when this component is attached to a light. Attenuation Distance The distance between the start and the end of the Attenuation Distance Curve. This value operates between 0 and 1 in world space. Attenuation Distance Curve Fades out the appearance of the lens flare over the distance between the GameObject this asset is attached to, and the Camera. Scale Distance The distance between the start and the end of the Scale Distance Curve. This value operates between 0 and 1 in world space. Scale Distance Curve Changes the size of the lens flare over the distance between the GameObject this asset is attached to, and the Camera. Screen Attenuation Curve Reduces the effect of the lens flare based on its distance from the edge of the screen. You can use this to display a lens flare at the edge of your screen Occlusion Property Description Enable Enable this property to partially obscure the lens flare based on the depth buffer Occlusion Radius Defines how far from the light source Unity occludes the lens flare. This value is in world space. Sample Count The number of random samples the CPU uses to generate the Occlusion Radius. Occlusion Offset Offsets the plane that the occlusion operates on. A higher value moves this plane closer to Camera. This value is in world space. For example, if a lens flare is inside the light bulb, you can use this to sample occlusion outside the light bulb. Occlusion Remap Curve Allow the occlusion [from 0 to 1] to be remap with any desired shape. Allow Off Screen Enable this property to allow lens flares outside the Camera's view to affect the current field of view."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/simple-lit-shader.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/simple-lit-shader.html",
    "title": "Simple Lit Shader | mmo-rpg-unity",
    "keywords": "Simple Lit Shader Use this Shader when performance is more important than photorealism. This Shader uses a simple approximation for lighting. Because this Shader does not calculate for physical correctness and energy conservation, it renders quickly. Using the Simple Lit Shader in the Editor To select and use this Shader: In your Project, create or find the Material you want to use the Shader on. Select the Material. A Material Inspector window opens. Click Shader, and select Universal Render Pipeline > Simple Lit. UI overview The Inspector window for this Shader contains these elements: Surface Options Surface Inputs Advanced Surface Options The Surface Options control how the Material is rendered on a screen. Property Description Surface Type Use this drop-down to apply an Opaque or Transparent surface type to the Material. This determines which render pass URP renders the material in. Opaque surface types are always fully visible, regardless of what’s behind them. URP renders opaque Materials first. Transparent surface types are affected by their background, and they can vary according to which type of transparent surface type you choose. URP renders transparent Materials in a separate pass after opaque objects. If you select Transparent, the Blending Mode drop-down appears. Blending Mode Select how Unity calculates the color of each pixel of a transparent Material when it blends the Material with the background. In the context of Blending Modes, Source refers to the transparent Material where the Blending Mode is set and Destination refers to anything that Material overlaps with. Alpha Alpha blending mode. Alpha uses the Material's alpha value to change how transparent an object is. 0 is fully transparent. 255 is fully opaque, this is translated to a value of 1 when used with the blending equations. The Material is always rendered in the Transparent render pass regardless of it's alpha value. This mode lets you use the Preserve Specular Lighting property. Alpha equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB × (1 − SourceAlpha) Premultiply Premultiply blending mode. Premultiply first multiplies the RGB values of the transparent Material by its alpha value then applies a similar effect to the Material as Alpha. The equation for Premultiply also allows areas of the transparent Material with an alpha value of 0 to have an additive blend effect. This can help reduce artifacts that may appear at the edge of the overlap between opaque and transparent pixels. Premultiply equation: OutputRGBA = SourceRGB + DestinationRGB × (1 − SourceAlpha) Additive Additive blending mode. Additive adds the color values of the Materials together to create the blend effect. The alpha value determines the strength of the source Material's color before the blend is calculated. This mode lets you use the Preserve Specular Lighting property. Additive equation: OutputRGBA = (SourceRGB × SourceAlpha) + DestinationRGB Multiply Multiply blending mode. Multiply multiplies the color of the Material with the color behind the surface. This creates a darker effect, like when you look through colored glass. This mode uses the Material’s alpha value to adjust how much the colors blend. An alpha value of 1 results in unadjusted multiplication of the colors while lower values blend the colors towards white. Multiply equation: OutputRGBA = SourceRGB × DestinationRGB Preserve Specular Lighting Indicates whether Unity preserves specular highlights on a GameObject or not. This applies even when your surface is transparent which means that only the reflected light is visible. This property only appears when the Surface Type is set to Transparent and Blending Mode is set to either Alpha or Additive. Material with Preserve Specular Lighting disabled. Material with Preserve Specular Lighting enabled. Render Face Use this drop-down to determine which sides of your geometry to render. Front Face renders the front face of your geometry and culls the back face. This is the default setting. Back Face renders the back face of your geometry and culls the front face. Both makes URP render both faces of the geometry. This is good for small, flat objects, like leaves, where you might want both sides visible. Alpha Clipping Makes your Material act like a Cutout Shader. Use this to create a transparent effect with hard edges between the opaque and transparent areas. For example, to create blades of grass. To achieve this effect, URP does not render alpha values below the specified Threshold, which appears when you enable Alpha Clipping. You can set the Threshold by moving the slider, which accepts values from 0 to 1. All values above your threshold are fully opaque, and all values below your threshold are invisible. For example, a threshold of 0.1 means that URP doesn't render alpha values below 0.1. The default value is 0.5. Surface Inputs The Surface Inputs describe the surface itself. For example, you can use these properties to make your surface look wet, dry, rough, or smooth. Property Description Base Map Adds color to the surface, also known as the diffuse map. To assign a Texture to the Base Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. The color next to the setting shows the tint on top of your assigned Texture. To assign another tint, you can click this color swatch. If you select Transparent or Alpha Clipping under Surface Options, your Material uses the Texture’s alpha channel or color. Specular Map Controls the color of your specular highlights from direct lighting, for example Directional, Point, and Spot lights. To assign a Texture to the Specular Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the textures in your Project. Alternatively, you can use the color picker. In Source, you can select a Texture in your Project to act as a source for the smoothness. By default, the source is the Alpha channel for this Texture. You can use the Smoothness slider to control the spread of highlights on the surface. 0 gives a wide, rough highlight. 1 gives a small, sharp highlight like glass. Values in between produce semi-glossy looks. For example, 0.5 produces a plastic-like glossiness. Normal Map Adds a normal map to the surface. With a normal map, you can add surface details like bumps, scratches and grooves. To add the map, click the object picker next to it. The normal map picks up ambient lighting in the environment. Emission Makes the surface look like it emits lights. When enabled, the Emission Map and Emission Color settings appear. To assign an Emission Map, click the object picture next to it. This opens the Asset Browser, where you can select from the textures in your Project. For Emission Color, you can use the color picker to assign a tint on top of the color. This can be more than 100% white, which is useful for effects like lava, that shines brighter than white while still being another color. If you have not assigned an Emission Map, the Emission setting only uses the tint you’ve assigned in Emission Color. If you do not enable Emission, URP sets the emission to black and does not calculate emission. Tiling A 2D multiplier value that scales the Texture to fit across a mesh according to the U and V axes. This is good for surfaces like floors and walls. The default value is 1, which means no scaling. Set a higher value to make the Texture repeat across your mesh. Set a lower value to stretch the Texture. Try different values until you reach your desired effect. Offset The 2D offset that positions the Texture on the mesh. To adjust the position on your mesh, move the Texture across the U or V axes. Advanced The Advanced settings affect the underlying calculations of your rendering. They do not have a visible effect on your surface. Property Description Specular Highlights Enable this to allow your Material to have specular highlights from direct lighting, for example Directional, Point, and Spot lights. This means that your Material reflects the shine from these light sources. Disable this to leave out these highlight calculations, so your Shader renders faster. By default, this feature is enabled. Enable GPU Instancing Makes URP render meshes with the same geometry and Material in one batch, when possible. This makes rendering faster. URP cannot render Meshes in one batch if they have different Materials or if the hardware does not support GPU instancing. Sorting Priority Use this slider to determine the chronological rendering order for a Material. URP renders Materials with lower values first. You can use this to reduce overdraw on devices by making the pipeline render Materials in front of other Materials first, so it doesn't have to render overlapping areas twice. This works similarly to the render queue in the built-in Unity render pipeline."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/speedtree.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/speedtree.html",
    "title": "SpeedTree Shaders | mmo-rpg-unity",
    "keywords": "SpeedTree Shaders The Universal Render Pipeline uses the SpeedTree system for tree Shaders. To read more about that, read the SpeedTree documentation in the Unity main manual. When you use SpeedTree Shaders in URP, keep the following in mind: There is no Global Illumination on trees in URP. Trees cannot receive shadows in URP. In URP, you can configure whether lights should be per vertex of per pixel in the URP Asset."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/understand-performance.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/understand-performance.html",
    "title": "Understand performance | mmo-rpg-unity",
    "keywords": "Understand performance The performance of your project depends on the Universal Render Pipeline (URP) features you use or enable, what your scenes contain, and which platforms you target. You can use the Unity Profiler or a GPU profiler such as RenderDoc or Xcode to check how much URP uses memory, the CPU and the GPU in your project. You can then use the information to enable or disable the features and settings that have the largest performance impact. URP usually performs better if you change settings that reduce the following: How much URP uses the CPU. For example, you can disable URP updating volumes every frame. How much memory URP uses to store textures. For example, you can disable High Dynamic Range (HDR) if you don't need it, to reduce the size of the color buffer. How many render textures URP copies to and from memory, which has a large impact on mobile platforms. For example, you can disable URP creating a depth texture if you don't need it. The number of passes in the render pipeline. For example, you can disable the opaque texture if you don't need it, or disable additional lights casting shadows. The number of draw calls URP sends to the GPU. For example, you can enable the SRP Batcher. The number of pixels URP renders to the screen, which has a big effect on mobile platforms where the GPU is less powerful. For example, you can reduce the render scale. Refer to the following for more information about which settings to disable or change to improve performance: Configure for better performance Optimize for better performance"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/universal-additional-camera-data.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/universal-additional-camera-data.html",
    "title": "The Universal Additional Camera Data component | mmo-rpg-unity",
    "keywords": "The Universal Additional Camera Data component The Universal Additional Camera Data component is a component the Universal Render Pipeline (URP) uses for internal data storage. The Universal Additional Camera Data component allows URP to extend and override the functionality and appearance of Unity's standard Camera component. In URP, a GameObject that has a Camera component must also have a Universal Additional Camera Data component. If your Project uses URP, Unity automatically adds the Universal Additional Camera Data component when you create a Camera GameObject. You cannot remove the Universal Additional Camera Data component from a Camera GameObject. If you don't use scripts to control and customise URP, you do not need to do anything with the Universal Additiona Camera Data component. If you do use scripts to control and customise URP, you can access a Camera's Universal Additional Camera Data component in a script like this: UniversalAdditionalCameraData cameraData = camera.GetUniversalAdditionalCameraData(); Note To use the GetUniversalAdditionalCameraData() method you must use the UnityEngine.Rendering.Universal namespace. To do this, add the following statement at the top of your script: using UnityEngine.Rendering.Universal;. For more information, refer to the UniversalAdditionalCameraData API. If you need to access the Universal Additional Camera Data component frequently in a script, you should cache the reference to it to avoid unnecessary CPU work. Note When a Camera uses a Preset, only a subset of properties are supported. Unsupported properties are hidden."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/universal-additional-light-data.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/universal-additional-light-data.html",
    "title": "The Universal Additional Light Data component | mmo-rpg-unity",
    "keywords": "The Universal Additional Light Data component Universal Additional Light Data is a component that the Universal Render Pipeline (URP) uses for internal data storage. The Universal Additional Light Data component allows URP to extend and override the functionality of Unity's standard Light component. In URP, a GameObject that has a Light component must also have a Universal Additional Light Data component. If your Project uses URP, Unity automatically adds the Universal Additional Light Data component when you create a Light GameObject. You cannot remove the Universal Additional Light Data component from a Light GameObject."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/universalrp-asset.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/universalrp-asset.html",
    "title": "Universal Render Pipeline Asset | mmo-rpg-unity",
    "keywords": "Universal Render Pipeline Asset Any Unity project that uses the Universal Render Pipeline (URP) must have a URP Asset to configure the settings. When you create a project using the URP template, Unity creates the URP Assets in the Settings project folder and assigns them in Project Settings. If you are migrating an existing project to URP, you need to create a URP Asset and assign the asset in the Graphics settings. The URP Asset controls several graphical features and quality settings for the Universal Render Pipeline. It is a scriptable object that inherits from ‘RenderPipelineAsset’. When you assign the asset in the Graphics settings, Unity switches from the built-in render pipeline to the URP. You can then adjust the corresponding settings directly in the URP, instead of looking for them elsewhere. You can have multiple URP assets and switch between them. For example, you can have one with Shadows on and one with Shadows off. If you switch between the assets to see the effects, you don’t have to manually toggle the corresponding settings for shadows every time. You cannot, however, switch between HDRP/SRP and URP assets, as the render pipelines are incompatible. UI overview In the URP, you can configure settings for: Rendering Quality Lighting Shadows Post-processing Adaptive Performance Note If you have the experimental 2D Renderer enabled (menu: Graphics Settings > add the 2D Renderer Asset under Scriptable Render Pipeline Settings), some of the options related to 3D rendering in the URP Asset don't have any impact on your final app or game. How to show Additional Properties Unity does not show certain advanced properties in the URP Asset by default. To see all available properties: In the URP Asset, in any section, click the vertical ellipsis icon (⋮) and select Show Additional Properties Unity shows all available properties in the current section. To show all additional properties in all sections: Click the vertical ellipsis icon (⋮) and select Show All Additional Properties. Unity opens the Core Render Pipeline section in the Preferences window. In the property Additional Properties > Visibility, select All Visible. Rendering The Rendering settings control the core part of the pipeline rendered frame. Property Description Depth Texture Enables URP to create a _CameraDepthTexture. URP then uses this depth texture by default for all Cameras in your scene. You can override this for individual cameras in the Camera Inspector. Opaque Texture Enable this to create a _CameraOpaqueTexture as default for all cameras in your scene. This works like the GrabPass in the built-in render pipeline. The Opaque Texture provides a snapshot of the scene right before URP renders any transparent meshes. You can use this in transparent Shaders to create effects like frosted glass, water refraction, or heat waves. You can override this for individual cameras in the Camera Inspector. Opaque Downsampling Set the sampling mode on the opaque texture to one of the following: None: Produces a copy of the opaque pass in the same resolution as the camera. 2x Bilinear: Produces a half-resolution image with bilinear filtering. 4x Box: Produces a quarter-resolution image with box filtering. This produces a softly blurred copy. 4x Bilinear: Produces a quarter-resolution image with bi-linear filtering. Terrain Holes If you disable this option, the URP removes all Terrain hole Shader variants when you build for the Unity Player, which decreases build time. SRP Batcher Enable the SRP Batcher. This is useful if you have many different Materials that use the same Shader. The SRP Batcher is an inner loop that speeds up CPU rendering without affecting GPU performance. When you use the SRP Batcher, it replaces the SRP rendering code inner loop. If both SRP Batcher and Dynamic Batching are enabled, SRP Batcher will take precedence over dynamic batching as long as the shader is SRP Batcher compatible. Note: If assets or shaders in a project are not optimized for use with the SRP Batcher, low performance devices might be more performant when you disable the SRP Batcher. Dynamic Batching Enable Dynamic Batching, to make the render pipeline automatically batch small dynamic objects that share the same Material. This is useful for platforms and graphics APIs that do not support GPU instancing. If your targeted hardware does support GPU instancing, disable Dynamic Batching. You can change this at run time. Debug Level Set the level of debug information that the render pipeline generates. Available options: Disabled: Debugging is disabled. This is the default. Profiling: Makes the render pipeline provide detailed information tags, which you can find in the FrameDebugger. Shader Variant Log Level Set the level of information about Shader Stripping and Shader Variants you want to display when Unity finishes a build. Available options: Disabled: Unity doesn’t log anything. Only Universal: Unity logs information for all of the URP Shaders. All: Unity logs information for all Shaders in your build. You can check the information in Console panel when your build has finished. Store Actions Defines if Unity discards or stores the render targets of the DrawObjects Passes. Available options: Auto: Unity uses the Discard option by default, and falls back to the Store option if it detects any injected Passes. Discard: Unity discards the render targets of render Passes that are not reused later (lower memory bandwidth). Store: Unity stores all render targets of each Pass. Store significantly increases the memory bandwidth on mobile and tile-based GPUs. Quality These settings control the quality level of the URP. This is where you can make performance better on lower-end hardware or make graphics look better on higher-end hardware. Tip: If you want to have different settings for different hardware, you can configure these settings across multiple Universal Render Pipeline assets, and switch them out as needed. Property Description HDR Enable this to allow rendering in High Dynamic Range (HDR) by default for every camera in your scene. With HDR, the brightest part of the image can be greater than 1. This gives you a wider range of light intensities, so your lighting looks more realistic, such as being able to pick out details and experience less saturation even with bright light. This is useful if you want a wide range of lighting or to use bloom effects. If you’re targeting lower-end hardware, you can disable this to skip HDR calculations and get better performance. You can override this for individual cameras in the Camera Inspector. HDR Precision The precision of the Camera color buffer in HDR rendering. The 64 bit precision lets you avoid banding artifacts, but requires higher bandwidth and might make sampling slower. Default value: 32 bit. Anti Aliasing (MSAA) Use Multisample Anti-aliasing by default for every Camera in your scene while rendering. This softens edges of your geometry, so they’re not jagged or flickering. In the drop-down menu, select how many samples to use per pixel: 2x, 4x, or 8x. The more samples you choose, the smoother your object edges are. If you want to skip MSAA calculations, or you don’t need them in a 2D game, select Disabled. You can override this for individual cameras in the Camera Inspector. Note: On mobile platforms that do not support the StoreAndResolve store action, if Opaque Texture is selected in the URP asset, Unity ignores the Anti Aliasing (MSAA) property at runtime (as if Anti Aliasing (MSAA) is set to Disabled). Render Scale This slider scales the render target resolution (not the resolution of your current device). Use this when you want to render at a smaller resolution for performance reasons or to upscale rendering to improve quality. Note: This only scales the game rendering. UI rendering is left at the native resolution for the device. Upscaling Filter Select which image filter Unity uses when performing the upscaling. Unity performs upscaling when the Render Scale value is less than 1.0. Automatic Unity selects one of the filtering options based on the Render Scale value and the current screen resolution. If integer scaling is possible, Unity selects the Nearest-Neighbor option, otherwise Unity selects the Bilinear option. Bilinear Unity uses the bilinear or linear filtering provided by the graphics API. Nearest-Neighbor Unity uses the nearest-neighbor or point sampling filtering provided by the graphics API. FidelityFX Super Resolution 1.0 Unity uses the AMD FidelityFX Super Resolution 1.0 (FSR) technique to perform upscaling. Unlike most other Upscaling Filter options, this filter remains active even at a Render Scale value of 1.0. This filter can still improve image quality even when no scaling is occurring. This also makes the transition between scale values 0.99 and 1.0 less noticeable in cases where dynamic resolution scaling is active. Note: This filter is only supported on devices that support Unity shader model 4.5 or higher. On devices that do not support Unity shader model 4.5, Unity uses the Automatic option instead. Override FSR Sharpness Unity shows this check box when you select the FSR filter. Selecting this check box lets you specify the intensity of the FSR sharpening pass. FSR Sharpness Specify the intensity of the FSR sharpening pass. A value of 0.0 provides no sharpening, a value of 1.0 provides maximum sharpness. Note: This option has no effect when FSR is not the active upscaling filter. LOD Cross Fade Use this property to enable or disable the LOD cross-fade. If you disable this option, URP removes all LOD cross-fade shader variants when you build the Unity Player, which decreases the build time. LOD Cross Fade Dithering Type When an LOD group has Fade Mode set to Cross Fade, Unity renders the Renderer's LOD meshes with cross-fade blending between them using alpha testing. This property defines the type of LOD cross-fade. Available options: Bayer Matrix: better performance than the Blue Noise option, but has a repetitive pattern. Blue Noise: uses a precomputed blue noise texture and provides a better look than the Bayer Matrix option, but has a slightly higher performance cost. Lighting These settings affect the lights in your Scene. If you disable some of these settings, the relevant keywords are stripped from the Shader variables. If there are settings that you know for certain you won’t use in your game or app, you can disable them to improve performance and reduce build time. Property Description Main Light These settings affect the main Directional Light in your scene. You can select this by assigning it as a Sun Source in the Lighting Inspector. If you don’t assign a sun source, the URP treats the brightest directional light in the scene as the main light. You can choose between Pixel Lighting and None. If you choose None, URP doesn’t render a main light, even if you’ve set a sun source. Cast Shadows Check this box to make the main light cast shadows in your scene. Shadow Resolution This controls how large the shadow map texture for the main light is. High resolutions give sharper, more detailed shadows. If memory or rendering time is an issue, try a lower resolution. Additional Lights Here, you can choose to have additional lights to supplement your main light. Choose between Per Vertex, Per Pixel, or Disabled. Per Object Limit This slider sets the limit for how many additional lights can affect each GameObject. Cast Shadows Check this box to make the additional lights cast shadows in your scene. Shadow Atlas Resolution This controls the size of the textures that cast directional shadows for the additional lights. This is a sprite atlas that packs up to 16 shadow maps. High resolutions give sharper, more detailed shadows. If memory or rendering time is an issue, try a lower resolution. Shadow Resolution Tiers Set the resolution of the shadows cast by additional lights at various tiers. Resolutions must have a value of 128 or greater, and are rounded to the next power of two. Note: This property is only visible when the Cast Shadows property is enabled for Additional Lights. Cookie Atlas Resolution The size of the cookie atlas the additional lights use. All additional lights are packed into a single cookie atlas. This property is only visible when the Light Cookies property is enabled. Cookie Atlas Format The format of the cookie atlas for additional lights. All additional lights are packed into a single cookie atlas. Available options: Grayscale Low Grayscale High Color Low Color High Color HDR This property is only visible when the Light Cookies property is enabled. Reflection Probes Use these properties to control reflection probe settings. Probe Blending Smooth the transitions between Reflection Probes. For more information, refer to Reflection Probe Blending. Box Projection Create reflections on objects based on their position within the probe's box, while still using a single probe as the reflection source. For more information, refer to Advanced Reflection Probe features. Mixed Lighting Enable Mixed Lighting to configure the pipeline to include mixed lighting shader variants in the build. Use Rendering Layers With this option selected, you can configure certain Lights to affect only specific GameObjects. For more information on Rendering Layers and how to use them, refer to the documentation on Rendering Layers. Light Cookies Enables light cookies. This property enables Cookie Atlas Resolution and Cookie Atlas Format for additional lights. SH Evaluation Mode Defines the spherical harmonic (SH) lighting evaluation type. Available options: Auto: Unity selects a mode automatically. Per Vertex: Evaluate lighting per vertex. Mixed: Evaluate lighting partially per vertex, partially per pixel. Per Pixel: Evaluate lighting per pixel. Shadows These settings let you configure how shadows look and behave, and find a good balance between the visual quality and performance. The Shadows section has the following properties. Property Description Max Distance The maximum distance from the Camera at which Unity renders the shadows. Unity does not render shadows farther than this distance. Note: This property is in metric units regardless of the value in the Working Unit property. Working Unit The unit in which Unity measures the shadow cascade distances. Cascade Count The number of shadow cascades. With shadow cascades, you can avoid crude shadows close to the Camera and keep the Shadow Resolution reasonably low. For more information, refer to the documentation on Shadow Cascades. Increasing the number of cascades reduces the performance. Cascade settings only affects the main light. Split 1 The distance where cascade 1 ends and cascade 2 starts. Split 2 The distance where cascade 2 ends and cascade 3 starts. Split 3 The distance where cascade 3 ends and cascade 4 starts. Last Border The size of the area where Unity fades out the shadows. Unity starts fading out shadows at the distance Max Distance - Last Border, at Max Distance the shadows fade to zero. Depth Bias Use this setting to reduce shadow acne. Normal Bias Use this setting to reduce shadow acne. Soft Shadows Select this check box to enable extra processing of the shadow maps to give them a smoother look. Performance impact: High. When this option is disabled, Unity samples the shadow map once with the default hardware filtering. Quality Select the quality level of soft shadow processing. Available options: Low: good balance of quality and performance for mobile platforms. Filtering method: 4 PCF taps. Medium: good balance of quality and performance for desktop platforms. Filtering method: 5x5 tent filter. This is the default value. High: best quality, higher performance impact. Filtering method: 7x7 tent filter. Conservative Enclosing Sphere Enable this option to improve shadow frustum culling and prevent Unity from excessively culling shadows in the corners of the shadow cascades. Disable this option only for compatibility purposes of existing projects created in previous Unity versions. If you enable this option in an existing project, you might need to adjust the shadows cascade distances because the shadow culling enclosing spheres change their size and position. Performance impact: Enabling this option is likely to improve performance, because the option minimizes the overlap of shadow cascades, which reduces the number of redundant static shadow casters. Post-processing This section allows you to fine-tune global post-processing settings. Property Description Grading Mode Select the color grading mode to use for the Project. High Dynamic Range: This mode works best for high precision grading similar to movie production workflows. Unity applies color grading before tonemapping. Low Dynamic Range: This mode follows a more classic workflow. Unity applies a limited range of color grading after tonemapping. LUT Size Set the size of the internal and external look-up textures (LUTs) that the Universal Render Pipeline uses for color grading. Higher sizes provide more precision, but have a potential cost of performance and memory use. You cannot mix and match LUT sizes, so decide on a size before you start the color grading process. The default value, 32, provides a good balance of speed and quality. Fast sRGB/Linear Conversions Select this option to use faster, but less accurate approximation functions when converting between the sRGB and Linear color spaces. Data Driven Lens Flare Allocate the shader variants and memory URP needs for lens flares effect. Volume Update Mode Select how Unity updates Volumes: every frame or when triggered via scripting. If you select Every Frame, URP requires more processing time on the CPU. In the Editor, Unity updates Volumes every frame when not in the Play mode. Adaptive Performance This section is available if the Adaptive Performance package is installed in the project. The Use Adaptive Performance property lets you enable the Adaptive Performance functionality. Property Description Use Adaptive Performance Select this check box to enable the Adaptive Performance functionality, which adjusts the rendering quality at runtime."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/universalrp-builtin-feature-comparison.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/universalrp-builtin-feature-comparison.html",
    "title": "Feature comparison table | mmo-rpg-unity",
    "keywords": "Feature comparison table For an overview of the features supported in the Universal Render Pipeline (URP) compared to the other Unity render pipelines, refer to the page Render pipeline feature comparison."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/unlit-shader.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/unlit-shader.html",
    "title": "Unlit Shader | mmo-rpg-unity",
    "keywords": "Unlit Shader Use this Shader for effects or unique objects in your visuals that don’t need lighting. Because there are no time-consuming lighting calculations or lookups, this Shader is optimal for lower-end hardware. The Unlit Shader uses the most simple shading model in URP. Using the Unlit Shader in the Editor To select and use this Shader: In your Project, create or find the Material you want to use the Shader on. Select the Material. A Material Inspector window opens. Click Shader, and select Universal Render Pipeline > Unlit. UI overview The Inspector window for this Shader contains these elements: Surface Options Surface Inputs Advanced Surface Options The Surface Options control how the Material is rendered on a screen. Property Description Surface Type Use this drop-down to apply an Opaque or Transparent surface type to the Material. This determines which render pass URP renders the material in. Opaque surface types are always fully visible, regardless of what’s behind them. URP renders opaque Materials first. Transparent surface types are affected by their background, and they can vary according to which type of transparent surface type you choose. URP renders transparent Materials in a separate pass after opaque objects. If you select Transparent, the Blending Mode drop-down appears. Blending Mode Use this drop-down to determine how URP calculates the color of each pixel of the transparent Material by blending the Material with the background pixels. Alpha uses the Material’s alpha value to change how transparent an object is. 0 is fully transparent. 1 appears fully opaque, but the Material is still rendered during the Transparent render pass. This is useful for visuals that you want to be fully visible but to also fade over time, like clouds. Premultiply applies a similar effect to the Material as Alpha, but preserves reflections and highlights, even when your surface is transparent. This means that only the reflected light is visible. For example, imagine transparent glass. Additive adds an extra layer to the Material, on top of another surface. This is good for holograms. Multiply multiplies the color of the Material with the color behind the surface. This creates a darker effect, like when you view an through tinted glass. Render Face Use this drop-down to determine which sides of your geometry to render. Front Face renders the front face of your geometry and culls the back face. This is the default setting. Back Face renders the front face of your geometry and culls the front face. Both makes URP render both faces of the geometry. This is good for small, flat objects, like leaves, where you might want both sides visible. Alpha Clipping Makes your Material act like a Cutout Shader. Use this to create a transparent effect with hard edges between the opaque and transparent areas. For example, to create blades of grass. To achieve this effect, URP does not render alpha values below the specified Threshold, which appears when you enable Alpha Clipping. You can set the Threshold by moving the slider, which accepts values from 0 to 1. All values above your threshold are fully opaque, and all values below your threshold are invisible. For example, a threshold of 0.1 means that URP doesn't render alpha values below 0.1. The default value is 0.5. Surface Inputs The Surface Inputs describe the surface itself. For example, you can use these properties to make your surface look wet, dry, rough, or smooth. Property Description Base Map Adds color to the surface, also known as the diffuse map. To assign a Texture to the Base Map setting, click the object picker next to it. This opens the Asset Browser, where you can select from the Textures in your Project. Alternatively, you can use the color picker. The color next to the setting shows the tint on top of your assigned Texture. To assign another tint, you can click this color swatch. If you select Transparent or Alpha Clipping under Surface Options, your Material uses the Texture’s alpha channel or color. Tiling A 2D multiplier value that scales the Texture to fit across a mesh according to the U and V axes. This is good for surfaces like floors and walls. The default value is 1, which means no scaling. Set a higher value to make the Texture repeat across your mesh. Set a lower value to stretch the Texture. Try different values until you reach your desired effect. Offset The 2D offset that positions the Texture on the mesh. To adjust the position on your mesh, move the Texture across the U or V axes. Advanced The Advanced settings affect the underlying calculations of your rendering. They do not have a visible effect on your surface. Property Description Enable GPU Instancing Makes URP render meshes with the same geometry and Material in one batch, when possible. This makes rendering faster. URP cannot render Meshes in one batch if they have different Materials or if the hardware does not support GPU instancing. Priority Use this slider to determine the chronological rendering order for a Material. URP renders Materials with lower values first. You can use this to reduce overdraw on devices by making the pipeline render Materials in front of other Materials first, so it doesn't have to render overlapping areas twice. This works similarly to the render queue in the built-in Unity render pipeline."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-10-0-x.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-10-0-x.html",
    "title": "Upgrading to version 10.0.x of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 10.0.x of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 10.0.x. Upgrading from URP 7.2.x and later releases URP 10.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. DepthNormals Pass Starting from version 10.0.x, URP can generate a normal texture called _CameraNormalsTexture. To render to this texture in your custom shader, add a Pass with the name DepthNormals. For example, refer to the implementation in Lit.shader. Screen Space Ambient Occlusion (SSAO) URP 10.0.x implements the Screen Space Ambient Occlusion (SSAO) effect. If you intend to use the SSAO effect with your custom shaders, consider the following entities related to SSAO: The _SCREEN_SPACE_OCCLUSION keyword. Input.hlsl contains the new declaration float2 normalizedScreenSpaceUV in the InputData struct. Lighting.hlsl contains the AmbientOcclusionFactor struct with the variables for calculating indirect and direct occlusion: struct AmbientOcclusionFactor { half indirectAmbientOcclusion; half directAmbientOcclusion; }; Lighting.hlsl contains the following function for sampling the SSAO texture: half SampleAmbientOcclusion(float2 normalizedScreenSpaceUV) Lighting.hlsl contains the following function: AmbientOcclusionFactor GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) To support SSAO in custom shader, add the DepthNormals Pass and the _SCREEN_SPACE_OCCLUSION keyword the the shader. For example, refer to Lit.shader. If your custom shader implements custom lighting functions, use the function GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) to get the AmbientOcclusionFactor value for your lighting calculations. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-10-1-x.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-10-1-x.html",
    "title": "Upgrading to version 10.1.x of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 10.1.x of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 10.1.x. Upgrading from URP 10.0.x URP 10.1.x does not have breaking changes compared with URP 10.0.x. To upgrade URP to version 10.1.x, install the new version of the package. Upgrading from URP 7.2.x and later releases URP 10.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. DepthNormals Pass Starting from version 10.0.x, URP can generate a normal texture called _CameraNormalsTexture. To render to this texture in your custom shader, add a Pass with the name DepthNormals. For example, refer to the implementation in Lit.shader. Screen Space Ambient Occlusion (SSAO) URP 10.0.x implements the Screen Space Ambient Occlusion (SSAO) effect. If you intend to use the SSAO effect with your custom shaders, consider the following entities related to SSAO: The _SCREEN_SPACE_OCCLUSION keyword. Input.hlsl contains the new declaration float2 normalizedScreenSpaceUV in the InputData struct. Lighting.hlsl contains the AmbientOcclusionFactor struct with the variables for calculating indirect and direct occlusion: struct AmbientOcclusionFactor { half indirectAmbientOcclusion; half directAmbientOcclusion; }; Lighting.hlsl contains the following function for sampling the SSAO texture: half SampleAmbientOcclusion(float2 normalizedScreenSpaceUV) Lighting.hlsl contains the following function: AmbientOcclusionFactor GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) To support SSAO in custom shader, add the DepthNormals Pass and the _SCREEN_SPACE_OCCLUSION keyword the the shader. For example, refer to Lit.shader. If your custom shader implements custom lighting functions, use the function GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) to get the AmbientOcclusionFactor value for your lighting calculations. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-11-0-x.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-11-0-x.html",
    "title": "Upgrading to version 11.0.x of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 11.0.x of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 11.0.x. Upgrading from URP 10.0.x–10.2.x The file names of the following Shader Graph shaders were renamed. The new file names do not have spaces: Autodesk Interactive Autodesk Interactive Masked Autodesk Interactive Transparent If your code uses the Shader.Find() method to search for the shaders, remove spaces from the shader names, for example, Shader.Find(\"AutodeskInteractive). Upgrading from URP 7.2.x and later releases URP 11.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. DepthNormals Pass Starting from version 10.0.x, URP can generate a normal texture called _CameraNormalsTexture. To render to this texture in your custom shader, add a Pass with the name DepthNormals. For example, refer to the implementation in Lit.shader. Screen Space Ambient Occlusion (SSAO) URP 10.0.x implements the Screen Space Ambient Occlusion (SSAO) effect. If you intend to use the SSAO effect with your custom shaders, consider the following entities related to SSAO: The _SCREEN_SPACE_OCCLUSION keyword. Input.hlsl contains the new declaration float2 normalizedScreenSpaceUV in the InputData struct. Lighting.hlsl contains the AmbientOcclusionFactor struct with the variables for calculating indirect and direct occlusion: struct AmbientOcclusionFactor { half indirectAmbientOcclusion; half directAmbientOcclusion; }; Lighting.hlsl contains the following function for sampling the SSAO texture: half SampleAmbientOcclusion(float2 normalizedScreenSpaceUV) Lighting.hlsl contains the following function: AmbientOcclusionFactor GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) To support SSAO in custom shader, add the DepthNormals Pass and the _SCREEN_SPACE_OCCLUSION keyword the the shader. For example, refer to Lit.shader. If your custom shader implements custom lighting functions, use the function GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) to get the AmbientOcclusionFactor value for your lighting calculations. Shadow Normal Bias In 11.0.x the formula used to apply Shadow Normal Bias has been slightly fix in order to work better with punctual lights. As a result, to match exactly shadow outlines from earlier revisions, the parameter might to be adjusted in some scenes. Typically, using 1.4 instead of 1.0 for a Directional light is usually enough. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-2021-2.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-2021-2.html",
    "title": "Upgrading to version 12 of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 12 of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 12.0.x. For information on converting assets made for a Built-in Render Pipeline project to assets compatible with URP, refer to the page Render Pipeline Converter. Upgrading from URP 11.x.x The Forward Renderer asset is renamed to the Universal Renderer asset. When you open an existing project in the Unity Editor containing URP 12, Unity updates the existing Forward Renderer assets to Universal Renderer assets. The Universal Renderer asset contains the property Rendering Path that lets you select the Forward or the Deferred Rendering Path. The method ClearFlag.Depth does not implicitly clear the Stencil buffer anymore. Use the new method ClearFlag.Stencil. URP 12 implements the Render Pipeline Converter feature. This feature replaces the asset upgrade functions that were previously available at Edit > Render Pipeline > Universal Render Pipeline > Upgrade... Upgrading from URP 10.0.x–10.2.x The file names of the following Shader Graph shaders were renamed. The new file names do not have spaces: Autodesk Interactive Autodesk Interactive Masked Autodesk Interactive Transparent If your code uses the Shader.Find() method to search for the shaders, remove spaces from the shader names, for example, Shader.Find(\"AutodeskInteractive). Upgrading from URP 7.2.x and later releases URP 12.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. DepthNormals Pass Starting from version 10.0.x, URP can generate a normal texture called _CameraNormalsTexture. To render to this texture in your custom shader, add a Pass with the name DepthNormals. For example, refer to the implementation in Lit.shader. Screen Space Ambient Occlusion (SSAO) URP 10.0.x implements the Screen Space Ambient Occlusion (SSAO) effect. If you intend to use the SSAO effect with your custom shaders, consider the following entities related to SSAO: The _SCREEN_SPACE_OCCLUSION keyword. Input.hlsl contains the new declaration float2 normalizedScreenSpaceUV in the InputData struct. Lighting.hlsl contains the AmbientOcclusionFactor struct with the variables for calculating indirect and direct occlusion: struct AmbientOcclusionFactor { half indirectAmbientOcclusion; half directAmbientOcclusion; }; Lighting.hlsl contains the following function for sampling the SSAO texture: half SampleAmbientOcclusion(float2 normalizedScreenSpaceUV) Lighting.hlsl contains the following function: AmbientOcclusionFactor GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) To support SSAO in custom shader, add the DepthNormals Pass and the _SCREEN_SPACE_OCCLUSION keyword the the shader. For example, refer to Lit.shader. If your custom shader implements custom lighting functions, use the function GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) to get the AmbientOcclusionFactor value for your lighting calculations. Shadow Normal Bias In 11.0.x the formula used to apply Shadow Normal Bias has been slightly fix in order to work better with punctual lights. As a result, to match exactly shadow outlines from earlier revisions, the parameter might to be adjusted in some scenes. Typically, using 1.4 instead of 1.0 for a Directional light is usually enough. Intermediate Texture In previous URP versions, URP performed the rendering via an intermediate Renderer if the Renderer had any active Renderer Features. On some platforms, this had significant performance implications. In this release, URP mitigates the issue in the following way: URP expects Renderer Features to declare their inputs using the ScriptableRenderPass.ConfigureInput method. The method provides the information that URP uses to determine automatically whether rendering via an intermediate texture is necessary. For compatibility purpose, there is a new property Intermediate Texture in the Universal Renderer. If you select Always in the property, URP uses an intermediate texture. Selecting Auto enables the new behavior. Use the Always option only if a Renderer Feature does not declare its inputs using the ScriptableRenderPass.ConfigureInput method. To ensure that existing projects work correctly, all existing Universal Renderer assets that were using any Renderer Features (excluding those included with URP) have the option Always selected in the Intermediate Texture property. Any newly created Universal Renderer assets have the option Auto selected. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. Upgrading from LWRP to 12.x.x There is no direct upgrade path from LWRP to URP 12.x.x. Follow the steps to upgrade LWRP to URP 11.x.x first, and then upgrade from URP 11.x.x to URP 12.x.x."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-2022-1.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-2022-1.html",
    "title": "Upgrading to URP 13 (Unity 2022.1) | mmo-rpg-unity",
    "keywords": "Upgrading to URP 13 (Unity 2022.1) This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to URP 13 (Unity 2022.1). For information on converting assets made for a Built-in Render Pipeline project to assets compatible with URP, refer to the page Render Pipeline Converter. Upgrading from URP 12 (Unity 2021.2) Changes to ScriptableRenderer API behavior Unity now issues an error when instances of ScriptableRendererFeature attempt to access render targets before they are allocated by the ScriptableRenderer class. The ScriptableRendererFeature class has a new virtual function SetupRenderPasses which is called when render targets are allocated and ready to be used. If your code uses the ScriptableRenderer.cameraColorTarget or the ScriptableRenderer.cameraDepthTarget property inside of the AddRenderPasses method override, you should move that implementation to the ScriptableRendererFeature.SetupRenderPasses method. The calls to the ScriptableRenderer.EnqueuePass method should still happen in the AddRenderPasses method. The following example shows how to change the code to use the new API. Code with the old API: public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { // The target is used before allocation m_CustomPass.Setup(renderer.cameraColorTarget); // Letting the renderer know which passes are used before allocation renderer.EnqueuePass(m_ScriptablePass); } Code with the new API: public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { // Letting the renderer know which passes are used before allocation renderer.EnqueuePass(m_ScriptablePass); } public override void SetupRenderPasses(ScriptableRenderer renderer, in RenderingData renderingData) { // The target is used after allocation m_CustomPass.Setup(renderer.cameraColorTarget); } The Universal Renderer is now using the RTHandle system The Universal Renderer is now using the RTHandle system for its internal targets and in its internal passes. All usages of the RenderTargetHandle struct are set as obsolete and the struct will be removed in the future. The public interfaces ScriptableRenderer.cameraColorTarget and ScriptableRenderer.cameraDepthTarget are marked as obsolete. Replace them with ScriptableRenderer.cameraColorTargetHandle and ScriptableRenderer.cameraDepthTargetHandle respectively. RTHandle targets do not use the CommandBuffer.GetTemporaryRT method and persist for more frames than the RenderTargetIdentifier structs. You cannot allocate RTHandle targets with the properties GraphicsFormat and DepthBufferBits set to any value except for 0. The cameraDepthTarget properties must be separate from the cameraColorTarget properties. The following helper functions let you create and use temporary render target with the RTHandle system in a similar way as with the GetTemporaryRT method previously: RenderingUtils.ReAllocateIfNeeded ShadowUtils.ShadowRTReAllocateIfNeeded If the render target does not change within the lifetime of the application, use the RTHandles.Alloc method to allocate an RTHandle target. This method is efficient since the code does not have to check if a render target should be allocated on each frame. If the render target is a full screen texture, which means that its resolution matches or is a fraction of the resolution of the screen, use a scaling factor such as Vector2D.one to support dynamic scaling. The following example shows how to change the code using the RenderTargetHandle API to use the new API. Code with the old API: public class CustomPass : ScriptableRenderPass { RenderTargetHandle m_Handle; // With the old API, RenderTargetIdentifier might combine color and depth RenderTargetIdentifier m_Destination; public CustomPass() { m_Handle.Init(\"_CustomPassHandle\"); } public override void OnCameraSetup(CommandBuffer cmd, ref RenderingData renderingData) { var desc = renderingData.cameraData.cameraTargetDescriptor; cmd.GetTemporaryRT(m_Handle.id, desc, FilterMode.Point); } public override void OnCameraCleanup(CommandBuffer cmd) { cmd.ReleaseTemporaryRT(m_Handle.id); } public void Setup(RenderTargetIdentifier destination) { m_Destination = destination; } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { CommandBuffer cmd = CommandBufferPool.Get(); // Set the same target for color and depth ScriptableRenderer.SetRenderTarget(cmd, m_Destination, m_Destination, clearFlag, clearColor); context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } } Code with the new API: public class CustomPass : ScriptableRenderPass { RTHandle m_Handle; // Then using RTHandles, the color and the depth properties must be separate RTHandle m_DestinationColor; RTHandle m_DestinationDepth; void Dispose() { m_Handle?.Release(); } public override void OnCameraSetup(CommandBuffer cmd, ref RenderingData renderingData) { var desc = renderingData.cameraData.cameraTargetDescriptor; // Then using RTHandles, the color and the depth properties must be separate desc.depthBufferBits = 0; RenderingUtils.ReAllocateIfNeeded(ref m_Handle, desc, FilterMode.Point, TextureWrapMode.Clamp, name: \"_CustomPassHandle\"); } public override void OnCameraCleanup(CommandBuffer cmd) { m_DestinationColor = null; m_DestinationDepth = null; } public void Setup(RTHandle destinationColor, RTHandle destinationDepth) { m_DestinationColor = destinationColor; m_DestinationDepth = destinationDepth; } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { CommandBuffer cmd = CommandBufferPool.Get(); CoreUtils.SetRenderTarget(cmd, m_DestinationColor, m_DestinationDepth, clearFlag, clearColor); context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } } Upgrading from URP 11.x.x The Forward Renderer asset is renamed to the Universal Renderer asset. When you open an existing project in the Unity Editor containing URP 12, Unity updates the existing Forward Renderer assets to Universal Renderer assets. The Universal Renderer asset contains the property Rendering Path that lets you select the Forward or the Deferred Rendering Path. The method ClearFlag.Depth does not implicitly clear the Stencil buffer anymore. Use the new method ClearFlag.Stencil. URP 12 and later implements the Render Pipeline Converter feature. This feature replaces the asset upgrade functions that were previously available at Edit > Render Pipeline > Universal Render Pipeline > Upgrade... Upgrading from URP 10.0.x–10.2.x The file names of the following Shader Graph shaders were renamed. The new file names do not have spaces: Autodesk Interactive Autodesk Interactive Masked Autodesk Interactive Transparent If your code uses the Shader.Find() method to search for the shaders, remove spaces from the shader names, for example, Shader.Find(\"AutodeskInteractive). Upgrading from URP 7.2.x and later releases URP 12.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. DepthNormals Pass Starting from version 10.0.x, URP can generate a normal texture called _CameraNormalsTexture. To render to this texture in your custom shader, add a Pass with the name DepthNormals. For example, refer to the implementation in Lit.shader. Screen Space Ambient Occlusion (SSAO) URP 10.0.x implements the Screen Space Ambient Occlusion (SSAO) effect. If you intend to use the SSAO effect with your custom shaders, consider the following entities related to SSAO: The _SCREEN_SPACE_OCCLUSION keyword. Input.hlsl contains the new declaration float2 normalizedScreenSpaceUV in the InputData struct. Lighting.hlsl contains the AmbientOcclusionFactor struct with the variables for calculating indirect and direct occlusion: struct AmbientOcclusionFactor { half indirectAmbientOcclusion; half directAmbientOcclusion; }; Lighting.hlsl contains the following function for sampling the SSAO texture: half SampleAmbientOcclusion(float2 normalizedScreenSpaceUV) Lighting.hlsl contains the following function: AmbientOcclusionFactor GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) To support SSAO in custom shader, add the DepthNormals Pass and the _SCREEN_SPACE_OCCLUSION keyword the the shader. For example, refer to Lit.shader. If your custom shader implements custom lighting functions, use the function GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) to get the AmbientOcclusionFactor value for your lighting calculations. Shadow Normal Bias In 11.0.x the formula used to apply Shadow Normal Bias has been slightly fix in order to work better with punctual lights. As a result, to match exactly shadow outlines from earlier revisions, the parameter might to be adjusted in some scenes. Typically, using 1.4 instead of 1.0 for a Directional light is usually enough. Intermediate Texture In previous URP versions, URP performed the rendering via an intermediate Renderer if the Renderer had any active Renderer Features. On some platforms, this had significant performance implications. In this release, URP mitigates the issue in the following way: URP expects Renderer Features to declare their inputs using the ScriptableRenderPass.ConfigureInput method. The method provides the information that URP uses to determine automatically whether rendering via an intermediate texture is necessary. For compatibility purpose, there is a new property Intermediate Texture in the Universal Renderer. If you select Always in the property, URP uses an intermediate texture. Selecting Auto enables the new behavior. Use the Always option only if a Renderer Feature does not declare its inputs using the ScriptableRenderPass.ConfigureInput method. To ensure that existing projects work correctly, all existing Universal Renderer assets that were using any Renderer Features (excluding those included with URP) have the option Always selected in the Intermediate Texture property. Any newly created Universal Renderer assets have the option Auto selected. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. Upgrading from LWRP to 12.x.x There is no direct upgrade path from LWRP to URP 12.x.x. Follow the steps to upgrade LWRP to URP 11.x.x first, and then upgrade from URP 11.x.x to URP 12.x.x."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-2022-2.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-2022-2.html",
    "title": "Upgrading to URP 14 (Unity 2022.2) | mmo-rpg-unity",
    "keywords": "Upgrading to URP 14 (Unity 2022.2) This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to URP 14 (Unity 2022.2). For information on converting assets made for a Built-in Render Pipeline project to assets compatible with URP, refer to the page Render Pipeline Converter. Upgrading from URP 13 (Unity 2022.1) Two shader defines were removed SHADER_QUALITY_LOW/MEDIUM/HIGH and SHADER_HINT_NICE_QUALITY shader defines were removed. If you used those defines in custom shaders, consider using SHADER_API_MOBILE or SHADER_API_GLES defines to replace SHADER_QUALITY_LOW/MEDIUM/HIGH. Upgrading from URP 12 (Unity 2021.2) Changes to ScriptableRenderer API behavior Unity now issues an error when instances of ScriptableRendererFeature attempt to access render targets before they are allocated by the ScriptableRenderer class. The ScriptableRendererFeature class has a new virtual function SetupRenderPasses which is called when render targets are allocated and ready to be used. If your code uses the ScriptableRenderer.cameraColorTarget or the ScriptableRenderer.cameraDepthTarget property inside of the AddRenderPasses method override, you should move that implementation to the ScriptableRendererFeature.SetupRenderPasses method. The calls to the ScriptableRenderer.EnqueuePass method should still happen in the AddRenderPasses method. The following example shows how to change the code to use the new API. Code with the old API: public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { // The target is used before allocation m_CustomPass.Setup(renderer.cameraColorTarget); // Letting the renderer know which passes are used before allocation renderer.EnqueuePass(m_ScriptablePass); } Code with the new API: public override void AddRenderPasses(ScriptableRenderer renderer, ref RenderingData renderingData) { // Letting the renderer know which passes are used before allocation renderer.EnqueuePass(m_ScriptablePass); } public override void SetupRenderPasses(ScriptableRenderer renderer, in RenderingData renderingData) { // The target is used after allocation m_CustomPass.Setup(renderer.cameraColorTarget); } The Universal Renderer is now using the RTHandle system The Universal Renderer is now using the RTHandle system for its internal targets and in its internal passes. All usages of the RenderTargetHandle struct are set as obsolete and the struct will be removed in the future. The public interfaces ScriptableRenderer.cameraColorTarget and ScriptableRenderer.cameraDepthTarget are marked as obsolete. Replace them with ScriptableRenderer.cameraColorTargetHandle and ScriptableRenderer.cameraDepthTargetHandle respectively. RTHandle targets do not use the CommandBuffer.GetTemporaryRT method and persist for more frames than the RenderTargetIdentifier structs. You cannot allocate RTHandle targets with the properties GraphicsFormat and DepthBufferBits set to any value except for 0. The cameraDepthTarget properties must be separate from the cameraColorTarget properties. The following helper functions let you create and use temporary render target with the RTHandle system in a similar way as with the GetTemporaryRT method previously: RenderingUtils.ReAllocateIfNeeded ShadowUtils.ShadowRTReAllocateIfNeeded If the render target does not change within the lifetime of the application, use the RTHandles.Alloc method to allocate an RTHandle target. This method is efficient since the code does not have to check if a render target should be allocated on each frame. If the render target is a full screen texture, which means that its resolution matches or is a fraction of the resolution of the screen, use a scaling factor such as Vector2D.one to support dynamic scaling. The following example shows how to change the code using the RenderTargetHandle API to use the new API. Code with the old API: public class CustomPass : ScriptableRenderPass { RenderTargetHandle m_Handle; // With the old API, RenderTargetIdentifier might combine color and depth RenderTargetIdentifier m_Destination; public CustomPass() { m_Handle.Init(\"_CustomPassHandle\"); } public override void OnCameraSetup(CommandBuffer cmd, ref RenderingData renderingData) { var desc = renderingData.cameraData.cameraTargetDescriptor; cmd.GetTemporaryRT(m_Handle.id, desc, FilterMode.Point); } public override void OnCameraCleanup(CommandBuffer cmd) { cmd.ReleaseTemporaryRT(m_Handle.id); } public void Setup(RenderTargetIdentifier destination) { m_Destination = destination; } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { CommandBuffer cmd = CommandBufferPool.Get(); // Set the same target for color and depth ScriptableRenderer.SetRenderTarget(cmd, m_Destination, m_Destination, clearFlag, clearColor); context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } } Code with the new API: public class CustomPass : ScriptableRenderPass { RTHandle m_Handle; // Then using RTHandles, the color and the depth properties must be separate RTHandle m_DestinationColor; RTHandle m_DestinationDepth; void Dispose() { m_Handle?.Release(); } public override void OnCameraSetup(CommandBuffer cmd, ref RenderingData renderingData) { var desc = renderingData.cameraData.cameraTargetDescriptor; // Then using RTHandles, the color and the depth properties must be separate desc.depthBufferBits = 0; RenderingUtils.ReAllocateIfNeeded(ref m_Handle, desc, FilterMode.Point, TextureWrapMode.Clamp, name: \"_CustomPassHandle\"); } public override void OnCameraCleanup(CommandBuffer cmd) { m_DestinationColor = null; m_DestinationDepth = null; } public void Setup(RTHandle destinationColor, RTHandle destinationDepth) { m_DestinationColor = destinationColor; m_DestinationDepth = destinationDepth; } public override void Execute(ScriptableRenderContext context, ref RenderingData renderingData) { CommandBuffer cmd = CommandBufferPool.Get(); CoreUtils.SetRenderTarget(cmd, m_DestinationColor, m_DestinationDepth, clearFlag, clearColor); context.ExecuteCommandBuffer(cmd); CommandBufferPool.Release(cmd); } } Upgrading from URP 11.x.x The Forward Renderer asset is renamed to the Universal Renderer asset. When you open an existing project in the Unity Editor containing URP 12, Unity updates the existing Forward Renderer assets to Universal Renderer assets. The Universal Renderer asset contains the property Rendering Path that lets you select the Forward or the Deferred Rendering Path. The method ClearFlag.Depth does not implicitly clear the Stencil buffer anymore. Use the new method ClearFlag.Stencil. URP 12 and later implements the Render Pipeline Converter feature. This feature replaces the asset upgrade functions that were previously available at Edit > Render Pipeline > Universal Render Pipeline > Upgrade... Upgrading from URP 10.0.x–10.2.x The file names of the following Shader Graph shaders were renamed. The new file names do not have spaces: Autodesk Interactive Autodesk Interactive Masked Autodesk Interactive Transparent If your code uses the Shader.Find() method to search for the shaders, remove spaces from the shader names, for example, Shader.Find(\"AutodeskInteractive). Upgrading from URP 7.2.x and later releases URP 12.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. DepthNormals Pass Starting from version 10.0.x, URP can generate a normal texture called _CameraNormalsTexture. To render to this texture in your custom shader, add a Pass with the name DepthNormals. For example, refer to the implementation in Lit.shader. Screen Space Ambient Occlusion (SSAO) URP 10.0.x implements the Screen Space Ambient Occlusion (SSAO) effect. If you intend to use the SSAO effect with your custom shaders, consider the following entities related to SSAO: The _SCREEN_SPACE_OCCLUSION keyword. Input.hlsl contains the new declaration float2 normalizedScreenSpaceUV in the InputData struct. Lighting.hlsl contains the AmbientOcclusionFactor struct with the variables for calculating indirect and direct occlusion: struct AmbientOcclusionFactor { half indirectAmbientOcclusion; half directAmbientOcclusion; }; Lighting.hlsl contains the following function for sampling the SSAO texture: half SampleAmbientOcclusion(float2 normalizedScreenSpaceUV) Lighting.hlsl contains the following function: AmbientOcclusionFactor GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) To support SSAO in custom shader, add the DepthNormals Pass and the _SCREEN_SPACE_OCCLUSION keyword the the shader. For example, refer to Lit.shader. If your custom shader implements custom lighting functions, use the function GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) to get the AmbientOcclusionFactor value for your lighting calculations. Shadow Normal Bias In 11.0.x the formula used to apply Shadow Normal Bias has been slightly fix in order to work better with punctual lights. As a result, to match exactly shadow outlines from earlier revisions, the parameter might to be adjusted in some scenes. Typically, using 1.4 instead of 1.0 for a Directional light is usually enough. Intermediate Texture In previous URP versions, URP performed the rendering via an intermediate Renderer if the Renderer had any active Renderer Features. On some platforms, this had significant performance implications. In this release, URP mitigates the issue in the following way: URP expects Renderer Features to declare their inputs using the ScriptableRenderPass.ConfigureInput method. The method provides the information that URP uses to determine automatically whether rendering via an intermediate texture is necessary. For compatibility purpose, there is a new property Intermediate Texture in the Universal Renderer. If you select Always in the property, URP uses an intermediate texture. Selecting Auto enables the new behavior. Use the Always option only if a Renderer Feature does not declare its inputs using the ScriptableRenderPass.ConfigureInput method. To ensure that existing projects work correctly, all existing Universal Renderer assets that were using any Renderer Features (excluding those included with URP) have the option Always selected in the Intermediate Texture property. Any newly created Universal Renderer assets have the option Auto selected. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. Upgrading from LWRP to 12.x.x There is no direct upgrade path from LWRP to URP 12.x.x. Follow the steps to upgrade LWRP to URP 11.x.x first, and then upgrade from URP 11.x.x to URP 12.x.x."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-7-2-0.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-7-2-0.html",
    "title": "Upgrading to version 7.2.0 of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 7.2.0 of the Universal Render Pipeline On this page, you will find information about upgrading from an older version of the Universal Render Pipeline (URP) to the current version. Building your Project for consoles To build a Project for a console, you need to install an additional package for each platform you want to support. For more information, refer to the documentation on Building for Consoles. Require Depth Texture In previous versions of URP, if post-processing was enabled it would cause the pipeline to always require depth. We have improved the post-processing integration to only require depth from the pipeline when Depth of Field, Motion Blur or SMAA effects are enabled. This improves performance in many cases. Because Cameras that use post-processing no longer require depth by default, you must now manually indicate that Cameras require depth if you are using it for other effects, such as soft particles. To make all Cameras require depth, enable the the Depth Texture option in the Pipeline Asset. To make an individual Camera require depth, set Depth Texture option to On in the Camera Inspector. Sampling shadows from the Main Light In previous versions of URP, if shadow cascades were enabled for the main Light, shadows would be resolved in a screen space pass. The pipeline now always resolves shadows while rendering opaque or transparent objects. This allows for consistency and solved many issues regarding shadows. If have custom HLSL shaders and sample _ScreenSpaceShadowmapTexture texture, you must upgrade them to sample shadows by using the GetMainLight function instead. For example: float4 shadowCoord = TransformWorldToShadowCoord(positionWorldSpace); Light mainLight = GetMainLight(inputData.shadowCoord); // now you can use shadow to apply realtime occlusion half shadow = mainLight.shadowAttenuation; You must also define the following in your .shader file to make sure your custom shader can receive shadows correctly: #pragma multi_compile _ _MAIN_LIGHT_SHADOWS #pragma multi_compile _ _MAIN_LIGHT_SHADOWS_CASCADE Transparent receiving shadows Transparent objects can now receive shadows when using shadow cascades. You can also optionally disable shadow receiving for transparent to improve performance. To do so, disable Transparent Receive Shadows in the Forward Renderer asset."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-7-3-0.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-7-3-0.html",
    "title": "Upgrading to version 7.3.0 of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 7.3.0 of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 7.3.0. Upgrading from URP 7.2.x URP 7.3.0 does not have breaking changes compared with URP 7.2.x. To upgrade URP to version 7.3.0, install the new version of the package. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. Perform the procedure Upgrading from URP 7.2.x."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-7-4-0.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-7-4-0.html",
    "title": "Upgrading to version 7.4.0 of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 7.4.0 of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 7.4.0. Upgrading from URP 7.2.x and later URP 7.4.0 does not have breaking changes compared with URP 7.2.x and later. To upgrade URP to version 7.4.0, install the new version of the package. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. Perform the procedure Upgrading from URP 7.2.x."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-8-0-0.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-8-0-0.html",
    "title": "Upgrading to version 8.0.0 of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 8.0.0 of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 8.0.0. Upgrading from URP 7.2.x and later URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use this package first. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use this package first."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-8-1-0.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-8-1-0.html",
    "title": "Upgrading to version 8.1.x of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 8.1.x of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 8.1.x. Upgrading from URP 8.0.x URP 8.1.x does not have breaking changes compared with URP 8.0.x. To upgrade URP to version 8.1.x, install the new version of the package. Upgrading from URP 7.2.x and later 7.x releases URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use this package first. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use this package first."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-8-2-0.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-8-2-0.html",
    "title": "Upgrading to version 8.2.x of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 8.2.x of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 8.2.x. Upgrading from URP 8.0.x-8.1.x URP 8.2.x does not have breaking changes compared with URP 8.0.x. To upgrade URP to version 8.2.x, install the new version of the package. Upgrading from URP 7.2.x and later 7.x releases URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use this package first. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use this package first."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-9-0-x.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guide-9-0-x.html",
    "title": "Upgrading to version 9.0.x of the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading to version 9.0.x of the Universal Render Pipeline This page describes how to upgrade from an older version of the Universal Render Pipeline (URP) to version 9.0.x. Upgrading from URP 8.0.x and later 8.x releases URP 9.0.x does not have breaking changes compared with URP 8.x.x. To upgrade URP to version 9.0.x, install the new version of the package. Upgrading from URP 7.2.x and later 7.x releases URP 9.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first. Upgrading from URP 7.0.x-7.1.x Upgrade to URP 7.2.0 first. Refer to Upgrading to version 7.2.0 of the Universal Render Pipeline. URP 8.x.x does not support the package Post-Processing Stack v2. If your Project uses the package Post-Processing Stack v2, migrate the effects that use that package first."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guides.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-guides.html",
    "title": "Upgrade guides | mmo-rpg-unity",
    "keywords": "Upgrade guides This section contains information about upgrading from an older version of the Universal Render Pipeline (URP) to a more recent version, and about upgrading from the Lightweight Render Pipeline (LWRP) to URP. For information on converting assets made for a Built-in Render Pipeline project to assets compatible with URP, refer to the page Render Pipeline Converter. Upgrading to URP 2022.2 Upgrading to URP 2022.1 Upgrading to URP 2021.2 Upgrading to URP 11.0.x Upgrading to URP 10.1.x Upgrading to URP 10.0.x Upgrading to URP 9.0.x Upgrading to URP 8.1.0 Upgrading to URP 8.0.0 Upgrading to URP 7.4.0 Upgrading to URP 7.3.0 Upgrading to URP 7.2.0 Upgrading from LWRP to URP"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-lwrp-to-urp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrade-lwrp-to-urp.html",
    "title": "Upgrading from the Lightweight Render Pipeline to the Universal Render Pipeline | mmo-rpg-unity",
    "keywords": "Upgrading from the Lightweight Render Pipeline to the Universal Render Pipeline The Universal Render Pipeline (URP) replaces the Lightweight Render Pipeline (LWRP) in Unity 2019.3. If your Project uses LWRP, you must upgrade it to use URP to use Unity 2019.3. Unity upgrades some things automatically, and you must make some manual changes. Follow the steps in this guide to transition from using LWRP to using URP. Before upgrading Update Assembly Definition Assets URP uses GUIDs instead of Assembly Definition string names. If you are using Assembly Definition Assets (ASMDefs) in your Project, you should ensure that Use GUIDs is enabled on each of them. Unity upgrades any existing string references to LWRP automatically as part of the upgrade process, but it is best practice to use GUIDs on your Assembly Definition Assets for future proofing. For each Assembly Definition Asset in your Project: Select the Assembly Defintion Asset In the Inspector, enable Use GUIDs For information on using Assembly Definition files, refer to the documentation on Assembly Definitions. Upgrade process Upgrading your version of LWRP To start the upgrade process: Open the Project you want to upgrade in Unity 2019.3 Unity automatically updates LWRP to a 7.x.x version, and pulls in the URP package as a dependency of the updated LWRP package. The Unity script updater automatically upgrades your script files. When the script updater has finished, all of your scripts should compile properly. Upgrading the Shader search path If your LWRP Project uses Shader.Find to search for LWRP Shaders, you need to change the search path. To do this: Change all instances of Shader.Find that search for Lightweight to search for Universal. Upgrading custom shaders Upgrading tags URP uses its own scripting tags. If your Shaders use the LWRP LightMode tags, they will work in your URP Project, because Unity uses an internal alias for this. However, you should change the tags manually to future-proof your Project. To do this: Change all instances of Lightweight2D tag to Universal2D. Change all instances of LightweightForward tag to UniversalForward. In addition to this, URP also uses a different RenderPipeline tag to LWRP. If your own Shaders include this tag, you need to change it manually for the Shaders to work: Change all instances of LightweightPipeline tag to UniversalPipeline. Upgrading Shader names The following Shader names have been changed for URP, so you need to manually update your Shader files: Change all instances of UsePass 'Lightweight Render Pipeline/...' to UsePass 'Universal Render Pipeline/...' Upgrading include paths URP uses different include paths to LWRP. LWRP 7.x.x contains forwarding includes, so your custom Shaders will upgrade from LWRP to URP. However, URP 7.x.x does not contain forwarding includes, so you must then manually update the include paths. Change all instances of #include 'Packages/com.unity.render-pipelines.lightweight/xxx' to #include 'Packages/com.unity.render-pipelines.universal/xxx' Upgrading namespaces In the .cs files in your Project, find and replace references to the LWRP namespace with the new Universal namespace. Change all instances of UnityEditor.Rendering.LWRP.xxx to now UnityEditor.Rendering.Universal.xxx Upgrading post-processing effects URP version 7.x supports both Post Processing Stack v2 (PPv2) and its own integrated post-processing solution. If you have the Post Processing Version 2 package installed in your Project and you want to use URP's integrated post-processing solution, you need to delete the Post Processing Stack v2 package before you install URP into your Project. When you have installed URP, you can then recreate your post-processing effects. Upgrading post-processing effects from LWRP to URP is a manual process. You must manually recreate each Post-Processing Profile in your Project, using URP's post-processing implementation. URP's integrated post-processing solution does not currently support custom post-processing effects. If your Project uses custom post-processing effects, these cannot currently be recreated in URP's integrated post-processing solution. Custom post-processing effects will be supported in a forthcoming release of URP. Installing URP and removing LWRP As part of the automatic upgrade process, Unity installed URP as a dependency of LWRP. You must now install URP as a dependency of the Project itself, so that when you remove LWRP, Unity does not automatically remove URP. To install URP as a dependency of the Project: Go to menu: Window > Package Manager. Locate the Universal RP package, and note the version number to the right of its name. This is the version of URP that has been added to your Project. Close Unity. In your file explorer, open the root folder of your Unity Project. Open the Packages folder, and locate manifest.json. This is your Project's Project Manifest file. Open the Project Manifest file using a text editor. At the top of the dependencies section, add the following entry: \"com.unity.render-pipelines.universal\": \"[Version number you noted earlier]\" So, for example, if the version of URP was 7.1.1, your dependencies section would look like this: \"dependencies\": { \"com.unity.render-pipelines.universal\": \"7.1.1\", ... } This marks the version of URP that you have installed as a dependency of the Project. You can now safely remove LWRP. Open your Project in Unity. Open the Package Manager Window. Locate Lightweight RP and select it. In the bottom right of the Package Manager window, click Remove. Unity completely removes the LWRP package from the Project."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrading-your-shaders.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/upgrading-your-shaders.html",
    "title": "Converting your shaders | mmo-rpg-unity",
    "keywords": "Converting your shaders Shaders written for the Built-in Render Pipeline are not compatible with Universal Render Pipeline (URP) shaders. Unity renders objects with the default magenta error shader if they use Built-In Render Pipeline shaders. Use the Render Pipeline Converter to convert any of Unity's built-in Built-In Render Pipeline materials and shaders to a URP material and shader. Refer to Shader mappings for more information. Note: The Render Pipeline Converter makes irreversible changes to the project. Back up your project before the conversion. Tip: If the preview thumbnails in the Project view are not shown correctly after the conversion, try right-clicking anywhere in the Project view and selecting Reimport All. For SpeedTree Shaders, Unity does not re-generate Materials when you re-import them, unless you click the Generate Materials or Apply & Generate Materials button. Custom shaders You cannot upgrade Custom Unity shaders written for the Built-in Render Pipeline. Instead, custom shaders must be rewritten to work with URP or recreated in ShaderGraph. For an example of how to rewrite and upgrade a Built-In Render Pipeline custom shader to be compatible with URP, refer to Upgrade custom shaders for URP compatibility. Any Materials in a Scene that use a custom shader when you upgrade a project to use URP turn pink to indicate the Material no longer works. To fix this, upgrade or change the Material's shader to one that is compatible with URP. Note: URP does not support Surface Shaders. Shader mappings The following table shows which URP shaders the Built-in Render Pipeline shaders convert to when you use the Render Pipeline Converter. Unity built-in shader Universal Render Pipeline shader Standard Universal Render Pipeline/Lit Standard (Specular Setup) Universal Render Pipeline/Lit Standard Terrain Universal Render Pipeline/Terrain/Lit Particles/Standard Surface Universal Render Pipeline/Particles/Lit Particles/Standard Unlit Universal Render Pipeline/Particles/Unlit Mobile/Diffuse Universal Render Pipeline/Simple Lit Mobile/Bumped Specular Universal Render Pipeline/Simple Lit Mobile/Bumped Specular(1 Directional Light) Universal Render Pipeline/Simple Lit Mobile/Unlit (Supports Lightmap) Universal Render Pipeline/Simple Lit Mobile/VertexLit Universal Render Pipeline/Simple Lit Legacy Shaders/Diffuse Universal Render Pipeline/Simple Lit Legacy Shaders/Specular Universal Render Pipeline/Simple Lit Legacy Shaders/Bumped Diffuse Universal Render Pipeline/Simple Lit Legacy Shaders/Bumped Specular Universal Render Pipeline/Simple Lit Legacy Shaders/Self-Illumin/Diffuse Universal Render Pipeline/Simple Lit Legacy Shaders/Self-Illumin/Bumped Diffuse Universal Render Pipeline/Simple Lit Legacy Shaders/Self-Illumin/Specular Universal Render Pipeline/Simple Lit Legacy Shaders/Self-Illumin/Bumped Specular Universal Render Pipeline/Simple Lit Legacy Shaders/Transparent/Diffuse Universal Render Pipeline/Simple Lit Legacy Shaders/Transparent/Specular Universal Render Pipeline/Simple Lit Legacy Shaders/Transparent/Bumped Diffuse Universal Render Pipeline/Simple Lit Legacy Shaders/Transparent/Bumped Specular Universal Render Pipeline/Simple Lit Legacy Shaders/Transparent/Cutout/Diffuse Universal Render Pipeline/Simple Lit Legacy Shaders/Transparent/Cutout/Specular Universal Render Pipeline/Simple Lit Legacy Shaders/Transparent/Cutout/Bumped Diffuse Universal Render Pipeline/Simple Lit Legacy Shaders/Transparent/Cutout/Bumped Specular Universal Render Pipeline/Simple Lit"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-concepts.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-concepts.html",
    "title": "URP Concepts | mmo-rpg-unity",
    "keywords": "URP Concepts This section describes the concepts and settings that let you configure the Universal Render Pipeline. This section contains the following topics: The Universal Render Pipeline Asset Universal Renderer Renderer Feature How to add a Renderer Feature"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-global-settings.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-global-settings.html",
    "title": "URP Global Settings | mmo-rpg-unity",
    "keywords": "URP Global Settings If a project has the URP package installed, Unity shows the URP Global Settings section in the Graphics tab in the Project Settings window. The URP Global Settings section lets you define project-wide settings for URP. The section contains the following settings. Rendering Layers (3D) Use this section to define the names of Rendering Layers. Rendering Layers only work with 3D Renderers. Shader Stripping The check boxes in this section define which shader variants Unity strips when you build the Player. Property Description Shader Variant Log Level Select what information about Shader variants Unity saves in logs when you build your Unity Project. Options: • Disabled: Unity doesn't save any shader variant information. • Only SRP Shaders: Unity saves only shader variant information for URP shaders. • All Shaders: Unity saves shader variant information for every shader type. Strip Debug Variants When enabled, Unity strips all debug view shader variants when you build the Player. This decreases build time, but prevents the use of Rendering Debugger in Player builds. Strip Unused Post Processing Variants When enabled, Unity assumes that the Player does not create new Volume Profiles at runtime. With this assumption, Unity only keeps the shader variants that the existing Volume Profiles use, and strips all the other variants. Unity keeps shader variants used in Volume Profiles even if the Scenes in the project do not use the Profiles. Strip Unused Variants When enabled, Unity performs shader stripping in a more efficient way. This option reduces the amount of shader variants in the Player by a factor of 2 if the project uses the following URP features: Rendering Layers Native Render Pass Reflection Probe Blending Reflection Probe Box Projection SSAO Renderer Feature Decal Renderer Feature Certain post-processing effects Disable this option only if you see issues in the Player. Strip Screen Coord Override Variants When enabled, Unity strips Screen Coordinates Override shader variants in Player builds."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-lighting-mode.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-lighting-mode.html",
    "title": "Lighting Mode | mmo-rpg-unity",
    "keywords": "Lighting Mode The Lighting Mode that you choose in the Lighting window determines the behavior of all Mixed Lights in the current Scene. URP supports the following Lighting Modes: Baked Indirect Subtractive Shadowmask"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-optimization.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-optimization.html",
    "title": "Optimization and debugging | mmo-rpg-unity",
    "keywords": "Optimization and debugging This section contains information related to optimization and debugging. This section contains the following topics: Rendering Debugger Optimize for better performance Update Quality Setting Presets for URP"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-renderer-feature-how-to-add.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-renderer-feature-how-to-add.html",
    "title": "How to add a Renderer Feature to a Renderer | mmo-rpg-unity",
    "keywords": "How to add a Renderer Feature to a Renderer To add a Renderer Feature to a Renderer: In the Project window, select a Renderer. The Inspector window shows the Renderer properties. In the Inspector window, select Add Renderer Feature. In the list, select a Renderer Feature. Unity adds the selected Renderer Feature to the Renderer. Unity shows Renderer Features as child items of the Renderer in the Project Window:"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-renderer-feature.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-renderer-feature.html",
    "title": "Pre-built effects (Renderer Features) | mmo-rpg-unity",
    "keywords": "Pre-built effects (Renderer Features) A Renderer Feature is an asset that lets you add a built-in effect to a Universal Render Pipeline (URP) Renderer, and configure its behavior. For examples of how to use Renderer Features, refer to the Renderer Features samples in URP Package Samples. Page Description How to add a Renderer Feature Add a Renderer Feature to a Renderer. Render Objects Renderer Feature Draw objects on a certain layer, at a certain time, with specific overrides. Decal Renderer Feature Project specific materials (decals) onto other objects in the scene. Decals interact with the scene's lighting and wrap around meshes. Screen Space Ambient Occlusion (SSAO) Renderer Feature Darken creases, holes, intersections, and surfaces that are close to each other, in realtime. Screen Space Shadows Renderer Feature Calculate screen-space shadows for opaque objects affected by the main directional light and draw them in the scene. Full Screen Pass Renderer Feature Reference for the Full Screen Pass Renderer Feature."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-shaders/birp-urp-custom-shader-upgrade-guide.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-shaders/birp-urp-custom-shader-upgrade-guide.html",
    "title": "Upgrade custom shaders for URP compatibility | mmo-rpg-unity",
    "keywords": "Upgrade custom shaders for URP compatibility Custom Shaders written for the Built-In Render Pipeline are not compatible with the Universal Render Pipeline (URP), and you can't upgrade them automatically with the Render Pipeline Converter. Instead, you must rewrite the incompatible sections of shader code to work with URP. You can also recreate custom shaders in Shader Graph. For more information, refer to documentation on ShaderGraph. Note: You can identify any materials in a scene that use custom shaders when you upgrade to URP as they turn magenta (bright pink) to indicate an error. This guide demonstrates how to upgrade a custom unlit shader from Built-In Render Pipeline to be fully compatible with URP through the following sections: Example Built-In Render Pipeline custom shader Make the custom shader URP compatible Enable tiling and offset for the shader Complete shader code Example Built-In Render Pipeline custom shader The following shader is a simple unlit shader that works with the Built-In Render Pipeline. This guide demonstrates how to upgrade this shader to be compatible with URP. Shader \"Custom/UnlitShader\" { Properties { [NoScaleOffset] _MainTex(\"Main Texture\", 2D) = \"white\" {} _Color(\"Color\", Color) = (1,1,1,1) } SubShader { Tags { \"RenderType\" = \"Opaque\" } Pass { CGPROGRAM #pragma vertex vert #pragma fragment frag #include \"UnityCG.cginc\" struct v2f { float4 position : SV_POSITION; float2 uv: TEXCOORD0; }; float4 _Color; sampler2D _MainTex; v2f vert(appdata_base v) { v2f o; o.position = UnityObjectToClipPos(v.vertex); o.uv = v.texcoord; return o; } fixed4 frag(v2f i) : SV_Target { fixed4 texel = tex2D(_MainTex, i.uv); return texel * _Color; } ENDCG } } } Make the custom shader URP compatible Built-In Render Pipeline shaders have two issues, which you can see in the Inspector window: A warning that Material property is found in another cbuffer. The SRP Batcher property displays not compatible. The following steps show how to solve these issues and make a shader compatible with URP and the SRP Batcher. Change CGPROGRAM and ENDCG to HLSLPROGRAM and ENDHLSL. Update the include statement to reference the Core.hlsl file. #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" Note: Core.hlsl includes the core SRP library, URP shader variables, and matrix defines and transformations, but it does not include lighting functions or default structs. Add \"RenderPipeline\" = \"UniversalPipeline\" to the shader tags. Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Note: URP does not support all ShaderLab tags. For more information on which tags URP supports, refer to URP ShaderLab Pass tags. Replace the struct v2f code block with the following struct Varyings code block. This changes the struct to use the URP naming convention of Varyings instead of v2f, and updates the shader to use the correct variables for URP. struct Varyings { // The positions in this struct must have the SV_POSITION semantic. float4 positionHCS : SV_POSITION; float2 uv : TEXCOORD0; }; Beneath the include statement and above the Varyings struct, define a new struct with the name Attributes. This is equivalent to the Built-In Render Pipeline's appdata structs but with the new URP naming conventions. Add the variables shown below to the Attributes struct. struct Attributes { float4 positionOS : POSITION; float2 uv : TEXCOORD0; }; Update the v2f vert function definition to use the new Varyings struct and take an instance of the Attributes struct as an input, as shown below. Varyings vert(Attributes IN) Update the vert function to output an instance of the Varyings struct and use the TransformObjectToHClip function to convert from object space to clip space. The function also needs to take the input Attributes UV and pass it to the output Varyings UV. Varyings vert(Attributes IN) { Varyings OUT; OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz); OUT.uv = IN.uv; return OUT; } Note: URP shaders use suffixes to indicate the space. OS means object space, and HCS means homogeneous clip space. Place a CBUFFER code block around the properties the shader uses, along with the UnityPerMaterial parameter. CBUFFER_START(UnityPerMaterial) float4 _Color; sampler2D _MainTex; CBUFFER_END Note: For a shader to be SRP Batcher compatible, you must declare all material properties within a CBUFFER code block. Even if a shader has multiple passes, all passes must use the same CBUFFER block. Update the frag function to use the Varyings input and the type half4, as shown below. The frag function must now use this type, as URP shaders do not support fixed types. half4 frag(Varyings IN) : SV_Target { half4 texel = tex2D(_MainTex, IN.uv); return texel * _Color; } This custom unlit shader is now compatible with the SRP Batcher and ready for use within URP. You can check this in the Inspector window: The warning that Material property is found in another cbuffer no longer appears. The SRP Batcher property displays compatible. Enable tiling and offset for the shader Although the shader is now compatible with URP and the SRP Batcher, you can't use use the Tiling and Offset properties without further changes. To add this functionality to the custom unlit shader, use the following steps. Rename the property _MainTex to _BaseMap along with any references to this property. This brings the shader code closer to standard URP shader conventions. Remove the [NoScaleOffset] ShaderLab attribute from the _BaseMap property. You can now see Tiling and Offset properties in the shader's Inspector window. Add the [MainTexture] ShaderLab attribute to the _BaseMap property and the [MainColor] attribute to the _Color property. This tells the Editor which property to return when you request the main texture or main color from another part of your project or in the Editor. The Properties section of your shader should now look as follows: Properties { [MainTexture] _BaseMap(\"Main Texture\", 2D) = \"white\" {} [MainColor] _Color(\"Color\", Color) = (1,1,1,1) } Add the TEXTURE2D(_BaseMap) and SAMPLER(sampler_BaseMap) macros above the CBUFFER block. These macros define the texture and sampler state variables for use later. For more information on sampler states, refer to Using sampler states. TEXTURE2D(_BaseMap); SAMPLER(sampler_BaseMap); Change the sampler2D _BaseMap variable inside the CBUFFER block to float4 _BaseMap_ST. This variable now stores the tiling and offset values set in the Inspector. CBUFFER_START(UnityPerMaterial) float4 _Color; float4 _BaseMap_ST; CBUFFER_END Change the frag function to access the texture with a macro instead of tex2D directly. To do this, replace tex2D with the SAMPLE_TEXTURE2D macro and add sampler_BaseMap as an additional parameter, as shown below: half4 frag(Varyings IN) : SV_Target { half4 texel = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, IN.uv); return texel * _Color; } In the vert function, change OUT.uv to use a macro instead of passing the texture coordinates as IN.uv directly. To do this, replace IN.uv with TRANSFORM_TEX(IN.uv, _BaseMap). Your vert function should now look like the following example: Varyings vert(Attributes IN) { Varyings OUT; OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz); OUT.uv = TRANSFORM_TEX(IN.uv, _BaseMap); return OUT; } Note: It's important that you define the vert function after the CBUFFER block, as the TRANSFORM_TEX macro uses the parameter with the _ST suffix. This shader now has a texture, modified by a color, and is fully SRP Batcher compatible. It also fully supports the Tiling and Offset properties. To see an example of the complete shader code, refer to the Complete shader code section of this page. Complete shader code Shader \"Custom/UnlitShader\" { Properties { _BaseMap(\"Base Map\", 2D) = \"white\" {} _Color(\"Color\", Color) = (1,1,1,1) } SubShader { Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { HLSLPROGRAM #pragma vertex vert #pragma fragment frag #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" struct Attributes { float4 positionOS : POSITION; float2 uv: TEXCOORD0; }; struct Varyings { float4 positionCS : SV_POSITION; float2 uv: TEXCOORD0; }; TEXTURE2D(_BaseMap); SAMPLER(sampler_BaseMap); CBUFFER_START(UnityPerMaterial) float4 _Color; float4 _BaseMap_ST; CBUFFER_END Varyings vert(Attributes IN) { Varyings OUT; OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz); OUT.uv = TRANSFORM_TEX(IN.uv, _BaseMap); return OUT; } half4 frag(Varyings IN) : SV_Target { float4 texel = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, IN.uv); return texel * _Color; } ENDHLSL } } }"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-shaders/urp-shaderlab-pass-tags.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-shaders/urp-shaderlab-pass-tags.html",
    "title": "URP ShaderLab Pass tags | mmo-rpg-unity",
    "keywords": "URP ShaderLab Pass tags This section contains descriptions of URP-specific ShaderLab Pass tags. NOTE: URP does not support the following LightMode tags: Always, ForwardAdd, PrepassBase, PrepassFinal, Vertex, VertexLMRGBM, VertexLM. LightMode The value of this tag lets the pipeline determine which Pass to use when executing different parts of the Render Pipeline. If you do not set the LightMode tag in a Pass, URP uses the SRPDefaultUnlit tag value for that Pass. The LightMode tag can have the following values. Property Description UniversalForward The Pass renders object geometry and evaluates all light contributions. URP uses this tag value in the Forward Rendering Path. UniversalGBuffer The Pass renders object geometry without evaluating any light contribution. Use this tag value in Passes that Unity must execute in the Deferred Rendering Path. UniversalForwardOnly The Pass renders object geometry and evaluates all light contributions, similarly to when LightMode has the UniversalForward value. The difference from UniversalForward is that URP can use the Pass for both the Forward and the Deferred Rendering Paths. Use this value if a certain Pass must render objects with the Forward Rendering Path when URP is using the Deferred Rendering Path. For example, use this tag if URP renders a Scene using the Deferred Rendering Path and the Scene contains objects with shader data that does not fit the GBuffer, such as Clear Coat normals. If a shader must render in both the Forward and the Deferred Rendering Paths, declare two Passes with the UniversalForward and UniversalGBuffer tag values. If a shader must render using the Forward Rendering Path regardless of the Rendering Path that the URP Renderer uses, declare only a Pass with the LightMode tag set to UniversalForwardOnly. If you use the SSAO Renderer Feature, add a Pass with the LightMode tag set to DepthNormalsOnly. For more information, refer to the DepthNormalsOnly value. DepthNormalsOnly Use this value in combination with UniversalForwardOnly in the Deferred Rendering Path. This value lets Unity render the shader in the Depth and normal prepass. In the Deferred Rendering Path, if the Pass with the DepthNormalsOnly tag value is missing, Unity does not generate the ambient occlusion around the Mesh. Universal2D The Pass renders objects and evaluates 2D light contributions. URP uses this tag value in the 2D Renderer. ShadowCaster The Pass renders object depth from the perspective of lights into the Shadow map or a depth texture. DepthOnly The Pass renders only depth information from the perspective of a Camera into a depth texture. Meta Unity executes this Pass only when baking lightmaps in the Unity Editor. Unity strips this Pass from shaders when building a Player. SRPDefaultUnlit Use this LightMode tag value to draw an extra Pass when rendering objects. Application example: draw an object outline. This tag value is valid for both the Forward and the Deferred Rendering Paths. URP uses this tag value as the default value when a Pass does not have a LightMode tag. UniversalMaterialType Unity uses this tag in the Deferred Rendering Path. The UniversalMaterialType tag can have the following values. If this tag is not set in a Pass, Unity uses the Lit value. Property Description Lit This value indicates that the shader type is Lit. During the G-buffer Pass, Unity uses stencil to mark the pixels that use the Lit shader type (specular model is PBR). Unity uses this value by default, if the tag is not set in a Pass. SimpleLit This value indicates that the shader type is SimpleLit. During the G-buffer Pass, Unity uses stencil to mark the pixels that use the SimpleLit shader type (specular model is Blinn-Phong)."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-universal-renderer.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/urp-universal-renderer.html",
    "title": "Universal Renderer | mmo-rpg-unity",
    "keywords": "Universal Renderer This page describes the URP Universal Renderer settings. For more information on rendering in URP, refer to Rendering in the Universal Render Pipeline. Rendering Paths The URP Universal Renderer implements three Rendering Paths: Forward Rendering Path. Forward+ Rendering Path. Deferred Rendering Path. Rendering Path comparison Each rendering path uses a different set of steps to calculate lighting and draw objects. Which rendering path you choose affects the performance of your game and lighting options. Forward rendering path: URP draws each object one by one. For each object, URP checks every light that affects it to calculate how the object looks. Forward+ rendering path: Works similarly to the Forward rendering path, but lets you use many more lights without affecting performance. Deferred rendering path: URP first renders information about every object into multiple buffers. Then in a later ('deferred') step, URP draws each screen pixel one by one by combining the information from the buffers. The following table shows the differences between the Forward and the Deferred Rendering Paths in URP. Feature Forward Forward+ Deferred Maximum number of real-time lights per object. 9 Unlimited. The per-Camera limit applies. Unlimited Per-pixel normal encoding No encoding (accurate normal values). No encoding (accurate normal values). Two options: Quantization of normals in G-buffer (loss of accuracy, better performance). Octahedron encoding (accurate normals, might have significant performance impact on mobile GPUs). For more information, refer to the section Encoding of normals in G-buffer. MSAA Yes Yes No Vertex lighting Yes No No Camera stacking Yes Yes Supported with a limitation: Unity renders only the base Camera using the Deferred Rendering Path. Unity renders all overlay Cameras using the Forward Rendering Path. How to find the Universal Renderer asset To find the Universal Renderer asset that a URP asset is using: Select a URP asset. In the Renderer List section, click a renderer item or the vertical ellipsis icon (⋮) next to a renderer. Universal Renderer asset reference This section describes the properties of the Universal Renderer asset. Filtering This section contains properties that define which layers the renderer draws. Property Description Opaque Layer Mask Select which opaque layers this Renderer draws Transparent Layer Mask Select which transparent layers this Renderer draws Rendering This section contains properties related to rendering. Property Description Rendering Path Select the Rendering Path. Options: Forward: The Forward Rendering Path. Forward+: The Forward+ Rendering Path. Deferred: The Deferred Rendering Path. Depth Priming Mode This property determines when Unity performs depth priming. Depth Priming can improve GPU frame timings by reducing the number of pixel shader executions. The performance improvement depends on the amount of overlapping pixels in the opaque pass and the complexity of the pixel shaders that Unity can skip by using depth priming. The feature has an upfront memory and performance cost. The feature uses a depth prepass to determine which pixel shader invocations Unity can skip, and the feature adds the depth prepass if it's not available yet. The options are: Disabled: Unity does not perform depth priming. Auto: If there is a Render Pass that requires a depth prepass, Unity performs the depth prepass and depth priming. Forced: Unity always performs depth priming. To do this, Unity also performs a depth prepass for every render pass. Note: Depth priming is disabled at runtime on certain hardware (Tile Based Deferred Rendering) regardless of this setting. On Android, iOS, and Apple TV, Unity performs depth priming only in the Forced mode. On tiled GPUs, which are common to those platforms, depth priming might reduce performance when combined with MSAA. This property is available only if Rendering Path is set to Forward Accurate G-buffer normals Indicates whether to use a more resource-intensive normal encoding/decoding method to improve visual quality. This property is available only if Rendering Path is set to Deferred. Depth Texture Mode Specifies at which stage in the render pipeline URP should copy the scene depth to a depth texture. The options are: After Opaques: URP copies the scene depth after the opaques render pass. After Transparents: URP copies the scene depth after the transparents render pass. Force Prepass: URP does a depth prepass to generate the scene depth texture. Note: On mobile devices, the After Transparents option can lead to a significant improvement in memory bandwidth. This is because the Copy Depth pass causes a switch in render target between the Opaque pass and the Transparents pass. When this occurs, Unity stores the contents of the Color Buffer in the main memory, and then loads it again once the Copy Depth pass is complete. The impact increases significantly when MSAA is enabled, because Unity must also store and load the MSAA data alongside the Color Buffer. Native RenderPass This section contains properties related to URP's Native RenderPass API. Property Description Native RenderPass Indicates whether to use URP's Native RenderPass API. When enabled, URP uses this API to structure render passes. As a result, you can use programmable blending in custom URP shaders. Enable Native RenderPass if you use Vulkan or Metal graphics APIs, so URP automatically reduces how often it copies render textures into and out of memory. For more information about the RenderPass API, refer to ScriptableRenderContext.BeginRenderPass. Note: Enabling this property has no effect on OpenGL ES. Shadows This section contains properties related to rendering shadows. Property Description Transparent Receive Shadows When this option is on, Unity draws shadows on transparent objects. Overrides This section contains Render Pipeline properties that this Renderer overrides. Stencil With this check box selected, the Renderer processes the Stencil buffer values. For more information on how Unity works with the Stencil buffer, refer to ShaderLab: Stencil. In URP, you can use bits 0 to 3 of the stencil buffer for custom rendering effects. This means you can use stencil indices 0 to 15. Compatibility This section contains settings related to backwards compatibility. Property Description Intermediate Texture This property lets you force URP to renders via an intermediate texture. Options: Auto: URP uses the information provided by the ScriptableRenderPass.ConfigureInput method to determine automatically whether rendering via an intermediate texture is necessary. Always: forces rendering via an intermediate texture. Use this option only for compatibility with Renderer Features that do not declare their inputs with ScriptableRenderPass.ConfigureInput. Using this option might have a significant performance impact on some platforms. Renderer Features This section contains the list of Renderer Features assigned to the selected Renderer. For information on how to add a Renderer Feature, refer to How to add a Renderer Feature to a Renderer. URP contains the pre-built Renderer Feature called Render Objects."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-camera.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-camera.html",
    "title": "Use the camera in a custom URP shader | mmo-rpg-unity",
    "keywords": "Use the camera in a custom URP shader To use the camera in a custom Universal Render Pipeline (URP) shader, follow these steps: Add #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" inside the HLSLPROGRAM in your shader file. The Core.hlsl file imports the ShaderVariablesFunction.hlsl file. Use one of the following methods from the ShaderVariablesFunction.hlsl file. Method Syntax Description GetCameraPositionWS float3 GetCameraPositionWS() Returns the world space position of the camera. GetScaledScreenParams float4 GetScaledScreenParams() Returns the width and height of the screen in pixels. GetViewForwardDir float3 GetViewForwardDir() Returns the forward direction of the view in world space. IsPerspectiveProjection bool IsPerspectiveProjection() Returns true if the camera projection is set to perspective. LinearDepthToEyeDepth half LinearDepthToEyeDepth(half linearDepth) Converts a linear depth buffer value to view depth. Refer to Cameras and depth textures for more information. TransformScreenUV void TransformScreenUV(inout float2 screenSpaceUV) Flips the y coordinate of the screen space position, if Unity uses an upside-down coordinate space. You can also input both a uv, and the screen height as a float, so the method outputs the position scaled to the screen size in pixels. Example The following URP shader draws object surfaces with colors that represent the direction from the surface to the camera. Shader \"Custom/DirectionToCamera\" { SubShader { Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { HLSLPROGRAM #pragma vertex vert #pragma fragment frag #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" struct Attributes { float4 positionOS : POSITION; float2 uv: TEXCOORD0; }; struct Varyings { float4 positionCS : SV_POSITION; float2 uv: TEXCOORD0; float3 viewDirection : TEXCOORD2; }; Varyings vert(Attributes IN) { Varyings OUT; // Get the positions of the vertex in different coordinate spaces VertexPositionInputs positions = GetVertexPositionInputs(IN.positionOS); OUT.positionCS = positions.positionCS; // Get the direction from the vertex to the camera, in world space OUT.viewDirection = GetCameraPositionWS() - positions.positionWS.xyz; return OUT; } half4 frag(Varyings IN) : SV_Target { // Set the fragment color to the direction vector return float4(IN.viewDirection, 1); } ENDHLSL } } } Additional resources Cameras in URP Writing custom shaders Upgrade custom shaders for URP compatibility HLSL in Unity"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-import.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-import.html",
    "title": "Import a file from the URP shader library | mmo-rpg-unity",
    "keywords": "Import a file from the URP shader library The High-Level Shader Language (HLSL) shader files for the Universal Render Pipeline (URP) are in the Packages/com.unity.render-pipelines.universal/ShaderLibrary/ folder in your project. To import a shader file into a custom shader file, add an #include directive inside the HLSLPROGRAM in your shader file. For example: HLSLPROGRAM ... #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" ... ENDHLSL You can then use the helper methods from the file. For example: float3 cameraPosition = GetCameraPositionWS(); Refer to Shader methods in URP for more information about the different shader files. You can also import shader files from the core Scriptable Render Pipeline (SRP). Refer to Shader methods in Scriptable Render Pipeline (SRP) Core. Examples Refer to Writing custom shaders for examples of using variables and helper methods from the files in the URP shader library. Additional resources include and include_with_pragmas directives in HLSL"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-lighting.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-lighting.html",
    "title": "Use lighting in a custom URP shader | mmo-rpg-unity",
    "keywords": "Use lighting in a custom URP shader To use lighting in a custom Universal Render Pipeline (URP) shader, follow these steps: Add #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl\" inside the HLSLPROGRAM in your shader file. Use any of the methods from the following sections. Get light data The Lighting.hlsl file imports the RealtimeLights.hlsl file, which contains the following methods. Method Syntax Description GetMainLight Light GetMainLight() Returns the main light in the scene. GetAdditionalLight Light GetAdditionalLight(uint lightIndex, float3 positionInWorldSpace) Returns the lightIndex additional light that affects positionWS. For example, if lightIndex is 0, this method returns the first additional light. GetAdditionalLightsCount int GetAdditionalLightsCount() Returns the number of additional lights. Refer to Use shadows in a custom URP shader for information on versions of these methods you can use to calculate shadows. Calculate lighting for a surface normal Method Syntax Description LightingLambert half3 LightingLambert(half3 lightColor, half3 lightDirection, half3 surfaceNormal) Returns the diffuse lighting for the surface normal, calculated using the Lambert model. LightingSpecular half3 LightingSpecular(half3 lightColor, half3 lightDirection, half3 surfaceNormal, half3 viewDirection, half4 specularAmount, half smoothnessAmount) Returns the specular lighting for the surface normal, using simple shading. Calculate ambient occlusion The Lighting.hlsl file imports the AmbientOcclusion.hlsl file, which contains the following methods. Method Syntax Description SampleAmbientOcclusion half SampleAmbientOcclusion(float2 normalizedScreenSpaceUV) Returns the ambient occlusion value at the position in screen space, where 0 means occluded and 1 means unoccluded. GetScreenSpaceAmbientOcclusion AmbientOcclusionFactor GetScreenSpaceAmbientOcclusion(float2 normalizedScreenSpaceUV) Returns the indirect and direct ambient occlusion values at the position in screen space, where 0 means occluded and 1 means unoccluded. Refer to Ambient occlusion for more information. Structs AmbientOcclusionFactor Use the GetScreenSpaceAmbientOcclusion method to return this struct. Field Description half indirectAmbientOcclusion The amount the object is in shadow from ambient occlusion caused by objects blocking indirect light. half directAmbientOcclusion The amount the object is in shadow from ambient occlusion caused by objects blocking direct light. Light Use the GetMainLight and GetAdditionalLight methods to return this struct. Field Description half3 direction The direction of the light. half3 color The color of the light. float distanceAttenuation The strength of the light, based on its distance from the object. half shadowAttenuation The strength of the light, based on whether the object is in shadow. uint layerMask The layer mask of the light. Example The following URP shader draws object surfaces with the amount of light they receive from the main directional light. Shader \"Custom/LambertLighting\" { SubShader { Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { HLSLPROGRAM #pragma vertex vert #pragma fragment frag #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl\" struct Attributes { float4 positionOS : POSITION; float2 uv: TEXCOORD0; }; struct Varyings { float4 positionCS : SV_POSITION; float2 uv: TEXCOORD0; half3 lightAmount : TEXCOORD2; }; Varyings vert(Attributes IN) { Varyings OUT; OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz); // Get the VertexNormalInputs of the vertex, which contains the normal in world space VertexNormalInputs positions = GetVertexNormalInputs(IN.positionOS); // Get the properties of the main light Light light = GetMainLight(); // Calculate the amount of light the vertex receives OUT.lightAmount = LightingLambert(light.color, light.direction, positions.normalWS.xyz); return OUT; } half4 frag(Varyings IN) : SV_Target { // Set the fragment color to the interpolated amount of light return float4(IN.lightAmount, 1); } ENDHLSL } } } Additional resources Writing custom shaders Upgrade custom shaders for URP compatibility HLSL in Unity Diffuse Specular"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-shadows.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-shadows.html",
    "title": "Use shadows in a custom URP shader | mmo-rpg-unity",
    "keywords": "Use shadows in a custom URP shader To use shadows in a custom Universal Render Pipeline (URP) shader, follow these steps: Add #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl\" inside the HLSLPROGRAM in your shader file. The Core.hlsl file imports the Shadows.hlsl and RealtimeLights.hlsl files. Use any of the methods from the following sections. Get a position in shadow space Use these methods to convert positions to shadow map positions. Method Syntax Description GetShadowCoord float4 GetShadowCoord(VertexPositionInputs vertexInputs) Converts a vertex position into shadow space. Refer to Transform positions in a custom URP shader for information on the VertexPositionInputs struct. TransformWorldToShadowCoord float4 TransformWorldToShadowCoord(float3 positionInWorldSpace) Converts a position in world space to shadow space. Calculate shadows The following methods calculate shadows using shadow maps. To use these methods, follow these steps first: Make sure there are objects in your scene that have a ShadowCaster shader pass, for example objects that use the Universal Render Pipeline/Lit shader. Add #pragma multi_compile _ _MAIN_LIGHT_SHADOWS _MAIN_LIGHT_SHADOWS_CASCADE _MAIN_LIGHT_SHADOWS_SCREEN to your shader, so it can access the shadow map for the main light. Add #pragma multi_compile _ _ADDITIONAL_LIGHT_SHADOWS to your shader, so it can access the shadow maps for additional lights. Method Syntax Description GetMainLight Light GetMainLight(float4 shadowCoordinates) Returns the main light in the scene, with a shadowAttenuation value based on whether the position at the shadow coordinates is in shadow. ComputeCascadeIndex half ComputeCascadeIndex(float3 positionInWorldSpace) Returns the index of the shadow cascade at the position in world space. Refer to Shadow cascades for more information. MainLightRealtimeShadow half MainLightRealtimeShadow(float4 shadowCoordinates) Returns the shadow value from the main shadow map at the coordinates. Refer to Shadow mapping for more information. AdditionalLightRealtimeShadow half AdditionalLightRealtimeShadow(int lightIndex, float3 positionInWorldSpace) Returns the shadow value from the additional light shadow map at the position in world space. GetMainLightShadowFade half GetMainLightShadowFade(float3 positionInWorldSpace) Returns the amount to fade the shadow from the main light, based on the distance between the position and the camera. GetAdditionalLightShadowFade half GetAdditionalLightShadowFade(float3 positionInWorldSpace) Returns the amount to fade the shadow from additional lights, based on the distance between the position and the camera. ApplyShadowBias float3 ApplyShadowBias(float3 positionInWorldSpace, float3 normalWS, float3 lightDirection) Adds shadow bias to the position in world space. Refer to Shadow troubleshooting for more information. Example The following URP shader draws simple shadows onto a surface. To generate shadows, make sure there are objects in your scene that have a ShadowCaster shader pass, for example objects that use the Universal Render Pipeline/Lit shader. Shader \"Custom/SimpleShadows\" { SubShader { Tags { \"RenderType\" = \"AlphaTest\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { HLSLPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ _MAIN_LIGHT_SHADOWS _MAIN_LIGHT_SHADOWS_CASCADE _MAIN_LIGHT_SHADOWS_SCREEN #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl\" struct Attributes { float4 positionOS : POSITION; }; struct Varyings { float4 positionCS : SV_POSITION; float4 shadowCoords : TEXCOORD3; }; Varyings vert(Attributes IN) { Varyings OUT; OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz); // Get the VertexPositionInputs for the vertex position VertexPositionInputs positions = GetVertexPositionInputs(IN.positionOS.xyz); // Convert the vertex position to a position on the shadow map float4 shadowCoordinates = GetShadowCoord(positions); // Pass the shadow coordinates to the fragment shader OUT.shadowCoords = shadowCoordinates; return OUT; } half4 frag(Varyings IN) : SV_Target { // Get the value from the shadow map at the shadow coordinates half shadowAmount = MainLightRealtimeShadow(IN.shadowCoords); // Set the fragment color to the shadow value return shadowAmount; } ENDHLSL } } } Additional resources Shadows Shadows in URP Writing custom shaders Upgrade custom shaders for URP compatibility HLSL in Unity"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-transformations.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods-transformations.html",
    "title": "Transform positions in a custom URP shader | mmo-rpg-unity",
    "keywords": "Transform positions in a custom URP shader To transform positions in a custom Universal Render Pipeline (URP) shader, follow these steps: Add #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" inside the HLSLPROGRAM in your shader file. The Core.hlsl file imports the ShaderVariablesFunction.hlsl file. Use one of the following methods from the ShaderVariablesFunction.hlsl file. Method Syntax Description GetNormalizedScreenSpaceUV float2 GetNormalizedScreenSpaceUV(float2 positionInClipSpace) Converts a position in clip space to screen space. GetObjectSpaceNormalizeViewDir half3 GetObjectSpaceNormalizeViewDir(float3 positionInObjectSpace) Converts a position in object space to the normalized direction towards the viewer. GetVertexNormalInputs VertexNormalInputs GetVertexNormalInputs(float3 normalInObjectSpace) Converts the normal of a vertex in object space to a tangent, bitangent, and normal in world space. You can also input both the normal and a float4 tangent in object space. GetVertexPositionInputs VertexPositionInputs GetVertexPositionInputs(float3 positionInObjectSpace) Converts the position of a vertex in object space to positions in world space, view space, clip space, and normalized device coordinates. GetWorldSpaceNormalizeViewDir half3 GetWorldSpaceNormalizeViewDir(float3 positionInWorldSpace) Returns the direction from a position in world space to the viewer, and normalizes the direction. GetWorldSpaceViewDir float3 GetWorldSpaceViewDir(float3 positionInWorldSpace) Returns the direction from a position in world space to the viewer. Structs VertexPositionInputs Use the GetVertexNormalInputs method to get this struct. Field Description float3 positionWS The position in world space. float3 positionVS The position in view space. float4 positionCS The position in clip space. float4 positionNDC The position as normalized device coordinates (NDC). VertexNormalInputs Use the GetVertexNormalInputs method to get this struct. Field Description real3 tangentWS The tangent in world space. real3 bitangentWS The bitangent in world space. float3 normalWS The normal in world space. Example The following URP shader draws object surfaces with colors that represent their position in screen space. Shader \"Custom/ScreenSpacePosition\" { SubShader { Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { HLSLPROGRAM #pragma vertex vert #pragma fragment frag #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" struct Attributes { float4 positionOS : POSITION; float2 uv: TEXCOORD0; }; struct Varyings { float4 positionCS : SV_POSITION; float2 uv: TEXCOORD0; float3 positionWS : TEXCOORD2; }; Varyings vert(Attributes IN) { Varyings OUT; OUT.positionCS = TransformObjectToHClip(IN.positionOS.xyz); // Get the position of the vertex in different spaces VertexPositionInputs positions = GetVertexPositionInputs(IN.positionOS); // Set positionWS to the screen space position of the vertex OUT.positionWS = positions.positionWS.xyz; return OUT; } half4 frag(Varyings IN) : SV_Target { // Set the fragment color to the screen space position vector return float4(IN.positionWS.xy, 0, 1); } ENDHLSL } } } Additional resources Writing custom shaders Upgrade custom shaders for URP compatibility HLSL in Unity Shader semantics"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/use-built-in-shader-methods.html",
    "title": "Shader methods in URP | mmo-rpg-unity",
    "keywords": "Shader methods in URP The Universal Render Pipeline (URP) has a library of High-Level Shader Language (HLSL) shader files that contain helper methods. You can import these files into your custom shader files and use the helper methods. Page Description Import a file from the URP shader library Use the #include directive in HLSL to import a URP shader file. Transform positions in a custom URP shader Transform vertex, fragment, normal and tangent positions between coordinate spaces. Use the camera in a custom URP shader Get the position and direction of the camera. Use lighting in a custom URP shader Get the lights in a scene, and calculate lighting. Use shadows in a custom URP shader Get shadow data from lights in the scene, and calculate shadows. Additional resources Writing custom shaders Upgrade custom shaders for URP compatibility HLSL in Unity Shader methods in Scriptable Render Pipeline (SRP) Core"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/whats-new/urp-whats-new.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/whats-new/urp-whats-new.html",
    "title": "What's new in URP 14 (Unity 2022.2) | mmo-rpg-unity",
    "keywords": "What's new in URP 14 (Unity 2022.2) This section contains information about new features, improvements, and issues fixed in URP 14. For a complete list of changes made in URP 14, refer to the Changelog. Features This section contains the overview of the new features in this release. Full Screen Pass Renderer Feature This Renderer Feature lets you inject full screen render passes at pre-defined injection points to create full screen effects. To read more about the feature, refer to page Full Screen Pass Renderer Feature. Full Screen Pass with a custom Grayscale Material. Custom post-processing effects The Full Screen Pass Renderer Feature lets you create custom post-processing effects with minimum coding effort. To read how to create a simple post-processing effect, refer to the page How to create a custom post-processing effect. The following images show a fog effect implemented with a Full Screen Render Pass Renderer Feature. The scene without the fog effect: The scene with the custom fog effect implemented as a Full Screen Render Pass Renderer Feature: Implementing a custom effect lets you overcome the limitation of the default Unity fog effect that does not affect the skybox: Rendering layers The Rendering Layers feature lets you configure certain Lights to affect only specific GameObjects. With the Custom Shadow Layers property, you can configure certain GameObjects to cast shadows only from specific Lights (even if those Lights do not affect the GameObjects). In this URP version, Rendering Layers work not only with Lights, but also with Decals. Refer to the following pages to learn more about the feature: Rendering Layers How to use Rendering Layers with Decals Forward+ Rendering Path The Forward+ Rendering Path lets you avoid the per object limit of the Forward Rendering Path. The Forward+ Rendering Path has the following advantages compared with the Forward Rendering Path: There is no per-object limit for the number of Lights that affect GameObjects, the per-Camera limit still applies. The per-Camera limits for different platforms are: Desktop and console platforms: 256 Lights Mobile platforms: 32 Lights. OpenGL ES 3.0 and earlier: 16 Lights. This implementation lets you avoid splitting big meshes when more than 8 lights affect them. Blending of more than 2 reflection probes. Support for multiple Lights when using Unity Entity Component System (ECS). More flexibility with procedural draws. For more information, refer to the page Forward+ Rendering Path. LOD Cross-fade The LOD cross-fade lets you achieve a smoother transition blending between the current mesh LOD and the next LOD based on the object's distance to the Camera. As the Camera moves, Unity shows different LODs to provide a good balance between quality and processing cost. Cross-fading lets you avoid harsh LOD snapping and popping. 1: LOD cross-fade off. 2: LOD cross-fade on. For more information, refer to the LOD Cross Fade property. Temporal anti-aliasing (TAA) Temporal anti-aliasing (TAA) is a spatial multi-frame anti-aliasing technique that uses results from current and previous rendered frames to remove jaggies in the current frame and reduce temporal judder between frames. TAA uses Motion Vectors to reduce or avoid shimmer and ghosting artifacts caused by moving objects that end up being in different pixel locations in different frames. To enable TAA for a Camera: Select the Camera. In the Inspector, in the Rendering section, select Temporal Anti-aliasing (TAA) in the Anti-aliasing property. The following image shows a frame with TAA off: The following image shows a frame with TAA on: Improvements This section contains the overview of the major improvements in this release. Screen space ambient occlusion (SSAO) Improvements This release implements multiple performance and quality improvements to the SSAO feature. The Falloff Distance property lets you improve performance for Scenes with a lot of distant objects Performance improvements: New Blur Quality property with three blur options: High, Medium, Low. The Downsample check box now not only affects the Ambient Occlusion pass but also the following blur passes. The Falloff Distance property lets you reduce computational work on objects far away from the Camera. The last Blur pass and the After Opaque pass are now merged into one when the After Opaque option is enabled. The Samples property now has three options with pre-defined sample counts that provide a good balance of visual quality and performance. Quality improvements: The Method property lets you choose the algorithm that Unity uses to calculate the ambient occlusion values. The Blue Noise algorithm is added in this release. A new depth test was added to avoid adding SSAO to objects far away from one another. For more information, refer to the page Screen Space Ambient Occlusion. 64 bit high precision HDR render target format URP can now render into 64-bit high precision HDR render target format. Compared to the default 32-bit HDR render target, the 64-bit option provides the following benefits: Better precision for all color channels which reduces banding. Even precision for color channels eliminates the subtle blue-yellow banding caused by the lower blue channel precision of the 32-bit target. Support for the alpha channel. The alpha channel enables the alpha output with some limitations. The 64-bit format uses twice more memory compared to the 32-bit format. It can also have a significant performance impact on mobile platforms. To select the 64-bit render target option: in URP Asset, navigate to Quality > HDR > HDR Precision. This setting controls only the internal HDR rendering precision, not HDR output. New bloom quality settings URP 14 adds two new properties to the Bloom post-processing effect: Downscale: set the bloom texture scale to either half size or quarter size. Max Iterations: set the maximum number of scale iterations (down and up) the bloom effect does. This property replaces the Skip Iterations property, which skipped a number of last iterations, but did not limit the maximum number. For more information, refer to the page Bloom. Improvements to the Render Pipeline Converter This release contains multiple usability improvements of the Render Pipeline Converter: The Render Pipeline Converter window now has the Initialize and Convert button. Certain dialogs now show the number of selected elements and the total number of elements. You can click each converter to see more information about the elements it converter. Improvements to the visual appearance and usability of the Render Pipeline Converter dialogs. Material converter section improvements: Items in the list are sorted alphabetically now. The converter handles Materials in packages better. The converter ignores Shader Graph shaders. Performance improvement: Indexing is significantly faster in this release. This improves the performance of converters that use an .index file. Full screen draws in URP now use the SRP Core Bliter API All the calls to cmd.Blit method are replaced with the Blitter API. This ensures a correct and consistent way to perform full screen draws. In the current URP version, using cmd.Blit might implicitly enable or disable XR shader keywords, which breaks XR SPI rendering. Refer to the Perform a full screen blit in URP page to read how to use the Blitter API. More consistent lighting behavior on different platforms Removed implicit mobile shader optimizations to keep the visual appearance of lighting consistent on all platforms. Changes are mostly related to light fade quality and shadow filtering. Light fade calculations on mobile platforms are now the same as on desktop platforms. In this release, URP implements full quality spherical harmonics and always normalized normals for lighting. SHADER_QUALITY_LOW/MEDIUM/HIGH and SHADER_HINT_NICE_QUALITY shader defines were removed. If you used those defines in custom shaders, consider using SHADER_API_MOBILE or SHADER_API_GLES defines to replace SHADER_QUALITY_LOW/MEDIUM/HIGH. URP uses the SHADER_API_MOBILE define only for platform-specific functions now, and not for implicit quality changes. XRSystem API URP can now use the XRSystem API override the Built-In Render Pipeline stereo matrices. This lets you inject modifications to the projection matrix and the view matrix in URP. Shader stripping improvement: Light cookie stripping The URP Asset now has the option Lighting > Light Cookies that lets you enable or disable Light Cookies. When Light Cookies are disabled in all URP Assets in Graphics and Quality settings, Unity strips all shader variants with Light Cookies. This can reduce the shader variant count up to two times. CPU performance improvements for light-heavy scenes This release contains optimizations to avoid unnecessary copies of Light and Camera data. The changes mostly affect scenes containing tens or hundreds of Lights with Light cookies, with shadows enabled, and when using the Deferred Rendering Path. In scenes with hundreds of Lights that use all the mentioned features, the rendering performance can be up to 25% faster in the Editor. Soft Shadows Quality property on Lights Point Lights and Spot Lights now have the Soft Shadows Quality property. Options Low, Medium, and High let you specify the soft shadow quality value for the Light. Issues resolved For a complete list of issues resolved in URP 14, refer to the Changelog. Known issues For information on the known issues in URP 14, refer to the section Known issues."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/working-with-textures.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/working-with-textures.html",
    "title": "Using textures | mmo-rpg-unity",
    "keywords": "Using textures How to access and use textures in a custom render pass in the Universal Render Pipeline (URP). Page Description URP blit best practices Understand the different ways to perform a blit operation in URP and best practices to follow when writing custom render passes. Perform a full screen blit in URP An example of creating a custom render pass and a custom Scriptable Renderer Feature that performs a full screen blit. Blit input and output textures Blit a camera color texture to an output texture, then set the output texture as a global shader property. Blit multiple RTHandle textures An example of a blit operation that involves multiple RTHandle textures and a custom shader effect."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-custom-shaders-urp.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-custom-shaders-urp.html",
    "title": "Writing custom shaders | mmo-rpg-unity",
    "keywords": "Writing custom shaders This section contains guidelines that help you to get started with writing shaders for Universal Render Pipeline (URP). The section contains the following topics: Creating a sample scene URP basic unlit shader Basic ShaderLab structure URP unlit shader with color input Drawing a texture Visualizing normal vectors Reconstruct the world space positions Built-in shader methods in URP Each example covers some extra information compared to the basic shader example. If you are new to writing shaders using Unity's ShaderLab language, consider going through the sections in the order of appearance on this page."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-basic-prerequisites.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-basic-prerequisites.html",
    "title": "Creating a sample scene | mmo-rpg-unity",
    "keywords": "Creating a sample scene To follow the examples in this section: Install URP into an existing Unity project, or create a new project using the Universal Project Template. In the sample Scene, create a GameObject to test the shaders on; for example, a capsule. Create a new Material and assign it to the capsule. Create a new Shader asset and assign it to the Material of the capsule. When following an example, open the shader asset to edit the Unity shader source file. Replace the code in the source file with the code in the example. To start writing URP shaders, continue to section URP unlit basic shader."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-basic-unlit-structure.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-basic-unlit-structure.html",
    "title": "URP unlit basic shader | mmo-rpg-unity",
    "keywords": "URP unlit basic shader This example shows a basic URP-compatible shader. This shader fills the mesh shape with a color predefined in the shader code. To see the shader in action, copy and paste the following ShaderLab code into the Shader asset. // This shader fills the mesh shape with a color predefined in the code. Shader \"Example/URPUnlitShaderBasic\" { // The properties block of the Unity shader. In this example this block is empty // because the output color is predefined in the fragment shader code. Properties { } // The SubShader block containing the Shader code. SubShader { // SubShader Tags define when and under which conditions a SubShader block or // a pass is executed. Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { // The HLSL code block. Unity SRP uses the HLSL language. HLSLPROGRAM // This line defines the name of the vertex shader. #pragma vertex vert // This line defines the name of the fragment shader. #pragma fragment frag // The Core.hlsl file contains definitions of frequently used HLSL // macros and functions, and also contains #include references to other // HLSL files (for example, Common.hlsl, SpaceTransforms.hlsl, etc.). #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" // The structure definition defines which variables it contains. // This example uses the Attributes structure as an input structure in // the vertex shader. struct Attributes { // The positionOS variable contains the vertex positions in object // space. float4 positionOS : POSITION; }; struct Varyings { // The positions in this struct must have the SV_POSITION semantic. float4 positionHCS : SV_POSITION; }; // The vertex shader definition with properties defined in the Varyings // structure. The type of the vert function must match the type (struct) // that it returns. Varyings vert(Attributes IN) { // Declaring the output object (OUT) with the Varyings struct. Varyings OUT; // The TransformObjectToHClip function transforms vertex positions // from object space to homogenous clip space. OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz); // Returning the output. return OUT; } // The fragment shader definition. half4 frag() : SV_Target { // Defining the color variable and returning it. half4 customColor = half4(0.5, 0, 0, 1); return customColor; } ENDHLSL } } } The fragment shader colors the GameObject dark red (RGB value (0.5, 0, 0)). The following section introduces you to the structure of this basic Unity shader. Basic ShaderLab structure Unity shaders are written in a Unity-specific language called ShaderLab. The Unity shader in this example has the following blocks: Shader Properties SubShader Pass HLSLPROGRAM Shader block ShaderLab code starts with the Shader declaration. Shader \"Example/URPUnlitShaderBasic\" The path in this declaration determines the display name and location of the Unity shader in the Shader menu on a Material. The method Shader.Find also uses this path. Properties block The Properties block contains the declarations of properties that users can set in the Inspector window on a Material. In this example, the Properties block is empty, because this Unity shader does not expose any Material properties that a user can define. SubShader block A Unity shader source file contains one or more SubShader blocks. When rendering a mesh, Unity selects the first SubShader that is compatible with the GPU on the target device. A SubShader block can optionally contain a SubShader Tags block. Use the Tags keyword to declare a SubShader Tags block. Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } A SubShader Tag with a name of RenderPipeline tells Unity which render pipelines to use this SubShader with, and the value of UniversalPipeline indicates that Unity should use this SubShader with URP. To execute the same shader in different render pipelines, create multiple SubShader blocks with different RenderPipeline tag values. To execute a SubShader block in HDRP, set the RenderPipeline tag to HDRenderPipeline, to execute it in the Built-in Render Pipeline, set RenderPipeline to an empty value. For more information on SubShader Tags, refer to ShaderLab: SubShader Tags. Pass block In this example, there is one Pass block that contains the HLSL program code. For more information on Pass blocks, refer to ShaderLab: Pass. A Pass block can optionally contain a Pass tags block. For more information, refer to URP ShaderLab Pass tags. HLSLPROGRAM block This block contains the HLSL program code. NOTE: HLSL language is the preferred language for URP shaders. NOTE: URP supports the CG language. If you add the CGPROGRAM/ENDCGPROGRAM block in a shader, Unity includes shaders from the Built-in Render Pipeline library automatically. If you include shaders from the SRP shader library, some SRP shader macros and functions might conflict with the Built-in Render Pipeline shader functions. Shaders with the CGPROGRAM block are not SRP Batcher compatible. This block contains the #include declaration with the reference to the Core.hlsl file. #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" The Core.hlsl file contains definitions of frequently used HLSL macros and functions, and also contains #include references to other HLSL files (for example, Common.hlsl and SpaceTransforms.hlsl). For example, the vertex shader in the HLSL code uses the TransformObjectToHClip function from the SpaceTransforms.hlsl file. The function transforms vertex positions from object space to homogenous space: Varyings vert(Attributes IN) { Varyings OUT; OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz); return OUT; } The fragment shader in this basic HLSL code outputs the single color predefined in the code: half4 frag() : SV_Target { half4 customColor; customColor = half4(0.5, 0, 0, 1); return customColor; } Section URP unlit shader with color input shows how to add the editable color property in the Inspector window on the Material."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-reconstruct-world-position.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-reconstruct-world-position.html",
    "title": "Reconstruct the world space positions of pixels from the depth texture | mmo-rpg-unity",
    "keywords": "Reconstruct the world space positions of pixels from the depth texture The Unity shader in this example reconstructs the world space positions for pixels using a depth texture and screen space UV coordinates. The shader draws a checkerboard pattern on a mesh to visualize the positions. The following illustration shows the end result: This page contains the following sections: Create the sample scene Edit the ShaderLab code The complete ShaderLab code Create the sample scene Create the sample scene to follow the steps in this section: Install URP into an existing Unity project, or create a new project using the Universal Project Template. In the sample Scene, create a plane GameObject and place it so that it occludes some of the GameObjects. Create a new Material and assign it to the plane. Create a new shader and assign it to the material. Copy and paste the Unity shader source code from the page URP unlit basic shader. Select the URP Asset. If you created the project using the Universal Render Pipeline template, the URP Asset path is Assets/Settings/UniversalRP-HighQuality. In the URP Asset, in the General section, enable Depth Texture. Open the shader you created on step 4. Edit the ShaderLab code This section assumes that you copied the source code from the page URP unlit basic shader. Make the following changes to the ShaderLab code: In the HLSLPROGRAM block, add the include declaration for the depth texture shader header. For example, place it under the existing include declaration for Core.hlsl. #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" // The DeclareDepthTexture.hlsl file contains utilities for sampling the Camera // depth texture. #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl\" The DeclareDepthTexture.hlsl file contains functions for sampling the Camera depth texture. This example uses the SampleSceneDepth function for sampling the Z coordinate for pixels. In the fragment shader definition, add Varyings IN as input. half4 frag(Varyings IN) : SV_Target In this example, the fragment shader uses the positionHCS property from the Varyings struct to get locations of pixels. In the fragment shader, to calculate the UV coordinates for sampling the depth buffer, divide the pixel location by the render target resolution _ScaledScreenParams. The property _ScaledScreenParams.xy takes into account any scaling of the render target, such as Dynamic Resolution. float2 UV = IN.positionHCS.xy / _ScaledScreenParams.xy; In the fragment shader, use the SampleSceneDepth functions to sample the depth buffer. #if UNITY_REVERSED_Z real depth = SampleSceneDepth(UV); #else // Adjust z to match NDC for OpenGL real depth = lerp(UNITY_NEAR_CLIP_VALUE, 1, SampleSceneDepth(UV)); #endif The SampleSceneDepth function comes from the DeclareDepthTexture.hlsl file. It returns the Z value in the range [0, 1]. For the reconstruction function (ComputeWorldSpacePosition) to work, the depth value must be in the normalized device coordinate (NDC) space. In D3D, Z is in range [0,1], in OpenGL, Z is in range [-1, 1]. This example uses the UNITY_REVERSED_Z constant to determine the platform and adjust the Z value range. Refer to step 6 in this example for more explanations. The UNITY_NEAR_CLIP_VALUE variable is a platform independent near clipping plane value for the clip space. For more information, refer to Platform-specific rendering differences. Reconstruct world space positions from the UV and Z coordinates of pixels. float3 worldPos = ComputeWorldSpacePosition(UV, depth, UNITY_MATRIX_I_VP); ComputeWorldSpacePosition is a utility function that calculates the world space position from the UV and the depth (Z) values. This function is defined in the Common.hlsl file of the SRP Core package. UNITY_MATRIX_I_VP is an inverse view projection matrix which transforms points from the clip space to the world space. To visualize the world space positions of pixels, create the checkboard effect. uint scale = 10; uint3 worldIntPos = uint3(abs(worldPos.xyz * scale)); bool white = (worldIntPos.x & 1) ^ (worldIntPos.y & 1) ^ (worldIntPos.z & 1); half4 color = white ? half4(1,1,1,1) : half4(0,0,0,1); The scale is the inverse scale of the checkboard pattern size. The abs function mirrors the pattern to the negative coordinate side. The uint3 declaration for the worldIntPos variable snaps the coordinate positions to integers. The AND operator in the expresion <integer value> & 1 checks if the value is even (0) or odd (1). The expression lets the code divide the surface into squares. The XOR operator in the expresion <integer value> ^ <integer value> flips the square color. The depth buffer might not have valid values for areas where no geometry is rendered. The following code draws black color in such areas. #if UNITY_REVERSED_Z if(depth < 0.0001) return half4(0,0,0,1); #else if(depth > 0.9999) return half4(0,0,0,1); #endif Different platforms use different Z values for far clipping planes (0 == far, or 1 == far). The UNITY_REVERSED_Z constant lets the code handle all platforms correctly. Save the shader code, the example is ready. The following illustration shows the end result: The complete ShaderLab code Below is the complete ShaderLab code for this example. // This Unity shader reconstructs the world space positions for pixels using a depth // texture and screen space UV coordinates. The shader draws a checkerboard pattern // on a mesh to visualize the positions. Shader \"Example/URPReconstructWorldPos\" { Properties { } // The SubShader block containing the Shader code. SubShader { // SubShader Tags define when and under which conditions a SubShader block or // a pass is executed. Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { HLSLPROGRAM // This line defines the name of the vertex shader. #pragma vertex vert // This line defines the name of the fragment shader. #pragma fragment frag // The Core.hlsl file contains definitions of frequently used HLSL // macros and functions, and also contains #include references to other // HLSL files (for example, Common.hlsl, SpaceTransforms.hlsl, etc.). #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" // The DeclareDepthTexture.hlsl file contains utilities for sampling the // Camera depth texture. #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl\" // This example uses the Attributes structure as an input structure in // the vertex shader. struct Attributes { // The positionOS variable contains the vertex positions in object // space. float4 positionOS : POSITION; }; struct Varyings { // The positions in this struct must have the SV_POSITION semantic. float4 positionHCS : SV_POSITION; }; // The vertex shader definition with properties defined in the Varyings // structure. The type of the vert function must match the type (struct) // that it returns. Varyings vert(Attributes IN) { // Declaring the output object (OUT) with the Varyings struct. Varyings OUT; // The TransformObjectToHClip function transforms vertex positions // from object space to homogenous clip space. OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz); // Returning the output. return OUT; } // The fragment shader definition. // The Varyings input structure contains interpolated values from the // vertex shader. The fragment shader uses the `positionHCS` property // from the `Varyings` struct to get locations of pixels. half4 frag(Varyings IN) : SV_Target { // To calculate the UV coordinates for sampling the depth buffer, // divide the pixel location by the render target resolution // _ScaledScreenParams. float2 UV = IN.positionHCS.xy / _ScaledScreenParams.xy; // Sample the depth from the Camera depth texture. #if UNITY_REVERSED_Z real depth = SampleSceneDepth(UV); #else // Adjust Z to match NDC for OpenGL ([-1, 1]) real depth = lerp(UNITY_NEAR_CLIP_VALUE, 1, SampleSceneDepth(UV)); #endif // Reconstruct the world space positions. float3 worldPos = ComputeWorldSpacePosition(UV, depth, UNITY_MATRIX_I_VP); // The following part creates the checkerboard effect. // Scale is the inverse size of the squares. uint scale = 10; // Scale, mirror and snap the coordinates. uint3 worldIntPos = uint3(abs(worldPos.xyz * scale)); // Divide the surface into squares. Calculate the color ID value. bool white = ((worldIntPos.x) & 1) ^ (worldIntPos.y & 1) ^ (worldIntPos.z & 1); // Color the square based on the ID value (black or white). half4 color = white ? half4(1,1,1,1) : half4(0,0,0,1); // Set the color to black in the proximity to the far clipping // plane. #if UNITY_REVERSED_Z // Case for platforms with REVERSED_Z, such as D3D. if(depth < 0.0001) return half4(0,0,0,1); #else // Case for platforms without REVERSED_Z, such as OpenGL. if(depth > 0.9999) return half4(0,0,0,1); #endif return color; } ENDHLSL } } }"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-unlit-color.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-unlit-color.html",
    "title": "URP unlit shader with color input | mmo-rpg-unity",
    "keywords": "URP unlit shader with color input The Unity shader in this example adds the Base Color property to the Material. You can select the color using that property and the shader fills the mesh shape with the color. Use the Unity shader source file from section URP unlit basic shader and make the following changes to the ShaderLab code: Add the _BaseColor property definition to the Properties block: Properties { [MainColor] _BaseColor(\"Base Color\", Color) = (1, 1, 1, 1) } This declaration adds the _BaseColor property with the label Base Color to the Material: When you declare a property with the [MainColor] attribute, Unity uses this property as the main color of the Material. Note: For compatibility reasons, the _Color property name is a reserved name. Unity uses a property with the name _Color as the main color even it does not have the [MainColor] attribute. When you declare a property in the Properties block, you also need to declare it in the HLSL code. NOTE: To ensure that the Unity shader is SRP Batcher compatible, declare all Material properties inside a single CBUFFER block with the name UnityPerMaterial. For more information on the SRP Batcher, refer to the page Scriptable Render Pipeline (SRP) Batcher. Add the following code before the vertex shader: CBUFFER_START(UnityPerMaterial) half4 _BaseColor; CBUFFER_END Change the code in the fragment shader so that it returns the _BaseColor property. half4 frag() : SV_Target { return _BaseColor; } Now you can select the color in the Base Color field in the Inspector window. The fragment shader fills the mesh with the color you select. Below is the complete ShaderLab code for this example. // This shader fills the mesh shape with a color that a user can change using the // Inspector window on a Material. Shader \"Example/URPUnlitShaderColor\" { // The _BaseColor variable is visible in the Material's Inspector, as a field // called Base Color. You can use it to select a custom color. This variable // has the default value (1, 1, 1, 1). Properties { [MainColor] _BaseColor(\"Base Color\", Color) = (1, 1, 1, 1) } SubShader { Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { HLSLPROGRAM #pragma vertex vert #pragma fragment frag #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" struct Attributes { float4 positionOS : POSITION; }; struct Varyings { float4 positionHCS : SV_POSITION; }; // To make the Unity shader SRP Batcher compatible, declare all // properties related to a Material in a a single CBUFFER block with // the name UnityPerMaterial. CBUFFER_START(UnityPerMaterial) // The following line declares the _BaseColor variable, so that you // can use it in the fragment shader. half4 _BaseColor; CBUFFER_END Varyings vert(Attributes IN) { Varyings OUT; OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz); return OUT; } half4 frag() : SV_Target { // Returning the _BaseColor value. return _BaseColor; } ENDHLSL } } } Section Drawing a texture shows how to draw a texture on the mesh."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-unlit-normals.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-unlit-normals.html",
    "title": "Visualizing normal vectors | mmo-rpg-unity",
    "keywords": "Visualizing normal vectors The Unity shader in this example visualizes the normal vector values on the mesh. Use the Unity shader source file from section URP unlit basic shader and make the following changes to the ShaderLab code: In struct Attributes, which is the input structure for the vertex shader in this example, declare the variable containing the normal vector for each vertex. struct Attributes { float4 positionOS : POSITION; // Declaring the variable containing the normal vector for each vertex. half3 normal : NORMAL; }; In struct Varyings, which is the input structure for the fragment shader in this example, declare the variable for storing the normal vector values for each fragment: struct Varyings { float4 positionHCS : SV_POSITION; // The variable for storing the normal vector values. half3 normal : TEXCOORD0; }; This example uses the three components of the normal vector as RGB color values for each fragment. To render the normal vector values on the mesh, use the following code as the fragment shader: half4 frag(Varyings IN) : SV_Target { half4 color = 0; color.rgb = IN.normal; return color; } Unity renders the normal vector values on the mesh: A part of the capsule is black. This is because in those points, all three components of the normal vector are negative. The next step shows how to render values in those areas as well. To render negative normal vector components, use the compression technique. To compress the range of normal component values (-1..1) to color value range (0..1), change the following line: color.rgb = IN.normal; to this line: color.rgb = IN.normal * 0.5 + 0.5; Now Unity renders the normal vector values as colors on the mesh. Below is the complete ShaderLab code for this example. // This shader visuzlizes the normal vector values on the mesh. Shader \"Example/URPUnlitShaderNormal\" { Properties { } SubShader { Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { HLSLPROGRAM #pragma vertex vert #pragma fragment frag #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" struct Attributes { float4 positionOS : POSITION; // Declaring the variable containing the normal vector for each // vertex. half3 normal : NORMAL; }; struct Varyings { float4 positionHCS : SV_POSITION; half3 normal : TEXCOORD0; }; Varyings vert(Attributes IN) { Varyings OUT; OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz); // Use the TransformObjectToWorldNormal function to transform the // normals from object to world space. This function is from the // SpaceTransforms.hlsl file, which is referenced in Core.hlsl. OUT.normal = TransformObjectToWorldNormal(IN.normal); return OUT; } half4 frag(Varyings IN) : SV_Target { half4 color = 0; // IN.normal is a 3D vector. Each vector component has the range // -1..1. To show all vector elements as color, including the // negative values, compress each value into the range 0..1. color.rgb = IN.normal * 0.5 + 0.5; return color; } ENDHLSL } } }"
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-unlit-texture.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/Documentation~/writing-shaders-urp-unlit-texture.html",
    "title": "Drawing a texture | mmo-rpg-unity",
    "keywords": "Drawing a texture The Unity shader in this example draws a texture on the mesh. Use the Unity shader source file from section URP unlit shader with color input and make the following changes to the ShaderLab code: In the Properties block, replace the existing code with the _BaseMap property definition. Properties { [MainTexture] _BaseMap(\"Base Map\", 2D) = \"white\" {} } When you declare a texture property in the Properties block, Unity adds the _BaseMap property with the label Base Map to the Material, and adds the Tiling and the Offset controls. When you declare a property with the [MainTexture] attribute, Unity uses this property as the main texture of the Material. Note: For compatibility reasons, the _MainTex property name is a reserved name. Unity uses a property with the name _MainTex as the main texture even it does not have the [MainTexture] attribute. In struct Attributes and struct Varyings, add the uv variable for the UV coordinates on the texture: float2 uv : TEXCOORD0; Define the texture as a 2D texture and specify a sampler for it. Add the following lines before the CBUFFER block: TEXTURE2D(_BaseMap); SAMPLER(sampler_BaseMap); The TEXTURE2D and the SAMPLER macros are defined in one of the files referenced in Core.hlsl. For tiling and offset to work, it's necessary to declare the texture property with the _ST suffix in the 'CBUFFER' block. The _ST suffix is necessary because some macros (for example, TRANSFORM_TEX) use it. NOTE: To ensure that the Unity shader is SRP Batcher compatible, declare all Material properties inside a single CBUFFER block with the name UnityPerMaterial. For more information on the SRP Batcher, refer to the page Scriptable Render Pipeline (SRP) Batcher. CBUFFER_START(UnityPerMaterial) float4 _BaseMap_ST; CBUFFER_END To apply the tiling and offset transformation, add the following line in the vertex shader: OUT.uv = TRANSFORM_TEX(IN.uv, _BaseMap); The TRANSFORM_TEX macro is defined in the Macros.hlsl file. The #include declaration contains a reference to that file. In the fragment shader, use the SAMPLE_TEXTURE2D macro to sample the texture: half4 frag(Varyings IN) : SV_Target { half4 color = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, IN.uv); return color; } Now you can select a texture in the Base Map field in the Inspector window. The shader draws that texture on the mesh. Below is the complete ShaderLab code for this example. // This shader draws a texture on the mesh. Shader \"Example/URPUnlitShaderTexture\" { // The _BaseMap variable is visible in the Material's Inspector, as a field // called Base Map. Properties { [MainTexture] _BaseMap(\"Base Map\", 2D) = \"white\" {} } SubShader { Tags { \"RenderType\" = \"Opaque\" \"RenderPipeline\" = \"UniversalPipeline\" } Pass { HLSLPROGRAM #pragma vertex vert #pragma fragment frag #include \"Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl\" struct Attributes { float4 positionOS : POSITION; // The uv variable contains the UV coordinate on the texture for the // given vertex. float2 uv : TEXCOORD0; }; struct Varyings { float4 positionHCS : SV_POSITION; // The uv variable contains the UV coordinate on the texture for the // given vertex. float2 uv : TEXCOORD0; }; // This macro declares _BaseMap as a Texture2D object. TEXTURE2D(_BaseMap); // This macro declares the sampler for the _BaseMap texture. SAMPLER(sampler_BaseMap); CBUFFER_START(UnityPerMaterial) // The following line declares the _BaseMap_ST variable, so that you // can use the _BaseMap variable in the fragment shader. The _ST // suffix is necessary for the tiling and offset function to work. float4 _BaseMap_ST; CBUFFER_END Varyings vert(Attributes IN) { Varyings OUT; OUT.positionHCS = TransformObjectToHClip(IN.positionOS.xyz); // The TRANSFORM_TEX macro performs the tiling and offset // transformation. OUT.uv = TRANSFORM_TEX(IN.uv, _BaseMap); return OUT; } half4 frag(Varyings IN) : SV_Target { // The SAMPLE_TEXTURE2D marco samples the texture with the given // sampler. half4 color = SAMPLE_TEXTURE2D(_BaseMap, sampler_BaseMap, IN.uv); return color; } ENDHLSL } } } Section Visualizing normal vectors shows how to visualize normal vectors on the mesh."
  },
  "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.render-pipelines.universal@14.0.11/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.render-pipelines.universal copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.searcher@4.9.2/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.searcher@4.9.2/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [4.9.2] - 2022-02-22 Fixed a bug that stopped keyboard keys from affecting navigation and interaction with search results list, unless user explicitly focused/click on list using the mouse [1396759] [4.9.1] - 2021-10-05 Fixed a usability issue where in some cases searcher would suggest one collapsed category of results that user would have to manually expand anyway Fixed bug that caused incorrect search results with non whitespaced queries for nodes with spaces in their name and for subgraphs [1359158] Fixed bug that causes search results to not be visible sometimes in the searcher window [1366061] Fixed bug that causes exceptions to be thrown when using the up/down arrow keys with search list focused [1358016] Fixed bug that causes some searcher items to be irreversibly collapsed due to expand icon disappearing on collapsing those items [1366074] [4.9.0] - 2021-09-07 Remove Lucene API and dlls [4.8.0] - 2021-02-17 Added ability for clients of searcher window to filter and prioritize search results as they need Fixed bug that causes searcher window to prioritize categories over node entries of the same name [case 1304055] Fixed bug that causes searcher window to close when double-clicking a category [case 1302267] Fixed bug that causes searcher window to be offset too far when accounting for host window boundaries [4.7.1] - 2020-10-15 Fix Regex error during highlighting when the query contains a backslash Fix serialization depth warning caused by a property's backing field getting serialized [4.7.0] - 2020-08-11 Added Lucene.Net DLLs and first version of the LuceneDatabase [4.6.0] - 2020-07-27 Added support for multi-select, enabled via MultiSelectEnabled in the SearcherAdapter. [4.5.0] - 2020-07-15 Add support for displaying icons in SearcherItem. [4.4.0] - 2020-07-13 Add custom UserData field to SearcherItem. Add SearcherTreeUtility to create a SearcherItem tree from a flat list of paths. [4.3.1] - 2020-06-08 Fix bug that cause keyboard navigation to fail. [case 1253544] [4.3.0] - 2020-05-27 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.3.0-preview.tgz Bump minor version for synonyms. [4.2.0] - 2020-04-30 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.2.0-preview.tgz Bump to minor version for API validation. [4.1.1] - 2020-04-30 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.1.1-preview.tgz Add all children is now an adapter override. [4.1.0] - 2020-03-20 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.1.0-preview.tgz Improve matching algorithm Add a splitter between searcher and details panel Fix adding all children of matching expanded categories [4.0.9] - 2019-10-22 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.9-preview.tgz Update ListView API [4.0.8] - 2019-09-16 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.8-preview.tgz Made SearcherItem Name property virtual [4.0.7] - 2019-08-29 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.7-preview.tgz Fix bold fonts (case 1178374) case 1178373 and 1071573014: minor examples tweaks [4.0.6] - 2019-08-01 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.6-preview.tgz Fix bug where items were selected twice when using keyboard inputs [4.0.5] - 2019-07-26 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.5-preview.tgz Fix searcher look to match Northstar changes [4.0.4] - 2019-07-23 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.4-preview.tgz Change the default size when the searcher has a details panel [4.0.3] - 2019-06-11 Package: https://artifactory.prd.cds.internal.unity3d.com/artifactory/upm-candidates/com.unity.searcher/-/com.unity.searcher-4.0.3-preview.tgz Added ability to use capital letters in a search bar Bugfix: Search bar focus after the escape button pressed [4.0.2] - 2019-05-24 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/4.0.2-preview API Make Match() virtual again in SearcherDatabase [4.0.1] - 2019-04-30 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/4.0.1-preview Bugfix: [MacOs] Fix issue where the searcher moves on the top left corner while resizing/moving [4.0.0] - 2019-04-24 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/4.0.0-preview Cleanup for promotion to production [3.0.12] - 2019-04-17 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.12 API: Make SearcherField public again [3.0.11] - 2019-04-15 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.11 Fix all issues flagged by ReSharper [3.0.10] - 2019-03-26 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.10 fix CI [3.0.9] - 2019-03-24 Package: none Add Yamato CI config [3.0.8] - 2019-03-24 Package: none Bugfix: Autocomplete text was misaligned. [3.0.7] - 2019-02-28 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.7 API: Remove Experimental API reference. [3.0.6] - 2019-09-27 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.6 UI: Restyling API: Add public ctor to SearcherDatabase [3.0.5] - 2018-12-18 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.5 Bugfix: Focus search text field when window is displayed [3.0.4] - 2018-11-30 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.4 Trigger callback when an item is selected instead of when the details panel is displayed [3.0.3] - 2018-11-28 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.3 Add alignments [3.0.2] - 2018-11-22 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.2 Bugfix: Searcher autocomplete label now bold to match text input style [3.0.1] - 2018-11-20 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.1 Bugfix [3.0.0] - 2018-11-20 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/3.0.0 Restyling and move + resize [2.1.1] - 2018-11-12 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.1.1 Fix text input filtering [2.1.0] - 2018-11-05 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.1.0 UIElements compatibility update [2.0.6] - 2018-08-15 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.6-preview Add possibility to sort items [2.0.5] - 2018-08-15 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.5-preview Filtering fix [2.0.4] - 2018-08-08 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.4-preview Added hooks for analytics [2.0.3] - 2018-08-07 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.3-preview The matchFilter is now also applied at database initial setup time [2.0.2] - 2018-08-02 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.2-preview Added matchFilter delegate on SearcherDatabase to further control the match criteria [2.0.1] - 2018-07-13 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.1-preview Fixed Exception when a whitespace query is entered [2.0.0] - 2018-07-12 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/2.0.0-preview Created a base class for Databases, renamed SearcherDatabase to LuceneDatabase, add a brand new SearcherDatabase written from scratch [1.0.6] - 2018-06-21 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.6-preview hotfix for left arrow on a child that cannot be collapsed will select the parent feature [1.0.5] - 2018-06-21 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.5-preview fixed an draw issue when expanding and collapsing an item on a small list - issue #25 pressing left arrow on a child that cannot be collapsed will select the parent [1.0.4] - 2018-05-16 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.4-preview fixed compilation error with latest trunk (around styles.flex) added third party notices file [1.0.3] - 2018-05-03 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.3-preview window close due to focus loss will now trigger the selection callback with null fixed potential null ref exception in sample code [1.0.2] - 2018-04-30 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.2-preview removed AutoCompleter in favor of a more robust top-result based approach [1.0.1] - 2018-04-26 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.1-preview now showing children of matching items - issue #19 fixed completion scoring with multiple databases search results in general have been improved [1.0.0] - 2018-04-25 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/1.0.0-preview added basic tests - issue #18 added a README and documentation fixed Searcher.Search() not returning anything if query contained capital letters - issue #22 [0.1.3] - 2018-04-23 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/0.1.3-preview added ability to add a title to the Searcher window - feature #3 removed Searcher arrow and moved default display point to top-right corner - related issues #2, #12, #16 fixed lingering arrow when bring Searcher window up from Inspector - issue #2 fixed SearcherWindow.Show() to always take world space display location - issue #17 [0.1.2] - 2018-04-18 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/0.1.2-experimental fixed Searcher's list is visually cut off when closing a parent SearcherItem - issue #9 scroll to selected item/best result add parents field, do not autocomplete it, search using a multi phrase query, auto create the parents path in overwritePath() fixed window arrow being removed AFTER the target window repaint, leaving remnant arrwos sometimes - issue #6 fixed Null Ref Exception when getting the selected item of an empty listview. only get it if relevant fixed bug where child was not under parent in Searcher [0.1.1] - 2018-03-21 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/0.1.1-experimental Minor fixes for VisualScripting [0.1.0] - 2018-03-05 Package: https://bintray.com/unity/unity-staging/com.unity.searcher/0.1.0-experimental This is the first release of Unity Package Searcher. General search window for use in the Editor. First target use is for GraphView node search."
  },
  "Library/PackageCache/com.unity.searcher@4.9.2/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.searcher@4.9.2/Documentation~/index.html",
    "title": "Searcher | mmo-rpg-unity",
    "keywords": "Searcher Disclaimer Currently, the API for the Searcher is not intended for public use. Using the API in external custom scripts or modifying the API is not recommended or supported at this time. The Searcher package adds a powerful search window to Unity's Graph View tools which lets you quickly find, select, and place items into the graph window. Features The Searcher window uses a tree view to display the available options and the categories they belong to. As you type, the Searcher makes predictions and provides auto-complete options for the item you might be trying to select. The Searcher also highlights the matching text in the tree view to help you quickly find what you're looking for. Some instances of the Searcher also provide inline documentation or notes in an extra window to the right of the item tree. Navigating the Searcher You can navigate through the Searcher with either your mouse or keyboard. Use your mouse to scroll through tree menu items. To expand or collapse tree menu items click on them, and double-click the item to make your selection. To navigate up and down the list of items with your keyboard, press the Up arrow key or Down arrow key. To expand tree menus, press the Right arrow key, and press the Left arrow key to collapse the tree menus. To make a selection of the highlighted item, press the Enter key."
  },
  "Library/PackageCache/com.unity.searcher@4.9.2/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.searcher@4.9.2/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Unity Companion Package License v1.0 (\"License\") Copyright © 2019 Unity Technologies ApS (\"Unity\") Unity hereby grants to you a worldwide, non-exclusive, no-charge, and royalty-free copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, sublicense, and distribute the software that is made available with this License (\"Software\"), subject to the following terms and conditions: Unity Companion Use Only. Exercise of the license granted herein is limited to exercise for the creation, use, and/or distribution of applications, software, or other content pursuant to a valid Unity development engine software license (\"Engine License\"). That means while use of the Software is not limited to use in the software licensed under the Engine License, the Software may not be used for any purpose other than the creation, use, and/or distribution of Engine License-dependent applications, software, or other content. No other exercise of the license granted herein is permitted. No Modification of Engine License. Neither this License nor any exercise of the license granted herein modifies the Engine License in any way. Ownership & Grant Back to You. 3.1. You own your content. In this License, \"derivative works\" means derivatives of the Software itself--works derived only from the Software by you under this License (for example, modifying the code of the Software itself to improve its efficacy); “derivative works” of the Software do not include, for example, games, apps, or content that you create using the Software. You keep all right, title, and interest to your own content. 3.2. Unity owns its content. While you keep all right, title, and interest to your own content per the above, as between Unity and you, Unity will own all right, title, and interest to all intellectual property rights (including patent, trademark, and copyright) in the Software and derivative works of the Software, and you hereby assign and agree to assign all such rights in those derivative works to Unity. 3.3. You have a license to those derivative works. Subject to this License, Unity grants to you the same worldwide, non-exclusive, no-charge, and royalty-free copyright license to derivative works of the Software you create as is granted to you for the Software under this License. Trademarks. You are not granted any right or license under this License to use any trademarks, service marks, trade names, products names, or branding of Unity or its affiliates (\"Trademarks\"). Descriptive uses of Trademarks are permitted; see, for example, Unity’s Branding Usage Guidelines at https://unity3d.com/public-relations/brand. Notices & Third-Party Rights. This License, including the copyright notice above, must be provided in all substantial portions of the Software and derivative works thereof (or, if that is impracticable, in any other location where such notices are customarily placed). Further, if the Software is accompanied by a Unity \"third-party notices\" or similar file, you acknowledge and agree that software identified in that file is governed by those separate license terms. DISCLAIMER, LIMITATION OF LIABILITY. THE SOFTWARE AND ANY DERIVATIVE WORKS THEREOF IS PROVIDED ON AN \"AS IS\" BASIS, AND IS PROVIDED WITHOUT WARRANTY OF ANY KIND, WHETHER EXPRESS OR IMPLIED, INCLUDING ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND/OR NONINFRINGEMENT. IN NO EVENT SHALL ANY COPYRIGHT HOLDER OR AUTHOR BE LIABLE FOR ANY CLAIM, DAMAGES (WHETHER DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL, INCLUDING PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES, LOSS OF USE, DATA, OR PROFITS, AND BUSINESS INTERRUPTION), OR OTHER LIABILITY WHATSOEVER, WHETHER IN AN ACTION OF CONTRACT, TORT, OR OTHERWISE, ARISING FROM OR OUT OF, OR IN CONNECTION WITH, THE SOFTWARE OR ANY DERIVATIVE WORKS THEREOF OR THE USE OF OR OTHER DEALINGS IN SAME, EVEN WHERE ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. USE IS ACCEPTANCE and License Versions. Your receipt and use of the Software constitutes your acceptance of this License and its terms and conditions. Software released by Unity under this License may be modified or updated and the License with it; upon any such modification or update, you will comply with the terms of the updated License for any use of any of the Software under the updated License. Use in Compliance with Law and Termination. Your exercise of the license granted herein will at all times be in compliance with applicable law and will not infringe any proprietary rights (including intellectual property rights); this License will terminate immediately on any breach by you of this License. Severability. If any provision of this License is held to be unenforceable or invalid, that provision will be enforced to the maximum extent possible and the other provisions will remain in full force and effect. Governing Law and Venue. This License is governed by and construed in accordance with the laws of Denmark, except for its conflict of laws rules; the United Nations Convention on Contracts for the International Sale of Goods will not apply. If you reside (or your principal place of business is) within the United States, you and Unity agree to submit to the personal and exclusive jurisdiction of and venue in the state and federal courts located in San Francisco County, California concerning any dispute arising out of this License (\"Dispute\"). If you reside (or your principal place of business is) outside the United States, you and Unity agree to submit to the personal and exclusive jurisdiction of and venue in the courts located in Copenhagen, Denmark concerning any Dispute."
  },
  "Library/PackageCache/com.unity.searcher@4.9.2/README.html": {
    "href": "Library/PackageCache/com.unity.searcher@4.9.2/README.html",
    "title": "Searcher | mmo-rpg-unity",
    "keywords": "Searcher Use the Searcher package to quickly search a large list of items via a popup window. For example, use Searcher to find, select, and put down a new node in a graph. The Searcher package also includes samples and tests. Features Popup Window Placement Tree View Keyboard Navigation Quick Search Auto-Complete Match Highlighting Multiple Databases Quick Usage Example void OnMouseDown( MouseDownEvent evt ) { var items = new List<SearcherItem> { new SearcherItem( \"Books\", \"Description\", new List<SearcherItem>() { new SearcherItem( \"Dune\" ), } ) }; items[0].AddChild( new SearcherItem( \"Ender's Game\" ) ); SearcherWindow.Show( this, // this EditorWindow items, \"Optional Title\", item => { Debug.Log( item.name ); return /*close window?*/ true; }, evt.mousePosition ); } Installing the Package Open this file in your project: Packages/manifest.json Add this to the dependencies array (makes sure to change the version string to your current version): \"com.unity.searcher\": \"4.0.0-preview\" For example, if this it he only package you depend on, you should have something like this (makes sure to change the version string to your current version): { \"dependencies\": { \"com.unity.searcher\": \"4.0.0-preview\" } } Enabling the Samples and Tests Right now, it seems Samples and Tests only show for local packages, meaning you cloned this repo inside your Packages folder. Given you've done that, open this file in your project: Packages/manifest.json Add a testables list with the package name so you get something like this (makes sure to change the version string to your current version): { \"dependencies\": { \"com.unity.searcher\": \"4.0.0-preview\" }, \"testables\" : [ \"com.unity.searcher\" ] } You should see a new top-level menu called Searcher and you should see Searcher tests in Test Runner. Searcher Creation from Database var bookItems = new List<SearcherItem> { new SearcherItem( \"Books\" ) }; var foodItems = new List<SearcherItem> { new SearcherItem( \"Foods\" ) }; // Create databases. var databaseDir = Application.dataPath + \"/../Library/Searcher\"; var bookDatabase = SearcherDatabase.Create( bookItems, databaseDir + \"/Books\" ); var foodDatabase = SearcherDatabase.Create( foodItems, databaseDir + \"/Foods\" ); // At a later time, load database from disk. bookDatabase = SearcherDatabase.Load( databaseDir + \"/Books\" ); var searcher = new Searcher( new SearcherDatabase[]{ foodDatabase, bookDatabase }, \"Optional Title\" ); Popup Window or Create Control Searcher m_Searcher; void OnMouseDown( MouseDownEvent evt ) { // Popup window... SearcherWindow.Show( this, m_Searcher, item => { Debug.Log( item.name ); return /*close window?*/ true; }, evt.mousePosition ); } // ...or create SearcherControl VisualElement void OnEnable() { // ...or create SearcherControl VisualElement var searcherControl = new SearcherControl(); searcherControl.Setup( m_Searcher, item => Debug.Log( item.name ) ); this.GetRootVisualContainer().Add( searcherControl ); } Customize the UI via ISearcherAdapter public interface ISearcherAdapter { VisualElement MakeItem(); VisualElement Bind( VisualElement target, SearcherItem item, ItemExpanderState expanderState, string text ); string title { get; } bool hasDetailsPanel { get; } void DisplaySelectionDetails( VisualElement detailsPanel, SearcherItem o ); void DisplayNoSelectionDetails( VisualElement detailsPanel ); void InitDetailsPanel( VisualElement detailsPanel ); } var bookDatabase = SearcherDatabase.Load( Application.dataPath + \"/Books\" ); var myAdapter = new MyAdapter(); // class MyAdapter : ISearcherAdapter var searcher = new Searcher( bookDatabase, myAdapter ); Technical details Requirements This version of Searcher is compatible with the following versions of the Unity Editor: 2019.1 and later (recommended) Known limitations Searcher version 1.0 includes the following known limitations: Only works with .Net 4.0 Package contents The following table indicates the main folders of the package: Location Description Editor/Resources Contains images used in the UI. Editor/Searcher Contains Searcher source files. Samples Contains the samples. Tests Contains the tests."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog All notable changes to this package are documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [Unreleased] Version Updated The version number for this package has increased due to a version update of a related graphics package. [14.0.10] - 2024-04-03 This version is compatible with Unity 2022.3.24f1. Version Updated The version number for this package has increased due to a version update of a related graphics package. [14.0.9] - 2024-01-22 This version is compatible with Unity 2022.3.19f1. Added Added the Feature Examples Sample to Shader Graph to show users how to achieve specific effects in Shader Graph. [14.0.9] - 2023-12-21 This version is compatible with Unity 2022.3.18f1. Changed Added a shader variant limit to the project settings, clarified the difference between the variant limit in user preferences. Fixed Fixed an issue where value nodes might appear on undo/redo where property nodes would be. Fixed an issue where drag-out node creation would leave the editor unresponsive. Fixed an issue where material override GUIs for Built-In would sometimes get ignored. Corrected a typo in the generated code for the NAND node. Fixed node creation menu location on macOS. Added issue with main preview window failing to refresh. Fixed an issue where sprite previews were not always rendering. Fixed an issue where an open asset inspector for subgraphs may mangle the json serialized representation for that subgraph asset. Fixed typos in the text of the the Node Reference samples. [14.0.8] - 2023-09-27 This version is compatible with Unity 2022.3.11f1. Added Added the new Node Reference sample pack which adds 146 reference assets to help users learn more about available nodes Changed [SGB-613][SGB-594] Addressed an issue where certain operations were taking too long as a result of graph concretization. Fixed Fixed Texture Size node causing compilation error in the Fullscreen ShaderGraph target. [SGB-561] Addressed issue where save/save as hotkeys weren't being caught by shadergraph editor window. [SGB-581][SGB-531] Addressed minor usability issues with Custom Function Nodes. [SGB-605] Addressed issue where adding dropdown property type to newly created subgraphs did not propagate to other open shadergraph editor windows. [SGB-597] Removed invalid character from imported material sub asset. [SGB-592][SGB-596] Addressed issue where docs links from editor were incorrect. Fixed a regression where adding nodes in large graphs would cause a major slowdown. [14.0.7] - 2023-05-23 This version is compatible with Unity 2022.2.22f1. Changed Improved blackboard property drag speed when reordering the blackboard. [SGB-383]. Made adjustments to flipbook node to avoid dropping frames on AMD GPU. [SGB-280]. Fixed parallax nodes so that they use the default UV Input Slot correctly. [SGB-511]. Fixed Addressed issue where missing targets were not handled on import. [SGB-1] Addressed various issues with the Swizzle node. [SGB-159] Addressed issue where duplicate serialized blackboard category children would in subgraphs would brick the ShaderGraph editor. [SGB-378] Addressed error feedback on import of graphs with invalid or missing targets, allowing them to be modified and saved. [SGB-166][SGB-167] Fixed issue where the Gradient Noise Node was causing implicit truncation warnings. [SGB-469] Fixed issue where custom interpolator previews would provide erroneous results when connecting through a reroute node. [SGB-89] Fixed issue where reroute node would sometimes show the wrong color for its appropriate inputs. [SGB-17] Fixed issue where subgraph gradient blackboard properties could have naming conflicts with parent graphs. [SGB-310] Fixed issue where the view position of the graph editor would sometimes be forgotten when swapping between two open shadergraph editor windows. [SGB-377] Fixed issue where node searcher would fail to populate when shadergraph was undocked after domain reload. [SGB-439][IN-30581] Fixed issue where custom mesh selector for master preview would fail to initialize. [SGB-445][IN-30614] Fixed issue where nodes with dynamic vectors would not correctly cache properties for previews. [SGB-359] Fixed for [SGB-466] and related issues where nodes with warning or error badges would fail to clean up their resources properly and leave the shader graph editor in an error state. Improved performance of disconnecting nodes in large graphs. Corrected a regression in float preview properties not updating previews. [SGB-526]. ShaderGraph styles were not applied correctly when the system locale was set in Turks. [14.0.6] - 2023-03-24 This version is compatible with Unity 2022.2.13f1. Changed Sped up rename operations on properties/keywords/dropdowns in large graph. Sped up setting blackboard values in large graphs. The asset postprocessor for shader graph now only performs the majority of its work when a shader-related asset has been changed. Fixed Fixed SRP Batcher compatibility issue with instanced properties. Fixed NullReferenceException when entering Play Mode with an unfocused Shader Graph window/on closing the Shader Graph Window. [14.0.5] - 2022-12-12 This version is compatible with Unity 2022.2.4f1. Fixed Fixed unity_StereoEyeIndex error when building XR project with URP Fullscreen master node containing Shader. Fixed a number of memory leaks in ShaderGraph where windows and view elements were not disposing of resources properly. [14.0.4] - 2022-11-04 This version is compatible with Unity 2022.2.2f1. Changed Reduced time taken by code generation when a shader graph asset is imported. Fixed Fixed a compilation bug in BiRP Target in some variants with lightmaps. Fixed shader graph incorrectly stripping variants for BiRP shaders that weren't built with shader graph. [14.0.3] - 2021-05-09 This version is compatible with Unity 2022.2.0b15. Fixed Fixed the sample buffer nodes in ShaderGraph. Set the default value of Normalize Output toggle in Transform Node to true to make different node versions consistent. [14.0.2] - 2021-02-04 This version is compatible with Unity 2022.2.0a14. Fixed Fixed ShaderGraph pixel and screen coordinates to work correctly with render scale [1387468] [14.0.1] - 2021-12-07 Added Added mip sampling modes for 2d textures, 2d texture arrays and 3d textures Fixed Fixed broken documentation URL for block nodes. 1381488 Fixed SRP-batching when PVT stacks are bound per material by properly declaring properties for PVT stacks [1372152] Fixed custom editor GUI support for the BuiltIn Target 1380485 [14.0.0] - 2021-11-17 Fixed Fixed issue where Duplicating/Copy-Pasting last keyword in the blackboard throws an exception [1394378] Fixed an issue where some graphs with incorrectly formatted data would not display their shader inputs in the blackboard [1384315] Fixed bug with Shader Graph subwindows having their header text overflow when the window is resized smaller than the title [1378203] Gradient field doesn't support HDR values Case 1381867 Fixed the behavior of checkerboard node with raytracing Fixed broken documentation URL for block nodes. 1381488 Fixed an issue where edges connected to SubGraphNodes would sometimes get lost on upgrading a pre-targets graphs 1379996 Added Added mip sampling modes for 2d textures, 2d texture arrays and 3d textures [13.1.2] - 2021-11-05 Added Added ability to set \"Global\" or \"Per Material\" shader declaration in PVT node settings [1372152] Show PVT stack names (needed for binding) under the Properties in the Shader Inspector Fixed Fixed a recent regression in ShaderGraph Screen Position behavior on some platforms in Built-in, Universal and HDRP [1369450] [13.1.1] - 2021-10-04 Added Adding ability to automatically cast Bools to Vector types in ShaderGraph [1359160] Added ShaderGraph import warning to old nodes and properties, and ability to dismiss the warning if old behavior is desired. Added normal transforms to the Transform node Added an automatically generated material subasset on ShaderGraphs. Changed Changed the title suffix on old nodes and properties rom \"Deprecated\" to \"Legacy\". Updated searcher package dependency version to 4.9.1 Renamed the Shader Graph Texel Size node to Texture Size and added two additional output ports that actually output the texel size in addition to the texture size. Fixed Fixed a usability issue where in some cases searcher would suggest one collapsed category of results that user would have to manually expand anyway Fixed bug that causes search results to not be visible sometimes in the searcher window [1366061] Fixed bug that causes exceptions to be thrown when using the up/down arrow keys with search list focused [1358016] Fixed bug that causes some searcher items to be irreversibly collapsed due to expand icon disappearing on collapsing those items [1366074] Fixed bug that caused incorrect search results with non whitespaced queries for nodes with spaces in their name and for subgraphs [1359158] Fixed Triplanar ShaderGraph node to handle arbitrary input and output coordinate spaces [1346477] (https://issuetracker.unity3d.com/issues/shader-graph-rotating-gameobject-get-material-stretched-when-using-triplanar-node) Fixed a bug that Parallax Mapping and Parallax Occlusion Mapping nodes don't use the same channel to sample heightmap by adding drop-downs for channel selecting to both of the nodes. [1347270] (https://fogbugz.unity3d.com/f/cases/1347270/) Fixed errors in the ShaderGraph Transform node [1368082] Fixed the Scene Depth node so it returns proper results in Eye space when using an orthographic camera [1311272] Fixed a bug where node preview doesn't update when a texture is changed in the explorer 1363784 Fixed missing shader keyword stage during keyword copying. Fixed a ShaderGraph warning when connecting a node using Object Space BiTangent to the vertex stage [1361512] (https://issuetracker.unity3d.com/issues/shader-graph-cross-implicit-truncation-of-vector-type-errors-are-thrown-when-connecting-transform-node-to-vertex-block) Fixed upgrade warnings on SpeedTree8 subgraphs. [13.1.0] - 2021-09-24 Fixed Fixed bug where an exception was thrown on undo operation after adding properties to a category [1348910] (https://fogbugz.unity3d.com/f/cases/1348910/) Fixed the sticky-note editable title text size in shader graph not matching the set font size [1357657]. Fixed unhandled exception when loading a subgraph with duplicate slots [1366200] (https://issuetracker.unity3d.com/product/unity/issues/guid/1366200/) [13.0.0] - 2021-09-01 Changed Remove use of deprecated UNITY_USE_NATIVE_HDR keyword in shaders. Added Adding control of anisotropic settings on inline Sampler state nodes in ShaderGraph. Fixed Fixed bug where it was not possible to switch to Graph Settings tab in Inspector if multiple nodes and an edge was selected [1357648] (https://fogbugz.unity3d.com/f/cases/1357648/) Fixed an incorrect direction transform from view to world space [1362034] (https://issuetracker.unity3d.com/product/unity/issues/guid/1362034/) Fixed ShaderGraph HDRP master preview disappearing for a few seconds when graph is modified [1330289] (https://issuetracker.unity3d.com/issues/shadergraph-hdrp-main-preview-is-invisible-until-moved) Fixed noise nodes to use a deterministic integer hash, instead of platform dependent floating point hashes [1156544] Fixed the appearance (wrong text color, and not wrapped) of a warning in Node Settings [1356725] (https://issuetracker.unity3d.com/product/unity/issues/guid/1356725/) Fixed the ordering of inputs on a SubGraph node to match the properties on the blackboard of the subgraph itself [1354463] Added more inputs to the Parallax Occlusion Mapping node to handle non-uniformly scaled UVs such as HDRP/Lit POM [1347008]. Fixed the wrong scaling of the main preview window [1356719] (https://issuetracker.unity3d.com/product/unity/issues/guid/1356719/) Fixed an issue where ShaderGraph \"view shader\" commands were opening in individual windows, and blocking Unity from closing [1367188] Improved screenspace position accuracy in the fragment shader by using VPOS [1352662] (https://issuetracker.unity3d.com/issues/shadergraph-dither-node-results-in-artifacts-when-far-from-origin-caused-by-screen-position-breaking-down) Fixed the node searcher results to prefer names over synonyms [1366058] Fixed the sticky-note editable title text size in shader graph not matching the set font size [1357657]. Fixed how graph errors were displayed when variant limits were reached [1355815] [12.0.0] - 2021-01-11 Added Added categories to the blackboard, enabling more control over the organization of shader properties and keywords in the Shader Graph tool. These categories are also reflected in the Material Inspector for URP + HDRP, for materials created from shader graphs. Added ability to define custom vertex-to-fragment interpolators. Support for the XboxSeries platform has been added. Stereo Eye Index, Instance ID, and Vertex ID nodes added to the shadergraph library. Added information about selecting and unselecting items to the Blackboard article. Added View Vector Node documentation Added custom interpolator thresholds on shadergraph project settings page. Added custom interpolator documentation Added subshadergraphs for SpeedTree 8 shadergraph support: SpeedTree8Wind, SpeedTree8ColorAlpha, SpeedTree8Billboard. Added an HLSL file implementing a version of the Unity core LODDitheringTransition function which can be used in a Shader Graph Added a new target for the built-in render pipeline, including Lit and Unlit sub-targets. Added stage control to ShaderGraph Keywords, to allow fragment or vertex-only keywords. For Texture2D properties, added linearGrey and red as options for default texture mode. For Texture2D properties, changed the \"bump\" option to be called \"Normal Map\", and will now tag these properties with the [NormalMap] tag. Added Branch On Input Connection node. This node can be used inside a subgraph to branch on the connection state of an exposed property. Added Use Custom Binding option to properties. When this option is enabled, a property can be connected to a Branch On Input Connection node. The user provides a custom label that will be displayed on the exposed property, when it is disconnected in a graph. Added new dropdown property type for subgraphs, to allow compile time branching that can be controlled from the parent graph, via the subgraph instance node. Added Dropdown node per dropdown property, that can be used to configure the desired branch control. Added selection highlight and picking shader passes for URP target. Added the ability to mark textures / colors as [MainTexture] and [MainColor]. Added the ability to enable tiling and offset controls for a Texture2D input. Added the Split Texture Transform node to allow using/overriding the provided tiling and offset from a texture input. Added Calculate Level Of Detail Texture 2D node, for calculating a Texture2D LOD level. Added Gather Texture 2D node, for retrieving the four samples (red component only) that would be used for bilinear interpolation when sampling a Texture2D. Added toggle \"Disable Global Mip Bias\" in Sample Texture 2D and Sample Texture 2D array node. This checkbox disables the runtimes automatic Mip Bias, which for instance can be activated during dynamic resolution scaling. Added Sprite option to Main Preview, which is similar to Quad but does not allow rotation. Sprite is used as the default preview for URP Sprite shaders. Added Tessellation Option to PositionNode settings, to provide access to the pre-displaced tessellated position. Added visible errors for invalid stage capability connections to shader graph. Added a ShaderGraph animated preview framerate throttle. Added many node synonyms for the Create Node search so that it's easier to find nodes. Changed Properties and Keywords are no longer separated by type on the blackboard. Categories allow for any combination of properties and keywords to be grouped together as the user defines. Vector2/Vector3/Vector4 property types will now be properly represented by a matching Vector2/Vector3/Vector4 UI control in the URP + HDRP Material Inspector as opposed to the fallback Vector4 field that was used for any multi-dimensional vector type in the past. Updated/corrected View Direction documentation Change Asset/Create/Shader/Blank Shader Graph to Asset/Create/Shader Graph/Blank Shader Graph Change Asset/Create/Shader/Sub Graph to Asset/Create/Shader Graph/Sub Graph Change Asset/Create/Shader/VFX Shader Graph to Asset/Create/Shader Graph/VFX Shader Graph Adjusted Blackboard article to clarify multi-select functionality Limited max number of inspectable items in the Inspector View to 20 items Added borders to inspector items styling, to better differentiate between separate items Updated Custom Function Node to use new ShaderInclude asset type instead of TextAsset (.hlsl and .cginc softcheck remains). Change BranchOnInputNode to choose NotConnected branch when generating Preview Only ShaderGraph keywords count towards the shader permutation variant limit, SubGraph keywords do not. ShaderGraph SubGraphs will now report errors and warnings in a condensed single error. Changed \"Create Node\" action in ShaderGraph stack separator context menu to \"Add Block Node\" and added it to main stack context menu GatherTexture2D and TexelSize nodes now support all shader stages. Fixed Fixed an issue where fog node density was incorrectly calculated. Fixed inspector property header styling Added padding to the blackboard window to prevent overlapping of resize region and scrollbars interfering with user interaction Blackboard now properly handles selection persistence of items between undo and redos Fixed the Custom Editor GUI field in the Graph settings that was ignored. Node included HLSL files are now tracked more robustly, so they work after file moves and renames [1301915] (https://issuetracker.unity3d.com/product/unity/issues/guid/1301915/) Prevent users from setting enum keywords with duplicate reference names and invalid characters [1287335] Fixed a bug where old preview property values would be used for node previews after an undo operation. Clean up console error reporting from node shader compilation so errors are reported in the graph rather than the Editor console [1296291] (https://issuetracker.unity3d.com/product/unity/issues/guid/1296291/) Fixed treatment of node precision in subgraphs, now allows subgraphs to switch precisions based on the subgraph node [1304050] (https://issuetracker.unity3d.com/issues/precision-errors-when-theres-a-precision-discrepancy-between-subgraphs-and-parent-graphs) Fixed an issue where the Rectangle Node could lose detail at a distance. New control offers additional method that preserves detail better [1156801] Fixed virtual texture layer reference names allowing invalid characters [1304146] Fixed issue with SRP Batcher compatibility [1310624] Fixed issue with Hybrid renderer compatibility [1296776] Fixed ParallaxOcclusionMapping node to clamp very large step counts that could crash GPUs (max set to 256). [1329025] (https://issuetracker.unity3d.com/issues/shadergraph-typing-infinity-into-the-steps-input-for-the-parallax-occlusion-mapping-node-crashes-unity) Fixed an issue where the shader variant limit exceeded message was not getting passed [1304168] (https://issuetracker.unity3d.com/product/unity/issues/guid/1304168) Fixed a bug in master node preview generation that failed compilation when a block was deleted [1319066] (https://issuetracker.unity3d.com/issues/shadergraph-deleting-stack-blocks-of-universal-rp-targeted-shadergraph-causes-the-main-preview-to-fail-to-compile) Fixed issue where vertex generation was incorrect when only custom blocks were present [1320695]. Fixed a bug where property deduplication was failing and spamming errors [1317809] (https://issuetracker.unity3d.com/issues/console-error-when-adding-a-sample-texture-operator-when-a-sampler-state-property-is-present-in-blackboard) Fixed a bug where big input values to the SimpleNoise node caused precision issues, especially noticeable on Mali GPUs. [1322891] (https://issuetracker.unity3d.com/issues/urp-mali-missing-glitch-effect-on-mali-gpu-devices) Fixed a bug where synchronously compiling an unencountered shader variant for preview was causing long delays in graph updates [1323744] Fixed a regression where custom function node file-included functions could not access shadergraph properties [1322467] Fixed an issue where a requirement was placed on a fixed-function emission property [1319637] Fixed default shadergraph precision so it matches what is displayed in the graph settings UI (single) [1325934] Fixed an unhelpful error message when custom function nodes didn't have a valid file [1323493]. Fixed an issue with how the transform node handled direction transforms from absolute world space in camera relative SRPs [1323726] Fixed a bug where changing a Target setting would switch the inspector view to the Node Settings tab if any nodes were selected. Fixed \"Disconnect All\" option being grayed out on stack blocks [1313201]. Fixed how shadergraph's prompt for \"unsaved changes\" was handled to fix double messages and incorrect window sizes [1319623]. Fixed an issue where users can't create multiple Boolean or Enum keywords on the blackboard. 1329021 Fixed an issue where generated property reference names could conflict with Shader Graph reserved keywords [1328762] (https://issuetracker.unity3d.com/product/unity/issues/guid/1328762/) Fixed a ShaderGraph issue where ObjectField focus and Node selections would both capture deletion commands [1313943]. Fixed a ShaderGraph issue where the right click menu doesn't work when a stack block node is selected [1320212]. Fixed a bug when a node was both vertex and fragment exclusive but could still be used causing a shader compiler error [1316128]. Fixed a ShaderGraph issue where a warning about an uninitialized value was being displayed on newly created graphs [1331377]. Fixed divide by zero warnings when using the Sample Gradient Node Fixed the default dimension (1) for vector material slots so that it is consistent with other nodes. (https://issuetracker.unity3d.com/product/unity/issues/guid/1328756/) Fixed reordering when renaming enum keywords. (https://issuetracker.unity3d.com/product/unity/issues/guid/1328761/) Fixed an issue where an integer property would be exposed in the material inspector as a float 1330302 Fixed a bug in ShaderGraph where sticky notes couldn't be copied and pasted [1221042]. Fixed an issue where upgrading from an older version of ShaderGraph would cause Enum keywords to be not exposed [1332510] Fixed an issue where a missing subgraph with a \"Use Custom Binding\" property would cause the parent graph to fail to load [1334621] (https://issuetracker.unity3d.com/issues/shadergraph-shadergraph-cannot-be-opened-if-containing-subgraph-with-custom-binding-that-has-been-deleted) Fixed a ShaderGraph issue where unused blocks get removed on edge replacement [1334341]. Fixed an issue where the ShaderGraph transform node would generate incorrect results when transforming a direction from view space to object space [1333781] (https://issuetracker.unity3d.com/product/unity/issues/guid/1333781/) Fixed a ShaderGraph issue where keyword properties could get stuck highlighted when deleted [1333738]. Fixed issue with ShaderGraph custom interpolator node dependency ordering [1332553]. Fixed SubGraph SamplerState property defaults not being respected [1336119] Fixed an issue where nested subgraphs with identical SamplerState property settings could cause compile failures [1336089] Fixed an issue where SamplerState properties could not be renamed after creation [1336126] Fixed loading all materials from project when saving a ShaderGraph. Fixed issues with double prompts for \"do you want to save\" when closing Shader Graph windows [1316104]. Fixed a ShaderGraph issue where resize handles on blackboard and graph inspector were too small [1329247] (https://issuetracker.unity3d.com/issues/shadergraph-resize-bounds-for-blackboard-and-graph-inspector-are-too-small) Fixed a ShaderGraph issue where a material inspector could contain an extra set of render queue, GPU instancing, and double-sided GI controls. Fixed a Shader Graph issue where property auto generated reference names were not consistent across all property types [1336937]. Fixed a warning in ShaderGraph about BuiltIn Shader Library assembly having no scripts. Fixed ShaderGraph BuiltIn target not having collapsible foldouts in the material inspector [1339256]. Fixed GPU instancing support in Shadergraph [1319655] (https://issuetracker.unity3d.com/issues/shader-graph-errors-are-thrown-when-a-propertys-shader-declaration-is-set-to-hybrid-per-instance-and-exposed-is-disabled). Fixed indent level in shader graph target foldout (case 1339025). Fixed ShaderGraph BuiltIn target shader GUI to allow the same render queue control available on URP with the changes for case 1335795. Fixed ShaderGraph BuiltIn target not to apply emission in the ForwardAdd pass to match surface shader results [1345574]. (https://issuetracker.unity3d.com/product/unity/issues/guid/1345574/) Fixed Procedural Virtual Texture compatibility with SRP Batcher [1329336] (https://issuetracker.unity3d.com/issues/procedural-virtual-texture-node-will-make-a-shadergraph-incompatible-with-srp-batcher) Fixed an issue where SubGraph keywords would not deduplicate before counting towards the permutation limit [1343528] (https://issuetracker.unity3d.com/issues/shader-graph-graph-is-generating-too-many-variants-error-is-thrown-when-using-subgraphs-with-keywords) Fixed an issue where an informational message could cause some UI controls on the graph inspector to be pushed outside the window [1343124] (https://issuetracker.unity3d.com/product/unity/issues/guid/1343124/) Fixed a ShaderGraph issue where selecting a keyword property in the blackboard would invalidate all previews, causing them to recompile [1347666] (https://issuetracker.unity3d.com/product/unity/issues/guid/1347666/) Fixed the incorrect value written to the VT feedback buffer when VT is not used. Fixed ShaderGraph isNaN node, which was always returning false on Vulkan and Metal platforms. Fixed ShaderGraph sub-graph stage limitations to be per slot instead of per sub-graph node [1337137]. Disconnected nodes with errors in ShaderGraph no longer cause the imports to fail [1349311] (https://issuetracker.unity3d.com/issues/shadergraph-erroring-unconnected-node-causes-material-to-become-invalid-slash-pink) ShaderGraph SubGraphs now report node warnings in the same way ShaderGraphs do [1350282]. Fixed ShaderGraph exception when trying to set a texture to \"main texture\" [1350573]. Fixed a ShaderGraph issue where Float properties in Integer mode would not be cast properly in graph previews 1330302 Fixed a ShaderGraph issue where hovering over a context block but not its node stack would not bring up the incorrect add menu 1351733 Fixed the BuiltIn Target to perform shader variant stripping [1345580] (https://issuetracker.unity3d.com/product/unity/issues/guid/1345580/) Fixed incorrect warning while using VFXTarget Fixed a bug with Sprite Targets in ShaderGraph not rendering correctly in game view [1352225] Fixed compilation problems on preview shader when using hybrid renderer v2 and property desc override Hybrid Per Instance Fixed a serialization bug wrt PVT property flags when using subgraphs. This fixes SRP batcher compatibility. [11.0.0] - 2020-10-21 Added Changed Fixed Fixed an issue where nodes with ports on one side would appear incorrectly on creation [1262050] Fixed a broken link in the TOC to Main Preview Fixed an issue with the Gradient color picker displaying different values than the selected color. Fixed an issue where blackboard properties when dragged wouldn't scroll the list of properties to show the user more of the property list [1293632] Fixed an issue where, when blackboard properties were dragged and then the user hit the \"Escape\" key, the drag indicator would still be visible Fixed an issue where renaming blackboard properties through the Blackboard wouldn't actually change the underlying property name Fixed an issue where blackboard wasn't resizable from all directions like the Inspector and Main Preview Fixed an issue where deleting a property node while your mouse is over it leaves the property highlighted in the blackboard [1238635] Fixed an issue where Float/Vector1 properties did not have the ability to be edited using a slider in the Inspector like the other Vector types Fixed an issue with inactive node deletion throwing a superfluous exception. Fixed an issue where interpolators with preprocessors were being packed incorrectly. Fixed rounded rectangle shape not rendering correctly on some platforms. Fixed an issue where generated BuildVertexDescriptionInputs() produced an HLSL warning, \"implicit truncation of vector type\" 1299179 Fixed an issue on upgrading graphs with inactive Master Nodes causing null ref errors. 1298867 Fixed an issue with duplicating a node with the blackboard closed 1294430 Fixed an issue where ShaderGraph stopped responding after selecting a node after opening the graph with the inspector window hidden 1304501 Fixed the InputNodes tests that were never correct. These were incorrect tests, no nodes needed tochange. Fixed the ViewDirection Node in Tangent space's calculation to match how the transform node works [1296788] Fixed an issue where SampleRawCubemapNode were requiring the Normal in Object space instead of World space [1307962] Boolean keywords now have no longer require their reference name to end in _ON to show up in the Material inspector [1306820] (https://issuetracker.unity3d.com/product/unity/issues/guid/1306820/) Newly created properties and keywords will no longer use obfuscated GUID-based reference names in the shader code [1300484] Fixed ParallaxMapping node compile issue on GLES2 Fixed a selection bug with block nodes after changing tabs [1312222] Fixed some shader graph compiler errors not being logged [1304162]. Fixed a shader graph bug where the Hue node would have a large seam with negative values [1340849]. Fixed an error when using camera direction with sample reflected cube map [1340538]. Fixed ShaderGraph's FogNode returning an incorrect density when the fog setting was disabled [1347235]. [10.3.0] - 2020-11-03 Added Users can now manually control the preview mode of nodes in the graph, and subgraphs Changed Adjusted and expanded Swizzle Node article as reviewed by docs editorial.(DOC-2695) Adjusted docs for SampleTexture2D, SampleTexture2DLOD, SampleTexture2DArray, SampleTexture3D, SampleCubemap, SampleReflectedCubemap, TexelSize, NormalFromTexture, ParallaxMapping, ParallaxOcclusionMapping, Triplanar, Sub Graphs, and Custom Function Nodes to reflect changes to texture wire data structures. (DOC-2568) Texture and SamplerState types are now HLSL structures (defined in com.unity.render-pipelines.core/ShaderLibrary/Texture.hlsl). CustomFunctionNode use of the old plain types is supported, but the user should upgrade to structures to avoid bugs. The shader graph inspector window will now switch to the \"Node Settings\" tab whenever a property/node/other selectable item in the graph is clicked on to save the user a click Fixed Fixed an issue where shaders could be generated with CR/LF (\"\\r\\n\") instead of just LF (\"\\n\") line endings [1286430] Fixed Custom Function Node to display the name of the custom function. [1293575] Addressed C# warning 0649 generated by unassigned structure members Fixed using TexelSize or reading sampler states from Textures output from a Subgraph or Custom Function Node [1284036] Shaders using SamplerState types now compile with GLES2 (SamplerStates are ignored, falls back to Texture-associated sampler state) [1292031] Fixed an issue where the horizontal scrollbar at the bottom of the shader graph inspector window could not be used due to the resizing widget always taking priority over it Fixed an issue where the shader graph inspector window could be resized past the edges of the shader graph view Fixed an issue where resizing the shader graph inspector window sometimes had unexpected results Fixed Graph Inspector scaling that was allocating too much space to the labels [1268134] Fixed some issues with our Convert To Subgraph contextual menu to allow passthrough and fix inputs/outputs getting lost. Fixed issue where a NullReferenceException would be thrown on resetting reference name for a Shader Graph property Fixed an upgrade issue where old ShaderGraph files with a weird/bugged state would break on update to master stack [1255011] Fixed a bug where non-word characters in an enum keyword reference name would break the graph. 1270168 Fixed issue where a NullReferenceException would be thrown on resetting reference name for a Shader Graph property [10.2.0] - 2020-10-19 Added Changed Renamed the existing Sample Cubemap Node to Sample Reflected Cubemap Node, and created a new Sample Cubemap Node that samples cubemaps with a direction. Removed unnecessary HDRP constant declarations used by Material inspector from the UnityPerMaterial cbuffer [1285701] Virtual Texture properties are now forced to be Exposed, as they do not work otherwise [1256374] Fixed Fixed an issue where old ShaderGraphs would import non-deterministically, changing their embedded property names each import [1283800] Using the TexelSize node on a ShaderGraph texture property is now SRP batchable [1284029] Fixed an issue where Mesh Deformation nodes did not have a category color. 1227081 Fixed SampleTexture2DLOD node to return opaque black on unsupported platforms [1241602] ShaderGraph now detects when a SubGraph is deleted while being used by a SubGraph node, and displays appropriate errors [1206438] Fixed an issue where the Main Preview window rendered too large on small monitors during first open. [1254392] Fixed an issue where Block nodes using Color slots would not be automatically removed from the Master Stack. [1259794] Fixed an issue where the Create Node menu would not close when pressing the Escape key. [1263667] Fixed an issue with the Preview Manager not updating correctly when deleting an edge that was created with a node (dragging off an existing node slot) Fixed an issue where ShaderGraph could not read matrices from a Material or MaterialPropertyBlock while rendering with SRP batcher [1256374] Fixed an issue where user setting a property to not Exposed, Hybrid-Instanced would result in a non-Hybrid Global property [1285700] Fixed an issue with Gradient when it is used as expose parameters. Generated code was failing [1285640 ] Fixed the subgraph slot sorting function [1286805] Fixed Parallax Occlusion Mapping not working in sub graphs. 1221317 All textures in a ShaderGraph, even those not used, will now be pulled into an Exported Package [1283902] Fixed an issue where the presence of an HDRP DiffusionProfile property or node would cause the graph to fail to load when HDRP package was not present [1287904] Fixed an issue where unknown type Nodes (i.e. HDRP-only nodes used without HDRP package) could be copied, resulting in an unloadable graph [1288475] Fixed an issue where dropping HDRP-only properties from the blackboard field into the graph would soft-lock the graph [1288887] Fixed an issue using the sample gradient macros in custom function nodes, which was using a scalar value instead of a vector value for the gradients [1299830] [10.1.0] - 2020-10-12 Added Added parallax mapping node and parallax occlusion mapping node. Added the possibility to have multiple POM node in a single graph. Added better error feedback when SampleVirtualTexture nodes run into issues with the VirtualTexture property inputs Added ability for Shader Graph to change node behavior without impacting existing graphs via the “Allow Deprecated Nodes” Changed Added method chaining support to shadergraph collection API. Optimized ShaderSubGraph import dependencies to minimize unnecessary reimports when using CustomFunctionNode Changed UI names from Vector1 to Float Renamed Float precision to Single Cleaned up the UI to add/remove Targets The * in the ShaderGraph title bar now indicates that the graph has been modified when compared to the state it was loaded, instead of compared to what is on disk Cancelling a \"Save changes on Close?\" will now cancel the Close as well When attempting to Save and encountering a Read Only file or other exception, ShaderGraph will allow the user to retry as many times as they like Fixed Fixed a bug where ShaderGraph subgraph nodes would not update their slot names or order Fixed an issue where very old ShaderGraphs would fail to load because of uninitialized data 1269616 Fixed an issue where ShaderGraph previews didn't display correctly when setting a texture to \"None\" [1264932] Fixed an issue with the SampleVirtualTexture node in ShaderGraph, where toggling Automatic Streaming would cause the node to incorrectly display four output slots [1271618] Fixed an issue in ShaderGraph with integer-mode Vector1 properties throwing errors when the value is changed [1264930] Fixed a bug where ShaderGraph would not load graphs using Procedural VT nodes when the nodes were the project had them disabled [1271598] Fixed an issue where the ProceduralVT node was not updating any connected SampleVT nodes when the number of layers was changed [1274288] Fixed an issue with how unknown nodes were treated during validation Fixed an issue where ShaderGraph shaders did not reimport automatically when some of the included files changed [1269634] Fixed an issue where building a context menu on a dragging block node would leave it floating and undo/redo would result in a soft-lock Fixed an issue where ShaderGraph was logging error when edited in play mode [1274148]. Fixed a bug where properties copied over with their graph inputs would not hook up correctly in a new graph [1274306] Fixed an issue where renaming a property in the blackboard at creation would trigger an error. Fixed an issue where ShaderGraph shaders did not reimport automatically when missing dependencies were reintroduced [1182895] Fixed an issue where ShaderGraph previews would not show error shaders when the active render pipeline is incompatible with the shader [1257015] ShaderGraph DDX, DDY, DDXY, and NormalFromHeight nodes do not allow themselves to be connected to vertex shader, as the derivative instructions can't be used [1209087] When ShaderGraph detects no active SRP, it will still continue to render the master preview, but it will use the error shader [1264642] VirtualTexture is no longer allowed as a SubGraph output (it is not supported by current system) [1254483] ShaderGraph Custom Function Node will now correctly convert function and slot names to valid HLSL identifiers [1258832] Fixed an issue where ShaderGraph Custom Function Node would reorder slots when you modified them [1280106] Fixed Undo handling when adding or removing Targets from a ShaderGraph [1257028] Fixed an issue with detection of circular subgraph dependencies [1269841] Fixed an issue where subgraph nodes were constantly changing their serialized data [1281975] Modifying a subgraph will no longer cause ShaderGraphs that use them to \"reload from disk?\" [1198885] Fixed issues with ShaderGraph title bar not correctly displaying the modified status * [1282031] Fixed issues where ShaderGraph could discard modified data without user approval when closed [1170503] Fixed an issue where ShaderGraph file dependency gathering would fail to include any files that didn't exist Fixed issues with ShaderGraph detection and handling of deleted graph files Fixed an issue where the ShaderGraph was corrupting the translation cache Fixed an issue where ShaderGraph would not prompt the user to save unsaved changes after an assembly reload Fixed an issue with Position Node not automatically upgrading Fixed an issue where failing SubGraphs would block saving graph files using them (recursion check would throw exceptions) [1283425] Fixed an issue where choosing \"None\" as the default texture for a texture property would not correctly preview the correct default color [1283782] Fixed some bugs with Color Nodes and properties that would cause incorrect collorspace conversions [10.0.0] - 2019-06-10 Added Added the Internal Inspector which allows the user to view data contained in selected nodes and properties in a new floating graph sub-window. Also added support for custom property drawers to let you visualize any data type you like and expose it to the inspector. Added samples for Procedural Patterns to the package. You can now use the right-click context menu to delete Sticky Notes. You can now save your graph as a new Asset. Added support for vertex skinning when you use the DOTS animation package. You can now use the right-click context menu to set the precision on multiple selected nodes. You can now select unused nodes in your graph. When you start the Editor, Shader Graph now displays Properties in the Blackboard as collapsed. Updated the zoom level to let you zoom in further. Blackboard properties now have a Duplicate menu option. When you duplicate properties, Shader Graph maintains the order, and inserts duplicates below the current selection. When you convert a node to a Sub Graph, the dialog now opens up in the directory of the original graph that contained the node. If the new Sub Graph is outside this directory, it also remembers that path for the next dialog to ease folder navigation. If Unity Editor Analytics are enabled, Shader Graph collects anonymous data about which nodes you use in your graphs. This helps the Shader Graph team focus our efforts on the most common graph scenarios, and better understand the needs of our customers. We don't track edge data and cannot recreate your graphs in any form. The Create Node Menu now has a tree view and support for fuzzy field searching. When a Shader Graph or Sub Graph Asset associated with a open window has been deleted, Unity now displays a dialog that asks whether you would like to save the graph as a new Asset or close the window. Added a drop-down menu to the PBR Master Node that lets you select the final coordinate space of normals delivered from the fragment function. Added support for users to drag and drop Blackboard Properties from one graph to another. Breaking out GraphData validation into clearer steps. Added AlphaToMask render state. Added a field to the Master Nodes that overrides the generated shader's ShaderGUI, which determines how a Material that uses a Shader Graph looks. Added Redirect Nodes. You can now double-click an edge to add a control point that allows you to route edges around other nodes and connect multiple output edges. Added Compute Deformation Node to read deformed vertex data from Dots Deformations. Added new graph nodes that allow sampling Virtual Textures Shader Graph now uses a new file format that is much friendlier towards version control systems and humans. Existing Shader Graphs and will use the new format next time they are saved. Added 'Allow Material Override' option to the built-in target for shader graph. Changed Changed the Branch node so that it uses a ternary operator (Out = bool ? a : B) instead of a linear interpolate function. Copied nodes are now pasted at the cursor location instead of slightly offset from their original location. Error messages reported on Sub Graph output nodes for invalid previews now present clearer information, with documentation support. Updated legacy COLOR output semantic to SV_Target in pixel shader for compatibility with DXC. Updated the functions in the Normal From Height node to avoid NaN outputs. Changed the Voronoi Node algorithm to increase the useful range of the input values and to always use float values internally to avoid clipping. Changed the Reference Suffix of Keyword Enum entries so that you cannot edit them, which ensures that material keywords compile properly. Updated the dependent version of Searcher to 4.2.0. Added support for Linear Blend Skinning Node to Universal Render Pipeline. Moved all code to be under Unity specific namespaces. Changed ShaderGraphImporter and ShaderSubgraphImporter so that graphs are imported before Models. Remove VFXTarget if VisualEffect Graph package isn't included. VFXTarget doesn't overwrite the shader export anymore, VFXTarget can be active with another target. Fixed Edges no longer produce errors when you save a Shader Graph. Shader Graph no longer references the NUnit package. Fixed a shader compatibility issue in the SRP Batcher when you use a hybrid instancing custom variable. Fixed an issue where Unity would crash when you imported a Shader Graph Asset with invalid formatting. Fixed an issue with the animated preview when there is no Camera with animated Materials in the Editor. Triplanar nodes no longer use Camera-relative world space by default in HDRP. Errors no longer occur when you activate Enable GPU Instancing on Shader Graph Materials. 1184870 Errors no longer occur when there are multiple tangent transform nodes on a graph. 1185752 The Main Preview for Sprite Lit and Sprite Unlit master nodes now displays the correct color. 1184656 Shader Graph shaders in Always Include Shaders no longer crash builds. 1191757 The Transform node now correctly transforms Absolute World to Object. Errors no longer occur when you change the precision of Sub Graphs. 1158413 Fixed an error where the UV channel drop-down menu on nodes had clipped text. 1188710 Added StencilOverride support. Sticky Notes can now be grouped properly. Fixed an issue where nodes couldn't be copied from a group. Fixed a bug that occurred when you duplicated multiple Blackboard properties or keywords simultaneously, where Shader Graph stopped working, potentially causing data loss. Fixed a bug where you couldn't reorder Blackboard properties. Shader Graph now properly duplicates the Exposed status for Shader properties and keywords. Fixed a bug where the Save Graph As dialog for a Shader or Sub Graph sometimes appeared in the wrong Project when you had multiple Unity Projects open simultaneously. Fixed an issue where adding the first output to a Sub Graph without any outputs prior caused Shader Graphs containing the Sub Graph to break. Fixed an issue where Shader Graph shaders using the CameraNode failed to build on PS4 with \"incompatible argument list for call to 'mul'\". Fixed a bug that caused problems with Blackboard property ordering. Fixed a bug where the redo functionality in Shader Graph often didn't work. Fixed a bug where using the Save As command on a Sub Graph raised an exception. Fixed a bug where the input fields sometimes didn't render properly. 1176268 Fixed a bug where the Gradient property didn't work with all system locales. 1140924 Fixed a bug where Properties in the Blackboard could have duplicate names. Fixed a bug where you could drag the Blackboard into a graph even when you disabled the Blackboard. Fixed a bug where the Vertex Normal slot on master nodes needed vertex normal data input to compile. 1193348 Fixed a bug where GetWorldSpaceNormalizeViewDir() could cause undeclared indentifier errors. 1190606 Fixed a bug where Emission on PBR Shader Graphs in the Universal RP would not bake to lightmaps. 1190225 Fixed a bug where Shader Graph shaders were writing to POSITION instead of SV_POSITION, which caused PS4 builds to fail. Fixed a bug where Object to Tangent transforms in the Transform node used the wrong matrix. 1162203 Fixed an issue where boolean keywords in a Shader Graph caused HDRP Material features to fail. 1204827 Fixed a bug where Object space normals scaled with Object Scale. Documentation links on nodes now point to the correct URLs and package versions. Fixed an issue where Sub Graphs sometimes had duplicate names when you converted nodes into Sub Graphs. Fixed an issue where the number of ports on Keyword nodes didn't update when you added or removed Enum Keyword entries. Fixed an issue where colors in graphs didn't update when you changed a Blackboard Property's precision while the Color Mode is set to Precision. Fixed a bug where custom mesh in the Master Preview didn't work. Fixed a number of memory leaks that caused Shader Graph assets to stay in memory after closing the Shader Graph window. You can now smoothly edit controls on the Dielectric Specular node. Fixed Blackboard Properties to support scientific notation. Fixed a bug where warnings in the Shader Graph or Sub Graph were treated as errors. Fixed a bug where the error Output value 'vert' is not initialized displayed on all PBR graphs in Universal. 1210710 Fixed a bug where PBR and Unlit master nodes in Universal had Alpha Clipping enabled by default. Fixed an issue in where analytics wasn't always working. Fixed a bug where if a user had a Blackboard Property Reference start with a digit the generated shader would be broken. Avoid unintended behavior by removing the ability to create presets from Shader Graph (and Sub Graph) assets. 1220914 Fixed a bug where undo would make the Master Preview visible regardless of its toggle status. Fixed a bug where any change to the PBR master node settings would lose connection to the normal slot. Fixed a bug where the user couldn't open up HDRP Master Node Shader Graphs without the Render Pipeline set to HDRP. Fixed a bug where adding a HDRP Master Node to a Shader Graph would softlock the Shader Graph. Fixed a bug where shaders fail to compile due to #pragma target generation when your system locale uses commas instead of periods. Fixed a compilation error when using Hybrid Renderer due to incorrect positioning of macros. Fixed a bug where the Create Node Menu lagged on load. Entries are now only generated when property, keyword, or subgraph changes are detected. 1209567. Fixed a bug with the Transform node where converting from Absolute World space in a sub graph causes invalid subscript errors. 1190813 Fixed a bug where depndencies were not getting included when exporting a shadergraph and subgraphs Fixed a bug where adding a \" to a property display name would cause shader compilation errors and show all nodes as broken Fixed a bug where the Position node would change coordinate spaces from World to Absolute World when shaders recompile. 1184617 Fixed a bug where instanced shaders wouldn't compile on PS4. Fixed a bug where switching a Color Nodes' Mode between Default and HDR would cause the Color to be altered incorrectly. Fixed a bug where nodes dealing with matricies would sometimes display a preview, sometimes not. Optimized loading a large Shader Graph. 1209047 Fixed NaN issue in triplanar SG node when blend goes to 0. Fixed a recurring bug where node inputs would get misaligned from their ports. [1224480] Fixed an issue where Blackboard properties would not duplicate with Precision or Hybrid Instancing options. Fixed an issue where Texture properties on the Blackboard would not duplicate with the same Mode settings. Fixed an issue where Keywords on the Blackboard would not duplicate with the same Default value. Shader Graph now requests preview shader compilation asynchronously. 1209047 Fixed an issue where Shader Graph would not compile master previews after an assembly reload. Fixed issue where Linear Blend Skinning node could not be converted to Sub Graph 1227087 Fixed a compilation error in preview shaders for nodes requiring view direction. Fixed undo not being recorded properly for setting active master node, graph precision, and node defaults. Fixed an issue where Custum Function nodes and Sub Graph Output nodes could no longer rename slots. Fixed a bug where searcher entries would not repopulate correctly after an undo was perfromed (https://fogbugz.unity3d.com/f/cases/1241018/) Fixed a bug where Redirect Nodes did not work as inputs to Custom Function Nodes. 1235999 Fixed a bug where changeing the default value on a keyword would reset the node input type to vec4 (https://fogbugz.unity3d.com/f/cases/1216760/) Fixed a soft lock when you open a graph when the blackboard hidden. Fixed an issue where keyboard navigation in the Create Node menu no longer worked. [1253544] Preview correctly shows unassigned VT texture result, no longer ignores null textures Don't allow duplicate VT layer names when renaming layers Moved VT layer TextureType to the VTProperty from the SampleVT node Fixed the squished UI of VT property layers Disallow Save As and Convert to Subgraph that would create recursive dependencies Fixed an issue where the user would not get a save prompt on application close 1262044 Fixed bug where output port type would not visually update when input type changed (for example from Vec1 to Vec3) 1259501 Fixed an issue with how we collected/filtered nodes for targets. Applied the work to the SearchWindowProvider as well Fixed a bug where the object selector for Custom Function Nodes did not update correctly. 1176129 Fixed a bug where whitespaces were allowed in keyword reference names Fixed a bug where the Create Node menu would override the Object Field selection window. 1176125 Fixed a bug where the Main Preview window was no longer a square aspect ratio. 1257053 Fixed a bug where the size of the Graph Inspector would not save properly. 1257084 Replace toggle by an enumField for lit/unlit with VFXTarget Alpha Clipping option in Graph inspector now correctly hides and indents dependent options. (https://fogbugz.unity3d.com/f/cases/1257041/) Fixed a bug where changing the name of a property did not update nodes on the graph. 1249164 Fixed a crash issue when ShaderGraph included in a project along with DOTS assemblies Added missing SampleVirtualTextureNode address mode control in ShaderGraph Fixed a badly named control on SampleVirtualTextureNode in ShaderGraph Fixed an issue where multiple SampleVirtualTextureNodes created functions with names that may collide in ShaderGraph Made sub graph importer deterministic to avoid cascading shader recompiles when no change was present. Adjusted style sheet for Blackboard to prevent ui conflicts. Fixed a bug where the SampleVirtualTexture node would delete slots when changing its LOD mode Use preview of the other target if VFXTarget is active. [7.1.1] - 2019-09-05 Added You can now define shader keywords on the Blackboard. Use these keywords on the graph to create static branches in the generated shader. The tab now shows whether you are working in a Sub Graph or a Shader Graph file. The Shader Graph importer now bakes the output node type name into a meta-data object. Fixed The Shader Graph preview no longer breaks when you create new PBR Graphs. Fixed an issue where deleting a group and a property at the same time would cause an error. Fixed the epsilon that the Hue Node uses to avoid NaN on platforms that support half precision. Emission nodes no longer produce errors when you use them in Sub Graphs. Exposure nodes no longer produce errors when you use them in Sub Graphs. Unlit master nodes no longer define unnecessary properties in the Universal Render Pipeline. Errors no longer occur when you convert a selection to a Sub Graph. Color nodes now handle Gamma and Linear conversions correctly. Sub Graph Output nodes now link to the correct documentation page. When you use Keywords, PBR and Unlit master nodes no longer produce errors. PBR master nodes now calculate Global Illumination (GI) correctly. PBR master nodes now apply surface normals. PBR master nodes now apply fog. The Editor now displays correct errors for missing or deleted Sub Graph Assets. You can no longer drag and drop recursive nodes onto Sub Graph Assets. [7.0.1] - 2019-07-25 Changed New Shader Graph windows are now docked to either existing Shader Graph windows, or to the Scene View. Fixed Fixed various dependency tracking issues with Sub Graphs and HLSL files from Custom Function Nodes. Fixed an error that previously occurred when you used Sampler State input ports on Sub Graphs. Normal Reconstruct Z node is now compatible with both fragment and vertex stages. Position node now draws the correct label for Absolute World. Node previews now inherit preview type correctly. Normal maps now unpack correctly for mobile platforms. Fixed an error that previously occurred when you used the Gradient Sample node and your system locale uses commas instead of periods. Fixed an issue where you couldn't group several nodes. [7.0.0] - 2019-07-10 Added You can now use the SHADERGRAPH_PREVIEW keyword in Custom Function Node to generate different code for preview Shaders. Color Mode improves node visibility by coloring the title bar by Category, Precision, or custom colors. You can now set the precision of a Shader Graph and individual nodes. Added the _TimeParameters variable which contains Time, Sin(Time), and Cosine(Time) Absolute World space on Position Node now provides absolute world space coordinates regardless of the active render pipeline. You can now add sticky notes to graphs. Changed The Custom Function Node now uses an object field to reference its source when using File mode. To enable master nodes to generate correct motion vectors for time-based vertex modification, time is now implemented as an input to the graph rather than as a global uniform. World space on Position Node now uses the default world space coordinates of the active render pipeline. Fixed Fixed an error in Custom Function Node port naming. Sampler State properties and nodes now serialize correctly. Labels in the Custom Port menu now use the correct coloring when using the Personal skin. Fixed an error that occured when creating a Sub Graph from a selection containing a Group Node. When you change a Sub Graph, Shader Graph windows now correctly reload. When you save a Shader Graph, all other Shader Graph windows no longer re-compile their preview Shaders. Shader Graph UI now draws with correct styling for 2019.3. When deleting edge connections to nodes with a preview error, input ports no longer draw in the wrong position. Fixed an error involving deprecated components from VisualElements. When you convert nodes to a Sub Graph, the nodes are now placed correctly in the Sub Graph. The Bitangent Vector Node now generates all necessary shader requirements. [6.7.0-preview] - 2019-05-16 Added Added a hidden path namespace for Sub Graphs to prevent certain Sub Graphs from populating the Create Node menu. Changed Anti-aliasing (4x) is now enabled on Shader Graph windows. Fixed When you click on the gear icon, Shader Graph now focuses on the selected node, and brings the settings menu to front view. Sub Graph Output and Custom Function Node now validate slot names, and display an appropriate error badge when needed. Remaining outdated documentation has been removed. When you perform an undo or redo to an inactive Shader Graph window, the window no longer breaks. When you rapidly perform an undo or redo, Shader Graph windows no longer break. Sub Graphs that contain references to non-existing Sub Graphs no longer break the Sub Graph Importer. You can now reference sub-assets such as Textures. You can now reference Scene Color and Scene Depth correctly from within a Sub Graph. When you create a new empty Sub Graph, it no longer shows a warning about a missing output. When you create outputs that start with a digit, Shader generation no longer fails. You can no longer add nodes that are not allowed into Sub Graphs. A graph must now always contain at least one Master Node. Duplicate output names are now allowed. Fixed an issue where the main preview was always redrawing. When you set a Master Node as active, the Main Preview now shows the correct result. When you save a graph that contains a Sub Graph node, the Shader Graph window no longer freezes. Fixed an error that occured when using multiple Sampler State nodes with different parameters. Fixed an issue causing default inputs to be misaligned in certain cases. You can no longer directly connect slots with invalid types. When the graph detects that situation, it now doesn't break and gives an error instead. [6.6.0] - 2019-04-01 Added You can now add Matrix, Sampler State and Gradient properties to the Blackboard. Added Custom Function node. Use this node to define a custom HLSL function either via string directly in the graph, or via a path to an HLSL file. You can now group nodes by pressing Ctrl + G. Added \"Delete Group and Contents\" and removed \"Ungroup All Nodes\" from the context menu for groups. You can now use Sub Graphs in other Sub Graphs. Preview shaders now compile in the background, and only redraw when necessary. Changed Removed Blackboard fields, which had no effect on Sub Graph input ports, from the Sub Graph Blackboard. Subgraph Output node is now called Outputs. Subgraph Output node now supports renaming of ports. Subgraph Output node now supports all port types. Subgraph Output node now supports reordering ports. When you convert nodes to a Sub Graph, Shader Graph generates properties and output ports in the Sub Graph, and now by default, names those resulting properties and output ports based on their types. When you delete a group, Shader Graph now deletes the Group UI, but doesn't delete the nodes inside. Fixed You can now undo edits to Vector port default input fields. You can now undo edits to Gradient port default input fields. Boolean port input fields now display correct values when you undo changes. Vector type properties now behave as expected when you undo changes. Fixed an error that previously occurred when you opened saved Shader Graphs containing one or more Voronoi nodes. You can now drag normal map type textures on to a Shader Graph to create Sample Texture 2D nodes with the correct type set. Fixed the Multiply node so default input values are applied correctly. Added padding on input values for Blend node to prevent NaN outputs. Fixed an issue where IsFaceSign would not compile within Sub Graph Nodes. Null reference errors no longer occur when you remove ports with connected edges. Default input fields now correctly hide and show when connections change. [6.5.0] - 2019-03-07 Fixed Fixed master preview for HDRP master nodes when alpha clip is enabled. [6.4.0] - 2019-02-21 Fixed Fixed the Transform node, so going from Tangent Space to any other space now works as expected. [6.3.0] - 2019-02-18 Fixed Fixed an issue where the Normal Reconstruct Z Node sometimes caused Not a Number (NaN) errors when using negative values. [6.2.0] - 2019-02-15 Fixed Fixed the property blackboard so it no longer goes missing or turns very small. Changed Code refactor: all macros with ARGS have been swapped with macros with PARAM. This is because the ARGS macros were incorrectly named. [6.1.0] - 2019-02-13 [6.0.0] - 2019-02-23 Added When you hover your cursor over a property in the blackboard, this now highlights the corresponding property elements in your Shader Graph. Similarly, if you hover over a property in the Shader Graph itself, this highlights the corresponding property in the blackboard. Property nodes in your Shader Graph now have a similar look and styling as the properties in the blackboard. Changed Errors in the compiled shader are now displayed as badges on the appropriate node. In the Scene Depth node you can now choose the depth sampling mode: Linear01, Raw or Eye. Fixed When you convert an inline node to a Property node, this no longer allows duplicate property names. When you move a node, you'll now be asked to save the Graph file. You can now Undo edits to Property parameters on the Blackboard. You can now Undo conversions between Property nodes and inline nodes. You can now Undo moving a node. You can no longer select the Texture2D Property type Mode, if the Property is not exposed. The Vector1 Property type now handles default values more intuitively when switching Mode dropdown. The Color node control is now a consistent width. Function declarations no longer contain double delimiters. The Slider node control now functions correctly. Fixed an issue where the Editor automatically re-imported Shader Graphs when there were changes to the asset database. Reverted the visual styling of various graph elements to their previous correct states. Previews now repaint correctly when Unity does not have focus. Code generation now works correctly for exposed Vector1 shader properties where the decimal separator is not a dot. The Rotate About Axis node's Modes now use the correct function versions. Shader Graph now preserves grouping when you convert nodes between property and inline. The Flip node now greys out labels for inactive controls. The Boolean property type now uses the ToggleUI property attribute, so as to not generate keywords. The Normal Unpack node no longer generates errors in Object space. The Split node now uses values from its default Port input fields. The Channel Mask node now allows multiple node instances, and no longer generates any errors. Serialized the Alpha control value on the Flip node. The Is Infinite and Is NaN nodes now use Vector 1 input ports, but the output remains the same. You can no longer convert a node inside a Sub Graph into a Sub Graph, which previously caused errors. The Transformation Matrix node's Inverse Projection and Inverse View Projection modes no longer produce errors. The term Shader Graph is now captilized correctly in the Save Graph prompt. [5.2.0] - 2018-11-27 Added Shader Graph now has Group Node, where you can group together several nodes. You can use this to keep your Graphs organized and nice. Fixed The expanded state of blackboard properties are now remembered during a Unity session. [5.1.0] - 2018-11-19 Added You can now show and hide the Main Preview and the Blackboard from the toolbar. Changed The Shader Graph package is no longer in preview. Moved NormalBlendRNM node to a dropdown option on Normal Blend node. Sample Cubemap node now has a SamplerState slot. New Sub Graph assets now default to the \"Sub Graphs\" path in the Create Node menu. New Shader Graph assets now default to the \"Shader Graphs\" path in the Shader menu. The Light Probe node is now a Baked GI node. When you use LWRP with lightmaps, this node now returns the correct lightmap data. This node is supported in HDRP. Reflection Probe nodes now only work with LWRP. This solves compilation errors in HDRP. Ambient nodes now only work with LWRP. This solves compilation errors in HDRP. Fog nodes now only work with LWRP. This solves compilation errors in HDRP. In HDRP, the Position port for the Object node now returns the absolute world position. The Baked GI, Reflection Probe, and Ambient nodes are now in the Input/Lighting category. The master node no longer has its own preview, because it was redundant. You can see the results for the master node in the Main Preview. Fixed Shadow projection is now correct when using the Unlit master node with HD Render Pipeline. Removed all direct references to matrices Matrix Construction nodes with different Mode values now evaluate correctly. Is Front Face node now works correctly when connected to Alpha and AlphaThreshold slots on the PBR master node. Corrected some instances of incorrect port dimensions on several nodes. Scene Depth and Scene Color nodes now work in single pass stereo in Lightweight Render Pipeline. Channel Mask node controls are now aligned correctly. In Lightweight Render Pipeline, Pre-multiply surface type now matches the Lit shader. Non-exposed properties in the blackboard no longer have a green dot next to them. Default reference name for shader properties are now serialized. You cannot change them after initial creation. When you save Shader Graph and Sub Graph files, they're now automatically checked out on version control. Shader Graph no longer throws an exception when you double-click a folder in the Project window. Gradient Node no longer throws an error when you undo a deletion. [5.0.0-preview] - 2018-09-28 [4.0.0-preview] - 2018-09-28 Added Shader Graph now supports the High Definition Render Pipeline with both PBR and Unlit Master nodes. Shaders built with Shader Graph work with both the Lightweight and HD render pipelines. You can now modify vertex position via the Position slot on the PBR and Unlit Master nodes. By default, the input to this node is object space position. Custom inputs to this slot should specify the absolute local position of a given vertex. Certain nodes (such as Procedural Shapes) are not viable in the vertex shader. Such nodes are incompatible with this slot. You can now edit the Reference name for a property. To do so, select the property and type a new name next to Reference. If you want to reset to the default name, right-click Reference, and select Reset reference. In the expanded property window, you can now toggle whether the property is exposed. You can now change the path of Shader Graphs and Sub Graphs. When you change the path of a Shader Graph, this modifies the location it has in the shader selection list. When you change the path of Sub Graph, it will have a different location in the node creation menu. Added Is Front Face node. With this node, you can change graph output depending on the face sign of a given fragment. If the current fragment is part of a front face, the node returns true. For a back face, the node returns false. Note: This functionality requires that you have enabled two sided on the Master node. Gradient functionality is now available via two new nodes: Sample Gradient and Gradient Asset. The Sample Gradient node samples a gradient given a Time parameter. You can define this gradient on the Gradient slot control view. The Gradient Asset node defines a gradient that can be sampled by multiple Sample Gradient nodes using different Time parameters. Math nodes now have a Waves category. The category has four different nodes: Triangle wave, Sawtooth wave, Square wave, and Noise Sine wave. The Triangle, Sawtooth, and Square wave nodes output a waveform with a range of -1 to 1 over a period of 1. The Noise Sine wave outputs a standard Sine wave with a range of -1 to 1 over a period of 2 * pi. For variance, random noise is added to the amplitude of the Sine wave, within a determined range. Added Sphere Mask node for which you can indicate the starting coordinate and center point. The sphere mask uses these with the Radius and Hardness parameters. Sphere mask functionality works in both 2D and 3D spaces, and is based on the vector coordinates in the Coords and Center input. Added support for Texture 3D and Texture 2D Array via two new property types and four new nodes. A new node Texture 2D LOD has been added for LOD functionality on a Texture 2D Sample. Sample Texture 2D LOD uses the exact same input and output slots as Sample Texture 2D, but also includes an input for level of detail adjustments via a Vector1 slot. Added Texel Size node, which allows you to get the special texture properties of a Texture 2D Asset via the {texturename}_TexelSize variable. Based on input from the Texture 2D Asset, the node outputs the width and height of the texel size in Vector1 format. Added Rotate About Axis node. This allows you to rotate a 3D vector space around an axis. For the rotation, you can specify an amount of degrees or a radian value. Unpacking normal maps in object space. Unpacking derivative maps option on sample texture nodes. Added Uint type for instancing support. Added HDR option for color material slots. Added definitions used by new HD Lit Master node. Added a popup control for a string list. Added conversion type (position/direction) to TransformNode. In your preview for nodes that are not master nodes, pixels now display as pink if they are not finite. Changed The settings for master nodes now live in a small window that you can toggle on and off. Here, you can change various rendering settings for your shader. There are two Normal Derive Nodes: Normal From Height and Normal Reconstruct Z. Normal From Height uses Vector1 input to derive a normal map. Normal Reconstruct Z uses the X and Y components in Vector2 input to derive the proper Z value for a normal map. The Texture type default input now accepts render textures. HD PBR subshader no longer duplicates surface description code into vertex shader. If the current render pipeline is not compatible, master nodes now display an error badge. The preview shader now only considers the current render pipeline. Because of this there is less code to compile, so the preview shader compiles faster. When you rename a shader graph or sub shader graph locally on your disk, the title of the Shader Graph window, black board, and preview also updates. Removed legacy matrices from Transfomation Matrix node. Texture 2D Array and Texture 3D nodes can no longer be used in the vertex shader. Normal Create node has been renamed to Normal From Texture. When you close the Shader Graph after you have modified a file, the prompt about saving your changes now shows the file name as well. Blend node now supports Overwrite mode. Simple Noise node no longer has a loop. The Polygon node now calculates radius based on apothem. Normal Strength node now calculates Z value more accurately. You can now connect Sub Graphs to vertex shader slots. If a node in the Sub Graph specifies a shader stage, that specific Sub Graph node is locked to that stage. When an instance of a Sub Graph node is connected to a slot that specifies a shader stage, all slots on that instance are locked to the stage. Separated material options and tags. Master node settings are now recreated when a topological modification occurs. Fixed Vector 1 nodes now evaluate correctly. (#334 and #337) Properties can now be copied and pasted. Pasting a property node into another graph will now convert it to a concrete node. (#300 and #307) Nodes that are copied from one graph to another now spawn in the center of the current view. (#333) When you edit sub graph paths, the search window no longer yields a null reference exception. The blackboard is now within view when deserialized. Your system locale can no longer cause incorrect commands due to full stops being converted to commas. Deserialization of subgraphs now works correctly. Sub graphs are now suffixed with (sub), so you can tell them apart from other nodes. Boolean and Texture type properties now function correctly in sub-graphs. The preview of a node does not obstruct the selection outliner anymore. The Dielectric Specular node no longer resets its control values. You can now copy, paste, and duplicate sub-graph nodes with vector type input ports. The Lightweight PBR subshader now normalizes normal, tangent, and view direction correctly. Shader graphs using alpha clip now generate correct depth and shadow passes. Normal Create node has been renamed to Normal From Texture. The preview of nodes now updates correctly. Your system locale can no longer cause incorrect commands due to full stops being converted to commas. Show Generated Code no longer throws an \"Argument cannot be null\" error. Sub Graphs now use the correct generation mode when they generate preview shaders. The CodeFunctionNode API now generates correct function headers when you use DynamicMatrix type slots. Texture type input slots now set correct default values for 'Normal' texture type. SpaceMaterialSlot now reads correct slot. Slider node control now functions correctly. Shader Graphs no longer display an error message intended for Sub Graphs when you delete properties. The Shader Graph and Sub Shader Graph file extensions are no longer case-sensitive. The dynamic value slot type now uses the correct decimal separator during HLSL generation. Fixed an issue where Show Generated Code could fail when external editor was not set. In the High Definition Render Pipeline, Shader Graph now supports 4-channel UVs. The Lightweight PBR subshader now generates the correct meta pass. Both PBR subshaders can now generate indirect light from emission. Shader graphs now support the SRP batcher. Fixed an issue where floatfield would be parsed according to OS locale settings with .NET 4.6"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Absolute-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Absolute-Node.html",
    "title": "Absolute Node | mmo-rpg-unity",
    "keywords": "Absolute Node Description Returns the absolute value of the input In. Components of the input Dynamic Vector that are positive will remain positive and components that are negative will be inverted and become positive. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Absolute_float4(float4 In, out float4 Out) { Out = abs(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Add-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Add-Node.html",
    "title": "Add Node | mmo-rpg-unity",
    "keywords": "Add Node Description Returns the sum of the two input values A and B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Add_float4(float4 A, float4 B, out float4 Out) { Out = A + B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/All-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/All-Node.html",
    "title": "All Node | mmo-rpg-unity",
    "keywords": "All Node Description Returns true if all components of the input In are non-zero. This is useful for Branching. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_All_float4(float4 In, out float Out) { Out = all(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Ambient-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Ambient-Node.html",
    "title": "Ambient Node | mmo-rpg-unity",
    "keywords": "Ambient Node Description Provides access to the Scene's Ambient color values. When Environment Lighting Source is set to Gradient Port Color/Sky returns the value Sky Color. When Environment Lighting Source is set to Color Port Color/Sky returns the value Ambient Color. Ports Equator and Ground always return the values Equator Color and Ground Color regardless of the current Environment Lighting Source. Note: Values of this Node are only updated when entering Play mode or saving the current Scene/Project. Note: The behavior of this Node is undefined globally. Shader Graph does not define the function of the node. Instead, each Render Pipeline defines what HLSL code to execute for this Node. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. A Node might be defined in one Render Pipeline and undefined in the other. If this Node is undefined, it returns 0 (black). Unity Render Pipelines Support Universal Render Pipeline The High Definition Render Pipeline does not support this Node. Ports Name Direction Type Binding Description Color/Sky Output Vector 3 None Color (Color) or Sky (Gradient) color value Equator Output Vector 3 None Equator (Gradient) color value Ground Output Vector 3 None Ground (Gradient) color value Generated Code Example The following example code represents one possible outcome of this node. float3 _Ambient_ColorSky = SHADERGRAPH_AMBIENT_SKY; float3 _Ambient_Equator = SHADERGRAPH_AMBIENT_EQUATOR; float3 _Ambient_Ground = SHADERGRAPH_AMBIENT_GROUND;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/And-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/And-Node.html",
    "title": "And Node | mmo-rpg-unity",
    "keywords": "And Node Description Returns true if both the inputs A and B are true. This is useful for Branching. Ports Name Direction Type Binding Description A Input Boolean None First input value B Input Boolean None Second input value Out Output Boolean None Output value Generated Code Example void Unity_And(float A, float B, out float Out) { Out = A && B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Any-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Any-Node.html",
    "title": "Any Node | mmo-rpg-unity",
    "keywords": "Any Node Description Returns true if any of the components of the input In are non-zero. This is useful for Branching. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Any_float4(float4 In, out float Out) { Out = any(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Arccosine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Arccosine-Node.html",
    "title": "Arccosine Node | mmo-rpg-unity",
    "keywords": "Arccosine Node Description Returns the arccosine of each component of the input In as a vector of the same dimension and equal length. Each component should be within the range of -1 to 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Arccosine_float4(float4 In, out float4 Out) { Out = acos(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Arcsine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Arcsine-Node.html",
    "title": "Arcsine Node | mmo-rpg-unity",
    "keywords": "Arcsine Node Description Returns the arcsine of each component of the input In as a vector of the same dimension and equal length. Each component should be within the range of -Pi/2 to Pi/2. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Arcsine_float4(float4 In, out float4 Out) { Out = asin(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Arctangent-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Arctangent-Node.html",
    "title": "Arctangent Node | mmo-rpg-unity",
    "keywords": "Arctangent Node Description Returns the arctangent of the value of input In. Each component should be within the range of -Pi/2 to Pi/2. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Arctangent_float4(float4 In, out float4 Out) { Out = atan(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Arctangent2-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Arctangent2-Node.html",
    "title": "Arctangent2 Node | mmo-rpg-unity",
    "keywords": "Arctangent2 Node Description Returns the arctangent of the values of both input A and input B. The signs (whether they are positive or negative values) of the input values are used to determine whether the output components, or channels, are positive or negative within a range of -Pi to Pi. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Arctangent2_float4(float4 A, float4 B, out float4 Out) { Out = atan2(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Artistic-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Artistic-Nodes.html",
    "title": "Artistic Nodes | mmo-rpg-unity",
    "keywords": "Artistic Nodes Adjustment Channel Mixer Contrast Controls the amount each of the channels of input In contribute to each of the output channels. Adjusts the contrast of input In by the amount of input Contrast. Hue Invert Colors Offsets the hue of input In by the amount of input Offset. Inverts the colors of input In on a per channel basis. Replace Color Saturation Replaces values in input In equal to input From to the value of input To. Adjusts the saturation of input In by the amount of input Saturation. White Balance Adjusts the temperature and tint of input In by the amount of inputs Temperature and Tint respectively. Blend Blend Blends the value of input Blend onto input Base using the blending mode defined by parameter Mode. Filter Dither Dither is an intentional form of noise used to randomize quantization error. It is used to prevent large-scale patterns such as color banding in images.. Mask Channel Mask Color Mask Masks values of input In on channels selected in dropdown Channels. Creates a mask from values in input In equal to input Mask Color. Normal Normal Blend Normal From Height Blends two normal maps defined by inputs A and B together. Creates a normal map from a height map defined by input Texture. Normal Strength Normal Unpack Adjusts the strength of the normal map defined by input In by the amount of input Strength. Unpacks a normal map defined by input In. Utility Colorspace Conversion Returns the result of converting the value of input In from one colorspace space to another."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Baked-GI-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Baked-GI-Node.html",
    "title": "Baked GI Node | mmo-rpg-unity",
    "keywords": "Baked GI Node Description Provides access to the Baked GI values at the vertex or fragment's position. Requires Position and Normal input for light probe sampling, and lightmap coordinates Static UV and Dynamic UV for all potential lightmap sampling cases. Note: The behavior of this Node is undefined globally. Shader Graph does not define the function of the node. Instead, each Render Pipeline defines what HLSL code to execute for this Node. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. A Node might be defined in one Render Pipeline and undefined in the other. If this Node is undefined, it returns 0 (black). Unity Render Pipelines Support This node is compatible with both the High Definition Render Pipeline (HDRP) and the Universal Render Pipeline (URP). However, this node does not work within unlit shaders for either pipeline. Ports Name Direction Type Binding Description Position Input Vector 3 Position (world space) Mesh vertex/fragment's Position Normal Input Vector 3 Normal (world space) Mesh vertex/fragment's Normal Static UV Input Vector 2 UV1 Lightmap coordinates for the static lightmap Dynamic UV Input Vector 2 UV2 Lightmap coordinates for the dynamic lightmap Out Output Vector 3 None Output color value Controls Name Type Options Description Apply Lightmap Scaling Toggle True, False If enabled lightmaps are automatically scaled and offset. Generated Code Example The following example code represents one possible outcome of this node. void Unity_BakedGI_float(float3 Position, float3 Normal, float2 StaticUV, float2 DynamicUV, out float Out) { Out = SHADERGRAPH_BAKED_GI(Position, Normal, StaticUV, DynamicUV, false); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Bitangent-Vector-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Bitangent-Vector-Node.html",
    "title": "Bitangent Node | mmo-rpg-unity",
    "keywords": "Bitangent Node Description Provides access to the mesh vertex or fragment's Bitangent Vector, depending on the effective Shader Stage of the graph section the Node is part of. The coordinate space of the output value can be selected with the Space dropdown parameter. Ports Name Direction Type Binding Description Out Output Vector 3 None Bitangent Vector for the Mesh Vertex/Fragment. Controls Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of Bitangent Vector to output."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Blackboard.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Blackboard.html",
    "title": "Blackboard | mmo-rpg-unity",
    "keywords": "Blackboard Description You can use the Blackboard to define, order, and categorize the Properties and Keywords in a graph. From the Blackboard, you can also edit the path for the selected Shader Graph Asset or Sub Graph. Accessing the Blackboard The Blackboard is visible by default, and you cannot drag it off the graph and lose it. However, you are able to position it anywhere in the Shader Graph Window. It always maintains the same distance from the nearest corner, even if you resize the window. Adding properties and keywords to the Blackboard To create a new property or keyword, click the Add (+) button on the Blackboard's title bar and select a type. For a full list of property types, see Property Types. Editing properties and keywords Select a property or keyword in the Blackboard or graph to modify its settings in the Node Settings Menu. Setting Description Name The property's display name. The Editor strips quotation marks from display names and replaces them with underscores. Rename an item via the Blackboard by double-clicking on its name. Reference The name that Shader Graph uses internally for this property. Although the Editor populates this value by default, you can modify it. To revert to the original reference name, right-click on the word Reference (not the entry field) and select Reset Reference in the context menu. If the Reference Name contains any characters that HLSL does not support, the Editor replaces those characters with underscores. Default The default value of this property in any Material based on this Shader Graph. For example, if you have a Shader Graph for grass and expose the grass color as a property, you might set the default to Green. Precision Set the precision mode for the property. See Precision Modes. Exposed Enable this setting to make the property available for you to edit via the C# API. Enabled by default. Modifying and selecting keywords and properties To reorder items listed on the Blackboard, drag and drop them. To delete items, use the Delete key on Windows or Command + Backspace keys on macOS. To select multiple items, hold down the Ctrl key while making your selections. To cancel the selection of one or multiple items, hold down the Ctrl key while clicking on the items you want to remove from the selection. Using Blackboard categories To make the properties in your shader more discoverable, organize them into categories. Expand and collapse categories to make the Blackboard easier to navigate. Creating, renaming, moving, and deleting categories To add a category, use + on the Blackboard. To rename a category, double-click on the category name, or right-click and select Rename. To move a category within the Blackboard, select and drag it. To remove a category, select it and press Delete, or right-click and select Delete. Deleting a category also deletes the properties within it, so move those you wish to keep. Adding, removing, and reordering properties and keywords To add a property or keyword to a category, expand the category with the foldout (⌄) symbol, then drag and drop the property or keyword onto the expanded category. To remove a property or keyword, select it and press Delete, or right-click and select Delete. To re-order properties or keywords, drag and drop them within a category or move them into other categories. Creating a category for specific properties and keywords Select multiple properties or keywords and use + on the Blackboard to create a category that contains all of the items you have selected. Copying and pasting categories, with or without properties You can paste empty categories, categories with all of their properties, and categories with some of their properties into one or more graphs. To copy a category with all of its properties: Select the property. Copy it with Ctrl+C. Paste it into your target graph with Ctrl+V. To copy a specific set of properties: Select the category. Hold down the Ctrl key. Click the properties you do not want to include to remove them from the selection. Copy the property with Ctrl+C. Paste it into your target graph with Ctrl+V. Using categories in the Material Inspector To modify a material you have created with a Shader Graph, you can adjust specific property or keyword values in the Material Inspector, or edit the graph itself. Working with Streaming Virtual Textures Streaming Virtual Texture Properties sample texture layers. To access these layers in the Material Inspector, expand the relevant Virtual Texture section with the ⌄ symbol next to its name. You can add and remove layers via the Inspector. Exposing properties and keywords Unity exposes properties and keywords by default. This enables write access from scripts, so that you can edit them via the C# API, in addition to the graph. Exposed items have a green dot in their label. Enable or disable this feature in the Node Settings menu. Creating nodes Drag a property or keyword from the Blackboard into the graph to create a node of that kind. Settings for a node in the graph are identical to those for the related property or keyword in the Blackboard. Expand these nodes to use a sub-member of the property value. Property node names include a green dot if the property is exposed."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Blackbody-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Blackbody-Node.html",
    "title": "Blackbody Node | mmo-rpg-unity",
    "keywords": "Blackbody Node Description Samples a Gradient that simulates the effect of black body radiation. The calculations in this node are based on data gathered by Mitchell Charity. This node outputs color in linear RGB space and preforms the conversion using a D65 whitepoint and a CIE 1964 10 degree color space. For more information, see What color is a blackbody? Ports Name Direction Type Binding Description Temperature Input Float None Temperature or temperature map in Kelvin to sample. Out Output Vector 3 None Intensity represented by color in Vector 3. Generated Code Example The following example code represents one possible outcome of this node. void Unity_Blackbody_float(float Temperature, out float3 Out) { float3 color = float3(255.0, 255.0, 255.0); color.x = 56100000. * pow(Temperature,(-3.0 / 2.0)) + 148.0; color.y = 100.04 * log(Temperature) - 623.6; if (Temperature > 6500.0) color.y = 35200000.0 * pow(Temperature,(-3.0 / 2.0)) + 184.0; color.z = 194.18 * log(Temperature) - 1448.6; color = clamp(color, 0.0, 255.0)/255.0; if (Temperature < 1000.0) color *= Temperature/1000.0; Out = color; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Blend-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Blend-Node.html",
    "title": "Blend Node | mmo-rpg-unity",
    "keywords": "Blend Node Description Blends the value of input Blend onto input Base using the blending mode defined by the Mode parameter. The strength of the blend is defined by input Opacity. An Opacity value of 0 will return the input Base, unaltered. Ports Name Direction Type Binding Description Base Input Dynamic Vector None Base layer value Blend Input Dynamic Vector None Blend layer value Opacity Input Float None Strength of blend Out Output Dynamic Vector None Output value Controls Name Type Options Description Mode Dropdown Burn, Darken, Difference, Dodge, Divide, Exclusion, HardLight, HardMix, Lighten, LinearBurn, LinearDodge, LinearLight, LinearLightAddSub, Multiply, Negation, Overlay, PinLight, Screen, SoftLight, Subtract, VividLight, Overwrite Blend mode to apply Generated Code Example The following example code represents one possible outcome of this node per blend mode. Burn void Unity_Blend_Burn_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = 1.0 - (1.0 - Blend)/Base; Out = lerp(Base, Out, Opacity); } Darken void Unity_Blend_Darken_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = min(Blend, Base); Out = lerp(Base, Out, Opacity); } Difference void Unity_Blend_Difference_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = abs(Blend - Base); Out = lerp(Base, Out, Opacity); } Dodge void Unity_Blend_Dodge_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base / (1.0 - Blend); Out = lerp(Base, Out, Opacity); } Divide void Unity_Blend_Divide_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base / (Blend + 0.000000000001); Out = lerp(Base, Out, Opacity); } Exclusion void Unity_Blend_Exclusion_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Blend + Base - (2.0 * Blend * Base); Out = lerp(Base, Out, Opacity); } HardLight void Unity_Blend_HardLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 result1 = 1.0 - 2.0 * (1.0 - Base) * (1.0 - Blend); float4 result2 = 2.0 * Base * Blend; float4 zeroOrOne = step(Blend, 0.5); Out = result2 * zeroOrOne + (1 - zeroOrOne) * result1; Out = lerp(Base, Out, Opacity); } HardMix void Unity_Blend_HardMix_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = step(1 - Base, Blend); Out = lerp(Base, Out, Opacity); } Lighten void Unity_Blend_Lighten_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = max(Blend, Base); Out = lerp(Base, Out, Opacity); } LinearBurn void Unity_Blend_LinearBurn_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base + Blend - 1.0; Out = lerp(Base, Out, Opacity); } LinearDodge void Unity_Blend_LinearDodge_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base + Blend; Out = lerp(Base, Out, Opacity); } LinearLight void Unity_Blend_LinearLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Blend < 0.5 ? max(Base + (2 * Blend) - 1, 0) : min(Base + 2 * (Blend - 0.5), 1); Out = lerp(Base, Out, Opacity); } LinearLightAddSub void Unity_Blend_LinearLightAddSub_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Blend + 2.0 * Base - 1.0; Out = lerp(Base, Out, Opacity); } Multiply void Unity_Blend_Multiply_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base * Blend; Out = lerp(Base, Out, Opacity); } Negation void Unity_Blend_Negation_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = 1.0 - abs(1.0 - Blend - Base); Out = lerp(Base, Out, Opacity); } Overlay void Unity_Blend_Overlay_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 result1 = 1.0 - 2.0 * (1.0 - Base) * (1.0 - Blend); float4 result2 = 2.0 * Base * Blend; float4 zeroOrOne = step(Base, 0.5); Out = result2 * zeroOrOne + (1 - zeroOrOne) * result1; Out = lerp(Base, Out, Opacity); } PinLight void Unity_Blend_PinLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 check = step (0.5, Blend); float4 result1 = check * max(2.0 * (Base - 0.5), Blend); Out = result1 + (1.0 - check) * min(2.0 * Base, Blend); Out = lerp(Base, Out, Opacity); } Screen void Unity_Blend_Screen_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = 1.0 - (1.0 - Blend) * (1.0 - Base); Out = lerp(Base, Out, Opacity); } SoftLight void Unity_Blend_SoftLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 result1 = 2.0 * Base * Blend + Base * Base * (1.0 - 2.0 * Blend); float4 result2 = sqrt(Base) * (2.0 * Blend - 1.0) + 2.0 * Base * (1.0 - Blend); float4 zeroOrOne = step(0.5, Blend); Out = result2 * zeroOrOne + (1 - zeroOrOne) * result1; Out = lerp(Base, Out, Opacity); } Subtract void Unity_Blend_Subtract_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = Base - Blend; Out = lerp(Base, Out, Opacity); } VividLight void Unity_Blend_VividLight_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { float4 result1 = 1.0 - (1.0 - Blend) / (2.0 * Base); float4 result2 = Blend / (2.0 * (1.0 - Base)); float4 zeroOrOne = step(0.5, Base); Out = result2 * zeroOrOne + (1 - zeroOrOne) * result1; Out = lerp(Base, Out, Opacity); } Overwrite void Unity_Blend_Overwrite_float4(float4 Base, float4 Blend, float Opacity, out float4 Out) { Out = lerp(Base, Blend, Opacity); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Block-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Block-Node.html",
    "title": "Block Node | mmo-rpg-unity",
    "keywords": "Block Node Description A Block is a specific type of node for the Master Stack. A Block represents a single piece of the surface (or vertex) description data that Shader Graph uses in the final shader output. Built In Block nodes are always available, but nodes that are specific to a certain render pipeline are only available for that pipeline. For example, Universal Block nodes are only available for the Universal Render Pipeline (URP), and High Definition Block nodes are only available for the High Definition Render Pipeline (HDRP). Some blocks are only compatible with specific Graph Settings, and might become active or inactive based on the graph settings you select. You can't cut, copy, or paste Blocks. Add and Remove Block Nodes To add a new Block node to a Context in the Master Stack, place the cursor over an empty area in the Context, then press the Spacebar or right-click and select Create Node. This brings up the Create Node menu, which displays only Block nodes that are valid for the Context. For example, Vertex Blocks don't appear in the Create Node menu of a Fragment Context. Select a Block node from the menu to add it to the Context. To remove a Block from the Context, select the Block node in the Context, then press the Delete key or right-click and select Delete. Automatically Add or Remove Blocks You can also enable or disable an option in the Shader Graph Preferences to automatically add and remove Blocks from a Context. If you enable Automatically Add or Remove Blocks, Shader Graph automatically adds the required Block nodes for that particular asset's Target or material type. It automatically removes any incompatible Block nodes that have no connections and default values. If you disable Automatically Add or Remove Blocks, Shader Graph doesn't automatically add and remove Block nodes. You must manually add and remove all Block nodes. Active and Inactive Blocks Active Block nodes are Blocks that contribute to the final shader. Inactive Block nodes are Blocks that are present in the Shader Graph, but don't contribute to the final shader. When you change the graph settings, certain Blocks might become active or inactive. Inactive Block nodes and any node streams that are connected only to Inactive Block nodes appear grayed out."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Boolean-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Boolean-Node.html",
    "title": "Boolean Node | mmo-rpg-unity",
    "keywords": "Boolean Node Description Defines a constant Boolean value in the Shader Graph, although internally to the shader this is treated as a constant float value that is ether 0 or 1, similar to Shaderlab's Toggle property. Can be converted to a Boolean type Property via the Node's context menu. Ports Name Direction Type Binding Description Out Output Boolean None Output value Controls Name Type Options Description Toggle Defines the output value. Generated Code Example The following example code represents one possible outcome of this node. float _Boolean = 1;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Branch-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Branch-Node.html",
    "title": "Branch Node | mmo-rpg-unity",
    "keywords": "Branch Node Description Provides a dynamic branch to the shader. If input Predicate is true, this node returns input True, otherwise it returns input False. The Branch Node evaluates the Predicate per vertex or per pixel depending on shader stage. Both sides of the branch are evaluated in the shader, and the branch not used is discarded. Ports Name Direction Type Binding Description Predicate Input Boolean None Determines which input to return. True Input Dynamic Vector None Returned if Predicate is true. False Input Dynamic Vector None Returned if Predicate is false. Out Output Dynamic Vector None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Branch_float4(float Predicate, float4 True, float4 False, out float4 Out) { Out = Predicate ? True : False; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Branch-On-Input-Connection-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Branch-On-Input-Connection-Node.html",
    "title": "Branch On Input Connection node | mmo-rpg-unity",
    "keywords": "Branch On Input Connection node The Branch On Input Connection node allows you to change the behavior of a Subgraph based on the connected state of an input property in the parent Shader Graph. You should use the Branch On Input Connection node when you want to create a default input for a port Shader Graph determines whether the property in the parent Shader Graph is connected, or not connected, and chooses a value to use as an output based on that connection state. Shader Graph uses two ports when it determines the node's connection state: The Branch On Input Connection node's Input port. The Subgraph node's matching Property port in the parent Shader Graph. For more information on Subgraph nodes, see Subgraph node. The Branch On Input Connection node's functionality is based on the Branch node. Note You can't use the Branch On Input Connection node with a Streaming Virtual Texture Property. For more information on Streaming Virtual Texturing, see Using Streaming Virtual Texturing in Shader Graph. The Branch On Input Connection node generates branching HLSL source code, but during compilation, the branch is optimized out of your shader. Create Node menu category The Branch On Input Connection node is under the Utility > Logic category in the Create Node menu. You can only use it in a Shader Subgraph. To use the Branch On Input Connection node in a Subgraph: Open the Subgraph where you want to add a Branch On Input Connection node. In the Blackboard, do one of the following: To add a new property, select Add (+), then select a property type from the menu. Enter a name for your new property and press Enter. Then, select your property in the Blackboard and drag it onto your graph to create a Property node. Select an existing property in the Blackboard and drag it onto your graph to create a Property node. With your Property node selected, in the Graph Inspector, enable Use Custom Binding. Note If you disable Use Custom Binding, you can't connect your Property node to the Branch On Input Connection node. If you've already made a connection, the Unity Editor breaks the connection and displays a warning on the node. In the Label field, enter the label for the default value that displays on your Subgraph node's port binding in its parent Shader Graph. For more information on port bindings, see Port Bindings. Press Spacebar or right-click and select Create Node. Find the Branch On Input Connection node in the Create Node Menu, then double-click or press Enter with the node selected to add it to your Subgraph. On your Property node, select the output port and drag its new connection to the Branch On Connection node's Input port. To specify the value Shader Graph uses when the Input port is connected on the Subgraph node in the parent Shader Graph, connect a node to the Connected port. To specify the value that Shader Graph uses when the Input port isn't connected, connect another node to the NotConnected port. To specify how Shader Graph uses your Connected or NotConnected values in your shader, connect any valid node to the Output port on the Branch On Input Connection node. Compatibility The Branch On Input Connection node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes Inputs The Branch On Input Connection node has the following input ports: Name Type Description Input Property The property that determines the branching logic in the node, based on its connection state in the parent Shader Graph. Connected Dynamic Vector The value to send to the Out port when Input is connected in the parent Shader Graph. NotConnected Dynamic Vector The value to send to the Out port when Input isn't connected in the parent Shader Graph. Outputs The Branch On Input Connection node has one output port: Name Type Description Out Dynamic Vector Outputs the value of either Connected or NotConnected, based on the Input property's connection state in the parent Shader Graph. Example Subgraph usage In the following example, a Branch On Input Connection node specifies the default behavior for a UV Subgraph input property. When a value for the UV property is connected in the parent graph, then the value from that property is passed to the Checkerboard node to determine the UV coordinates for the checkerboard pattern. When the UV property isn't connected, then the Branch On Input Connection node uses the UV0 channel from the UV node for the Checkerboard node's UV coordinates: Note When you preview a Subgraph, the Branch On Input Connection node always uses its NotConnected value. Related nodes The following nodes are related or similar to the Branch On Input Connection node: Branch node Subgraph node"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Built-In-Blocks.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Built-In-Blocks.html",
    "title": "Built In Blocks | mmo-rpg-unity",
    "keywords": "Built In Blocks Vertex Blocks Name Type Binding Description Position Vector 3 Object Space Position Defines the absolute object space vertex position per vertex. Normal Vector 3 Object Space Normal Defines the absolute object space vertex normal per vertex. Tangent Vector 3 Object Space Tangent Defines the absolute object space vertex tangent per vertex. Color Vector 4 Vertex Color Defines vertex color. Expected range 0 - 1. Fragment Blocks Name Type Binding Description Base Color Vector 3 None Defines material's base color value. Expected range 0 - 1. Normal (Tangent Space) Vector 3 Tangent Space Normal Defines material's normal value in tangent space. Normal (Object Space) Vector 3 Object Space Normal Defines material's normal value in object space. Normal (World Space) Vector 3 World Space Normal Defines material's normal value in world space. Emission Vector 3 None Defines material's emission color value. Expects positive values. Metallic Float None Defines material's metallic value, where 0 is non-metallic and 1 is metallic. Specular Vector 3 None Defines material's specular color value. Expected range 0 - 1. Smoothness Float None Defines material's smoothness value. Expected range 0 - 1. Ambient Occlusion Float None Defines material's ambient occlusion value. Expected range 0 - 1. Alpha Float None Defines material's alpha value. Used for transparency and/or alpha clip. Expected range 0 - 1. Alpha Clip Threshold Float None Fragments with an alpha below this value are discarded. Expected range 0 - 1."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Calculate-Level-Of-Detail-Texture-2D-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Calculate-Level-Of-Detail-Texture-2D-Node.html",
    "title": "Calculate Level Of Detail Texture 2D node | mmo-rpg-unity",
    "keywords": "Calculate Level Of Detail Texture 2D node The Calculate Level of Detail Texture 2D node takes an input Texture 2D and outputs the mip level of a Texture sample. This node is useful in situations where you need to know the mip level of a Texture, such as when you might want to modify the mip level before sampling in your shader. The Calculate Level of Detail Texture 2D node also has a clamped and unclamped mode: Clamped: The node clamps the returned mip level to the actual mips available on the Texture. The node uses the CalculateLevelOfDetail HLSL intrinsic function. Use this mode when you want to know which mip to sample your Texture from and restrict the result to an existing mip. Unclamped: The node returns the ideal mip level, based on an idealized Texture with all its mips present. The node uses the CalculateLevelOfDetailUnclamped HLSL intrinsic function. Use this mode when you need a more generic value for your mip level. For example, a Texture might only have 3 mips: a 64×64 mip, a 32×32 mip, and a 16×16 mip. When you use the Calculate Level Of Detail Texture 2D node in its Clamped mode, the node restricts the LOD output to one of the 3 mips on the Texture, even if the ideal mip level might be a smaller resolution, such as an 8×8 version. In its Unclamped mode, the node outputs the ideal 8×8 mip level, even though it doesn't exist on the Texture. Note On platforms where these HLSL functions don't exist, Shader Graph determines an appropriate approximation to use, instead. Create Node menu category The Calculate Level of Detail Texture 2D node is under the Input > Texture category in the Create Node menu. Compatibility The Calculate Level of Detail Texture 2D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes The Calculate Level of Detail Texture 2D node can only be connected to a Block node in the Fragment Context. For more information on Block nodes and Contexts, refer to Master Stack. Inputs The Calculate Level of Detail Texture 2D node has the following input ports: Name Type Binding Description Texture Texture 2D None The Texture to use in the mip level calculation. UV Vector 2 UV The UV coordinate to use to calculate the Texture's mip level. Sampler SamplerState None The Sampler State and corresponding settings to use to calculate the Texture's mip level. Controls The Calculate Level of Detail Texture 2D node has one control: Name Type Options Description Clamp Toggle True, False When enabled, Shader Graph clamps the output mip level to the actual mips present on the provided Texture input. When disabled, Shader Graph returns an ideal mip level, based on an idealized Texture with all its mips present. Outputs The Calculate Level of Detail Texture 2D node has one output port: Name Type Description LOD Float The final calculated mip level of the Texture. Example graph usage In the following example, a Calculate Level of Detail Texture 2D node calculates the mip level of the Leaves_Albedo Texture for a set of UV coordinates and a specific Sampler State. It sends the calculated mip level for the Texture to the LOD input port on a Sample Texture 2D LOD node, which samples the same Texture: Related nodes The following nodes are related or similar to the Calculate Level of Detail Texture 2D node: Sample Texture 2D LOD node Sampler State node Gather Texture 2D node Texture 2D Asset node"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Camera-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Camera-Node.html",
    "title": "Camera Node | mmo-rpg-unity",
    "keywords": "Camera Node Description Provides access to various parameters of the Camera currently being used for rendering. This is comprised of values the Camera's GameObject, such as Position and Direction, as well as various projection parameters. Unity Render Pipelines Support Universal Render Pipeline The High Definition Render Pipeline does not support this Node. Ports Name Direction Type Binding Description Position Output Vector 3 None Position of the Camera's GameObject in world space Direction Output Vector 3 None The Camera's forward vector direction Orthographic Output Float None Returns 1 if the Camera is orthographic, otherwise 0 Near Plane Output Float None The Camera's near plane distance Far Plane Output Float None The Camera's far plane distance Z Buffer Sign Output Float None Returns -1 when using a reversed Z Buffer, otherwise 1 Width Output Float None The Camera's width if orthographic Height Output Float None The Camera's height if orthographic Generated Code Example The following example code represents one possible outcome of this node. float3 _Camera_Position = _WorldSpaceCameraPos; float3 _Camera_Direction = -1 * mul(UNITY_MATRIX_M, transpose(mul(UNITY_MATRIX_I_M, UNITY_MATRIX_I_V)) [2].xyz); float _Camera_Orthographic = unity_OrthoParams.w; float _Camera_NearPlane = _ProjectionParams.y; float _Camera_FarPlane = _ProjectionParams.z; float _Camera_ZBufferSign = _ProjectionParams.x; float _Camera_Width = unity_OrthoParams.x; float _Camera_Height = unity_OrthoParams.y;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Ceiling-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Ceiling-Node.html",
    "title": "Ceiling Node | mmo-rpg-unity",
    "keywords": "Ceiling Node Description Returns the smallest integer value, or whole number, that is greater than or equal to the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Ceiling_float4(float4 In, out float4 Out) { Out = ceil(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Channel-Mask-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Channel-Mask-Node.html",
    "title": "Channel Mask Node | mmo-rpg-unity",
    "keywords": "Channel Mask Node Description Masks values of input In on channels selected in dropdown Channels. Outputs a vector of the same length as the input vector but with the selected channels set to 0. Channels available in the dropdown Channels will represent the amount of channels present in input In. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Controls Name Type Options Description Channels Mask Dropdown Dynamic Selects any number of channels to mask Generated Code Example The following example code represents one possible outcome of this node. void Unity_ChannelMask_RedGreen_float4(float4 In, out float4 Out) { Out = float4(0, 0, In.b, In.a); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Channel-Mixer-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Channel-Mixer-Node.html",
    "title": "Channel Mixer Node | mmo-rpg-unity",
    "keywords": "Channel Mixer Node Description Controls the amount each of the channels of input In contribute to each of the channels of output Out. The slider parameters on the node control the contribution of each of the input channels. The toggle button parameters control which of the output channels is currently being edited. Slider controls for editing the contribution of each input channnel range between -2 and 2. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Out Output Vector 3 None Output value Controls Name Type Options Description Toggle Button Array R, G, B Selects the output channel to edit. R Slider Controls contribution of input red channel to selected output channel. G Slider Controls contribution of input green channel to selected output channel. B Slider Controls contribution of input blue channel to selected output channel. Shader Function Generated Code Example The following example code represents one possible outcome of this node. _ChannelMixer_Red = float3 (OutRedInRed, OutRedInGreen, OutRedInBlue); _ChannelMixer_Green = float3 (OutGreenInRed, OutGreenInGreen, OutGreenInBlue); _ChannelMixer_Blue = float3 (OutBlueInRed, OutBlueInGreen, OutBlueInBlue); void Unity_ChannelMixer_float(float3 In, float3 _ChannelMixer_Red, float3 _ChannelMixer_Green, float3 _ChannelMixer_Blue, out float3 Out) { Out = float3(dot(In, _ChannelMixer_Red), dot(In, _ChannelMixer_Green), dot(In, _ChannelMixer_Blue)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Channel-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Channel-Nodes.html",
    "title": "Channel Nodes | mmo-rpg-unity",
    "keywords": "Channel Nodes Combine Flip Creates new vectors from the four inputs R, G, B and A. Flips the individual channels of input In selected by the Node's parameters. Split Swizzle Splits the input vector In into four Float outputs R, G, B and A. Creates a new vector from the reordered elements of the input vector."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Checkerboard-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Checkerboard-Node.html",
    "title": "Checkerboard Node | mmo-rpg-unity",
    "keywords": "Checkerboard Node Description Generates a checkerboard of alternating colors between inputs Color A and Color B based on input UV. The checkerboard scale is defined by input Frequency. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Color A Input Color RGB None First checker color Color B Input Color RGB None Second checker color Frequency Input Vector 2 None Scale of checkerboard per axis Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Checkerboard_float(float2 UV, float3 ColorA, float3 ColorB, float2 Frequency, out float3 Out) { UV = (UV.xy + 0.5) * Frequency; float4 derivatives = float4(ddx(UV), ddy(UV)); float2 duv_length = sqrt(float2(dot(derivatives.xz, derivatives.xz), dot(derivatives.yw, derivatives.yw))); float width = 1.0; float2 distance3 = 4.0 * abs(frac(UV + 0.25) - 0.5) - width; float2 scale = 0.35 / duv_length.xy; float freqLimiter = sqrt(clamp(1.1f - max(duv_length.x, duv_length.y), 0.0, 1.0)); float2 vector_alpha = clamp(distance3 * scale.xy, -1.0, 1.0); float alpha = saturate(0.5f + 0.5f * vector_alpha.x * vector_alpha.y * freqLimiter); Out = lerp(ColorA, ColorB, alpha.xxx); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Circle-Pupil-Animation-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Circle-Pupil-Animation-Node.html",
    "title": "Circle Pupil Animation Node | mmo-rpg-unity",
    "keywords": "Circle Pupil Animation Node This node applies a deformation to a normalized IrisUV coordinate to simulate the opening and closure of the pupil. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Circle Pupil Animation Node No Yes Ports name Direction type description IrisUV Input Vector2 Position of the fragment to shade in object space. Pupil Radius Input float Direction of the incident ray in object space. Either from the camera in rasterization or from the previous bounce in ray tracing. Maximal Pupil Aperture Input float The normal of the eye surface in object space. Minimal Pupil Aperture Input float The index of refraction of the eye (1.333 by default). Pupil Apertur Input float Distance between the end of the cornea and the iris plane. For the default model, this value should be 0.02 IrisUV Output Vector2 Position of the refracted point on the iris plane in object space."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Clamp-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Clamp-Node.html",
    "title": "Clamp Node | mmo-rpg-unity",
    "keywords": "Clamp Node Description Returns the input In clamped between the minimum and maximum values defined by inputs Min and Max respectively. Ports Name Direction Type Description In Input Dynamic Vector Unclamped input value Min Input Dynamic Vector Minimum value Max Input Dynamic Vector Maximum value Out Output Dynamic Vector Clamped output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Clamp_float4(float4 In, float4 Min, float4 Max, out float4 Out) { Out = clamp(In, Min, Max); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Color-Mask-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Color-Mask-Node.html",
    "title": "Color Mask Node | mmo-rpg-unity",
    "keywords": "Color Mask Node Description Creates a mask from values in input In equal to input Mask Color. Input Range can be used to define a wider range of values around input Mask Color to create the mask. Colors within this range will return 1, otherwise the node will return 0. Input Fuzziness can be used to soften the edges around the selection similar to anti-aliasing. Ports Name Direction Type Binding Description In Input Vector 3 None Input value. Mask Color Input Vector 3 Color Color to use for mask. Range Input Float None Select colors within this range from input Mask Color. Fuzziness Input Float None Feather edges around selection. Higher values result in a softer selection mask. Out Output Float None Output mask value. Generated Code Example The following example code represents one possible outcome of this node. void Unity_ColorMask_float(float3 In, float3 MaskColor, float Range, float Fuzziness, out float4 Out) { float Distance = distance(MaskColor, In); Out = saturate(1 - (Distance - Range) / max(Fuzziness, 1e-5)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Color-Modes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Color-Modes.html",
    "title": "Color Modes | mmo-rpg-unity",
    "keywords": "Color Modes Description Shader Graph can display colors on nodes in your graph to improve readability. This feature uses Color Modes to change which colors to display in the graph. Use the Color Mode: drop-down menu in the top right corner of the Shader Graph Window to change the Color Modes. Modes Name Description None Does not display colors on the nodes. All nodes use the default gray. Category Displays colors on the nodes based on their assigned category. See Category Colors below. Precision Displays colors on the nodes based on the current Precision Mode in use. User Defined Lets you set the display colors on a per-node basis. These are custom colors for your graph. See User Defined Colors below. Category Colors This mode displays colors on the nodes based on their category. See the Node Library to learn about the different categories available. The table below lists current categories and their corresponding colors. Name Color Hex Value Artistic #DB773B Channel #97D13D Input #CB3022 Math #4B92F3 Procedural #9C4FFF Utility #AEAEAE UV #08D78B Note: Sub Graph nodes in a main Shader Graph fall in the Utility category. If you select Category mode, all Sub Graphs use the Utility color. Precision Colors This mode displays colors on the nodes based on their current precision. If you set a node to Inherit Precision, the display color reflects the currently active precision. See Precision Modes for more information about inheritance. User Defined Colors This mode displays colors on the nodes based on user preferences. In this mode, the user defines colors for each node. If a custom color is not set, the node displays in the default gray. To set a custom color for a node, right-click on the target node to bring up the the context menu, and select Color. Option Description Change... Brings up a color picker menu and lets you set your own custom color on the node. Reset Removes the currently selected color and sets it to the default gray. Overriding Default Colors For each project, you can override preset colors in the Category and Precision modes. Unity uses a .uss style sheet and Hex color codes to set colors. The default style sheet in your project is Packages/com.unity.shadergraph/Editor/Resources/Styles/ColorMode.uss. The best practice is to create a copy of this file to override the presets. Under your project's Assets folder, create a new Editor/Resources/Styles folder structure, and place a copy of ColorMode.uss in the Styles folder. Change the Hex color codes in this .uss file to override the presets and use your own custom colors for the Category and Precision modes."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Color-Node.html",
    "title": "Color Node | mmo-rpg-unity",
    "keywords": "Color Node Description Defines a constant Vector 4 value in the shader using a Color field. Can be converted to a Color Property Type via the Node's context menu. The value of the Mode parameter will also respected when generating the Property. NOTE: In versions prior to 10.0, Shader Graph assumed that HDR colors from the Color Node were in gamma space. Version 10.0 corrected this behavior, and Shader Graph now interprets HDR colors in linear space. HDR Color nodes that you created with older versions maintain the old behavior, but you can use the Graph Inspector to upgrade them. To mimic the old behavior on a new HDR Color node, you can use a Colorspace Conversion Node to convert the HDR color from RGB to Linear. Ports Name Direction Type Binding Description Out Output Vector 4 None Output value Controls Name Type Options Description Color Defines the output value. Mode Dropdown Default, HDR Sets properties of the Color field Generated Code Example The following example code represents one possible outcome of this node. float4 _Color = IsGammaSpace() ? float4(1, 2, 3, 4) : float4(SRGBToLinear(float3(1, 2, 3)), 4);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Colorspace-Conversion-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Colorspace-Conversion-Node.html",
    "title": "Colorspace Conversion Node | mmo-rpg-unity",
    "keywords": "Colorspace Conversion Node Description Returns the result of converting the value of input In from one colorspace space to another. The spaces to transform from and to are defined by the values of the dropdowns on the node. Ports Name Direction Type Description In Input Vector 3 Input value Out Output Vector 3 Output value Controls Name Type Options Description From Dropdown RGB, Linear, HSV Selects the colorspace to convert from To Dropdown RGB, Linear, HSV Selects the colorspace to convert to Generated Code Example The following example code represents one possible outcome of this node per from/to permutation. RGB > RGB void Unity_ColorspaceConversion_RGB_RGB_float(float3 In, out float3 Out) { Out = In; } RGB > Linear void Unity_ColorspaceConversion_RGB_Linear_float(float3 In, out float3 Out) { float3 linearRGBLo = In / 12.92;; float3 linearRGBHi = pow(max(abs((In + 0.055) / 1.055), 1.192092896e-07), float3(2.4, 2.4, 2.4)); Out = float3(In <= 0.04045) ? linearRGBLo : linearRGBHi; } RGB > HSV void Unity_ColorspaceConversion_RGB_HSV_float(float3 In, out float3 Out) { float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 P = lerp(float4(In.bg, K.wz), float4(In.gb, K.xy), step(In.b, In.g)); float4 Q = lerp(float4(P.xyw, In.r), float4(In.r, P.yzx), step(P.x, In.r)); float D = Q.x - min(Q.w, Q.y); float E = 1e-10; Out = float3(abs(Q.z + (Q.w - Q.y)/(6.0 * D + E)), D / (Q.x + E), Q.x); } Linear > RGB void Unity_ColorspaceConversion_Linear_RGB_float(float3 In, out float3 Out) { float3 sRGBLo = In * 12.92; float3 sRGBHi = (pow(max(abs(In), 1.192092896e-07), float3(1.0 / 2.4, 1.0 / 2.4, 1.0 / 2.4)) * 1.055) - 0.055; Out = float3(In <= 0.0031308) ? sRGBLo : sRGBHi; } Linear > Linear void Unity_ColorspaceConversion_Linear_Linear_float(float3 In, out float3 Out) { Out = In; } Linear > HSV void Unity_ColorspaceConversion_Linear_HSV_float(float3 In, out float3 Out) { float3 sRGBLo = In * 12.92; float3 sRGBHi = (pow(max(abs(In), 1.192092896e-07), float3(1.0 / 2.4, 1.0 / 2.4, 1.0 / 2.4)) * 1.055) - 0.055; float3 Linear = float3(In <= 0.0031308) ? sRGBLo : sRGBHi; float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 P = lerp(float4(Linear.bg, K.wz), float4(Linear.gb, K.xy), step(Linear.b, Linear.g)); float4 Q = lerp(float4(P.xyw, Linear.r), float4(Linear.r, P.yzx), step(P.x, Linear.r)); float D = Q.x - min(Q.w, Q.y); float E = 1e-10; Out = float3(abs(Q.z + (Q.w - Q.y)/(6.0 * D + E)), D / (Q.x + E), Q.x); } HSV > RGB void Unity_ColorspaceConversion_HSV_RGB_float(float3 In, out float3 Out) { float4 K = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 P = abs(frac(In.xxx + K.xyz) * 6.0 - K.www); Out = In.z * lerp(K.xxx, saturate(P - K.xxx), In.y); } HSV > Linear void Unity_ColorspaceConversion_HSV_Linear_float(float3 In, out float3 Out) { float4 K = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 P = abs(frac(In.xxx + K.xyz) * 6.0 - K.www); float3 RGB = In.z * lerp(K.xxx, saturate(P - K.xxx), In.y); float3 linearRGBLo = RGB / 12.92; float3 linearRGBHi = pow(max(abs((RGB + 0.055) / 1.055), 1.192092896e-07), float3(2.4, 2.4, 2.4)); Out = float3(RGB <= 0.04045) ? linearRGBLo : linearRGBHi; } HSV > HSV void Unity_ColorspaceConversion_HSV_HSV_float(float3 In, out float3 Out) { Out = In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Combine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Combine-Node.html",
    "title": "Combine Node | mmo-rpg-unity",
    "keywords": "Combine Node Description Creates new vectors from the four inputs R, G, B and A. Output RGBA is a Vector 4 composed of inputs R, G, B and A. Output RGB is a Vector 3 composed of inputs R, G and B. Output RG is a Vector 2 composed of inputs R and G. Ports Name Direction Type Binding Description R Input Float None Defines red channel of output G Input Float None Defines green channel of output B Input Float None Defines blue channel of output A Input Float None Defines alpha channel of output RGBA Output Vector 4 None Output value as Vector 4 RGB Output Vector 3 None Output value as Vector 3 RG Output Vector 2 None Output value as Vector 2 Generated Code Example The following example code represents one possible outcome of this node. void Unity_Combine_float(float R, float G, float B, float A, out float4 RGBA, out float3 RGB, out float2 RG) { RGBA = float4(R, G, B, A); RGB = float3(R, G, B); RG = float2(R, G); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Comparison-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Comparison-Node.html",
    "title": "Comparison Node | mmo-rpg-unity",
    "keywords": "Comparison Node Description Compares the two input values A and B based on the condition selected on the dropdown. This is often used as an input to the Branch Node. Ports Name Direction Type Binding Description A Input Float None First input value B Input Float None Second input value Out Output Boolean None Output value Controls Name Type Options Description Dropdown Equal, NotEqual, Less, LessOrEqual, Greater, GreaterOrEqual Condition for comparison Generated Code Example The following example code represents one possible outcome of this node per comparison type. Equal void Unity_Comparison_Equal_float(float A, float B, out float Out) { Out = A == B ? 1 : 0; } NotEqual void Unity_Comparison_NotEqual_float(float A, float B, out float Out) { Out = A != B ? 1 : 0; } Less void Unity_Comparison_Less_float(float A, float B, out float Out) { Out = A < B ? 1 : 0; } LessOrEqual void Unity_Comparison_LessOrEqual_float(float A, float B, out float Out) { Out = A <= B ? 1 : 0; } Greater void Unity_Comparison_Greater_float(float A, float B, out float Out) { Out = A > B ? 1 : 0; } GreaterOrEqual void Unity_Comparison_GreaterOrEqual_float(float A, float B, out float Out) { Out = A >= B ? 1 : 0; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Compute-Deformation-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Compute-Deformation-Node.html",
    "title": "Compute Deformation Node | mmo-rpg-unity",
    "keywords": "Compute Deformation Node Description This node lets you pass compute deformed vertex data to a vertex shader, and only works with the Entities Graphics package. You must provide DeformedVertexData in the _DeformedMeshData buffer. The node uses the _ComputeMeshIndex property to calculate where the DeformedVertexData associated with the current mesh are located in the _DeformedMeshData buffer. To output data, you must either install both the Entities Graphics package and DOTS Animation packages, or use a custom solution. Ports Name Direction Type Stage Description Position Output Vector3 Vertex Outputs the deformed vertex position. Normal Output Vector3 Vertex Outputs the deformed vertex normal. Tangent Output Vector3 Vertex Outputs the deformed vertex tangent."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Compute-Vertex-Position-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Compute-Vertex-Position-Water-Node.html",
    "title": "Compute Water Vertex Position | mmo-rpg-unity",
    "keywords": "Compute Water Vertex Position This node provides access to the water mesh vertex position. It's used in water instead of the Position node. The High Definition Render Pipeline (HDRP) uses this node in the default water shader graph. Don't modify the settings of this node. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Compute Water Vertex Position No Yes Ports Name Direction Type Description PositionWS Output Vector3 The position of the water surface vertex in world space."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Constant-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Constant-Node.html",
    "title": "Constant Node | mmo-rpg-unity",
    "keywords": "Constant Node Description Defines a Float of a mathematical constant value in the shader. Ports Name Direction Type Binding Description Out Output Float None Output value Controls Name Type Options Description Mode Dropdown PI, TAU, PHI, E, SQRT2 Sets output constant value Generated Code Example The following example code represents one possible outcome of this node per constant type. PI float _Constant_PI = 3.1415926; TAU float _Constant_TAU = 6.28318530; PHI float _Constant_PHI = 1.618034; E float _Constant_E = 2.718282; SQRT2 float _Constant_SQRT2 = 1.414214;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Contrast-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Contrast-Node.html",
    "title": "Contrast Node | mmo-rpg-unity",
    "keywords": "Contrast Node Description Adjusts the contrast of input In by the amount of input Contrast. A Contrast value of 1 will return the input unaltered. A Contrast value of 0 will return the midpoint of the input. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Contrast Input Float None Contrast value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Contrast_float(float3 In, float Contrast, out float3 Out) { float midpoint = pow(0.5, 2.2); Out = (In - midpoint) * Contrast + midpoint; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Cornea-Refraction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Cornea-Refraction-Node.html",
    "title": "Cornea Refraction Node | mmo-rpg-unity",
    "keywords": "Cornea Refraction Node This node performs the refraction of the view ray in object space and returns the object space position that results. This is used to simulate the refraction that can be seen when looking at an eye. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Cornea Refraction Node No Yes Ports name Direction type description Position OS Input Vector3 Position of the fragment to shade in object space. View Direction OS Input Vector3 Direction of the incident ray in object space. Either from the camera in rasterization or from the previous bounce in ray tracing. Cornea Normal OS Input Vector3 The normal of the eye surface in object space. Cornea IOR Input float The index of refraction of the eye (1.333 by default). Iris Plane Offset Input float Distance between the end of the cornea and the iris plane. For the default model, this value should be 0.02 RefractedPositionOS Output Vector3 Position of the refracted point on the iris plane in object space."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Cosine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Cosine-Node.html",
    "title": "Cosine Node | mmo-rpg-unity",
    "keywords": "Cosine Node Description Returns the cosine of the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Cosine_float4(float4 In, out float4 Out) { Out = cos(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Create-Node-Menu.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Create-Node-Menu.html",
    "title": "Create Node Menu | mmo-rpg-unity",
    "keywords": "Create Node Menu Description Use the Create Node Menu to create nodes in Shader Graph. To open the Create Node Menu, either right-click on the workspace in the Shader Graph Window and select Create Node, or press the spacebar. At the top of the Create Node Menu is a search bar. To search for a node, type any part of its name in the search field. The search box gives you autocomplete options, and you can press Tab to accept the predictive text. It highlights matching text in yellow. The Create Node Menu lists all nodes that are available in Shader Graph, categorized by their function. User-created Sub Graphs are also available in the Create Node Menu under Sub Graph Assets, or in a custom category that you define in the Sub Graph Asset. To add a node to the workspace, double-click it in the Create Node Menu. Contextual Create Node Menu A contextual Create Node Menu filters the available nodes, and only shows those that use the Data Type of a selected edge. It lists every available Port on nodes that match that Data Type. To open a contextual Create Node Menu, click and drag an Edge from a Port, and then release it in an empty area of the workspace. Master Stack Create Node Menu To add a new Block Node to the Master Stack, either right click and select Create Node or press spacebar with the stack selected. The Create Node Menu will display all available blocks for the master stack based on the render pipelines in your project. Any block can be added to the master stack via the Create Node Menu. If the block added is not compatible with the current Graph settings, the block will be disabled until the settings are configured to support it."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Create-Shader-Graph.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Create-Shader-Graph.html",
    "title": "Creating a new Shader Graph Asset | mmo-rpg-unity",
    "keywords": "Creating a new Shader Graph Asset After you configure an SRP, you can create a new Shader Graph Asset. Right-click the Project window, locate Create > Shader Graph in the context menu, then select your desired type of Shader Graph. The type of Shader Graph available is dependent on the render pipelines present in your project. Some options may or may not be present based on the render pipelines. The following options are always available: Blank Shader Graph A completely blank shader graph. No target is selected and no blocks are added to the Master Stack. Sub Graph A blank sub graph asset. A sub menu for each installed render pipeline may be present containing template stacks for standard shading models ( Lit, Unlit, etc ). For a full list of provided options, refer to the Universal Render Pipeline and High Definition Render Pipeline documentation. For this example, Universal is installed so a Unversal Lit Shader Graph has been created. Double-click your newly created Shader Graph Asset to open it in the Shader Graph window. Shader Graph window The Shader Graph window consists of the Master Stack, the Preview Window, the Blackboard, and the Graph Inspector. Master Stack The final connection that determines your shader output. Refer to Master Stack for more information. Preview window An area to preview the current shader output. Here, you can rotate the object, and zoom in and out. You can also change the basic mesh on which the shader is previewed. Refer to Main Preview for more information. Blackboard An area that contains all of the shader's properties in a single, collected view. Use the Blackboard to add, remove, rename, and reorder properties. Refer to Blackboard for more information. After you've set up a project, and become familiar with the Shader Graph window, refer to My first Shader Graph for more information on how to get started. Internal Inspector An area that contains information contextual to whatever the user is currently clicking on. It's a window that automatically is hidden by default and only appears when something is selected that can be edited by the user. Use the Internal Inspector to display and modify properties, node options, and the graph settings. Refer to Internal Inspector for more information."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Cross-Product-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Cross-Product-Node.html",
    "title": "Cross Product Node | mmo-rpg-unity",
    "keywords": "Cross Product Node Description Returns the cross product of the values of the inputs A and B. The cross product of two vectors results in a third vector which is perpendicular to the two input vectors. The result's magnitude is equal to the magnitudes of the two inputs multiplied together and then multiplied by the sine of the angle between the inputs. You can determine the direction of the result vector using the \"left hand rule\". Ports Name Direction Type Description A Input Vector 3 First input value B Input Vector 3 Second input value Out Output Vector 3 Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_CrossProduct_float(float3 A, float3 B, out float3 Out) { Out = cross(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Cubemap-Asset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Cubemap-Asset-Node.html",
    "title": "Cubemap Asset Node | mmo-rpg-unity",
    "keywords": "Cubemap Asset Node Description Defines a constant Cubemap Asset for use in the shader. To sample the Cubemap Asset it should be used in conjunction with a Sample Cubemap Node. When using a separate Cubemap Asset Node you can sample a Cubemap twice, with different parameters, without defining the Cubemap itself twice. Ports Name Direction Type Binding Description Out Output Cubemap None Output value Controls Name Type Options Description Object Field (Cubemap) Defines the cubemap asset from the project."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Custom-Function-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Custom-Function-Node.html",
    "title": "Custom Function Node | mmo-rpg-unity",
    "keywords": "Custom Function Node Description The Custom Function Node enables you to inject your own custom HLSL code in Shader Graphs. This provides you with an extra level of control when you need it (for example, to do some fine-grained optimization). You can either write small functions directly into graphs by using the string mode, or reference external HLSL include files. Use the Custom Port Menu to define your own input and output ports on the node itself. How to Use Use the Create Node Menu to create Custom Function nodes. By default, new Custom Function nodes don't have any input or output ports. In the Graph Inspector, open the Node Settings to access the Custom Function and Custom Port Menu menus. Custom Function menu Menu Item Description Inputs A Custom Port Menu that defines the node's input ports. Outputs A Custom Port Menu that defines the node's input ports. Type A function type selector. Choose File to reference an external file or string to directly input functions to the node. Name Part of the name this custom function has in the final generated code. Suffixed by the function type _half or _float. Source An asset field to reference the external HLSL include file. Only available in File mode. Body A text box where you enter HLSL code. Only available in String mode. Defining the Function via string If you select String mode, the graph generates the shader function. The Name field defines the name of the generated function, and the Body field defines the contents of the generated function. Unity handles the arguments, braces, and indent scope automatically. In String mode you may use the token $precision instead of half or float in the Body field. Unity replaces this with the correct type, based on that node's precision, when the node is processed. The example in the image above generates the following function: void MyFunction_float(float3 A, float B, out float3 Out) { Out = A + B + 1/2; } Defining the Function via file If you select File mode, the graph does not automatically generate the shader function. This mode injects an include reference in the final generated shader, and uses a function from within the referenced file. The Name field must match the name of the function you wish to call. The Source field contains a reference to the HLSL file that includes the function. When you use File mode for the Custom Function node, you must manually format the functions properly. One thing to note when creating custom functions for Shader Graph is the precision suffixes. The generated code appends a precision suffix to function names. Your include file function must also append your desired precision suffix (shown below with _float), or contain multiple functions with both _float and _half suffixes, but your Name field must not include the precision suffix. //UNITY_SHADER_NO_UPGRADE #ifndef MYHLSLINCLUDE_INCLUDED #define MYHLSLINCLUDE_INCLUDED void MyFunction_float(float3 A, float B, out float3 Out) { Out = A + B; } #endif //MYHLSLINCLUDE_INCLUDED File mode allows for more flexbility with custom functions in a graph. You can define uniform variables outside of the function scope, as shown here with a matrix. //UNITY_SHADER_NO_UPGRADE #ifndef MYHLSLINCLUDE_INCLUDED #define MYHLSLINCLUDE_INCLUDED float4x4 _MyMatrix; void MyFunction_float(float3 A, float B, out float3 Out) { A = mul(float4(A, 0.0), _MyMatrix).rgb; Out = A + B; } #endif //MYHLSLINCLUDE_INCLUDED You can define multiple functions in the same file, and call them from your referenced function. Alternatively, you can reference the same file, but use different functions from different Custom Function nodes. //UNITY_SHADER_NO_UPGRADE #ifndef MYHLSLINCLUDE_INCLUDED #define MYHLSLINCLUDE_INCLUDED float3 MyOtherFunction_float(float3 In) { return In * In; } void MyFunction_float(float3 A, float B, out float3 Out) { A = MyOtherFunction_float(A); Out = A + B; } #endif //MYHLSLINCLUDE_INCLUDED You can even include other files that contain other functions. //UNITY_SHADER_NO_UPGRADE #ifndef MYHLSLINCLUDE_INCLUDED #define MYHLSLINCLUDE_INCLUDED #include \"Assets/MyOtherInclude.hlsl\" void MyFunction_float(float3 A, float B, out float3 Out) { A = MyOtherFunction_float(A); Out = A + B; } #endif //MYHLSLINCLUDE_INCLUDED Reusing Custom Function Nodes The Custom Function node, on its own, is a single node instance. If you wish to re-use the same custom functions without re-creating the inputs, outputs, and function referencing, use Sub Graphs. Sub Graphs appear in the Create Node Menu, and they enable you to share or re-use your custom functions. Create your custom function either directly in a Sub Graph, or right-click the existing Custom Function node and select Convert to Sub Graph. To add the appropriate input and output ports, use the Graph Inspector and Custom Port Menu. After this, you can reuse your custom function as many times as needed, even within other Sub Graphs. Working with texture wires From version 10.3, Shader Graph has five new data structures to ensure that Custom Function Nodes (CFNs) and SubGraphs input and output data from texture wires in a consistent way. The new structures also make it possible for SamplerState to compile on GLES2 platforms and access data associated with textures via myInputTex.samplerstate and myInputTex.texelSize. Four structures are for the texture types, and one is for the sampler state: UnityTexture2D UnityTexture2DArray UnityTexture3D UnityTextureCube UnitySamplerState CFNs you create with earlier versions of Shader Graph continue to work after this change. As part of the automatic update, Unity transitions them to the new Bare node type. This type replicates the old input and output behavior. All other types pass the new structs. However, you should manually upgrade CFNs that produce texture or samplerstate types as output to ensure that they behave consistently—and to gain the benefits of the new design. Unity flags this type of outdated Custom Function Nodes with a warning when you open your Shader Graph in 10.3 or later. How to upgrade Change all of the input and output types from Bare to non-Bare. String type: Ensure that your HLSL string already uses Unity's texture access macros (such as SAMPLE_TEXTURE2D). File type: Replace Bare types (such as Texture2D) with the new struct types (such as UnityTexture2D) in your function parameters. If your HLSL code is using platform-specific or non-standard texture operations, you'll need to convert the way you access textures to take that structure into account. For example, myInputTex.GetDimensions(...) would become myInputTex.tex.GetDimensions(...) From version 10.3, you can access data associated with textures via myInputTex.samplerstate and myInputTex.texelSize."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Custom-Interpolators.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Custom-Interpolators.html",
    "title": "Custom Interpolators | mmo-rpg-unity",
    "keywords": "Custom Interpolators Description The Custom Interpolator feature provides fine-grained control over the specific calculations Shader Graph uses to bring data from the vertex stage to the pixel stage. There are two target audiences for Custom Interpolators: Technical Directors and Lead Technical Artists setting up environments for their teams. Graphics programmers helping artists to optimize content performance. Supported data types Custom interpolators support float, vec2, vec3, and vec4 options. Channel limits The Custom Interpolator feature supports a maximum of 32 channels. A channel is equivalent to four floats. Each float is an interpolator variable. Different platforms and GPUs have different interpolator variable limits. Exceeding the interpolator limitations of your target platform prevents your shaders from compiling. For detailed information about the number of interpolators supported by common interfaces, see the Unity documentation on Shader semantics, and view the section Interpolator count limits. Test your Custom Interpolators on your target configuration to ensure that your content compiles properly. Technical directors can set warnings and errors to help their team members avoid creating graphs with too many channels to be compatible with their target pipeline, platform, or GPU. See Creating channel warnings and errors below. How to use To use this feature, create a Custom Interpolator block in the Vertex context of the Master Stack and set a name and a data type. Create a vertex node to write data to that interpolator. Use the interpolator in your graph, then connect your graph to the relevant block in the Fragment context. These instructions include a contextual example illustrating the process of using a Custom Interpolator to fetch per-vertex data from a texture. To read the HLSL you use to replicate this behavior with the Built In Render Pipeline, see the Unity documentation on Shader semantics and view the section Vertex ID: SV_VertexID. Creating channel warnings and errors It is not possible to limit the number of channels a user can create in a Shader Graph. However, it is possible to create alerts to let users know when they are close to or exceeding a certain number of channels. The Warning Threshold lets users know that they are approaching the channel limit, and the Error Threshold informs them if they have reached or surpassed that limit. The Warning Threshold value must be between 8 and 32 channels. The Error Threshold value must be higher than the Warning Threshold, and has a minimum value of 8 channels. To configure these parameters, go to the Unity Editor Project Settings menu and open the Custom Interpolator Channel Settings. Adding a Custom Interpolator block to the Master Stack Right-click in the Vertex contex to create a block node. Select Custom Interpolator. Select a data type. Enter a name for this interpolator. In the illustrated example, you use the Vector 4 (vec4) data type. Writing data to the interpolator Right-click in your graph to create a node. Select the type Vertex ID. Connect this node to the Custom Interpolator block. In the example, you write Vertex ID values from your graph into the Custom Interpolator. Reading data from the interpolator Right-click in your graph to create a node. Select Custom Interpolator. Connect the Custom Interpolator node to the relevant block in the Fragment context. In this example, you connect to the Base Color block in order to pass the Vertex ID from the vertex shader to the fragment shader and use it as color output. Deleting the block from the Master Stack If you delete a Custom Interpolator which is associated with nodes that are still in your graph, Unity displays an alert. If you want to keep using these nodes, you can create a new Custom Interpolator and associate them with it. This prevents the alert from appearing."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Custom-Port-Menu.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Custom-Port-Menu.html",
    "title": "Custom Port Menu | mmo-rpg-unity",
    "keywords": "Custom Port Menu Description The Custom Port Menu is displayed in the Node Settings tab of the Graph Inspector by clicking on the Custom Function Node and Sub Graph output node. This menu allows you to add, remove, rename, reorder, and define the types of your custom input and output ports. How to Use Select the Custom Function Node or the Sub Graph output node to view the Custom Port Menu in the Inspector. To close the menu, click anywhere in the graph or on another graph-element. Adding and Removing Ports To add ports, click the + icon at the bottom right corner of the port list. To remove ports, select a port using the hamburger icon on the left, and click the - icon at the bottom right corner of the port list. Renaming Ports To rename a port, double-click its text field and enter the new name. Currently, only the following characters are valid for port names: A-Z, a-z, 0-9, _, ( ), and whitespace. If the name contains an invalid character, an error badge appears. Reordering Ports To reorder ports, click and hold the hamburger icon on the left, and drag the port to your desired place in the list. Changing Port Types To change a port type, use the Type drop-down menu on the right. See the Data Types page for a list of currently valid port types."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/DDX-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/DDX-Node.html",
    "title": "DDX Node | mmo-rpg-unity",
    "keywords": "DDX Node Description Returns the partial derivative of the input In with respect to the screen-space x-coordinate. This node can only be used in the pixel shader stage. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output partial derivative value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DDX_float4(float4 In, out float4 Out) { Out = ddx(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/DDXY-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/DDXY-Node.html",
    "title": "DDXY Node | mmo-rpg-unity",
    "keywords": "DDXY Node Description Returns the sum of both partial derivatives of input In, with respect to the screen-space x-coordinate and screen-space y-coordinate respectively. This node can only be used in the pixel shader stage. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output partial derivative value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DDXY_float4(float4 In, out float4 Out) { Out = ddxy(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/DDY-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/DDY-Node.html",
    "title": "DDY Node | mmo-rpg-unity",
    "keywords": "DDY Node Description Returns the partial derivative of the input In with respect to the screen-space y-coordinate. This node can only be used in the pixel shader stage. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output partial derivative value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DDY_float4(float4 In, out float4 Out) { Out = ddy(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Data-Types.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Data-Types.html",
    "title": "Data Types | mmo-rpg-unity",
    "keywords": "Data Types Description There are a number of Data Types in Shader Graph. Each Port on a Node has an associated Data Type that defines what edges can be connected to it. The Data Types have colors for usability, these colors are applied to ports and edges of that Data Type. Some Data Types have associated Property Types for exposing these values to the Inspector for Materials that use the shader. Data Types Name Color Description Float Light Blue A Float or scalar value Vector 2 Green A Vector 2 value Vector 3 Yellow A Vector 3 value Vector 4 Pink A Vector 4 value Dynamic Vector Light Blue See Dynamic Data Types below Matrix 2 Blue A Matrix 2x2 value Matrix 3 Blue A Matrix 3x3 value Matrix 4 Blue A Matrix 4x4 value Dynamic Matrix Blue See Dynamic Data Types below Dynamic Blue See Dynamic Data Types below Boolean Purple A Boolean value. Defined as a float in the generated shader Texture 2D Red A Texture 2D asset Texture 2D Array Red A Texture 2D Array asset Texture 3D Red A Texture 3D asset Cubemap Red A Cubemap asset Virtual Texture Gray A Texture Stack Gradient Gray A Gradient value. Defined as a struct in the generated shader SamplerState Gray A state used for sampling a texture Promoting/Truncating All Vector types can be promoted or truncated to match any Vector type Port. This behaviour occurs only when the Port in question is not of type Dynamic Vector. When truncating, excess channels are simply removed. When promoting, the extra required channels are filled by default values. These values are (0, 0, 0, 1). Dynamic Data Types Some Data Types are dynamic. This means a port using these Data Types can change their underlying Concrete Data Type based on what Data Type is connected to it. By default, Nodes using dynamic Data Types can only have one Concrete Data Type, meaning that once a connected edge has applied its Data Type to that port, all other Dynamic Data Type slots of that Node will apply the same Data Type. One notable exception to this is the Multiply Node which allows both Dynamic Matrix and Vector types. Dynamic Vector The Dynamic Vector type allows connected edges of any Vector type. All connected edges are automatically truncated to the type with the lowest dimension, unless the lowest dimension is 1, in which case the Float is promoted. Dynamic Matrix The Dynamic Matrix type allows connected edges of any Matrix type. All connected edges are automatically truncated to the type with the lowest dimension. Dynamic The Dynamic type is a special case. Nodes that support it must define how it is validated. In the case of the Multiply Node, it allows connections of any Vector or Matrix type, ensuring the correct multiplication is applied depending on the mix of Data Types."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Degrees-To-Radians-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Degrees-To-Radians-Node.html",
    "title": "Degrees To Radians Node | mmo-rpg-unity",
    "keywords": "Degrees To Radians Node Description Returns the value of input In converted from degrees to radians. One degree is equivalent to approximately 0.0174533 radians and a full rotation of 360 degrees is equal to 2 Pi radians. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DegreesToRadians_float4(float4 In, out float4 Out) { Out = radians(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Dielectric-Specular-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Dielectric-Specular-Node.html",
    "title": "Dielectric Specular Node | mmo-rpg-unity",
    "keywords": "Dielectric Specular Node Description Returns a Dielectric Specular F0 value for a physically based material. The material to use can be selected with the Material dropdown parameter on the Node. A Common Material type defines a range between 0.034 and 0.048 sRGB values. The value between this range can be selected with the Range parameter. This Material type should be used for various materials such as plastics and fabrics. You can use Custom material type to define your own physically based material value. The output value in this case is defined by its index of refraction. This can be set by the parameter IOR. Ports Name Direction Type Binding Description Out Output Float None Output value Controls Name Type Options Description Material Dropdown Common, RustedMetal, Water, Ice, Glass, Custom Selects the material value to output. Range Slider Controls output value for Common material type. IOR Slider Controls index of refraction for Custom material type. Generated Code Example The following example code represents one possible outcome of this node per Material mode. Common float _DielectricSpecular_Range = 0.5; float _DielectricSpecular_Out = lerp(0.034, 0.048, _DielectricSpecular_Range); RustedMetal float _DielectricSpecular_Out = 0.030; Water float _DielectricSpecular_Out = 0.020; Ice float _DielectricSpecular_Out = 0.018; Glass float _DielectricSpecular_Out = 0.040; Custom float _DielectricSpecular_IOR = 1; float _DielectricSpecular_Out = pow(_Node_IOR - 1, 2) / pow(_DielectricSpecular_IOR + 1, 2);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Diffusion-Profile-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Diffusion-Profile-Node.html",
    "title": "Diffusion Profile Node | mmo-rpg-unity",
    "keywords": "Diffusion Profile Node The Diffusion Profile Node allows you to sample a Diffusion Profile Asset in your Shader Graph. For information on what a Diffusion Profile is and the properties that it contains, see the Diffusion Profile documentation. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Diffusion Profile Node No Yes Ports name Direction type description Out Output float Outputs a unique float that the Shader uses to identify the Diffusion Profile. Notes The output of this Node is a float value that represents a Diffusion Profile. The Shader can use this value to find settings for the Diffusion Profile Asset that this value represents. If you modify the output value, the Shader can no longer use it to find the settings for the Diffusion Profile Asset. You can use this behavior to enable and disable Diffusion Profiles in your Shader Graph. To disable a Diffusion Profile, multiply the output by 0. To enable a Diffusion Profile, multiply the output by 1. This allows you to use multiple Diffusion Profiles in different parts of your Shader Graph. Be aware that the High Definition Render Pipeline (HDRP) does not support blending between Diffusion Profiles. This is because HDRP can only evaluate a single Diffusion Profile per pixel."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Distance-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Distance-Node.html",
    "title": "Distance Node | mmo-rpg-unity",
    "keywords": "Distance Node Description Returns the euclidean distance between the values of the inputs A and B. This is useful for, among other things, calculating the distance between two points in space and is commonly used in calculating a Signed Distance Function. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Distance_float4(float4 A, float4 B, out float Out) { Out = distance(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Dither-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Dither-Node.html",
    "title": "Dither Node | mmo-rpg-unity",
    "keywords": "Dither Node Description Dither is an intentional form of noise used to randomize quantization error. It is used to prevent large-scale patterns such as color banding in images. The Dither node applies dithering in screen-space to ensure a uniform distribution of the pattern. This can be adjusted by connecting another node to input Screen Position. This Node is commonly used as an input to Alpha Clip Threshold on the Master Node to give the appearance of transparency to an opaque item. This is useful for creating geometry that appears to be transparent but has the advantages of rendering as opaque, such as writing depth or being rendered in deferred. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Screen Position Input Vector 4 Screen Position Coordinates used to apply dither pattern Out Output Dynamic Vector None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Dither_float4(float4 In, float4 ScreenPosition, out float4 Out) { float2 uv = ScreenPosition.xy * _ScreenParams.xy; float DITHER_THRESHOLDS[16] = { 1.0 / 17.0, 9.0 / 17.0, 3.0 / 17.0, 11.0 / 17.0, 13.0 / 17.0, 5.0 / 17.0, 15.0 / 17.0, 7.0 / 17.0, 4.0 / 17.0, 12.0 / 17.0, 2.0 / 17.0, 10.0 / 17.0, 16.0 / 17.0, 8.0 / 17.0, 14.0 / 17.0, 6.0 / 17.0 }; uint index = (uint(uv.x) % 4) * 4 + uint(uv.y) % 4; Out = In - DITHER_THRESHOLDS[index]; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Divide-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Divide-Node.html",
    "title": "Divide Node | mmo-rpg-unity",
    "keywords": "Divide Node Description Returns the result of input A (dividend) divided by input B (divisor). Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Divide_float4(float4 A, float4 B, out float4 Out) { Out = A / B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Dot-Product-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Dot-Product-Node.html",
    "title": "Dot Product Node | mmo-rpg-unity",
    "keywords": "Dot Product Node Description Returns the dot product, or scalar product, of the two input vectors A and B. The dot product is a value equal to the magnitudes of the two vectors multiplied together and then multiplied by the cosine of the angle between them. For normalized input vectors, the Dot Product node returns 1 if they point in exactly the same direction, -1 if they point in completely opposite directions and 0 if the vectors are perpendicular. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_DotProduct_float4(float4 A, float4 B, out float Out) { Out = dot(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Edge.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Edge.html",
    "title": "Edge | mmo-rpg-unity",
    "keywords": "Edge Description An Edge defines a connection between two Ports. Edges define how data flows through the Shader Graph node network. They can only be connected from an input Port to an output Port. Each Edge has a Data Type which defines what Ports it can be connected to. Each Data Type has an associated color for identifying its type. You can create a new Edge by clicking and dragging from a Port with the left mouse button. Edges can be deleted with Delete (Windows), Command + Backspace (OSX) or from the context menu by right clicking on the Node. You can open a contextual Create Node Menu by dragging an Edge from a Port with the left mouse button and releasing it in an empty area of the workspace."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Ellipse-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Ellipse-Node.html",
    "title": "Ellipse Node | mmo-rpg-unity",
    "keywords": "Ellipse Node Description Generates an ellipse shape based on input UV at the size specified by inputs Width and Height. The generated shape can be offset or tiled by connecting a Tiling And Offset Node. Note that in order to preserve the ability to offset the shape within the UV space the shape will not automatically repeat if tiled. To achieve a repeating dot effect first connect your input through a Fraction Node. NOTE: This Node can only be used in the Fragment Shader Stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Ellipse width Height Input Float None Ellipse height Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Ellipse_float(float2 UV, float Width, float Height, out float4 Out) { float d = length((UV * 2 - 1) / float2(Width, Height)); Out = saturate((1 - d) / fwidth(d)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Emission-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Emission-Node.html",
    "title": "Emission Node | mmo-rpg-unity",
    "keywords": "Emission Node The Emission Node allows you to apply emission in your Shader Graph. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Emission No Yes Ports Name Direction Type Description color Input LDR Color(RGB) Sets the low dynamic range (LDR) color of the emission. intensity Input Float Sets the intensity of the emission color. output Output HDR Color(RGB) Outputs the high dynamic range (HDR) color that this Node produces. Notes Emission Unit You can use two physical light units to control the strength of the emission: Nits. EV100. Exposure Weight You can use Exposure Weight to determine how exposure affects emission. It is a value between 0 and 1 where. A value of 0 means that exposure does not effect this part of the emission. A value of 1 means that exposure fully affects this part of the emission."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Foam-Data-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Foam-Data-Water-Node.html",
    "title": "Evaluate Foam Data | mmo-rpg-unity",
    "keywords": "Evaluate Foam Data This node calculates water foam intensity. This node outputs foam as monochrome in the red channel. If you connect the output of this node to a Base Color block, all the channels are red. To prevent this, split the output and use only the red channel. You can't apply a tint to foam. The High Definition Render Pipeline (HDRP) uses this node in the default water shader graph. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Evaluate Foam Data No Yes Ports Name Direction Type Description SurfaceGradient Input Vector3 The perturbation of the normal, as a surface gradient. LowFrequencySurfaceGradient Input Vector3 The perturbation of the low frequency normal, as a surface gradient. The low frequency normal is the normal of the water surface without high frequency details such as ripples. SimulationFoam Input Float The amount of foam. HDRP uses this property in the default water shader graph to fetch foam data from the simulation. CustomFoam Input Float The amount of foam, if you create your own foam. SurfaceGradient Output Vector3 The calculated water surface normal, as a surface gradient. Foam Output Float The combination of the amount of foam and a foam texture. Smoothness Output Float The smoothness of the water surface. For more information about this property, see Settings and Properties Related to the Water System."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Refraction-Data-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Refraction-Data-Water-Node.html",
    "title": "Evaluate Refraction Data | mmo-rpg-unity",
    "keywords": "Evaluate Refraction Data This node calculates water refraction. The High Definition Render Pipeline (HDRP) uses this node in the default water shader graph. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Evaluate Refraction Data No Yes Ports Name Direction Type Description NormalWS Input Vector3 The water surface normal in world space. LowFrequencyNormalWS Input Vector3 The low frequency normal of the water surface in world space. This is the normal of the water surface without high frequency details such as ripples. RefractedPositionWS Output Vector3 The refracted position of the water bed you observe through the water, in world space. DistortedWaterNDC Output Vector2 The screen space position of the refracted point. AbsorptionTint Output Vector3 An absorption factor that HDRP uses to blend between the water surface and the refracted underwater color."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Scattering-Color-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Scattering-Color-Water-Node.html",
    "title": "Evaluate Scattering Color | mmo-rpg-unity",
    "keywords": "Evaluate Scattering Color This node calculates the scattered diffuse color of water. The High Definition Render Pipeline (HDRP) uses this node in the default water shader graph. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Evaluate Scattering Color No Yes Ports Name Direction Type Description AbsorptionTint Input Vector3 An absorption factor that HDRP uses to blend between the water surface and the refracted underwater color. LowFrequencyHeight Input Float The vertical displacement of the water surface. This doesn't include ripples. HorizontalDisplacement Input Float The horizontal displacement of the water surface. SSSMask Input Float Mask that defines where the water surface has subsurface scattering. DeepFoam Input Float The amount of foam under the water's surface. ScatteringColor Output Vector3 The diffuse color of the water."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Simulation-Additional-Data-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Simulation-Additional-Data-Water-Node.html",
    "title": "Evaluate Simulation Additional Data | mmo-rpg-unity",
    "keywords": "Evaluate Simulation Additional Data This node provides access to Water's surface foam, surface gradient, and deep foam. You can also use this node to dampen the normals for each water band. The High Definition Render Pipeline (HDRP) uses this node in the default water shader graph to fetch data from the water simulation. Don't modify the settings of this node. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Evaluate Simulation Additional Data No Yes Ports Name Direction Type Description BandsMultiplier Input Vector4 The amount to dampen displacement for each water band. Bands are different wave frequencies that create swells, agitations or ripples on the water. SurfaceGradient Output Vector3 The perturbation of the normal, as a surface gradient. LowFrequencySurfaceGradient Output Vector3 The perturbation of the low frequency normal, as a surface gradient. The low frequency normal is the normal of the water surface without high frequency details such as ripples. SurfaceFoam Output Float The amount of foam. DeepFoam Output Float The amount of foam under the water's surface."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Simulation-Caustics-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Simulation-Caustics-Water-Node.html",
    "title": "Evaluate Simulation Caustics | mmo-rpg-unity",
    "keywords": "Evaluate Simulation Caustics This node calculates water caustics. This node outputs caustics as monochrome in the red channel. If you connect the output of this node to a Base Color block, all the channels are red. To prevent this, split the output and use only the red channel. You can't apply a tint to caustics. Caustics don't have an effect above the water unless you script this behavior. For example: If your scene contains a boat that sits in water, HDRP doesn't project caustics on the part of the boat's hull that's above water. A swimming pool inside a room doesn't bounce caustics off the walls or ceiling. The High Definition Render Pipeline (HDRP) uses this node in the default water shader graph. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Evaluate Simulation Caustics No Yes Ports Name Direction Type Description RefractedPositionWS Input Vector3 The refracted position of the water bed you observe through the water, in world space. DistortedWaterNDC Input Vector2 The screen space position of the refracted point. Caustics Output Float The intensity of the caustics."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Simulation-Displacement-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Simulation-Displacement-Water-Node.html",
    "title": "Evaluate Water Simulation Displacement | mmo-rpg-unity",
    "keywords": "Evaluate Water Simulation Displacement This node calculates water surface displacement. The High Definition Render Pipeline (HDRP) uses this node in the default water shader graph. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Evaluate Water Simulation Displacement No Yes Ports Name Direction Type Description PositionWS Input Vector3 The position of the water surface vertex in world space. BandsMultiplier Input Vector4 The amount to dampen displacement for each water band. Bands are different wave frequencies that create swells, agitations or ripples on the water. Displacement Output Vector3 The vertical and horizontal displacement of the water. LowFrequencyHeight Output Float The vertical displacement of the water surface. This doesn't include ripples. SSSMask Output Float Mask that defines where the water surface has subsurface scattering."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Tip-Thickness-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Evaluate-Tip-Thickness-Water-Node.html",
    "title": "Evaluate Tip Thickness | mmo-rpg-unity",
    "keywords": "Evaluate Tip Thickness This node calculates the thickness of the water at the tips of waves. The High Definition Render Pipeline (HDRP) uses this node in the default water shader graph. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Evaluate Tip Thickness No Yes Ports Name Direction Type Description LowFrequencyNormal Input Vector3 The low frequency normal of the water surface in world space. This is the normal of the water surface without high frequency details such as ripples. LowFrequencyHeight Input Float The vertical displacement of the water surface. This doesn't include ripples. TipThickness Output Float The thickness of the water in a wave tip."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Exponential-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Exponential-Node.html",
    "title": "Exponential Node | mmo-rpg-unity",
    "keywords": "Exponential Node Description Returns the exponential value of input In. The exponential base can be switched between base-e and base 2 from the Base dropdown on the node. Base E : Returns e to the power of input In Base 2 : Returns 2 to the power of input In Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Controls Name Type Options Description Base Dropdown BaseE, Base2 Selects the exponential base Generated Code Example The following example code represents one possible outcome of this node per Base mode. Base E void Unity_Exponential_float4(float4 In, out float4 Out) { Out = exp(In); } Base 2 void Unity_Exponential2_float4(float4 In, out float4 Out) { Out = exp2(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Exposure-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Exposure-Node.html",
    "title": "Exposure Node | mmo-rpg-unity",
    "keywords": "Exposure Node The Exposure Node allows you to get the Camera's exposure value from the current or previous frame. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Exposure No Yes Ports name Direction type description Output Output float The exposure value. Exposure Type You can use Exposure Type to select which exposure value to get. | name | description | |--- | ---| | CurrentMultiplier | Gets the Camera's exposure value from the current frame. | | InverseCurrentMultiplier | Gets the inverse of the Camera's exposure value from the current frame. | | PreviousMultiplier | Gets the Camera's exposure value from the previous frame. | | InversePreviousMultiplier | Gets the inverse of the Camera's exposure value from the previous frame. |"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Eye-Index-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Eye-Index-Node.html",
    "title": "Eye Index Node | mmo-rpg-unity",
    "keywords": "Eye Index Node Description Provides access to the Eye Index when stereo rendering is enabled. Ports Name Direction Type Binding Description Out Output Float None Eye Index for the camera of a stereo draw."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Eye-Surface-Type-Debug-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Eye-Surface-Type-Debug-Node.html",
    "title": "Eye Surface Type Debug Node | mmo-rpg-unity",
    "keywords": "Eye Surface Type Debug Node Debug node that allows you to visually validate the current pupil radius. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Eye Surface Type Debug Node No Yes Ports name Direction type description PositionOS Input Vector3 Position in object space of the current fragment to shade. EyeColor Input Color Final Diffuse color of the Eye. IrisRadius Input float The radius of the Iris in the used model. For the default model, this value should be 0.225. Pupil Radius Input float Radius of the pupil in the iris texture as a percentage. IsActive Input bool Flag that defines if the node should be active. SurfaceColor Output Color Final Diffuse color of the Eye."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fade-Transition-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fade-Transition-Node.html",
    "title": "Fade Transition Node | mmo-rpg-unity",
    "keywords": "Fade Transition Node Description Fade Transition is a method of adding noise to add variation while a function transitions from on to off. This node takes in a fade value and remaps it using the noise value (usually from a texture). When FadeValue is 0, the output is always 0, and when FadeValue is 1, the output is always exactly 1. In between 0 and 1 the transition will follow the pattern in the noise. This Node is commonly used as an input to Alpha on a Master Node to provide an LOD transition. Ports Name Direction Type Binding Description Texture Input Texture 2D None Input value Noise Input Float None The noise variation to apply to the fade function FadeValue Input Float None The amount of transition to apply FadeContrast Input Float None The contrast at which a single pixel goes from fully transparent to fully opaque. Higher values cause sharper edges in the transition Fade Output Float None The resulting fade value Generated Code Example The following example code represents one possible outcome of this node. float Unity_FadeTransitionNode_ApplyFade_float(float noise, float fadeValue, float fadeContrast) { float ret = saturate(fadeValue*(fadeContrast+1)+(noise-1)*fadeContrast); return ret; } float Result = Unity_FadeTransitionNode_ApplyFade_float( _NoiseValue, _FadeValue, _FadeContrast);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/First-Shader-Graph.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/First-Shader-Graph.html",
    "title": "My first Shader Graph | mmo-rpg-unity",
    "keywords": "My first Shader Graph Before you begin, make sure that your project is set up properly, and the graphs are loading correctly. See Getting started with Shader Graph for more information. Create a New Graph Use the Project Browser to create a new Shader Graph Asset in your project. The Create > Shader Graph will display the various creation options. A Blank Shader Graph will create a Shader Graph with no selected active targets or block nodes. You will need to select a target via the Graph Settings Menu to continue. Certain integrations, like Render Pipelines, can also provide pre-configured options for Shader Graphs. For this example, a Universal > Lit Shader Graph has been created and opened. Create a new node Use the Create Node menu to create new nodes. There are two ways to open the menu: Right click, and select Create Node from the context menu. Press the spacebar. In the menu, you can type in the search bar to look for specific nodes, or browse all nodes in the library. In this example, we'll create a Color node. First, type \"color\" in the Create Node menu's search bar. Then, click Color, or highlight Color and press Enter to create a Color node. Connect nodes To build a graph, you need to connect nodes together. To do so, click the Output Slot of a node, and drag that connection into the Input Slot of another node. Start by connecting the Color node to the Base Color block of our Fragment Stack. Change node output Notice that the connection updated the main preview, and the 3D Object in the Main Preview is now black, which is the color specified in the Color node. You can click on the color bar in that node, and use the color picker to change the color. Any changes you make on the node updates the object in the Main Preview in real time. For example, if you pick red, the 3D Object immediately reflects this change. Save the graph Currently, Shader Graphs do not automatically save. There are two ways to save your changes: Click the Save Asset button in the top left corner of the window. Close the graph. If Unity detects any unsaved changes, a pop-up window appears, and asks if you want to save those changes. Create a Material After saving your graph, use the shader to create a new Material. The process of creating a new Material and assigning it a Shader Graph shader is the same as that for regular shaders. In either the main menu or the Project View context menu, select Assets > Create > Material. Select the Material you just created. In its Inspector window, select the Shader drop-down menu, click Shader Graphs, and choose the Shader Graph shader you wish to apply to the Material. You can also right-click the Shader Graph shader, and select Create > Material. This method automatically assigns that Shader Graph shader to the newly created Material. A Material is also automatically generated as a subasset of the Shader Graph. You can assign it directly to an object in your scene. Modifying a property from the Blackboard on the Shader Graph will update this material in real time, which allows for quick visualization in the scene. Put the Material in the Scene Now that you have assigned your shader to a Material, you can apply it to objects in the Scene. Drag and drop the Material onto an object in the Scene. Alternatively, in the object's Inspector window, locate Mesh Renderer > Materials, and apply the Material to the Element. Use properties to edit the graph You can also use properties to alter your shader's appearance. Properties are options that are visible from the Material's Inspector, which lets others change settings in your shader without the need to open the Shader Graph. To create a new property, use the Add (+) button on the top right corner of the Blackboard, and select the type of property to create. In this example, we'll select Color. This adds a new property in the Blackboard with the following options in the Node Settings tab of the Graph Inspector when the property is selected. Option Description Property button To change the name of the property, right-click the button in the Blackboard, select Rename, then enter a new property name. To delete the property, right-click the button, and select Delete. Exposed Enable this checkbox to make the property visible from the Material's Inspector. Reference The property's name that appears in C# scripts. To change the Reference name, enter a new string. Default The default value of the property. Mode The mode of the property. Each property has different modes. For Color, you can select either Default or HDR. Precision The default precision of the property. Hybrid Instanced An experimental feature that enables this property to be instanced when using the Hybrid DOTS renderer. There are two ways to reference a property in your graph: Drag the property from the Blackboard onto the graph. Right-click and select Create Node. The property is listed in the Properties category. Try connecting the property to the Base Color block. The object immediately changes to black. Save your graph, and return to the Material's Inspector. The property now appears in the Inspector. Any changes you make to the property in the Inspector affects all objects that use this Material. More Tutorials Older tutorials use an outdated format of Shader Graph with master nodes. When looking at older tutorials, reference the Upgrade Guide for tips on how to convert the master node to a Master Stack. To keep exploring how to use Shader Graph to author shaders, check out these blog posts: Art That Moves: Creating Animated Materials with Shader Graph Shader Graph Updates and Sample Project Custom Lighting in Shader Graph: Expanding Your Graphs in 2019 Unity 2018.3 Shader Graph Update: Lit Master Node Creating an Interactive Vertex Effect using Shader Graph Introduction to Shader Graph: Build your shaders with a visual editor You can also visit the Unity YouTube Channel and look for video tutorials on Shader Graph, or head to our user forum to find the latest information and conversations about Shader Graph."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Flip-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Flip-Node.html",
    "title": "Flip Node | mmo-rpg-unity",
    "keywords": "Flip Node Description Flips the individual channels of input In selected by the Node's parameters. Positive values become negative values and vice versa. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Controls Name Type Options Description Red Toggle True, False If true red channel will be flipped. Green Toggle True, False If true green channel will be flipped. Disabled if In is Float. Blue Toggle True, False If true blue channel will be flipped. Disabled if In is Vector 2 or smaller. Alpha Toggle True, False If true alpha channel will be flipped. Disabled if In is Vector 3 or smaller. Generated Code Example The following example code represents one possible outcome of this node. float2 _Flip_Flip = float4(Red, Green, Blue, Alpha); void Unity_Flip_float4(float4 In, float4 Flip, out float4 Out) { Out = (Flip * -2 + 1) * In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Flipbook-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Flipbook-Node.html",
    "title": "Flipbook Node | mmo-rpg-unity",
    "keywords": "Flipbook Node Description Creates a flipbook, or texture sheet animation, of the UVs supplied to input UV. The amount of tiles on the sheet are defined by the values of the inputs Width and Height. The index of the current tile is defined by the value of the input Tile. This node can be used to create a texture animation functionality, commonly used for particle effects and sprites, by supplying Time to the input Tile and outputting to the UV input slot of a Texture Sampler. UV data is typically in the range of 0 to 1 starting from the bottom left of UV space. This can be seen by the black value at the bottom left corner of a UV preview. As flipbooks typically start from top left the parameter Invert Y is enabled by default, however you can change the direction of the Flipbook by switching the Invert X and Invert Y parameters. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Amount of horizontal tiles Height Input Float None Amount of vertical tiles Tile Input Float None Current tile index Out Output Vector 2 None Output UV value Controls Name Type Options Description Invert X Toggle True, False If enabled tiles are iterated from right to left Invert Y Toggle True, False If enabled tiles are iterated from top to bottom Generated Code Example The following example code represents one possible outcome of this node. float2 _Flipbook_Invert = float2(FlipX, FlipY); void Unity_Flipbook_float(float2 UV, float Width, float Height, float Tile, float2 Invert, out float2 Out) { Tile = floor(fmod(Tile + float(0.00001), Width*Height)); float2 tileCount = float2(1.0, 1.0) / float2(Width, Height); float base = floor((Tile + float(0.5)) * tileCount.x); float tileX = (Tile - Width * base); float tileY = (Invert.y * Height - (base + Invert.y * 1)); Out = (UV + float2(tileX, tileY)) * tileCount; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Float.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Float.html",
    "title": "Float Node | mmo-rpg-unity",
    "keywords": "Float Node Description Defines a Float value in the shader. If Port X is not connected with an Edge this Node defines a constant Float. Ports Name Direction Type Binding Description X Input Float None Input x component value Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. float _Vector1_Out = X;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Floor-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Floor-Node.html",
    "title": "Floor Node | mmo-rpg-unity",
    "keywords": "Floor Node Description Returns the largest integer value, or whole number, that is less than or equal to the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Floor_float4(float4 In, out float4 Out) { Out = floor(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fog-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fog-Node.html",
    "title": "Fog Node | mmo-rpg-unity",
    "keywords": "Fog Node Description Provides access to the Scene's Fog parameters. Note: The behavior of this Node is undefined globally. Shader Graph does not define the function of the node. Instead, each Render Pipeline defines what HLSL code to execute for this Node. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. A Node might be defined in one Render Pipeline and undefined in the other. If this Node is undefined, it returns 0 (black). Unity Render Pipelines Support Universal Render Pipeline The High Definition Render Pipeline does not support this Node. Ports Name Direction Type Binding Description Position Input Vector 3 Position (object space) Mesh vertex/fragment's position Color Output Vector 4 None Fog color Density Output Float None Fog density based on depth. Returns a value between 0 and 1, where 0 is no fog and 1 is full fog. Generated Code Example The following example code represents one possible outcome of this node. void Unity_Fog_float(float3 Position, out float4 Color, out float Density) { SHADERGRAPH_FOG(Position, Color, Density); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fraction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fraction-Node.html",
    "title": "Fraction Node | mmo-rpg-unity",
    "keywords": "Fraction Node Description Returns the fractional (or decimal) part of input In; which is greater than or equal to 0 and less than 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Fraction_float4(float4 In, out float4 Out) { Out = frac(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fresnel-Effect-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fresnel-Effect-Node.html",
    "title": "Fresnel Effect Node | mmo-rpg-unity",
    "keywords": "Fresnel Effect Node Description Fresnel Effect is the effect of differing reflectance on a surface depending on viewing angle, where as you approach the grazing angle more light is reflected. The Fresnel Effect node approximates this by calculating the angle between the surface normal and the view direction. The wider this angle is, the greater the return value will be. This effect is often used to achieve rim lighting, common in many art styles. Ports Name Direction Type Description Normal Input Vector 3 Normal direction. By default bound to World Space Normal View Dir Input Vector 3 View direction. By default bound to World Space View Direction Power Input Float Exponent of the power calculation Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_FresnelEffect_float(float3 Normal, float3 ViewDir, float Power, out float Out) { Out = pow((1.0 - saturate(dot(normalize(Normal), normalize(ViewDir)))), Power); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fresnel-Equation-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Fresnel-Equation-Node.html",
    "title": "Fresnel Equation Node | mmo-rpg-unity",
    "keywords": "Fresnel Equation Node Description The Fresnel Equation Node adds equations that affect Material interactions to the Fresnel Component. You can select an equation in the Mode dropdown. You can find Numerical values of refractive indices at refractiveindex.info. Ports (Schlick) Name Direction Type Binding Description f0 Input Vector{1, 2, 3} None Represente the reflection of the surface when we face typically 0.02-0.08 for a dielectric material. DotVector Input Float None The dot product between the normal and the surface. Fresnel Output same as f0 None Fresnel coefficient, which describe the amount of light reflected or transmitted. Ports (Dielectric) Name Direction Type Binding Description IOR Source Input Vector None The refractive index of the medium the light source originates in. IOR Medium Input Vector None The refractive index of the medium that the light refracts into. DotVector Input Float None The dot product between the normal and the surface. Fresnel Output same as f0 None The fresnel coefficient, which describe the amount of light reflected or transmitted. Ports (DielectricGeneric) Name Direction Type Binding Description IOR Source Input Vector None The refractive index of the medium the light source originates in. IOR Medium Input Vector None The refractive index of the medium that the light refracts into. IOR MediumK Input Vector None The refractive index Medium (imaginary part), or the medium causing the refraction. DotVector Input Float None The dot product between the normal and the surface. Fresnel Output same as f0 None Fresnel coefficient, which describe the amount of light reflected or transmitted. Controls Name Type Options Description Mode Dropdown • Schlick: This mode produces an approximation based on Schlick's Approximation. Use the Schlick mode for interactions between air and dielectric materials. • Dielectric: Use this mode for interactions between two dielectric Materials. For example, air to glass, glass to water, or water to air. • DielectricGeneric: This mode computes a Fresnel equation for interactions between a dielectric and a metal. For example, clear-coat- to metal, glass to metal, or water to metal. Note: if the IORMediumK value is 0, DielectricGeneric behaves in the same way as the Dielectric mode. Generated Code Example The following example code represents one possible outcome of this node. void Unity_FresnelEquation_Schlick(out float Fresnel, float cos0, float f0) { Fresnel = F_Schlick(f0, cos0); } void Unity_FresnelEquation_Dielectric(out float3 Fresnel, float cos0, float3 iorSource, float3 iorMedium) { FresnelValue = F_FresnelDielectric(iorMedium/iorSource, cos0); } void Unity_FresnelEquation_DielectricGeneric(out float3 Fresnel, float cos0, float3 iorSource, float3 iorMedium, float3 iorMediumK) { FresnelValue = F_FresnelConductor(iorMedium/iorSource, iorMediumK/iorSource, cos0); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Gather-Texture-2D-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Gather-Texture-2D-Node.html",
    "title": "Gather Texture 2D node | mmo-rpg-unity",
    "keywords": "Gather Texture 2D node The Gather Texture 2D node samples the red channel of four neighboring pixels from a sample point. It returns a value of RRRR, and takes each R value from a different neighbor. Normal Texture sampling reads all four channels (RGBA) of a Texture. This node is useful when you want to modify the bilinear interpolation between pixels, such as when you want to create custom blends. This node uses the Gather HLSL intrinsic function. For platforms where this intrinsic function doesn't exist, Shader Graph uses an appropriate approximation, instead. Note When you use the Metal graphics API, the sample, sample_compare, gather, and gather_compare intrinsics use an integer (int2) offset argument when sampling or gathering from a 2D Texture. The intrinsics apply this value to Texture coordinates before looking up each pixel. The offset value must be in the range of -8 to +7, or the Metal API clamps the offset value. The pixels that the Gather Texture 2D samples are always from the top mip level of the Texture, from a 2×2 block of pixels around the sample point. Rather than blending the 2×2 sample, it returns the sampled pixels in counter-clockwise order. It starts with the sample to the lower left of the query location: Create Node menu category The Gather Texture 2D node is under the Input > Texture category in the Create Node menu. Compatibility The Gather Texture 2D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes The Gather Texture 2D node can only be connected to a Block node in the Fragment Context. For more information on Block nodes and Contexts, refer to Master Stack. Inputs The Gather Texture 2D node has the following input ports: Name Type Binding Description Texture Texture 2D None The Texture to sample. UV Vector 2 UV The UV coordinates to use to take the sample. Sampler SamplerState None The Sampler State and its corresponding settings to use for the sample. Offset Vector 2 None The pixel offset to apply to the sample's UV coordinates. The Offset value is in pixels, not UV space. Outputs The Gather Texture 2D node has the following output ports: Name Type Description RGBA Vector 4 The sample value. This is the red channels of the 4 neighboring pixels from the specified sample position on the given Texture. R Float The first neighboring pixel's red channel. G Float The second neighboring pixel's red channel. B Float The third neighboring pixel's red channel. A Float The fourth neighboring pixel's red channel. Example graph usage In the following example, a Gather Texture 2D node creates a blurred version of a Texture by averaging its 4 samples: Then, the rest of the Shader Graph uses a Sample Texture 2D node to sample the Texture again, and uses a Lerp node to determine when to use the blurred Texture and when to use the regular Texture: By changing the value provided to the T port on the Lerp node, you can change whether you want to blur or sharpen the Texture in your Shader Graph: Related nodes The following nodes are related or similar to the Gather Texture 2D node: Sample Texture 2D node Sample Texture 2D LOD node Sampler State node Texture 2D Asset node"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Getting-Started.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Getting-Started.html",
    "title": "Getting started with Shader Graph | mmo-rpg-unity",
    "keywords": "Getting started with Shader Graph Use Shader Graph with either of the Scriptable Render Pipelines (SRPs) available in Unity version 2018.1 and later: The High Definition Render Pipeline (HDRP) The Universal Render Pipeline (URP) As of Unity version 2021.2, you can also use Shader Graph with the Built-In Render Pipeline. Note Shader Graph support for the Built-In Render Pipeline is for compatibility purposes only. Shader Graph doesn't receive updates for Built-In Render Pipeline support, aside from bug fixes for existing features. It's recommended to use Shader Graph with the Scriptable Render Pipelines. When you install HDRP or URP into your project, Unity also installs the Shader Graph package automatically. You can manually install Shader Graph for use with the Built-In Render Pipeline on Unity version 2021.2 and later with the Package Manager. For more information on how to install a package, see Adding and removing packages in the Unity User Manual. For more information about how to set up a Scriptable Render Pipeline, see Getting started with HDRP or Getting started with URP."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Gradient-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Gradient-Node.html",
    "title": "Gradient Node | mmo-rpg-unity",
    "keywords": "Gradient Node Description Defines a constant Gradient for use in Shader Graph, although internally to the shader this is defined as a struct. To sample the Gradient it should be used in conjunction with a Sample Gradient Node. When using a separate Gradient Node, you can sample a Gradient multiple times with different Time parameters. Ports Name Direction Type Description Out Output Gradient Output value Controls Name Type Options Description Gradient Field Defines the gradient. Generated Code Example The following example code represents one possible outcome of this node. Gradient Unity_Gradient_float() { Gradient g; g.type = 1; g.colorsLength = 4; g.alphasLength = 4; g.colors[0] = 0.1; g.colors[1] = 0.2; g.colors[2] = 0.3; g.colors[3] = 0.4; g.colors[4] = 0; g.colors[5] = 0; g.colors[6] = 0; g.colors[7] = 0; g.alphas[0] = 0.1; g.alphas[1] = 0.2; g.alphas[2] = 0.3; g.alphas[3] = 0.4; g.alphas[4] = 0; g.alphas[5] = 0; g.alphas[6] = 0; g.alphas[7] = 0; return g; } Gradient _Gradient = Unity_Gradient_float();"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Gradient-Noise-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Gradient-Noise-Node.html",
    "title": "Gradient Noise Node | mmo-rpg-unity",
    "keywords": "Gradient Noise Node Description Generates a gradient, or Perlin, noise based on input UV. The scale of the generated noise is controlled by input Scale. In terms of performance cost, Gradient Noise node can be slightly more computationally intensive than sampling a texture map. You can also choose to use two different hashing methods for calculating the noise. As of Unity version 2021.2, the Gradient Noise node defaults to the Deterministic hash, to ensure consistent results for noise generation across platforms. Because the UV value is used as the seed for the noise generation, you can offset, scale, or distort the UV value to generate different noise patterns. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Scale Input Float None Noise scale Out Output Float None Output value in the range 0.0 to 1.0 Controls Name Type Options Description Hash Type Dropdown Deterministic, LegacyMod Selects the hash function used to generate random numbers for noise generation. Generated Code Example The following example code represents one possible outcome of this node. float2 unity_gradientNoise_dir(float2 p) { p = p % 289; float x = (34 * p.x + 1) * p.x % 289 + p.y; x = (34 * x + 1) * x % 289; x = frac(x / 41) * 2 - 1; return normalize(float2(x - floor(x + 0.5), abs(x) - 0.5)); } float unity_gradientNoise(float2 p) { float2 ip = floor(p); float2 fp = frac(p); float d00 = dot(unity_gradientNoise_dir(ip), fp); float d01 = dot(unity_gradientNoise_dir(ip + float2(0, 1)), fp - float2(0, 1)); float d10 = dot(unity_gradientNoise_dir(ip + float2(1, 0)), fp - float2(1, 0)); float d11 = dot(unity_gradientNoise_dir(ip + float2(1, 1)), fp - float2(1, 1)); fp = fp * fp * fp * (fp * (fp * 6 - 15) + 10); return lerp(lerp(d00, d01, fp.y), lerp(d10, d11, fp.y), fp.x); } void Unity_GradientNoise_float(float2 UV, float Scale, out float Out) { Out = unity_gradientNoise(UV * Scale) + 0.5; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Graph-Settings-Tab.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Graph-Settings-Tab.html",
    "title": "Graph Settings Tab | mmo-rpg-unity",
    "keywords": "Graph Settings Tab Description The Graph Settings tab on the Graph Inspector make it possible to change settings that affect the Shader Graph as a whole. Graph Settings options Menu Item Description Precision A Precision Mode drop-down menu that lets you set the default precision for the entire graph. You can override the Precision setting here at the node level in your graph. Preview Mode (Subgraphs only) Your options are Inherit, Preview 2D, and Preview 3D. Active Targets A list that contains the Targets you've selected. You can add or remove entries using the Add (+) and Remove (-) buttons. Shader Graph supports three targets: the Universal Render Pipeline, the High Definition Render Pipeline, and Built-In Render Pipeline. Target-specific settings appear below the standard setting options. The displayed Target-specific settings change according to which Targets you select."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Graph-Target.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Graph-Target.html",
    "title": "Graph Target | mmo-rpg-unity",
    "keywords": "Graph Target A Target determines the end point compatibility of a shader you generate using Shader Graph. You can select Targets for each Shader Graph asset, and use the Graph Settings Menu to change the Targets. Targets hold information such as the required generation format, and variables that allow compatibility with different render pipelines or integration features like Visual Effect Graph. You can select any number of Targets for each Shader Graph asset. If a Target you select isn't compatible with other Targets you've already selected, an error message that explains the problem appears. Target Settings are specific to each Target, and can vary between assets depending on which Targets you've selected. Be aware that Universal Render Pipeline (URP) Target Settings and High Definition Render Pipeline (HDRP) Target Settings might change in future versions. Typically, each Target you select generates a valid subshader from the graph. For example, a Shader Graph asset with both URP and HDRP Targets will generate two subshaders. When you use a graph that targets multiple render pipelines, you must reimport the Shader Graph asset if you change the active render pipeline. This updates the Material Inspector for any Materials that use your graph. Shader Graph supports three targets: the Universal Render Pipeline, the High Definition Render Pipeline, and the Built-In Render Pipeline. Not all blocks are compatible with all targets. If a block in your graph becomes inactive when you choose a target, that block is not compatible with that target. The visual results of a graph are not the same in all render pipelines. This is because of the technical differences between URP, Built-In, and HDRP. Shader Graphs that target the Built-In Render Pipeline replicate the results of shaders handwritten in ShaderLab, with the exception of normal maps. For mathematical correctness, normal maps created with Shader Graph behave as they do in URP even when your build targets the Built-In Render Pipeline."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Custom-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Custom-Color-Node.html",
    "title": "Custom Color Node (HDRP) | mmo-rpg-unity",
    "keywords": "Custom Color Node (HDRP) The Custom Color Node accesses the custom pass color buffer allocated by HDRP. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Custom Color Node No Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Sets the normalized screen coordinates to sample. Output Output Vector 4 None The value the custom pass color buffer contains at the sampled coordinates. Generated Code Example The following example code represents one possible outcome of this node. void Unity_CustomDepth_LinearEye_float(float4 UV, out float Out) { Out = SampleCustomColor(UV.xy); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Custom-Depth-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Custom-Depth-Node.html",
    "title": "Custom Depth Node (HDRP) | mmo-rpg-unity",
    "keywords": "Custom Depth Node (HDRP) The Custom Depth Node accesses the custom pass depth buffer allocated by HDRP. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Custom Depth Node No Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Sets the normalized screen coordinates that this node samples. Output Output Vector 4 None The output value of this node. Depth Sampling modes Name Description Linear01 The linear depth value between 0 and 1. Raw The raw depth value. Eye The depth value converted to eye space units. Generated Code Example The following example code represents one possible outcome of this node. void Unity_CustomDepth_LinearEye_float(float4 UV, out float Out) { Out = LinearEyeDepth(SampleCustomDepth(UV.xy), _ZBufferParams); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Sample-Buffer-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Sample-Buffer-Node.html",
    "title": "HD Sample Buffer Node | mmo-rpg-unity",
    "keywords": "HD Sample Buffer Node Description The HD Sample Buffer Node samples a buffer directly from the Camera. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) HD Sample Buffer No Yes Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value. Sampler Input SamplerState None Determines the sampler that Unity uses to sample the buffer. Output Output Float None Output value. Controls Name Type Options Description Source Buffer Dropdown World Normal, Roughness, Motion Vectors, PostProcess Input, Blit Source. Determines which buffer to sample. Generated Code Example The following example code represents one possible outcome of this node: float4 Unity_HDRP_SampleBuffer_float(float2 uv, SamplerState samplerState) { return SAMPLE_TEXTURE2D_X_LOD(_CustomPostProcessInput, samplerState, uv * _RTHandlePostProcessScale.xy, 0); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Scene-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Scene-Color-Node.html",
    "title": "HD Scene Color Node | mmo-rpg-unity",
    "keywords": "HD Scene Color Node The HD Scene Color Node does the same thing as the Scene Color Node, but allows you to access the mips of the color buffer. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) HD Scene Color No Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Sets the normalized screen coordinates to sample. Lod Input float None Sets the mip level that the sampler uses to sample the color buffer. Output Output Vector 3 None Output value Notes Exposure You can use the Exposure property to specify if you want to output the Camera color with exposure applied or not. By default, this property is disabled to avoid double exposure. The sampler that this Node uses to sample the color buffer is in trilinear clamp mode. This allows the sampler to smoothly interpolate between the mip maps."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Scene-Depth-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/HD-Scene-Depth-Node.html",
    "title": "HD Scene Depth Node | mmo-rpg-unity",
    "keywords": "HD Scene Depth Node Description The HD Scene Depth node uses a UV input to access the current Camera's depth buffer. Unity expects normalized screen coordinates for this value. You can also use this node to access the mipmaps in the depth buffer. You can only use the HD Scene Depth node in the Fragment Shader Stage and with non-opaque materials. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) HD Scene Color No Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Sets the normalized screen coordinates to sample. Lod Input float None Sets the mip level that the sampler uses to sample the depth buffer. Output Output Vector 3 None Output value. Depth Sampling modes Name Description Linear01 Linear depth value between 0 and 1 Raw Raw depth value Eye Depth converted to eye space units Notes To use the HD Scene Depth node in a Custom Render Pipeline, you need to explicitly define its behavior, otherwise it returns white."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Hue-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Hue-Node.html",
    "title": "Hue Node | mmo-rpg-unity",
    "keywords": "Hue Node Description Offsets the hue of input In by the amount of input Offset. The unit of the offset can be set with the parameter Range. Offset in Degrees is in the range -180 to 180. In Radians it is -Pi to Pi. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Offset Input Float None Amount to offset hue Out Output Vector 3 None Output value Controls Name Type Options Description Range Dropdown Degrees, Radians The unit used for the input Offset Generated Code Example The following example code represents one possible outcome of this node per Base mode. Degrees void Unity_Hue_Degrees_float(float3 In, float Offset, out float3 Out) { float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 P = lerp(float4(In.bg, K.wz), float4(In.gb, K.xy), step(In.b, In.g)); float4 Q = lerp(float4(P.xyw, In.r), float4(In.r, P.yzx), step(P.x, In.r)); float D = Q.x - min(Q.w, Q.y); float E = 1e-10; float3 hsv = float3(abs(Q.z + (Q.w - Q.y)/(6.0 * D + E)), D / (Q.x + E), Q.x); float hue = hsv.x + Offset / 360; hsv.x = (hue < 0) ? hue + 1 : (hue > 1) ? hue - 1 : hue; float4 K2 = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 P2 = abs(frac(hsv.xxx + K2.xyz) * 6.0 - K2.www); Out = hsv.z * lerp(K2.xxx, saturate(P2 - K2.xxx), hsv.y); } Radians void Unity_Hue_Radians_float(float3 In, float Offset, out float3 Out) { float4 K = float4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0); float4 P = lerp(float4(In.bg, K.wz), float4(In.gb, K.xy), step(In.b, In.g)); float4 Q = lerp(float4(P.xyw, In.r), float4(In.r, P.yzx), step(P.x, In.r)); float D = Q.x - min(Q.w, Q.y); float E = 1e-10; float3 hsv = float3(abs(Q.z + (Q.w - Q.y)/(6.0 * D + E)), D / (Q.x + E), Q.x); float hue = hsv.x + Offset; hsv.x = (hue < 0) ? hue + 1 : (hue > 1) ? hue - 1 : hue; // HSV to RGB float4 K2 = float4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0); float3 P2 = abs(frac(hsv.xxx + K2.xyz) * 6.0 - K2.www); Out = hsv.z * lerp(K2.xxx, saturate(P2 - K2.xxx), hsv.y); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Hyperbolic-Cosine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Hyperbolic-Cosine-Node.html",
    "title": "Hyperbolic Cosine Node | mmo-rpg-unity",
    "keywords": "Hyperbolic Cosine Node Description Returns the hyperbolic cosine of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_HyperbolicCosine_float4(float4 In, out float4 Out) { Out = cosh(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Hyperbolic-Sine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Hyperbolic-Sine-Node.html",
    "title": "Hyperbolic Sine Node | mmo-rpg-unity",
    "keywords": "Hyperbolic Sine Node Description Returns the hyperbolic sine of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_HyperbolicSine_float4(float4 In, out float4 Out) { Out = sinh(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Hyperbolic-Tangent-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Hyperbolic-Tangent-Node.html",
    "title": "Hyperbolic Tangent Node | mmo-rpg-unity",
    "keywords": "Hyperbolic Tangent Node Description Returns the hyperbolic tangent of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_HyperbolicTangent_float4(float4 In, out float4 Out) { Out = tanh(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Input-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Input-Nodes.html",
    "title": "Input Nodes | mmo-rpg-unity",
    "keywords": "Input Nodes Basic Boolean Color Defines a constant Boolean value in the shader. Defines a constant Vector 4 value in the shader using a Color field. Constant Integer Defines a Float of a mathematical constant value in the shader. Defines a constant Float value in the shader using an Integer field. Slider Time Defines a constant Float value in the shader using a Slider field. Provides access to various Time parameters in the shader. Float Vector 2 Defines a Float value in the shader. Defines a Vector 2 value in the shader. Vector 3 Vector 4 Defines a Vector 3 value in the shader. Defines a Vector 4 value in the shader. Geometry Bitangent Vector Normal Vector Provides access to the mesh vertex or fragment's Bitangent Vector. Provides access to the mesh vertex or fragment's Normal Vector. Position Screen Position Provides access to the mesh vertex or fragment's Position. Provides access to the mesh vertex or fragment's Screen Position. Tangent Vector UV Provides access to the mesh vertex or fragment's Tangent Vector. Provides access to the mesh vertex or fragment's UV coordinates. Vertex Color View Direction Provides access to the mesh vertex or fragment's Vertex Color value. Provides access to the mesh vertex or fragment's View Direction vector. Vertex ID Provides access to the mesh vertex or fragment's Vertex ID value. Gradient Blackbody Gradient Samples a radiation based gradient from temperature input (in Kelvin). Defines a constant Gradient in the shader. Sample Gradient Samples a Gradient given the input of Time. Matrix Matrix 2x2 Matrix 3x3 Defines a constant Matrix 2x2 value in the shader. Defines a constant Matrix 3x3 value in the shader. Matrix 4x4 Transformation Matrix Defines a constant Matrix 4x4 value in the shader. Defines a constant Matrix 4x4 value for a default Unity Transformation Matrix in the shader. Mesh Deformation Compute Deformation Node Linear Blend Skinning Node Passes compute deformed vertex data to a vertex shader. Only works with the Entities Graphics package. Applies Linear Blend Vertex Skinning. Only works with the Entities Graphics package. PBR Dielectric Specular Metal Reflectance Returns a Dielectric Specular F0 value for a physically based material. Returns a Metal Reflectance value for a physically based material. Scene Ambient Camera Provides access to the Scene's Ambient color values. Provides access to various parameters of the current Camera. Fog Baked GI Provides access to the Scene's Fog parameters. Provides access to the Baked GI values at the vertex or fragment's position. Object Reflection Probe Provides access to various parameters of the Object. Provides access to the nearest Reflection Probe to the object. Scene Color Scene Depth Provides access to the current Camera's color buffer. Provides access to the current Camera's depth buffer. Screen Eye Index Provides access to parameters of the screen. Provides access to the Eye Index when stereo rendering. Texture Cubemap Asset Sample Cubemap Defines a constant Cubemap Asset for use in the shader. Samples a Cubemap and returns a Vector 4 color value for use in the shader. Sample Reflected Cubemap Node Sample Texture 2D Samples a Cubemap with reflected vector and returns a Vector 4 color value for use in the shader. Samples a Texture 2D and returns a color value for use in the shader. Sample Texture 2D Array Sample Texture 2D LOD Samples a Texture 2D Array at an Index and returns a color value for use in the shader. Samples a Texture 2D at a specific LOD and returns a color value for use in the shader. Sample Texture 3D Sample Virtual Texture Samples a Texture 3D and returns a color value for use in the shader. Samples a Virtual Texture and returns color values for use in the shader. Sampler State Texture Size Defines a Sampler State for sampling textures. Returns the Width and Height of the texel size of Texture 2D input. Texture 2D Array Asset Texture 2D Asset Defines a constant Texture 2D Array Asset for use in the shader. Defines a constant Texture 2D Asset for use in the shader. Texture 3D Asset Defines a constant Texture 3D Asset for use in the shader."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Instance-ID-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Instance-ID-Node.html",
    "title": "Instance ID Node | mmo-rpg-unity",
    "keywords": "Instance ID Node Description When Unity renders with GPU instancing, it assigns an Instance ID to each geometry. Use this node to capture Instance ID values in Graphics.DrawMeshInstanced API calls. When Unity does not render with GPU instancing, this ID is 0. When Unity uses dynamic instancing, instance IDs might not be consistent across multiple frames. Ports Name Direction Type Binding Description Out Output Float None Instance ID for mesh of a given instanced draw call."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Integer-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Integer-Node.html",
    "title": "Integer Node | mmo-rpg-unity",
    "keywords": "Integer Node Description Defines a constant Float value in the shader using an Integer field. Can be converted to a Float type Property with a Mode setting of Integer via the Node's context menu. Ports Name Direction Type Binding Description Out Output Float None Output value Controls Name Type Options Description Integer Defines the output value. Generated Code Example The following example code represents one possible outcome of this node. float _Integer = 1;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Internal-Inspector.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Internal-Inspector.html",
    "title": "Graph Inspector | mmo-rpg-unity",
    "keywords": "Graph Inspector Description The Graph Inspector makes it possible for you to interact with any selectable graph elements and graph-wide settings for a Shader Graph Asset. You can use the Graph Inspector to edit attributes and default values. When you open a Shader Graph, the Graph Inspector displays the Graph Settings tab by default. Graph-wide settings for that specific Shader Graph appear in this tab. How to use Select a node in the graph to display settings available for that node in the Graph Inspector. Settings available for that node appear in the Node Settings tab of the Graph Inspector. For example, if you select a Property node either in the graph or the Blackboard, the Node Settings tab displays attributes of the Property that you can edit. Graph elements that currently work with the Graph Inspector: Properties Keywords Custom Function nodes Subgraph Output nodes Per-node precision Graph elements that currently do not work with the Graph Inspector: Edges Sticky Notes Groups Material Override Enabling the Allow Material Override option in the Graph Settings makes it possible for you to override certain graph properties via the Material Inspector."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Inverse-Lerp-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Inverse-Lerp-Node.html",
    "title": "Inverse Lerp Node | mmo-rpg-unity",
    "keywords": "Inverse Lerp Node Description Returns the linear parameter that produces the interpolant specified by input T within the range of input A to input B. Inverse Lerp is the inverse operation of the Lerp Node. It can be used to determine what the input to a Lerp was based on its output. For example, the value of a Lerp between 0 and 2 with a T value of 0.5 is 1. Therefore the value of an Inverse Lerp between 0 and 2 with a T value of 1 is 0.5. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value T Input Dynamic Vector Time value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_InverseLerp_float4(float4 A, float4 B, float4 T, out float4 Out) { Out = (T - A)/(B - A); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Invert-Colors-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Invert-Colors-Node.html",
    "title": "Invert Colors Node | mmo-rpg-unity",
    "keywords": "Invert Colors Node Description Inverts the colors of input In on a per channel basis. This Node assumes all input values are in the range 0 - 1. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Controls Name Type Options Description Red Toggle True, False If true red channel is inverted Green Toggle True, False If true green channel is inverted. Disabled if input vector dimension is less than 2 Blue Toggle True, False If true blue channel is inverted. Disabled if input vector dimension is less than 3 Alpha Toggle True, False If true alpha channel is inverted. Disabled if input vector dimension is less than 4 Generated Code Example The following example code represents one possible outcome of this node. float2 _InvertColors_InvertColors = float4(Red, Green, Blue, Alpha); void Unity_InvertColors_float4(float4 In, float4 InvertColors, out float4 Out) { Out = abs(InvertColors - In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Iris-Limbal-Ring-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Iris-Limbal-Ring-Node.html",
    "title": "Iris Limbal Ring Node | mmo-rpg-unity",
    "keywords": "Iris Limbal Ring Node Calculates the intensity of the Limbal ring, a darkening feature of eyes. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Iris Limbal Ring Node No Yes Ports name Direction type description IrisUV Input Vector2 Normalized UV coordinates that can be used to sample either a texture or procedurally generate an Iris Texture. View Direction OS Input Vector3 Direction of the incident ray in object space. Either from the camera in rasterization or from the previous bounce in ray tracing. LimbalRingSize Input float Normalized [0, 1] value that defines the relative size of the limbal ring. LimbalRingFade Input float Normalized [0, 1] value that defines strength of the fade out of the limbal ring. LimbalRingIntensity Input float Positive value that defines how dark the limbal ring is. Iris Limbal Ring Color Output Color Intensity of the limbal ring."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Iris-Offset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Iris-Offset-Node.html",
    "title": "Iris Offset Node | mmo-rpg-unity",
    "keywords": "Iris Offset Node Applies an offset to the center of the Iris as real world eyes are never symmetrical and centered. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Iris Offset Node No Yes Ports name Direction type description IrisUV Input Vector2 Normalized UV coordinates to sample either a texture or procedurally generate an Iris Texture. IrisOffset Input Vector2 Normalized [0, 1]x[0,1] value that defines on each axis the intensity of the offset of the Center of the pupil. IrisUV Output Vector2 Normalized UV coordinates to sample either a texture or procedurally generate an Iris Texture."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Iris-Out-Of-Bound-Color-Clamp-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Iris-Out-Of-Bound-Color-Clamp-Node.html",
    "title": "Iris Out of Bound Color Clamp Node | mmo-rpg-unity",
    "keywords": "Iris Out of Bound Color Clamp Node Clamps the color of the Iris to a given color. This is useful in case the refraction ray reaches the inside of the cornea. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Iris Out of Bound Color Clamp Node No Yes Ports name Direction type description IrisUV Input Vector2 Normalized UV coordinates to sample either a texture or procedurally generate an Iris Texture. Iris Color Input Color Previously sampled or generated color of the Iris. Clamp Color Input Color The color to clamp the Iris to. Iris Color Output Color Result Iris color for the rest of the pipeline."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Iris-UV-Location-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Iris-UV-Location-Node.html",
    "title": "Iris UV Location Node | mmo-rpg-unity",
    "keywords": "Iris UV Location Node This node converts the object position of the cornea/iris to a UV Sampling coordinate. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Iris UV Location Node No Yes Ports name Direction type description Position OS Input Vector3 Position on the iris Plane in object space. Iris Radius Input float The radius of the Iris in the used model. For the default model, this value should be 0.225. IrisUV Output Vector2 ormalized UV coordinates that can be used to sample either a texture or procedurally generate an Iris Texture."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Is-Front-Face-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Is-Front-Face-Node.html",
    "title": "Is Front Face Node | mmo-rpg-unity",
    "keywords": "Is Front Face Node Description Returns true if currently rendering a front face and false if rendering a back face. This value is always true unless the Master Node's Two Sided value is set to true in the Material Options. This is useful for Branching. NOTE: This Node can only be used in the Fragment Shader Stage. Ports Name Direction Type Binding Description Out Output Boolean None Output value"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Is-Infinite-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Is-Infinite-Node.html",
    "title": "Is Infinite Node | mmo-rpg-unity",
    "keywords": "Is Infinite Node Description Returns true if the input In is an infinite value. This is useful for Branching. Ports Name Direction Type Binding Description In Input Float None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_IsInfinite_float(float In, out float Out) { Out = isinf(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Is-NaN-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Is-NaN-Node.html",
    "title": "Is NaN Node | mmo-rpg-unity",
    "keywords": "Is NaN Node Description Returns true if the input In is not a number (NaN). This is useful for Branching. Ports Name Direction Type Binding Description In Input Float None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_IsNan_float(float In, out float Out) { Out = (In < 0.0 || In > 0.0 || In == 0.0) ? 0 : 1; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Keyword-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Keyword-Node.html",
    "title": "Keyword node | mmo-rpg-unity",
    "keywords": "Keyword node Description You can use a Keyword node to create a static branch in your Shader Graph that references a Keyword on the Blackboard. The appearance of a Keyword node, including its available ports, changes based on the Keyword it references. Creating new Keyword Nodes Because each Keyword node references a specific Keyword, you must first define at least one Keyword on the Blackboard. Drag a Keyword from the Blackboard to the workspace to make a Keyword node that corresponds to that Keyword. You can also right-click anywhere on the workspace, and use the Create Node menu to make a new Keyword node. Under Keywords, there is a list of Keywords that you defined on the Blackboard. Click on a Keyword in that list to create a corresponding Keyword node."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Keywords.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Keywords.html",
    "title": "Keywords | mmo-rpg-unity",
    "keywords": "Keywords Description Use Keywords to create different variants for your Shader Graph. Keywords enable you to create shaders: With features that you can turn on or off for each Material instance. With features that behave differently on certain platforms. That scale in complexity based on conditions you set. There are three types of Keywords: Boolean, Enum, and Built-in. Unity defines a Keyword in the graph, shader, and optionally, the Material Inspector based on its type. See Boolean Keyword, Enum Keyword, and Built-in Keyword for more information about Keyword types. For more information about how these Keywords affect the final shader, see documentation on Making multiple shader program variants. In Shader Graph, you first define a Keyword on the Blackboard, then use a Keyword Node to create a branch in the graph. The Editor is able to compile variants on demand when it needs them to render content. If you declare many different variants, you can end up with millions or trillions of possibilities. However, the Player needs to determine at build time which variants are in use and include them when it pre-compiles your shaders. To manage memory effectively, the Player strips unused variants based on their keyword and Editor settings. See the next section, Common parameters, to learn more about how you can give the Player hints about what it needs to compile and what it can ignore. When the Player strips out a variant in the build process, it displays the pink error shader. Common parameters Although some fields are specific to certain types of Keywords, all Keywords have the following parameters. Name Type Description Display Name String The display name of the Keyword. Unity shows this name in the title bar of nodes that reference the corresponding Keyword, and also in the Material Inspector if you expose that Keyword. Exposed Boolean When you set this parameter to true, Unity displays this Keyword in the Material Inspector. If you set it to false, the Keyword does not appear in the Material Inspector. If you intend to access a GLOBAL shader variable, be sure to add it as you would normally add an input variable, but deselect Exposed. Reference Name String The internal name for the Keyword in the shader. If you overwrite the Reference Name parameter, take note of the following: Keyword Reference Names are always in full capitals, so Unity converts all lowercase letters to uppercase. If the Reference Name contains any characters that HLSL does not support, Unity replaces those characters with underscores. Right-click on a Reference Name, and select Reset Reference to revert to the default Reference Name. Definition Enum Sets how the Keyword is defined in the shader. Determines when to compile keyword variants. There are three available options: Shader Feature: Unity only compiles keyword variants when a Material selects the relevant option. For this option to be available in the Player, a Material selecting it must exist at build-time. Multi Compile: Pre-compiles all the variant possibilities. This is slower and uses more memory, but allows the option to be dynamically switched in the Player. Predefined: The render pipeline defines this keyword and controls the settings for it. Scope Enum Sets the scope at which to define the Keyword. The following options are available: Global Keywords: Defines Keyword for the entire project, and it counts towards the global keyword limit. Local Keywords: Defines Keyword for only one shader, which has its own local keyword limit. When you use Predefined Keywords, Unity disables this field. Stages Set the stage the keyword applies to. The following options are available: All - Applies this keyword to all shader stages. Vertex - Applies this keyword to the vertex stage. Fragment - Applies this keyword to the fragment stage. Boolean Keywords Boolean Keywords are either on or off. This results in two shader variants. Unity exposes Boolean Keywords in the Material Inspector if the Exposed parameter is set to is true. To enable the keyword from a script, use EnableKeyword on the keyword's Reference name. DisableKeyword disables the keyword. To learn more about Boolean Keywords, see Shader variants and keywords. Type-specific parameters Boolean Keywords have one Boolean-specific parameter in addition to the common parameters listed above. Name Type Description Default Boolean Enable this parameter to set the Keyword's default state to on, and disable it to set the Keyword's default state to off. This parameter determines the value to use for the Keyword when Shader Graph generates previews. It also defines the Keyword's default value when you use this shader to create a new Material. Enum Keywords Enum Keywords can have two or more states, which you define in the Entries list. If you expose an Enum Keyword, the Display Names in its Entries list appear in a dropdown menu in the Material Inspector. Special characters such as ( ) or ! @ are not valid in the Entry Name of an Enum Keyword. Shader Graph converts invalid characters to underscores ( _ ). When you define an Enum Keyword, Shader Graph displays labels for each state consisting of a sanitized version of the Enum's Entry Name appended to the main Reference name. When controlling a keyword via script with a, Material.EnableKeyword or Shader.EnableKeyword function, enter the state label in the format {REFERENCE}_{REFERENCESUFFIX}. For example, if your reference name is MYENUM and the desired entry is OPTION1, then you would call Material.EnableKeyword(\"MYENUM_OPTION1\"). When you select an option, this disables the other options. Type-specific parameters In addition to the common parameters listed above, Enum Keywords have the following additional parameters. Name Type Description Default Enum Select an entry from the drop-down menu to determine which value to use for the Keyword when Shader Graph generates previews. This also defines the Keyword's default value when you use this shader to create a new Material. When you edit the Entries list, Shader Graph automatically updates the options in this control. Entries Reorderable List This list defines all the states for the Keyword. Each state has a separate Display Name and Reference Suffix. • Display Name: Appears in drop-down menus for the Keyword on the Internal Inspector and the Material Inspector. Shader Graph also uses this name for port labels on nodes that reference the Keyword. • Reference Suffix: This is the final keyword, presented in the format Reference_ReferenceSuffix. Built-in Keywords Built-in Keywords are always of either the Boolean or Enum type, but they behave slightly differently from Boolean or Enum Keywords that you create. The Unity Editor or active Render Pipeline sets their values, and you cannot edit these. All Built-in Keyword fields in the Node Settings tab of the Graph Inspector are grayed out except for the Default field, which you can enable or disable to show the differences in Shader Graph previews. You also cannot expose Built-in Keywords in the Material Inspector."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Length-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Length-Node.html",
    "title": "Length Node | mmo-rpg-unity",
    "keywords": "Length Node Description Returns the length of input In. This is also known as magnitude. A vector's length is calculated with Pythagorean Theorum. The length of a Vector 2 can be calculated as: Where x and y are the components of the input vector. Length can be calculated for other dimension vectors by adding or removing components. And so on. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Length_float4(float4 In, out float Out) { Out = length(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Lerp-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Lerp-Node.html",
    "title": "Lerp Node | mmo-rpg-unity",
    "keywords": "Lerp Node Description Returns the result of linearly interpolating between input A and input B by input T. For example, when the value of input T is 0 the return value is equal to the value of input A, when it is 1 the return value is equal to the value of input B and when it is 0.5 the return value is the midpoint of the two inputs A and B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value T Input Dynamic Vector Time value. Typical range: 0 to 1. Though you can use values outside of this range they may cause unpredictable results. Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Lerp_float4(float4 A, float4 B, float4 T, out float4 Out) { Out = lerp(A, B, T); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Linear-Blend-Skinning-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Linear-Blend-Skinning-Node.html",
    "title": "Linear Blend Skinning Node | mmo-rpg-unity",
    "keywords": "Linear Blend Skinning Node Description This node lets you apply Linear Blend Vertex Skinning, and only works with the Entities Graphics package. You must provide skinned matrices in the _SkinMatrices buffer. The node uses the _SkinMatrixIndex property to calculate where the matrices associated with the current mesh are located in the _SkinMatrices buffer. Ports Name Direction Type Stage Description Position Input Vector3 Vertex Position of the vertex in object space. Normal Input Vector3 Vertex Normal of the vertex in object space. Tangent Input Vector3 Vertex Tangent of the vertex in object space. Position Output Vector3 Vertex Outputs the skinned vertex position. Normal Output Vector3 Vertex Outputs the skinned vertex normal. Tangent Output Vector3 Vertex Outputs the skinned vertex tangent."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Log-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Log-Node.html",
    "title": "Log Node | mmo-rpg-unity",
    "keywords": "Log Node Description Returns the logarithm of input In. Log is the inverse operation to the Exponential Node. For example, the result of a base-2 Exponential using an input value of 3 is 8. Therefore the result of a base-2 Log using an input value of 8 is 3. The logarithmic base can be switched between base-e, base-2 and base-10 from the Base dropdown on the node. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Controls Name Type Options Description Base Dropdown BaseE, Base2, Base10 Selects the logarithmic base Generated Code Example The following example code represents one possible outcome of this node per Base mode. Base E void Unity_Log_float4(float4 In, out float4 Out) { Out = log(In); } Base 2 void Unity_Log2_float4(float4 In, out float4 Out) { Out = log2(In); } Base 10 void Unity_Log10_float4(float4 In, out float4 Out) { Out = log10(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Main-Light-Direction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Main-Light-Direction-Node.html",
    "title": "Get Main Light Direction Node | mmo-rpg-unity",
    "keywords": "Get Main Light Direction Node Description Provides access to the direction of the main directional light in the scene. The main directional light is the one casting shadows if there is any. Otherwise, it fallbacks to the first non shadow casting directional light. Ports Name Direction Type Description Direction Output Vector3 The normalized direction of the sun light in world space."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Main-Preview.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Main-Preview.html",
    "title": "Main Preview | mmo-rpg-unity",
    "keywords": "Main Preview Description The Main Preview displays a representation of the shader on the active Render Pipeline. It updates in real-time and automatically updates to display any changes you make in the Shader Graph. The title bar of the Main Preview displays the name of the current shader. The Main Preview can be moved to anywhere in the Shader Graph Window and will automatically move with the nearest corner of that window. Preview Mesh You can rotate the preview mesh by holding left mouse button and dragging on the Main Preview and you can scale it by using the scroll wheel. The preview mesh can be changed by right clicking on the Main Preview. Here you can select from any primitive mesh types or select a custom mesh."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Master-Stack.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Master-Stack.html",
    "title": "Master Stack | mmo-rpg-unity",
    "keywords": "Master Stack Description The Master Stack is the end point of a Shader Graph that defines the final surface appearance of a shader. Your Shader Graph should always contain only one Master Stack. The content of the Master Stack might change depending on the Graph Settings you select. The Master Stack is made up of Contexts, which contain Block nodes. Contexts The Master Stack contains two Contexts: Vertex and Fragment. These represent the two stages of a shader. Nodes that you connect to Blocks in the Vertex Context become part of the final shader's vertex function. Nodes that you connect to Blocks in the Fragment Context become part of the final shader's fragment (or pixel) function. If you connect any nodes to both Contexts, they are executed twice, once in the vertex function and then again in the fragment function. You can't cut, copy, or paste Contexts."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Math-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Math-Nodes.html",
    "title": "Math Nodes | mmo-rpg-unity",
    "keywords": "Math Nodes Advanced Absolute Exponential Returns the absolute value of input In. Returns the exponential value of input In. Length Log Returns the length of input In. Returns the logarithm of input In. Modulo Negate Returns the remainder of input A divided by input B. Returns the inverse value of input In. Normalize Posterize Returns the normalized vector of input In. Returns the input In converted into a number of values defined by input Steps. Reciprocal Reciprocal Square Root Returns the result of 1 divided by input In. Returns the result of 1 divided by the square root of input In. Basic Add Divide Returns the sum of the two input values. Returns the result of input A divided by input B. Multiply Power Returns the result of input A multiplied by input B. Returns the result of input A to the power of input B. Square Root Subtract Returns the square root of input In. Returns the result of input A minus input B. Derivative DDX DDXY Returns the partial derivative with respect to the screen-space x-coordinate. Returns the sum of both partial derivatives. DDY Returns the partial derivative with respect to the screen-space y-coordinate. Interpolation Inverse Lerp Lerp Returns the parameter that produces the interpolant specified by input T within the range of input A to input B. Returns the result of linearly interpolating between input A and input B by input T. Smoothstep Returns the result of a smooth Hermite interpolation between 0 and 1, if input In is between inputs Edge1 and Edge2. Matrix Matrix Construction Matrix Determinant Constructs square matrices from the four input vectors M0, M1, M2 and M3. Returns the determinant of the matrix defined by input In. Matrix Split Matrix Transpose Splits a square matrix defined by input In into vectors. Returns the transposed value of the matrix defined by input In. Range Clamp Fraction Returns the input In clamped between the minimum and maximum values defined by inputs Min and Max respectively. Returns the fractional (or decimal) part of input In; which is greater than or equal to 0 and less than 1. Maximum Minimum Returns the largest of the two inputs values A and B. Returns the smallest of the two inputs values A and B. One Minus Random Range Returns the result of input In subtracted from 1. Returns a pseudo-random number that is between the minimum and maximum values defined by inputs Min and Max. Remap Saturate Remaps the value of input In from between the values of input Out Min Max to between the values of input In Min Max. Returns the value of input In clamped between 0 and 1. Round Ceiling Floor Returns the smallest integer value, or whole number, that is greater than or equal to the value of input In. Returns the largest integer value, or whole number, that is less than or equal to the value of input In. Round Sign Returns the value of input In rounded to the nearest integer, or whole number. Returns -1 if the value of input In is less than zero, 0 if equal to zero and 1 if greater than zero. Step Truncate Returns 1 if the value of input In is greater than or equal to the value of input Edge, otherwise returns 0. Returns the integer, or whole number, component of the value of input In. Trigonometry Arccosine Arcsine Returns the arccosine of each component the input In as a vector of equal length. Returns the arcsine of each component the input In as a vector of equal length. Arctangent Arctangent2 Returns the arctangent of the value of input In. Each component should be within the range of -Pi/2 to Pi/2. Returns the arctangent of the values of both input A and input B. Cosine Degrees to Radians Returns the cosine of the value of input In. Returns the value of input In converted from degrees to radians. Hyperbolic Cosine Hyperbolic Sine Returns the hyperbolic cosine of input In. Returns the hyperbolic sine of input In. Hyperbolic Tangent Radians to Degrees Returns the hyperbolic tangent of input In. Returns the value of input In converted from radians to degrees. Sine Tangent Returns the sine of the value of input In. Returns the tangent of the value of input In. Vector Cross Product Distance Returns the cross product of the values of the inputs A and B. Returns the Euclidean distance between the values of the inputs A and B. Dot Product Fresnel Effect Returns the dot product, or scalar product, of the values of the inputs A and B. Fresnel Effect is the effect of differing reflectance on a surface depending on viewing angle, where as you approach the grazing angle more light is reflected. Projection Reflection Returns the result of projecting the value of input A onto a straight line parallel to the value of input B. Returns a reflection vector using input In and a surface normal Normal. Rejection Rotate About Axis Returns the result of the projection of the value of input A onto the plane orthogonal, or perpendicular, to the value of input B. Rotates the input vector In around the axis Axis by the value of Rotation. Projection Rejection Returns the result of projecting the value of input A onto a straight line parallel to the value of input B. Returns the result of the projection of the value of input A onto the plane orthogonal, or perpendicular, to the value of input B. Sphere Mask Transform Creates a sphere mask originating from input Center. Returns the result of transforming the value of input In from one coordinate space to another. Wave Noise Sine Wave Sawtooth Wave Returns the sine of the value of input In. For variance, random noise is added to the amplitude of the sine wave. Returns a sawtooth wave from the value of input In. Matrix Split Matrix Transpose Splits a square matrix defined by input In into vectors. Returns the transposed value of the matrix defined by input In. Noise Sine Wave Sawtooth Wave Square Wavve Triangle Wave"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-2x2-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-2x2-Node.html",
    "title": "Matrix 2x2 Node | mmo-rpg-unity",
    "keywords": "Matrix 2x2 Node Description Defines a constant Matrix 2x2 value in the shader. Ports Name Direction Type Binding Description Out Output Matrix 2 None Output value Controls Name Type Options Description Matrix 2x2 Sets output value Generated Code Example The following example code represents one possible outcome of this node. float2x2 _Matrix2x2 = float2x2(1, 0, 0, 1);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-3x3-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-3x3-Node.html",
    "title": "Matrix 3x3 Node | mmo-rpg-unity",
    "keywords": "Matrix 3x3 Node Description Defines a constant Matrix 3x3 value in the shader. Ports Name Direction Type Binding Description Out Output Matrix 3 None Output value Controls Name Type Options Description Matrix 3x3 Sets output value Generated Code Example The following example code represents one possible outcome of this node. float3x3 _Matrix3x3 = float3x3(1, 0, 0, 0, 1, 0, 0, 0, 1);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-4x4-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-4x4-Node.html",
    "title": "Matrix 4x4 Node | mmo-rpg-unity",
    "keywords": "Matrix 4x4 Node Description Defines a constant Matrix 4x4 value in the shader. Ports Name Direction Type Binding Description Out Output Matrix 4 None Output value Controls Name Type Options Description Matrix 4x4 Sets output value Generated Code Example The following example code represents one possible outcome of this node. float4x4 _Matrix4x4 = float4x4(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-Construction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-Construction-Node.html",
    "title": "Matrix Construction Node | mmo-rpg-unity",
    "keywords": "Matrix Construction Node Description Constructs square matrices from the four input vectors M0, M1, M2 and M3. This node can be used to generate matrices of types Matrix 2x2, Matrix 3x3 and Matrix 4x4. The dropdown on the node can be used to select whether the inputs values specify the matrix rows or columns. Row : Input vectors specify matrix rows from top to bottom. Column : Input vectors specify matrix columns from left to right. Matrix outputs are taken from the top left corner of the construction of the inputs. This can be used to generate different dimension square matrices from different dimension vectors. For example, connecting Vector 2 type values to inputs M0 and M1 will generate the desired matrix from the output 2x2. Ports Name Direction Type Description M0 Input Vector 4 First row or column M1 Input Vector 4 Second row or column M2 Input Vector 4 Third row or column M3 Input Vector 4 Fourth row or column 4x4 Output Matrix 4x4 Output as Matrix 4x4 3x3 Output Matrix 3x3 Output as Matrix 3x3 2x2 Output Matrix 2x2 Output as Matrix 2x2 Controls Name Type Options Description Dropdown Row, Column Selects how the output matrix should be filled Generated Code Example The following example code represents one possible outcome of this node per mode. Row void Unity_MatrixConstruction_Row_float(float4 M0, float4 M1, float4 M2, float3 M3, out float4x4 Out4x4, out float3x3 Out3x3, out float2x2 Out2x2) { Out4x4 = float4x4(M0.x, M0.y, M0.z, M0.w, M1.x, M1.y, M1.z, M1.w, M2.x, M2.y, M2.z, M2.w, M3.x, M3.y, M3.z, M3.w); Out3x3 = float3x3(M0.x, M0.y, M0.z, M1.x, M1.y, M1.z, M2.x, M2.y, M2.z); Out2x2 = float2x2(M0.x, M0.y, M1.x, M1.y); } Column void Unity_MatrixConstruction_Column_float(float4 M0, float4 M1, float4 M2, float3 M3, out float4x4 Out4x4, out float3x3 Out3x3, out float2x2 Out2x2) { Out4x4 = float4x4(M0.x, M1.x, M2.x, M3.x, M0.y, M1.y, M2.y, M3.y, M0.z, M1.z, M2.z, M3.z, M0.w, M1.w, M2.w, M3.w); Out3x3 = float3x3(M0.x, M1.x, M2.x, M0.y, M1.y, M2.y, M0.z, M1.z, M2.z); Out2x2 = float2x2(M0.x, M1.x, M0.y, M1.y); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-Determinant-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-Determinant-Node.html",
    "title": "Matrix Determinant | mmo-rpg-unity",
    "keywords": "Matrix Determinant Description Returns the determinant of the matrix defined by input In. It can be viewed as the scaling factor of the transformation described by the matrix. Ports Name Direction Type Description In Input Dynamic Matrix Input value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_MatrixDeterminant_float4x4(float4x4 In, out float Out) { Out = determinant(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-Split-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-Split-Node.html",
    "title": "Matrix Split Node | mmo-rpg-unity",
    "keywords": "Matrix Split Node Description Splits a square matrix defined by input In into vectors. Output vector dimension is defined by the dimension of the input matrix. The dropdown on the node can be used to select whether the output values are taken from the rows or columns of the input matrix. Row : Output vectors are composed of matrix rows from top to bottom. Column : Output vectors are composed of matrix columns from left to right. An input matrix of type Matrix 2x2 or Matrix 3x3 will return 0 values in the rows (or columns, depending on dropdown selection) that are beyond their dimension. For example, connecting Matrix 2x2 type to input In will return the correct Vector 2 type outputs to output slots M0 and M1, leaving outputs M2 and M3 to return 0 values. Ports Name Direction Type Description In Input Dynamic Matrix Input value M0 Output Dynamic Vector First row or column M1 Output Dynamic Vector Second row or column M2 Output Dynamic Vector Third row or column M3 Output Dynamic Vector Fourth row or column Controls Name Type Options Description Dropdown Row, Column Selects how the output vectors should be filled Generated Code Example The following example code represents one possible outcome of this node. float2 _MatrixSplit_M0 = float2(In[0].r, In[0].g); float2 _MatrixSplit_M1 = float2(In[1].r, In[1].g); float2 _MatrixSplit_M2 = float2(0, 0); float2 _MatrixSplit_M3 = float2(0, 0);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-Transpose-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Matrix-Transpose-Node.html",
    "title": "Matrix Transpose | mmo-rpg-unity",
    "keywords": "Matrix Transpose Description Returns the transposed value of the matrix defined by input In. This can be seen as the operation of flipping the matrix over its diagonal. The result is that it switches the row and column indices of the matrix. Ports Name Direction Type Description In Input Dynamic Matrix Input value Out Output Dynamic Matrix Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_MatrixTranspose_float4x4(float4x4 In, out float4x4 Out) { Out = transpose(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Maximum-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Maximum-Node.html",
    "title": "Maximum Node | mmo-rpg-unity",
    "keywords": "Maximum Node Description Returns the largest of the two inputs values A and B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Maximum_float4(float4 A, float4 B, out float4 Out) { Out = max(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Metal-Reflectance-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Metal-Reflectance-Node.html",
    "title": "Metal Reflectance Node | mmo-rpg-unity",
    "keywords": "Metal Reflectance Node Description Returns a Metal Reflectance value for a physically based material. The material to use can be selected with the Material dropdown parameter on the Node. When using Specular Workflow on a PBR Master Node this value should be supplied to the Specular Port. When using Metallic Workflow this value should be supplied to the Albedo Port. Ports Name Direction Type Binding Description Out Output Vector 3 None Output value Controls Name Type Options Description Material Dropdown Iron, Silver, Aluminium, Gold, Copper, Chromium, Nickel, Titanium, Cobalt, Platform Selects the material value to output. Generated Code Example The following example code represents one possible outcome of this node. Iron float3 _MetalReflectance_Out = float3(0.560, 0.570, 0.580); Silver float3 _MetalReflectance_Out = float3(0.972, 0.960, 0.915); Aluminium float3 _MetalReflectance_Out = float3(0.913, 0.921, 0.925); Gold float3 _MetalReflectance_Out = float3(1.000, 0.766, 0.336); Copper float3 _MetalReflectance_Out = float3(0.955, 0.637, 0.538); Chromium float3 _MetalReflectance_Out = float3(0.550, 0.556, 0.554); Nickel float3 _MetalReflectance_Out = float3(0.660, 0.609, 0.526); Titanium float3 _MetalReflectance_Out = float3(0.542, 0.497, 0.449); Cobalt float3 _MetalReflectance_Out = float3(0.662, 0.655, 0.634); Platinum float3 _MetalReflectance_Out = float3(0.672, 0.637, 0.585);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Minimum-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Minimum-Node.html",
    "title": "Minimum Node | mmo-rpg-unity",
    "keywords": "Minimum Node Description Returns the smallest of the two inputs values A and B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Minimum_float4(float4 A, float4 B, out float4 Out) { Out = min(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Modulo-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Modulo-Node.html",
    "title": "Modulo Node | mmo-rpg-unity",
    "keywords": "Modulo Node Description Returns the remainder of dividing input A by input B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Modulo_float4(float4 A, float4 B, out float4 Out) { Out = fmod(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Multiply-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Multiply-Node.html",
    "title": "Multiply Node | mmo-rpg-unity",
    "keywords": "Multiply Node Description Returns the result of input A multiplied by input B. If both inputs are a vector type, the output type will be a vector type with the same dimension as the evaluated type of those inputs. If both inputs are a matrix type, the output type will be a matrix type with the same dimension as the evaluated type of those inputs. If one input is a vector type and the other is a matrix type, then output type will be a vector with the same dimension as the vector type input. Ports Name Direction Type Description A Input Dynamic First input value B Input Dynamic Second input value Out Output Dynamic Output value Generated Code Example The following example code represents different possible outcomes of this node. Vector * Vector void Unity_Multiply_float4_float4(float4 A, float4 B, out float4 Out) { Out = A * B; } Vector * Matrix void Unity_Multiply_float4_float4x4(float4 A, float4x4 B, out float4 Out) { Out = mul(A, B); } Matrix * Matrix void Unity_Multiply_float4x4_float4x4(float4x4 A, float4x4 B, out float4x4 Out) { Out = mul(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Nand-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Nand-Node.html",
    "title": "Nand Node | mmo-rpg-unity",
    "keywords": "Nand Node Description Returns true if both the inputs A and B are false. This is useful for Branching. Ports Name Direction Type Binding Description A Input Boolean None First input value B Input Boolean None Second input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Nand_float(float A, float B, out float Out) { Out = !A && !B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Negate-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Negate-Node.html",
    "title": "Negate Node | mmo-rpg-unity",
    "keywords": "Negate Node Description Returns the flipped sign value of input In. Positive values become negative and negative values become positive. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Negate_float4(float4 In, out float4 Out) { Out = -1 * In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Node-Library.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Node-Library.html",
    "title": "Node Library | mmo-rpg-unity",
    "keywords": "Node Library Description The Node Library contains documentation for all the individual Nodes in Shader Graph; including descriptions, ports, parameters, shader code and example images. The Nodes are organised in the same categories as found in the Create Node Menu for convenience. Graph Nodes Artistic Channel Input Math Procedural Utility UV Block Nodes Built In Universal High Definition"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Node.html",
    "title": "Node | mmo-rpg-unity",
    "keywords": "Node Description A Node defines an input, output or operation on the Shader Graph, depending on its available Ports. A Node may have any number of input and/or output ports. You create a Shader Graph by connecting these ports with Edges. A Node might also have any number of Controls, these are controls on the Node that do not have ports. You can collapse a Node by clicking the Collapse button in the top-right corner of the Node. This will hide all unconnected ports. For components of a Node see: Port Edge There are many available Nodes in Shader Graph. For a full list of all available Nodes see the Node Library. Preview Many nodes include a preview. This preview displays the main output value at that stage in the graph. Hide this preview with the Collapse control that displays when you hover over the node. You can also collapse and expand node previews via the Context Menu in the Shader Graph Window. To configure the appearance of node previews, see Preview Mode Control. Context Menu Right clicking on a Node will open a context menu. This menu contains many operations that can be performed on the Node. Note that when multiple nodes are selected, these operations will be applied to the entire selection. Item Description Copy Shader Copies the generated HLSL code at this stage in the graph to the clipboard Disconnect All Removes all edges from all ports on the Node(s) Cut Cuts selected Node(s) to the clipboard Copy Copies selected Nodes(s) to the clipboard Paste Pastes Node(s) in the clipboard Delete Deletes selected Node(s) Duplicate Duplicates selected Node(s) Convert To Sub-graph Creates a new Sub-graph Asset with the selected Node(s) included Convert To Inline Node Converts a Property Node into a regular node of the appropriate Data Type Convert To Property Converts a Node into a new Property on the Blackboard of the appropriate Property Type Open Documentation Opens a new web browser to the selected Nodes documentation page in the Node Library Color Mode Nodes interact with the Shader Graph Window's Color Modes. Colors are displayed on nodes underneath the text on the node title bar. See Color Modes for more information on available colors for nodes."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Noise-Sine-Wave-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Noise-Sine-Wave-Node.html",
    "title": "Noise Sine Wave Node | mmo-rpg-unity",
    "keywords": "Noise Sine Wave Node Description Returns the sine of the value of input In. For variance, psuedo-random noise is added to the amplitude of the sine wave, within a range determined by input Min Max. Ports Name Direction Type Description In Input Dynamic Vector Input value Min Max Input Vector 2 Minimum and Maximum values for noise intensity Out Output Dynamic Vector Output value Generated Code Example void Unity_NoiseSineWave_float4(float4 In, float2 MinMax, out float4 Out) { float sinIn = sin(In); float sinInOffset = sin(In + 1.0); float randomno = frac(sin((sinIn - sinInOffset) * (12.9898 + 78.233))*43758.5453); float noise = lerp(MinMax.x, MinMax.y, randomno); Out = sinIn + noise; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Blend-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Blend-Node.html",
    "title": "Normal Blend Node | mmo-rpg-unity",
    "keywords": "Normal Blend Node Description Blends two normal maps defined by inputs A and B together, normalizing the result to create a valid normal map. Ports Name Direction Type Binding Description A Input Vector 3 None First input value B Input Vector 3 None Second input value Out Output Vector 3 None Output value Controls Name Type Options Description Mode Dropdown Default, Reoriented Selects the the method used for blending. Generated Code Example The following example code represents one possible outcome of this node per Mode. Default void Unity_NormalBlend_float(float3 A, float3 B, out float3 Out) { Out = normalize(float3(A.rg + B.rg, A.b * B.b)); } Reoriented void Unity_NormalBlend_Reoriented_float(float3 A, float3 B, out float3 Out) { float3 t = A.xyz + float3(0.0, 0.0, 1.0); float3 u = B.xyz * float3(-1.0, -1.0, 1.0); Out = (t / t.z) * dot(t, u) - u; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-From-Height-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-From-Height-Node.html",
    "title": "Normal From Height Node | mmo-rpg-unity",
    "keywords": "Normal From Height Node Description Creates a normal map from a height value defined by input Input with a strength defined by input Strength. Ports Name Direction Type Description In Input Float Input height value Strength Input Float The strength of the output normal. Considered in real-world units, recommended range is 0 - 0.1 . Out Output Vector 3 Output value Controls Name Type Options Description Output Space Dropdown Tangent, World Sets the coordinate space of the output normal. Generated Code Example The following example code represents one possible outcome of this node per Output Space mode. Tangent void Unity_NormalFromHeight_Tangent_float(float In, float Strength, float3 Position, float3x3 TangentMatrix, out float3 Out) { float3 worldDerivativeX = ddx(Position); float3 worldDerivativeY = ddy(Position); float3 crossX = cross(TangentMatrix[2].xyz, worldDerivativeX); float3 crossY = cross(worldDerivativeY, TangentMatrix[2].xyz); float d = dot(worldDerivativeX, crossY); float sgn = d < 0.0 ? (-1.0f) : 1.0f; float surface = sgn / max(0.000000000000001192093f, abs(d)); float dHdx = ddx(In); float dHdy = ddy(In); float3 surfGrad = surface * (dHdx*crossY + dHdy*crossX); Out = normalize(TangentMatrix[2].xyz - (Strength * surfGrad)); Out = TransformWorldToTangent(Out, TangentMatrix); } World void Unity_NormalFromHeight_World_float(float In, float Strength, float3 Position, float3x3 TangentMatrix, out float3 Out) { float3 worldDerivativeX = ddx(Position); float3 worldDerivativeY = ddy(Position); float3 crossX = cross(TangentMatrix[2].xyz, worldDerivativeX); float3 crossY = cross(worldDerivativeY, TangentMatrix[2].xyz); float d = dot(worldDerivativeX, crossY); float sgn = d < 0.0 ? (-1.0f) : 1.0f; float surface = sgn / max(0.000000000000001192093f, abs(d)); float dHdx = ddx(In); float dHdy = ddy(In); float3 surfGrad = surface * (dHdx*crossY + dHdy*crossX); Out = normalize(TangentMatrix[2].xyz - (Strength * surfGrad)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-From-Texture-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-From-Texture-Node.html",
    "title": "Normal From Texture Node | mmo-rpg-unity",
    "keywords": "Normal From Texture Node Description Converts a height map defined by input Texture into a normal map. UV values and sampler state can be defined by inputs UV and Sampler respectively. If nothing is connected to these ports they will use default values from the inputs. See Port Bindings for more information. The strength of the created normal map can be defined by inputs Offset and Strength, where Offset defines the maximum distance of a normal detail and Strength acts as a multiplier to the result. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Binding Description Texture Input Texture None Height map UV Input Vector 2 UV Texture coordinates Sampler Input Sampler State None Sampler for Texture Offset Input Float None Amount to offset samples Strength Input Float None Strength multiplier Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_NormalFromTexture_float(Texture texture, SamplerState Sampler, float2 UV, float Offset, float Strength, out float3 Out) { Offset = pow(Offset, 3) * 0.1; float2 offsetU = float2(UV.x + Offset, UV.y); float2 offsetV = float2(UV.x, UV.y + Offset); float normalSample = Texture.Sample(Sampler, UV); float uSample = Texture.Sample(Sampler, offsetU); float vSample = Texture.Sample(Sampler, offsetV); float3 va = float3(1, 0, (uSample - normalSample) * Strength); float3 vb = float3(0, 1, (vSample - normalSample) * Strength); Out = normalize(cross(va, vb)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Reconstruct-Z-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Reconstruct-Z-Node.html",
    "title": "Normal Reconstruct Z Node | mmo-rpg-unity",
    "keywords": "Normal Reconstruct Z Node Description Derives the correct Z value for generated normal maps using a given X and Y value from input In. Ports Name Direction Type Description In Input Vector 2 Normal X and Y value Out Output Vector 3 Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_NormalReconstructZ_float(float2 In, out float3 Out) { float reconstructZ = sqrt(1.0 - saturate(dot(In.xy, In.xy))); float3 normalVector = float3(In.x, In.y, reconstructZ); Out = normalize(normalVector); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Strength-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Strength-Node.html",
    "title": "Normal Strength Node | mmo-rpg-unity",
    "keywords": "Normal Strength Node Description Adjusts the strength of the normal map defined by input In by the amount of input Strength. A Strength value of 1 will return the input unaltered. A Strength value of 0 will return a blank normal map. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Strength Input Float None Strength value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_NormalStrength_float(float3 In, float Strength, out float3 Out) { Out = {precision}3(In.rg * Strength, lerp(1, In.b, saturate(Strength))); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Unpack-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Unpack-Node.html",
    "title": "Normal Unpack Node | mmo-rpg-unity",
    "keywords": "Normal Unpack Node Description Unpacks a normal map defined by input In. This node is used to unpack a texture that is defined as a Normal Map in its Texture Import Settings when it is sampled as if it were a default texture. Note that in most cases this node is unnecessary as the normal map should be sampled as such by setting its Type parameter to Normal when it is sampled using a Sample Texture 2D or Triplanar node. Ports Name Direction Type Binding Description In Input Vector 4 None Input value Out Output Vector 3 None Output value Controls Name Type Options Description Space Dropdown Tangent, Object Sets the coordinate space of the input normal. Generated Code Example The following example code represents one possible outcome of this node per Space mode. Tangent void Unity_NormalUnpack_float(float4 In, out float3 Out) { Out = UnpackNormalmapRGorAG(In); } Object void Unity_NormalUnpackRGB_float(float4 In, out float3 Out) { Out = UnpackNormalmapRGB(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Vector-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normal-Vector-Node.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Description Provides access to the mesh vertex or fragment's Normal Vector. The coordinate space of the output value can be selected with the Space dropdown parameter. Ports Name Direction Type Binding Description Out Output Vector 3 None Mesh's Normal Vector. Parameters Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of Normal Vector to output."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normalize-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Normalize-Node.html",
    "title": "Normalize Node | mmo-rpg-unity",
    "keywords": "Normalize Node Description Returns the normalized value of input In. The output vector will have the same direction as input In but a length of 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Normalize_float4(float4 In, out float4 Out) { Out = normalize(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Not-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Not-Node.html",
    "title": "Not Node | mmo-rpg-unity",
    "keywords": "Not Node Description Returns the opposite of input In. If In is true the output will be false, otherwise it will be true. This is useful for Branching. Ports Name Direction Type Binding Description In Input Boolean None Input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_NormalUnpack_float(float In, out float Out) { Out = !In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Object-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Object-Node.html",
    "title": "Object Node | mmo-rpg-unity",
    "keywords": "Object Node Description Provides access to various parameters of the currently rendering Object. Note: The behaviour of the Position Port can be defined per Render Pipeline. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. Unity Render Pipelines Support Universal Render Pipeline High Definition Render Pipeline Ports Name Direction Type Binding Description Position Output Vector 3 None Object position in world space Scale Output Vector 3 None Object scale in world space World Bounds Min Output Vector 3 None Minimum value of the renderer bounds in world space World Bounds Max Output Vector 3 None Maximum value of the renderer bounds in world space Bounds Size Output Vector 3 None Size of the renderer bounds Note: the bounds values are the equivalent of the bounds in the renderer component. This means that vertex deformation done in ShaderGraph doesn't affect these values. Generated Code Example The following example code represents one possible outcome of this node. float3 _Object_Position = SHADERGRAPH_OBJECT_POSITION; float3 _Object_Scale = float3(length(float3(UNITY_MATRIX_M[0].x, UNITY_MATRIX_M[1].x, UNITY_MATRIX_M[2].x)), length(float3(UNITY_MATRIX_M[0].y, UNITY_MATRIX_M[1].y, UNITY_MATRIX_M[2].y)), length(float3(UNITY_MATRIX_M[0].z, UNITY_MATRIX_M[1].z, UNITY_MATRIX_M[2].z))); float3 _Object_WorldBoundsMin = SHADERGRAPH_RENDERER_BOUNDS_MIN; float3 _Object_WorldBoundsMax = SHADERGRAPH_RENDERER_BOUNDS_MAX; float3 _Object_BoundsSize = (SHADERGRAPH_RENDERER_BOUNDS_MAX - SHADERGRAPH_RENDERER_BOUNDS_MIN);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/One-Minus-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/One-Minus-Node.html",
    "title": "One Minus Node | mmo-rpg-unity",
    "keywords": "One Minus Node Description Returns the result of input In subtracted from 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_OneMinus_float4(float4 In, out float4 Out) { Out = 1 - In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Or-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Or-Node.html",
    "title": "Or Node | mmo-rpg-unity",
    "keywords": "Or Node Description Returns true if either of the inputs A and B are true. This is useful for Branching. Ports Name Direction Type Binding Description A Input Boolean None First input value B Input Boolean None Second input value Out Output Boolean None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Or_float(float In, out float Out) { Out = A || B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Pack-Vertex-Data-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Pack-Vertex-Data-Water-Node.html",
    "title": "Pack Water Vertex Data | mmo-rpg-unity",
    "keywords": "Pack Water Vertex Data This node packs multiple water properties into two UV properties for the vertex context. The High Definition Render Pipeline (HDRP) uses this node in the default water shader graph. Don't modify the settings of this node. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Pack Water Vertex Data No Yes Ports Name Direction Type Description PositionWS Input Vector3 The position of the water surface vertex in world space. Displacement Input Vector3 The vertical and horizontal displacement of the water. LowFrequencyHeight Input Float The vertical displacement of the water surface. This doesn't include ripples. SSSMask Input Float Mask that defines where the water surface has subsurface scattering. PositionOS Output Vector3 The position of the water surface vertex in object space. NormalOS Output Vector3 The water surface normal in object space. uv0 Output Vector4 The inputs packed into a UV coordinate set for the vertex context. uv1 Output Vector4 The inputs packed into a UV coordinate set for the vertex context."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Parallax-Mapping-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Parallax-Mapping-Node.html",
    "title": "Parallax Mapping Node | mmo-rpg-unity",
    "keywords": "Parallax Mapping Node Description The Parallax Mapping node lets you create a parallax effect that displaces a Material's UVs to create the illusion of depth inside a Material. This implementation uses the single step process that does not account for occlusion. For information on how the effect looks, see the Height Map page. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Description Heightmap Input Texture2D The Texture that specifies the depth of the displacement. Heightmap Sampler Input Sampler State The Sampler to sample Heightmap with. Amplitude Input Float A multiplier to apply to the height of the Heightmap (in centimeters). UVs Input Vector2 The UVs that the sampler uses to sample the Texture. Parallax UVs Output Vector2 The UVs after adding the parallax offset. Generated Code Example The following example code represents one possible outcome of this node. float2 _ParallaxMapping_ParallaxUVs = UVs.xy + ParallaxMapping(Heightmap, Heightmap_Sampler, IN.TangentSpaceViewDirection, Amplitude * 0.01, UVs.xy);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Parallax-Occlusion-Mapping-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Parallax-Occlusion-Mapping-Node.html",
    "title": "Parallax Occlusion Mapping Node | mmo-rpg-unity",
    "keywords": "Parallax Occlusion Mapping Node Description You can use the Parallax Occlusion Mapping (POM) node to create a parallax effect that displaces a material's UVs and depth to create the illusion of depth inside that material. If you receive a texture sampling error while using this node in a graph that includes Custom Function nodes or Subgraphs, try upgrading to Shader Graph version 10.3 or later. This may resolve the errors. When you assign the same Texture2D to a POM node and a Sample Texture 2D node, you need to avoid transforming the UV coordinates twice. To prevent this, connect the Split Texture Transform node’s Texture Only port to the Sample Texture 2D Node’s UV port. Ports Name Direction Type Description Heightmap Input Texture2D The Texture that specifies the depth of the displacement. Heightmap Sampler Input Sampler State The Sampler to sample Heightmap with. Amplitude Input Float A multiplier to apply to the height of the Heightmap (in centimeters). Steps Input Float The number of steps that the linear search of the algorithm performs. UVs Input Vector2 The UVs that the sampler uses to sample the Texture. Tiling Input Vector2 The tiling to apply to the input UVs. Offset Input Vector2 The offset to apply to the input UVs. Primitive Size Input Vector2 Size of the UV space in object space. For example, a Unity built-in Plane mesh has a primitive size of (10,10). LOD Input Float The level of detail to use to sample the Heightmap. This value should always be positive. LOD Threshold Input Float The Heightmap mip level where the Parallax Occlusion Mapping effect begins to fade out. This is equivalent to the Fading Mip Level Start property in the High Definition Render Pipeline's (HDRP) Lit Material. Pixel Depth Offset Output Float The offset to apply to the depth buffer to produce the illusion of depth. Connect this output to the Depth Offset on the Master Node to enable effects that rely on the depth buffer, such as shadows and screen space ambient occlusion. Parallax UVs Output Vector2 UVs that you have added the parallax offset to. Generated Code Example The following example code represents one possible outcome of this node. float3 ParallaxOcclusionMapping_ViewDir = IN.TangentSpaceViewDirection * GetDisplacementObjectScale().xzy; float ParallaxOcclusionMapping_NdotV = ParallaxOcclusionMapping_ViewDir.z; float ParallaxOcclusionMapping_MaxHeight = Amplitude * 0.01; ParallaxOcclusionMapping_MaxHeight *= 2.0 / ( abs(Tiling.x) + abs(Tiling.y) ); float2 ParallaxOcclusionMapping_UVSpaceScale = ParallaxOcclusionMapping_MaxHeight * Tiling / PrimitiveSize; // Transform the view vector into the UV space. float3 ParallaxOcclusionMapping_ViewDirUV = normalize(float3(ParallaxOcclusionMapping_ViewDir.xy * ParallaxOcclusionMapping_UVSpaceScale, ParallaxOcclusionMapping_ViewDir.z)); // TODO: skip normalize PerPixelHeightDisplacementParam ParallaxOcclusionMapping_POM; ParallaxOcclusionMapping_POM.uv = UVs.xy; float ParallaxOcclusionMapping_OutHeight; float2 _ParallaxOcclusionMapping_ParallaxUVs = UVs.xy + ParallaxOcclusionMapping(Lod, Lod_Threshold, Steps, ParallaxOcclusionMapping_ViewDirUV, ParallaxOcclusionMapping_POM, ParallaxOcclusionMapping_OutHeight); float _ParallaxOcclusionMapping_PixelDepthOffset = (ParallaxOcclusionMapping_MaxHeight - ParallaxOcclusionMapping_OutHeight * ParallaxOcclusionMapping_MaxHeight) / max(ParallaxOcclusionMapping_NdotV, 0.0001);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Polar-Coordinates-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Polar-Coordinates-Node.html",
    "title": "Polar Coordinates Node | mmo-rpg-unity",
    "keywords": "Polar Coordinates Node Description Converts the value of input UV to polar coordinates. In mathematics, the polar coordinate system is a two-dimensional coordinate system in which each point on a plane is determined by a distance from a reference point and an angle from a reference direction. The resulting effect is that the x channel of the input to UV is converted to a distance value from the point specified by the value of input Center and the y channel of same input is converted to the value of an angle of rotation around that point. These values can be scaled by the values of inputs Radial Scale and Length Scale respectively. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center reference point Radial Scale Input Float None Scale of distance value Length Scale Input Float None Scale of angle value Out Output Vector 2 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_PolarCoordinates_float(float2 UV, float2 Center, float RadialScale, float LengthScale, out float2 Out) { float2 delta = UV - Center; float radius = length(delta) * 2 * RadialScale; float angle = atan2(delta.x, delta.y) * 1.0/6.28 * LengthScale; Out = float2(radius, angle); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Polygon-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Polygon-Node.html",
    "title": "Polygon Node | mmo-rpg-unity",
    "keywords": "Polygon Node Description Generates a regular polygon shape based on input UV at the size specified by inputs Width and Height. The polygon's amount of sides is determined by input Sides. The generated shape can be offset or tiled by connecting a Tiling And Offset Node. Note that in order to preserve the ability to offset the shape within the UV space the shape will not automatically repeat if tiled. To achieve a repeating polygon effect first connect your input through a Fraction Node. NOTE: This Node can only be used in the Fragment shader stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Sides Input Float None Amount of sides Width Input Float None Polygon width Height Input Float None Polygon height Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Polygon_float(float2 UV, float Sides, float Width, float Height, out float Out) { float pi = 3.14159265359; float aWidth = Width * cos(pi / Sides); float aHeight = Height * cos(pi / Sides); float2 uv = (UV * 2 - 1) / float2(aWidth, aHeight); uv.y *= -1; float pCoord = atan2(uv.x, uv.y); float r = 2 * pi / Sides; float distance = cos(floor(0.5 + pCoord / r) * r - pCoord) * length(uv); Out = saturate((1 - distance) / fwidth(distance)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Port-Bindings.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Port-Bindings.html",
    "title": "Port Bindings | mmo-rpg-unity",
    "keywords": "Port Bindings Description Some input Ports might have Port Bindings. This means there is an expectation of the data that should be supplied to the Port, such as a Normal Vector or UV. However, a Port Binding only affects a Port that does not have a connected Edge. These Ports still have a regular Data Type that define what Edges can be connected to them. In practice this means that if no Edge is connected to the Port the default data used in that port will be taken from its Port Binding. A full list of Port Bindings and their associated default options is found below. Port Bindings List Name Data Type Options Description Bitangent Vector 3 Vertex or fragment bitangent, label describes expected transform space Color Vector 4 RGBA Color picker ColorRGB Vector 3 RGB Color picker Normal Vector 3 Vertex or fragment normal vector, label describes expected transform space Position Vector 3 Vertex or fragment position, label describes expected transform space Screen Position Vector 4 Default, Raw, Center, Tiled Vertex or fragment position in screen space. Dropdown selects mode. See Screen Position Node for details Tangent Vector 3 Vertex or fragment tangent vector, label describes expected transform space UV Vector 2 UV0, UV1, UV2, UV3 Mesh UV coordinates. Dropdown selects UV channel. Vertex Color Vector 4 RGBA vertex color value. View Direction Vector 3 Vertex or fragment view direction vector, label describes expected transform space"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Port.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Port.html",
    "title": "Port | mmo-rpg-unity",
    "keywords": "Port Description A Port defines an input or output on a Node. Connecting Edges to a Port allows data to flow through the Shader Graph node network. Each Port has a Data Type which defines what edges can be connected to it. Each data type has an associated color for identifying its type. Only one edge can be connected to any input Port but multiple edges can be connected to an output Port. You can open a contextual Create Node Menu by dragging an edge from a Port with left mouse button and releasing it in an empty area of the workspace. Default Inputs Each Input Port, a Port on the left side of a node implying that it is for inputting data into the node, has a Default Input. This appears as a small field connected to the Port when there is no edge connected. This field will display an input for the ports data type unless the Port has a Port Binding. If a Port does have a port binding the default input field might display a special field, such as a dropdown for selecting UV channels, or just a label to help you understand the intended input, such as coordinate space labels for geometry data."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Position-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Position-Node.html",
    "title": "Position Node | mmo-rpg-unity",
    "keywords": "Position Node Description Provides access to the mesh vertex's or fragment's Position, depending on the effective Shader Stage of the graph section that the Node is part of. Use the Space drop-down parameter to select the coordinate space of the output value. Ports Name Direction Type Binding Description Out Output Vector 3 None Position for the Mesh Vertex/Fragment. Controls Name Type Options Description Space Dropdown Object, View, World, Tangent, Absolute World Selects the coordinate space of Position to output. World and Absolute World The Position Node provides drop-down options for both World and Absolute World space positions. The Absolute World option always returns the absolute world position of the object in the Scene for all Scriptable Render Pipelines. The World option returns the default world space of the selected Scriptable Render Pipeline. The High Definition Render Pipeline uses Camera Relative as its default world space. The Universal Render Pipeline uses Absolute World as its default world space. Upgrading from previous versions If you use a Position Node in World space on a graph authored in Shader Graph version 6.7.0 or earlier, it automatically upgrades the selection to Absolute World. This ensures that the calculations on your graph remain accurate to your expectations, since the World output might change. If you use a Position Node in World space in the High Definition Render Pipeline to manually calculate Camera Relative world space, you can now change your node from Absolute World to World, which lets you use Camera Relative world space out of the box."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Posterize-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Posterize-Node.html",
    "title": "Posterize Node | mmo-rpg-unity",
    "keywords": "Posterize Node Description Posterization or posterisation of an image entails conversion of a continuous gradation of tone to several regions of fewer tones, with abrupt changes from one tone to another. https://en.wikipedia.org/wiki/Posterization This node returns the posterized (also known as quantized) value of the input In into an amount of values specified by input Steps. Ports Name Direction Type Description In Input Dynamic Vector Input value Steps Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Posterize_float4(float4 In, float4 Steps, out float4 Out) { Out = floor(In / (1 / Steps)) * (1 / Steps); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Power-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Power-Node.html",
    "title": "Power Node | mmo-rpg-unity",
    "keywords": "Power Node Description Returns the result of input A to the power of input B. Note: If the input A is negative, the output might be inconsistent or NaN. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Power_float4(float4 A, float4 B, out float4 Out) { Out = pow(A, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Precision-Modes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Precision-Modes.html",
    "title": "Precision Modes | mmo-rpg-unity",
    "keywords": "Precision Modes Description Shader Graph provides specific data precision modes for nodes, graphs, and Sub Graphs to help you optimize your content for different platforms. To set the precision of an entire graph, select the Graph Settings tab in the Graph Inspector and adjust the Precision control. Select a node in your graph and select the Node Settings tab in the Graph Inspector to adjust the precision of individual nodes. Precision mode settings Name Description Single This is a high-precision floating point value. The number of bits is platform-specific. For modern desktop computers, it is 32 bits. This mode is useful for world space positions, texture coordinates, and scalar computations that involve complex functions such as trigonometry, power, and exponentiation. Half This is a low-precision floating point value. The number of bits is platform-specific. For modern desktop computers, it is 16 bits. This mode is useful for short vectors, directions, object space positions, and many high dynamic range colors, but not very strong light sources, such as the sun. Switchable This mode is only for Sub Graphs. When you enable this mode for a Sub Graph, the default precision of the Sub Graph is decided by its Sub Graph node. See Use Graph Precision below. Inherit This mode determines a node's precision based on a set of inheritance rules. See Precision inheritance. Use Graph Precision This mode forces this node to use the same precision setting as the graph. If this is a node in a Sub Graph, and that Sub Graph’s Precision is set to Switchable, then the precision of this node is the precision of the Sub Graph node representing this Sub Graph. Using Precision Modes Visualizing Precision in a graph To visualize data precision in a graph, set the Color Mode control to Precision. This applies color coding to your nodes: Single nodes are blue Half nodes are red Switchable nodes are Green. Setting graph Precision To set the default precision for the entire graph to Single or Half, open the Graph Settings and set the Precision property. Newly-created nodes in a graph default to the Inherit precision mode, and inherit the graph's precision. Setting node Precision Select a node to access its precision setting. The precision you set for a node determines the precision of the data types which that node uses for its calculations. Precision Inheritance All nodes use the Inherit precision mode by default. In this mode, a node that has one or more edge connections takes on the precision mode of an incoming edge. Nodes that do not have any edge connections take on Graph Precision. If you change the Graph Precision mode, the precision of those nodes also changes. Inputs on the node Final precision determined by inheritance No inputs Graph Precision Only Half inputs Half Only Single inputs Single Half and Single inputs Single Only Switchable inputs Switchable Switchable and Half inputs Switchable Switchable and Single inputs Single Switchable, Half and Single inputs Single Simple inheritance Simple inheritance refers to the inheritance behaviour of a node with only one precision type on its inputs. In the figure below, Node A has the Inherit mode. Because it has no incoming edge, it takes the Graph Precision, which is Half. Node B also has the Inherit mode, so it inherits the Half precision mode from Node A. Complex inheritance Complex inheritance refers to the inheritance behaviour of a node with multiple precision types on its inputs. A node reads precision settings from each input port. If you connect a node to several others with a variety of precision modes, the node with the highest resolution determines the precision mode for the group. In the figure below, node D has the Inherit mode. It receives input from the adjacent edges via inputs 1 and 2. Node B passes the Half mode through input 1. Node C passes the Single mode through input 2. Because Single is 32-bit and Half only 16-bit, Single takes precedence, so Node D uses Single precision. Mixed inheritance Mixed inheritance refers to the inheritance behaviour on a node with both simple and complex inheritance types. Nodes with no input ports, such as Input nodes, inherit the Graph Precision. However, complex inheritance rules still affect other nodes in the same group, as illustrated in the figure below. Switchable precision The Switchable mode overrides Half mode but not Single. Sub Graph precision Precision behavior and user interface elements for Sub Graphs and their nodes do not differ from other graphs and nodes. Sub Graphs represent a function, and you can affect that function's inputs, outputs, and operators by modifying the relevant set of precision settings. The Sub Graph properties correspond to the function's inputs. The internal node properties correspond to the function's operators. The output node corresponds to the function's outputs. Outputs To manually determine the precision of a Sub Graph's output, modify the Output node’s Precision Mode setting. Inputs To manually determine the precision of Sub Graph Inputs, open the Graph Inspector and set precision modes for each individual Property. Properties that use the Inherit option take on the Graph Precision you set for the Sub Graph. Sub Graph Precision within other graphs By default, a Sub Graph has a Precision Mode of Switchable. You can modify Precision Mode of any Sub Graph node for that Sub Graph, as long as you set the Precision Mode on the Sub Graph as Switchable. Shader Graph won't allow you to change the Precision Mode for any Sub Graph node that doesn't have its Sub Graph set to Switchable. This is because the input and output precision you set in a Sub Graph define the precision of its associated Sub Graph Node. For example, let's say that Sub Graph A is Switchable. You open Graph 1, which includes a Sub Graph Node referencing Sub Graph A. Like all other nodes, Sub Graph Node A defaults to Inherit. You change the precision of Sub Graph Node A to Half. The precision of Sub Graph A also becomes Half."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Preview-Mode-Control.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Preview-Mode-Control.html",
    "title": "Preview mode control | mmo-rpg-unity",
    "keywords": "Preview mode control Description This control enables you to manually select your preferred preview mode for a node that has a preview. When you select Inherit in the Preview Mode Control, the Editor automatically selects the preview mode to use. That decision is determined by either the type of the node you are previewing, the Sub Graph setting (if this node is in a Sub Graph) or other upstream nodes. To override the inheritance mode, select Preview 2D or Preview 3D. This mode control functionality also applies to Sub Graph previews. See Graph Settings menu. How to use For nodes: Add a node which includes a preview. Select the node. In the Graph Inspector or Node Settings, find the Preview control. Select an option. For SubGraphs: Select a mode in the Sub Graph Graph Settings menu. Related Preview node"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Preview-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Preview-Node.html",
    "title": "Preview Node | mmo-rpg-unity",
    "keywords": "Preview Node Description This node enables you to inspect a preview at a specific point in a Shader Graph. It does not modify any input values. By default, the Editor automatically selects a preview mode. That decision is determined by both the type of the node you are previewing and other upstream nodes. With Preview Mode Control, you can manually select your preferred preview mode. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Preview_float4(float4 In, out float4 Out) { Out = In; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Procedural-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Procedural-Nodes.html",
    "title": "Procedural Nodes | mmo-rpg-unity",
    "keywords": "Procedural Nodes Checkerboard Generates a checkerboard of alternating colors between inputs Color A and Color B based on input UV. Noise Gradient Noise Simple Noise Generates a gradient, or Perlin, noise based on input UV. Generates a simple, or Value, noise based on input UV. Voronoi Generates a Voronoi, or Worley, noise based on input UV. Shape Ellipse Polygon Generates an ellipse shape based on input UV at the size specified by inputs Width and Height. Generates a regular polygon shape based on input UV at the size specified by inputs Width and Height. The polygon's amount of sides is determined by input Sides. Rectangle Rounded Rectangle Generates a rectangle shape based on input UV at the size specified by inputs Width and Height. Generates a rounded rectangle shape based on input UV at the size specified by inputs Width and Height. The input Radius defines the radius of each corner. Rounded Polygon Generates a rounded polygon shape based on input UV at the size specified by inputs Width and Height. The input Sides specifies the number of sides, and the input Roundness defines the roundness of each corner."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Projection-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Projection-Node.html",
    "title": "Projection Node | mmo-rpg-unity",
    "keywords": "Projection Node Description Returns the result of projecting the value of input A onto a straight line parallel to the value of input B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Projection_float4(float4 A, float4 B, out float4 Out) { Out = B * dot(A, B) / dot(B, B); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Property-Types.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Property-Types.html",
    "title": "Property Types | mmo-rpg-unity",
    "keywords": "Property Types Description Property Types are the types of Property than can be defined on the Blackboard for use in the Graph. These Properties are exposed to the Inspector for Materials that use the shader. Each property has an associated Data Type. See Data Types for more information. Common Parameters In addition to values specific to their Data Types, most properties have the following common parameters. Name Type Description Display Name String The display name of the property Exposed Boolean If true this property will be exposed on the material inspector Reference Name String The internal name used for the property inside the shader Override Property Declaration Boolean An advanced option to enable explicit control of the shader declaration for this property Shader Declaration Enumeration Controls the shader declaration of this property NOTE: If you overwrite the Reference Name parameter be aware of the following conditions: If your Reference Name does not begin with an underscore, one will be automatically appended. If your Reference Name contains any characters which are unsupported in HLSL they will be removed. You can revert to the default Reference Name by right clicking on it and selecting Reset Reference. Float Defines a Float value. Data Type Modes Float Default, Slider, Integer Default Displays a scalar input field in the material inspector. Field Type Description Default Float The default value of the Property. Slider Displays a slider field in the material inspector. Field Type Description Default Float The default value of the Property. Min Float The minimum value of the slider. Max Float The maximum value of the slider. Integer Displays an integer input field in the material inspector. Field Type Description Default Integer The default value of the Property. Vector 2 Defines a Vector 2 value. Displays a Vector 4 input field in the material inspector, where the z and w components are not used. Data Type Modes Vector 2 Field Type Description Default Vector 2 The default value of the Property. Vector 3 Defines a Vector 3 value. Displays a Vector 4 input field in the material inspector, where the w component is not used. Data Type Modes Vector 3 Field Type Description Default Vector 3 The default value of the Property. Vector 4 Defines a Vector 4 value. Displays a Vector 4 input field in the material inspector. Data Type Modes Vector 4 Field Type Description Default Vector 4 The default value of the Property. Color Defines a Color value. If the Property Inspector displays Main Color, this is the Main Color for the shader. To select or deselect this node as the Main Color, right-click it in the graph or Blackboard and select Set as Main Color or Clear Main Color. Corresponds to the MainColor ShaderLab Properties attribute. Data Type Modes Color Default, HDR Default Displays an sRGB color field in the material inspector. Field Type Description Default Vector 4 The default value of the Property. HDR Displays an HDR color field in the material inspector. Field Type Description Default Vector 4 The default value of the Property. NOTE: In versions prior to 10.0, Shader Graph didn't correct HDR colors for the project colorspace. Version 10.0 corrected this behavior. HDR color properties that you created with older versions maintain the old behavior, but you can use the Graph Inspector to upgrade them. To mimic the old behavior in a gamma space project, you can use the Colorspace Conversion Node to convert a new HDR Color property from RGB to Linear space. Texture 2D Defines a Texture 2D value. Displays an object field of type Texture in the material inspector. If the Property Inspector displays Main Texture, this is the Main Texture for the shader. To select or deselect this node as the Main Texture, right-click on it in the graph or Blackboard and select Set as Main Texture or Clear Main Texture. Corresponds to the MainTexture ShaderLab Properties attribute. Data Type Modes Texture White, Black, Grey, Bump Field Type Description Default Texture The default value of the Property. Use Tiling and Offset Boolean When set to false, activates the property NoScaleOffset, to enable manipulation of scale and offset separately from other texture properties. See SplitTextureTransformNode. Texture 3D Defines a Texture 3D value. Displays an object field of type Texture 3D in the material inspector. Data Type Modes Texture Field Type Description Default Texture The default value of the Property. Texture 2D Array Defines a Texture 2D Array value. Displays an object field of type Texture 2D Array in the material inspector. Data Type Modes Texture Field Type Description Default Texture The default value of the Property. Cubemap Defines a Cubemap value. Displays an object field of type Texture in the material inspector. Data Type Modes Cubemap Field Type Description Default Cubemap The default value of the Property. Virtual Texture Defines a Texture Stack, which appears as object fields of type Texture in the Material Inspector. The number of fields correspond to the number of layers in the property. Data Type Modes Virtual Texture Field Type Description Default Texture The default value of the Property. Boolean Defines a Boolean value. Displays a ToggleUI field in the material inspector. Note that internally to the shader this value is a Float. The Boolean type in Shader Graph is merely for usability. Data Type Modes Boolean Field Type Description Default Boolean The default value of the Property."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Radial-Shear-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Radial-Shear-Node.html",
    "title": "Radial Shear Node | mmo-rpg-unity",
    "keywords": "Radial Shear Node Description Applies a radial shear warping effect similar to a wave to the value of input UV. The center reference point of the warping effect is defined by input Center and the overall strength of the effect is defined by the value of input Strength. Input Offset can be used to offset the individual channels of the result. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center reference point Strength Input Float None Strength of the effect Offset Input Vector 2 None Individual channel offsets Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_RadialShear_float(float2 UV, float2 Center, float Strength, float2 Offset, out float2 Out) { float2 delta = UV - Center; float delta2 = dot(delta.xy, delta.xy); float2 delta_offset = delta2 * Strength; Out = UV + float2(delta.y, -delta.x) * delta_offset + Offset; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Radians-To-Degrees-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Radians-To-Degrees-Node.html",
    "title": "Radians To Degrees Node | mmo-rpg-unity",
    "keywords": "Radians To Degrees Node Description Returns the value of input In converted from radians to degrees. One radian is equivalent to approximately 57.2958 degrees and a full rotation of 2 Pi radians is equal to 360 degrees. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_RadiansToDegrees_float4(float4 In, out float4 Out) { Out = degrees(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Random-Range-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Random-Range-Node.html",
    "title": "Random Range Node | mmo-rpg-unity",
    "keywords": "Random Range Node Description Returns a pseudo-random number value based on input Seed that is between the minimum and maximum values defined by inputs Min and Max respectively. Whilst the same value in input Seed will always result in the same output value, the output value itself will appear random. Input Seed is a Vector 2 value for the convenience of generating a random number based on a UV input, however for most cases a Float input will suffice. Ports Name Direction Type Description Seed Input Vector 2 Seed value used for generation Min Input Float Minimum value Max Input Float Maximum value Out Output Float Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_RandomRange_float(float2 Seed, float Min, float Max, out float Out) { float randomno = frac(sin(dot(Seed, float2(12.9898, 78.233)))*43758.5453); Out = lerp(Min, Max, randomno); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Reciprocal-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Reciprocal-Node.html",
    "title": "Reciprocal Node | mmo-rpg-unity",
    "keywords": "Reciprocal Node Description Returns the result of dividing 1 by the input In. This can be calculated by a fast approximation on Shader Model 5 by setting Method to Fast. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Controls Name Type Options Description Method Dropdown Default, Fast Selects the method used Generated Code Example The following example code represents one possible outcome of this node per Method mode. Default void Unity_Reciprocal_float4(float4 In, out float4 Out) { Out = 1.0/In; } Fast (Requires Shader Model 5) void Unity_Reciprocal_Fast_float4(float4 In, out float4 Out) { Out = rcp(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Reciprocal-Square-Root-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Reciprocal-Square-Root-Node.html",
    "title": "Reciprocal Square Root Node | mmo-rpg-unity",
    "keywords": "Reciprocal Square Root Node Description Returns the result of 1 divided by the square root of the input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_ReciprocalSquareRoot_float4(float4 In, out float4 Out) { Out = rsqrt(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rectangle-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rectangle-Node.html",
    "title": "Rectangle Node | mmo-rpg-unity",
    "keywords": "Rectangle Node Description Generates a rectangle shape based on input UV at the size specified by inputs Width and Height. The generated shape can be offset or tiled by connecting a Tiling And Offset Node. Note that in order to preserve the ability to offset the shape within the UV space the shape will not automatically repeat if tiled. To achieve a repeating rectangle effect first connect your input through a Fraction Node. NOTE: This Node can only be used in the Fragment Shader Stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Rectangle width Height Input Float None Rectangle height Out Output Float None Output value Controls Name Type Options Description Dropdown Fastest, Nicest Robustness of computation Generated Code Example The following example code represents one possible outcome of this node. void Unity_Rectangle_float(float2 UV, float Width, float Height, out float Out) { float2 d = abs(UV * 2 - 1) - float2(Width, Height); d = 1 - d / fwidth(d); Out = saturate(min(d.x, d.y)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Reflection-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Reflection-Node.html",
    "title": "Reflection Node | mmo-rpg-unity",
    "keywords": "Reflection Node Description Returns a reflection vector using input In and a surface normal Normal. Ports Name Direction Type Description In Input Dynamic Vector Incident vector value Normal Input Dynamic Vector Normal vector value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Reflection_float4(float4 In, float4 Normal, out float4 Out) { Out = reflect(In, Normal); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Reflection-Probe-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Reflection-Probe-Node.html",
    "title": "Reflection Probe Node | mmo-rpg-unity",
    "keywords": "Reflection Probe Node Description Provides access to the nearest Reflection Probe to the object. Requires Normal and View Direction to sample the probe. You can achieve a blurring effect by sampling at a different Level of Detail using the LOD input. Note: The behavior of this Node is undefined globally. Shader Graph does not define the function of the node. Instead, each Render Pipeline defines what HLSL code to execute for this Node. Different Render Pipelines may produce different results. If you're building a shader in one Render Pipeline that you want to use in both, try checking it in both pipelines before production. A Node might be defined in one Render Pipeline and undefined in the other. If this Node is undefined, it returns 0 (black). Unity Render Pipelines Support Universal Render Pipeline The High Definition Render Pipeline does not support this Node. Ports Name Direction Type Binding Description View Dir Input Vector 3 View Direction (object space) Mesh's view direction Normal Input Vector 3 Normal (object space) Mesh's normal vector LOD Input Float None Level of detail for sampling Out Output Vector 3 None Output color value Generated Code Example The following example code represents one possible outcome of this node. void Unity_ReflectionProbe_float(float3 ViewDir, float3 Normal, float LOD, out float3 Out) { Out = SHADERGRAPH_REFLECTION_PROBE(ViewDir, Normal, LOD); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Refract-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Refract-Node.html",
    "title": "Refract Node | mmo-rpg-unity",
    "keywords": "Refract Node Description You can use the Refract node to give a shader a refraction effect. The Refract node generates a refraction using the following to produce a new refracted vector: A normalized incident vector. A normalized normal vector of the surface. The refractive index of the source and the medium. The Refract node uses the principles described in Snell's Law. A medium's refractive index has an angle where the surface behaves like a perfect mirror. This angle is called total internal reflection. To avoid a NaN result, set the Refract node's Mode to Safe. This makes the Refract node generate a null vector when it reaches the critical angle before total internal reflection. Ports Name Direction Type Binding Description Incident Input Vector None The normalized vector from the light source to the surface. For example, this could be from a light source to a pixel, or from the Camera to a surface. Normal Input Vector None The normalized normal of the surface that causes the refraction. IOR Source Input Float None The refractive index of the medium the light source originates in. IOR Medium Input Float None The refractive index of the medium that the light refracts into. Refracted Output Vector None The refracted vector. Intensity Output Float None Intensity of the refraction. Controls Name Type Options Description Mode Dropdown • Safe: Returns a null vector result instead of a NaN result at the point of critical angle refraction. • CriticalAngle: Avoids the Safe check for a potential NaN result. Generated Code Example The following example code represents one possible outcome of this node. void Unity_RefractCriticalAngle(float3 Incident, float3 Normal, float IORInput, float IORMedium, out float Out) { $precision internalIORInput = max(IORInput, 1.0); $precision internalIORMedium = max(IORMedium, 1.0); $precision eta = internalIORInput/internalIORMedium; $precision cos0 = dot(Incident, Normal); $precision k = 1.0 - eta*eta*(1.0 - cos0*cos0); Refracted = k >= 0.0 ? eta*Incident - (eta*cos0 + sqrt(k))*Normal : reflect(Incident, Normal); Intensity = internalIORSource <= internalIORMedium ?; saturate(F_Transm_Schlick(IorToFresnel0(internalIORMedium, internalIORSource), -cos0)) : (k >= 0.0 ? saturate(F_FresnelDielectric(internalIORMedium/internalIORSource, -cos0)) : 0.0); } void Unity_RefractSafe(float3 Incident, float3 Normal, float IORInput, float IORMedium, out float Out) { $precision internalIORInput = max(IORInput, 1.0); $precision internalIORMedium = max(IORMedium, 1.0); $precision eta = internalIORInput/internalIORMedium; $precision cos0 = dot(Incident, Normal); $precision k = 1.0 - eta*eta*(1.0 - cos0*cos0); Refracted = eta*Incident - (eta*cos0 + sqrt(max(k, 0.0)))*Normal; Intensity = internalIORSource <= internalIORMedium ?; saturate(F_Transm_Schlick(IorToFresnel0(internalIORMedium, internalIORSource), -cos0)) : (k >= 0.0 ? saturate(F_FresnelDielectric(internalIORMedium/internalIORSource, -cos0)) : 1.0); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rejection-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rejection-Node.html",
    "title": "Rejection Node | mmo-rpg-unity",
    "keywords": "Rejection Node Description Returns the result of the projection of the value of input A onto the plane orthogonal, or perpendicular, to the value of input B. The value of the rejection vector is equal to the original vector, the value of input A, minus the value of the Projection of the same inputs. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Rejection_float4(float4 A, float4 B, out float4 Out) { Out = A - (B * dot(A, B) / dot(B, B)) }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Remap-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Remap-Node.html",
    "title": "Remap Node | mmo-rpg-unity",
    "keywords": "Remap Node Description Returns a value between the x and y components of input Out Min Max based on the linear interpolation of the value of input In between the x and y components of input In Min Max. Ports Name Direction Type Description In Input Dynamic Vector Input value In Min Max Input Vector 2 Minimum and Maximum values for input interpolation Out Min Max Input Vector 2 Minimum and Maximum values for output interpolation Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Remap_float4(float4 In, float2 InMinMax, float2 OutMinMax, out float4 Out) { Out = OutMinMax.x + (In - InMinMax.x) * (OutMinMax.y - OutMinMax.x) / (InMinMax.y - InMinMax.x); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Replace-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Replace-Color-Node.html",
    "title": "Replace Color Node | mmo-rpg-unity",
    "keywords": "Replace Color Node Description Replaces values in input In equal to input From to the value of input To. Input Range can be used to define a wider range of values around input From to replace. Input Fuzziness can be used to soften the edges around the selection similar to anti-aliasing. Ports Name Direction Type Binding Description In Input Vector 3 None Input value From Input Vector 3 Color Color to replace To Input Vector 3 Color Color to replace with Range Input Float None Replace colors within this range from input From Fuzziness Input Float None Soften edges around selection Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_ReplaceColor_float(float3 In, float3 From, float3 To, float Range, float Fuzziness, out float3 Out) { float Distance = distance(From, In); Out = lerp(To, In, saturate((Distance - Range) / max(Fuzziness, 1e-5f))); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rotate-About-Axis-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rotate-About-Axis-Node.html",
    "title": "Rotate About Axis Node | mmo-rpg-unity",
    "keywords": "Rotate About Axis Node Description Rotates the input vector In around the axis Axis by the value of Rotation. The unit for rotation angle can be selected by the parameter Unit. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Axis Input Vector 3 None Axis to rotate around Rotation Input Float None Amount of rotation to apply Out Output Vector 3 None Output value Controls Name Type Options Description Unit Dropdown Radians, Degrees Switches the unit for input Rotation Generated Code Example The following example code represents one possible outcome of this node per Unit mode. Radians void Unity_RotateAboutAxis_Radians_float(float3 In, float3 Axis, float Rotation, out float3 Out) { float s = sin(Rotation); float c = cos(Rotation); float one_minus_c = 1.0 - c; Axis = normalize(Axis); float3x3 rot_mat = { one_minus_c * Axis.x * Axis.x + c, one_minus_c * Axis.x * Axis.y - Axis.z * s, one_minus_c * Axis.z * Axis.x + Axis.y * s, one_minus_c * Axis.x * Axis.y + Axis.z * s, one_minus_c * Axis.y * Axis.y + c, one_minus_c * Axis.y * Axis.z - Axis.x * s, one_minus_c * Axis.z * Axis.x - Axis.y * s, one_minus_c * Axis.y * Axis.z + Axis.x * s, one_minus_c * Axis.z * Axis.z + c }; Out = mul(rot_mat, In); } Degrees void Unity_RotateAboutAxis_Degrees_float(float3 In, float3 Axis, float Rotation, out float3 Out) { Rotation = radians(Rotation); float s = sin(Rotation); float c = cos(Rotation); float one_minus_c = 1.0 - c; Axis = normalize(Axis); float3x3 rot_mat = { one_minus_c * Axis.x * Axis.x + c, one_minus_c * Axis.x * Axis.y - Axis.z * s, one_minus_c * Axis.z * Axis.x + Axis.y * s, one_minus_c * Axis.x * Axis.y + Axis.z * s, one_minus_c * Axis.y * Axis.y + c, one_minus_c * Axis.y * Axis.z - Axis.x * s, one_minus_c * Axis.z * Axis.x - Axis.y * s, one_minus_c * Axis.y * Axis.z + Axis.x * s, one_minus_c * Axis.z * Axis.z + c }; Out = mul(rot_mat, In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rotate-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rotate-Node.html",
    "title": "Rotate Node | mmo-rpg-unity",
    "keywords": "Rotate Node Description Rotates value of input UV around a reference point defined by input Center by the amount of input Rotation. The unit for rotation angle can be selected by the parameter Unit. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center point to rotate around Rotation Input Float None Amount of rotation to apply Out Output Vector 2 None Output UV value Controls Name Type Options Description Unit Dropdown Radians, Degrees Switches the unit for input Rotation Generated Code Example The following example code represents one possible outcome of this node per Unit mode. Radians void Unity_Rotate_Radians_float(float2 UV, float2 Center, float Rotation, out float2 Out) { UV -= Center; float s = sin(Rotation); float c = cos(Rotation); float2x2 rMatrix = float2x2(c, -s, s, c); rMatrix *= 0.5; rMatrix += 0.5; rMatrix = rMatrix * 2 - 1; UV.xy = mul(UV.xy, rMatrix); UV += Center; Out = UV; } Degrees void Unity_Rotate_Degrees_float(float2 UV, float2 Center, float Rotation, out float2 Out) { Rotation = Rotation * (3.1415926f/180.0f); UV -= Center; float s = sin(Rotation); float c = cos(Rotation); float2x2 rMatrix = float2x2(c, -s, s, c); rMatrix *= 0.5; rMatrix += 0.5; rMatrix = rMatrix * 2 - 1; UV.xy = mul(UV.xy, rMatrix); UV += Center; Out = UV; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Round-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Round-Node.html",
    "title": "Round Node | mmo-rpg-unity",
    "keywords": "Round Node Description Returns the value of input In rounded to the nearest integer, or whole number. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Round_float4(float4 In, out float4 Out) { Out = round(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rounded-Polygon-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rounded-Polygon-Node.html",
    "title": "Rounded Polygon Node | mmo-rpg-unity",
    "keywords": "Rounded Polygon Node Description Generates a rounded polygon shape based on input UV at the size specified by inputs Width and Height. The input Sides specifies the number of sides, and the input Roundness defines the roundness of each corner. You can connect a Tiling And Offset Node to offset or tile the shape. To preserve the ability to offset the shape within the UV space, the shape does not automatically repeat if you tile it. To achieve a repeating rounded polygon effect, first connect your UV input through a Fraction Node. You can only use the Rounded Polygon Node in the Fragment Shader Stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Rounded Polygon width Height Input Float None Rounded Polygon height Sides Input Float None Number of sides of the polygon Roundness Input Float None Roundness of corners Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. void RoundedPolygon_Func_float(float2 UV, float Width, float Height, float Sides, float Roundness, out float Out) { UV = UV * 2. + float2(-1.,-1.); float epsilon = 1e-6; UV.x = UV.x / ( Width + (Width==0)*epsilon); UV.y = UV.y / ( Height + (Height==0)*epsilon); Roundness = clamp(Roundness, 1e-6, 1.); float i_sides = floor( abs( Sides ) ); float fullAngle = 2. * PI / i_sides; float halfAngle = fullAngle / 2.; float opositeAngle = HALF_PI - halfAngle; float diagonal = 1. / cos( halfAngle ); // Chamfer values float chamferAngle = Roundness * halfAngle; // Angle taken by the chamfer float remainingAngle = halfAngle - chamferAngle; // Angle that remains float ratio = tan(remainingAngle) / tan(halfAngle); // This is the ratio between the length of the polygon's triangle and the distance of the chamfer center to the polygon center // Center of the chamfer arc float2 chamferCenter = float2( cos(halfAngle) , sin(halfAngle) )* ratio * diagonal; // starting of the chamfer arc float2 chamferOrigin = float2( 1., tan(remainingAngle) ); // Using Al Kashi algebra, we determine: // The distance distance of the center of the chamfer to the center of the polygon (side A) float distA = length(chamferCenter); // The radius of the chamfer (side B) float distB = 1. - chamferCenter.x; // The refence length of side C, which is the distance to the chamfer start float distCref = length(chamferOrigin); // This will rescale the chamfered polygon to fit the uv space // diagonal = length(chamferCenter) + distB; float uvScale = diagonal; UV *= uvScale; float2 polaruv = float2 ( atan2( UV.y, UV.x ), length(UV) ); polaruv.x += HALF_PI + 2*PI; polaruv.x = fmod( polaruv.x + halfAngle, fullAngle ); polaruv.x = abs(polaruv.x - halfAngle); UV = float2( cos(polaruv.x), sin(polaruv.x) ) * polaruv.y; // Calculate the angle needed for the Al Kashi algebra float angleRatio = 1. - (polaruv.x-remainingAngle) / chamferAngle; // Calculate the distance of the polygon center to the chamfer extremity float distC = sqrt( distA*distA + distB*distB - 2.*distA*distB*cos( PI - halfAngle * angleRatio ) ); Out = UV.x; float chamferZone = ( halfAngle - polaruv.x ) < chamferAngle; Out = lerp( UV.x, polaruv.y / distC, chamferZone ); // Output this to have the shape mask instead of the distance field Out = saturate((1 - Out) / fwidth(Out)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rounded-Rectangle-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Rounded-Rectangle-Node.html",
    "title": "Rounded Rectangle Node | mmo-rpg-unity",
    "keywords": "Rounded Rectangle Node Description Generates a rounded rectangle shape based on input UV at the size specified by inputs Width and Height. The radius of each corner is defined by input Radius. The generated shape can be offset or tiled by connecting a Tiling And Offset Node. Note that in order to preserve the ability to offset the shape within the UV space the shape will not automatically repeat if tiled. To achieve a repeating rounded rectangle effect first connect your input through a Fraction Node. NOTE: This Node can only be used in the Fragment Shader Stage. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Width Input Float None Rounded Rectangle width Height Input Float None Rounded Rectangle height Radius Input Float None Corner radius Out Output Float None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_RoundedRectangle_float(float2 UV, float Width, float Height, float Radius, out float Out) { Radius = max(min(min(abs(Radius * 2), abs(Width)), abs(Height)), 1e-5); float2 uv = abs(UV * 2 - 1) - float2(Width, Height) + Radius; float d = length(max(0, uv)) / Radius; Out = saturate((1 - d) / fwidth(d)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Cubemap-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Cubemap-Node.html",
    "title": "Sample Cubemap Node | mmo-rpg-unity",
    "keywords": "Sample Cubemap Node Description Samples a Cubemap and returns a Vector 4 color value for use in the shader. Requires a Direction (Dir) input in world space to sample the Cubemap. You can achieve a blurring effect by using the LOD input to sample at a different Level of Detail. You can also use the Sampler input to define a custom Sampler State. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Binding Description Cube Input Cubemap None Cubemap to sample Dir Input Vector 3 Normal (world space) Direction or Mesh's normal vector Sampler Input Sampler State Default sampler state Sampler for the Cubemap LOD Input Float None Level of detail for sampling Out Output Vector 4 None Output value Generated Code Example The following example code represents one possible outcome of this node. float4 _SampleCubemap_Out = SAMPLE_TEXTURECUBE_LOD(Cubemap, Sampler, Dir, LOD);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Gradient-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Gradient-Node.html",
    "title": "Sample Gradient Node | mmo-rpg-unity",
    "keywords": "Sample Gradient Node Description Samples a Gradient given the input of Time. Returns a Vector 4 color value for use in the shader. Ports Name Direction Type Binding Description Gradient Input Gradient None Gradient to sample Time Input Float None Point at which to sample gradient (0.0–1.0) Out Output Vector 4 None Output value as Vector4 Generated Code Example The following example code represents one possible outcome of this node. void Unity_SampleGradient_float(float4 Gradient, float Time, out float4 Out) { float3 color = Gradient.colors[0].rgb; [unroll] for (int c = 1; c < 8; c++) { float colorPos = saturate((Time - Gradient.colors[c-1].w) / (Gradient.colors[c].w - Gradient.colors[c-1].w)) * step(c, Gradient.colorsLength-1); color = lerp(color, Gradient.colors[c].rgb, lerp(colorPos, step(0.01, colorPos), Gradient.type)); } #ifndef UNITY_COLORSPACE_GAMMA color = SRGBToLinear(color); #endif float alpha = Gradient.alphas[0].x; [unroll] for (int a = 1; a < 8; a++) { float alphaPos = saturate((Time - Gradient.alphas[a-1].y) / (Gradient.alphas[a].y - Gradient.alphas[a-1].y)) * step(a, Gradient.alphasLength-1); alpha = lerp(alpha, Gradient.alphas[a].x, lerp(alphaPos, step(0.01, alphaPos), Gradient.type)); } Out = float4(color, alpha); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Reflected-Cubemap-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Reflected-Cubemap-Node.html",
    "title": "Sample Reflected Cubemap Node | mmo-rpg-unity",
    "keywords": "Sample Reflected Cubemap Node Description Samples a Cubemap with reflected vector and returns a Vector 4 color value for use in the shader. Requires View Direction (View Dir) and Normal inputs to sample the Cubemap. You can achieve a blurring effect by using the LOD input to sample at a different Level of Detail. You can also use the Sampler input to define a custom Sampler State. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Binding Description Cube Input Cubemap None Cubemap to sample View Dir Input Vector 3 View Direction (object space) Mesh's view direction Normal Input Vector 3 Normal (object space) Mesh's normal vector Sampler Input Sampler State Default sampler state Sampler for the Cubemap LOD Input Float None Level of detail for sampling Out Output Vector 4 None Output value Generated Code Example The following example code represents one possible outcome of this node. float4 _SampleCubemap_Out = SAMPLE_TEXTURECUBE_LOD(Cubemap, Sampler, reflect(-ViewDir, Normal), LOD);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Texture-2D-Array-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Texture-2D-Array-Node.html",
    "title": "Sample Texture 2D Array node | mmo-rpg-unity",
    "keywords": "Sample Texture 2D Array node The Sample Texture 2D Array node samples a Texture 2D Array asset and returns a Vector 4 color value. You can specify the UV coordinates for a texture sample and use a Sampler State node to define a specific Sampler State. The node's Index input port specifies which index of a Texture 2D Array to sample. For more information about Texture 2D Arrays, see Texture Arrays in the Unity User manual. Note If you experience texture sampling errors for this node in a graph with Custom Function Nodes or Sub Graphs, upgrade to Shader Graph version 10.3 or later. Create Node menu category The Sample Texture 2D Array node is under the Input > Texture category in the Create Node menu. Compatibility The Sample Texture 3D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes With its default settings, this node can only connect to a Block node in the Fragment Context of a Shader Graph. To sample a Texture for the Vertex Context of a Shader Graph, set the Mip Sampling Mode to LOD. Inputs The Sample Texture 3D node has the following input ports: Name Type Binding Description Texture Array Texture 2D Array None The Texture 2D Array asset to sample. Index Float None The index of the specific Texture in the Texture array to sample. The index value is the Texture's location in the Texture array. The index values in an array always start at 0. An array with four textures would have locations 0, 1, 2, and 3. UV Vector 2 None UV coordinates to use to sample the Texture. Sampler Sampler State Default Sampler State The Sampler State and settings to use to sample the texture. LOD Float LOD NOTE: The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, refer to Additional node settings. The specific mip to use when sampling the Texture. UV Vector 2 UV The UV coordinates to use to sample the texture. Sampler Sampler State Default Sampler State The Sampler State and settings to use to sample the texture. LOD Float LOD The specific mip to use when sampling the Texture. NOTE The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, refer to Additional node settings. Bias Float Bias NOTE: The Bias Input port only displays if Mip Sampling Mode is Bias. For more information, refer to Additional node settings. If Use Global Mip Bias is enabled, Unity adds this Bias amount to the Global Mip Bias for a texture's mip calculation. If Global Mip Bias is disabled, Unity uses this Bias amount instead of the Global Mip Bias. DDX Float DDY NOTE: The DDX Input port only displays if Mip Sampling Mode is Gradient. For more information, refer to Additional node settings. The specific DDX value to use to calculate the texture's mip when sampling. For more information on DDX values for mipmaps, refer to Mipmaps introduction in the Unity User Manual. DDY Float DDY NOTE The DDY Input port only displays if Mip Sampling Mode is Gradient. For more information, refer to Additional node settings. The specific DDY value to use to calculate the texture's mip when sampling. For more information on DDY values for mipmaps, refer to Mipmaps introduction> in the Unity User Manual. Additional node settings The Sample Texture 3D node has some additional settings that you can access from the Graph Inspector: Name Type Description Use Global Mip Bias Toggle Enable Use Global Mip Bias to use the render pipeline's Global Mip Bias. This bias adjusts the percentage of texture information taken from a specific mip when sampling. For more information on mip bias, see Mipmaps introduction in the Unity User Manual. Enabled Shader Graph uses the render pipeline's Global Mip Bias to adjust the texture information taken when sampling. Disabled Shader Graph doesn't use the render pipeline's Global Mip Bias to adjust texture information when sampling. Mip Sampling Mode Dropdown Choose the sampling mode to use to calculate the mip level of the texture. Standard The render pipeline calculates and automatically selects the mip for the texture. LOD The render pipeline lets you set an explicit mip for the texture on the node. The texture will always use this mip, regardless of the DDX or DDY calculations between pixels. Set the Mip Sampling Mode to LOD to connect the node to a Block node in the Vertex Context. For more information on Block nodes and Contexts, see Master Stack. Gradient The render pipeline lets you set the DDX and DDY values to use for its mip calculation, instead of using the values calculated from the texture's UV coordinates. For more information on DDX and DDY values, see Mipmaps introduction in the User Manual. Bias The render pipeline lets you set a bias to adjust the calculated mip for a texture up or down. Negative values bias the mip to a higher resolution. Positive values bias the mip to a lower resolution. The render pipeline can add this value to the value of the Global Mip Bias, or use this value instead of its Global Mip Bias. For more information on mip bias, see Mipmaps introduction in the User Manual. Outputs The Sample Texture 3D node has the following output ports: Name Type Description RGBA Vector 4 The full RGBA Vector 4 color value of the texture sample. R Float The Red channel or X component of the texture sample. G Float The Green channel or Y component of the texture sample. B Float The Blue channel or Z component of the texture sample. A Float The Alpha channel or W component of the texture sample. Example graph usage In the following example, the Sample Texture 2D Array node samples a Texture array that has 4 different cloth normal maps. Change the number given to the Index port as an input, and the Sample Texture 2D Array node can sample a specific normal map from the array. The Index value changes the output the node sends to the Normal Unpack node, and the Normal (Tangent Space) Block node in the Master Stack. Generated code example The following code represents this node in Unity's shader code: float4 _SampleTexture2DArray_RGBA = SAMPLE_TEXTURE2D_ARRAY(Texture, Sampler, UV, Index); float _SampleTexture2DArray_R = _SampleTexture2DArray_RGBA.r; float _SampleTexture2DArray_G = _SampleTexture2DArray_RGBA.g; float _SampleTexture2DArray_B = _SampleTexture2DArray_RGBA.b; float _SampleTexture2DArray_A = _SampleTexture2DArray_RGBA.a; Related nodes The following nodes are related or similar to the Sample Texture 3D node: Sample Texture 2D node Sample Texture 3D node Sampler State node"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Texture-2D-LOD-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Texture-2D-LOD-Node.html",
    "title": "Sample Texture 2D LOD Node | mmo-rpg-unity",
    "keywords": "Sample Texture 2D LOD Node Description Samples a Texture 2D and returns a Vector 4 color value for use in the shader. You can override the UV coordinates using the UV input and define a custom Sampler State using the Sampler input. Use the LOD input to adjust the level of detail of the sample. To use the Sample Texture 2D LOD Node to sample a normal map, set the Type dropdown parameter to Normal. This Node is useful for sampling a Texture in the vertex Shader Stage as the Sample Texture 2D Node is unavailable in this Shader Stage. On platforms that do not support this operation, opaque black is returned instead. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading to version 10.3 or later. Ports Name Direction Type Binding Description Texture Input Texture 2D None Texture 2D to sample UV Input Vector 2 UV UV coordinates Sampler Input Sampler State Default sampler state Sampler for the texture LOD Input Float None Level of detail to sample RGBA Output Vector 4 None Output value as RGBA R Output Float None red (x) component of RGBA output G Output Float None green (y) component of RGBA output B Output Float None blue (z) component of RGBA output A Output Float None alpha (w) component of RGBA output Controls Name Type Options Description Type Dropdown Default, Normal Selects the texture type Generated Code Example The following example code represents one possible outcome of this node per Type mode. Default float4 _SampleTexture2DLOD_RGBA = SAMPLE_TEXTURE2D_LOD(Texture, Sampler, UV, LOD); float _SampleTexture2DLOD_R = _SampleTexture2DLOD_RGBA.r; float _SampleTexture2DLOD_G = _SampleTexture2DLOD_RGBA.g; float _SampleTexture2DLOD_B = _SampleTexture2DLOD_RGBA.b; float _SampleTexture2DLOD_A = _SampleTexture2DLOD_RGBA.a; Normal float4 _SampleTexture2DLOD_RGBA = SAMPLE_TEXTURE2D_LOD(Texture, Sampler, UV, LOD); _SampleTexture2DLOD_RGBA.rgb = UnpackNormalRGorAG(_SampleTexture2DLOD_RGBA); float _SampleTexture2DLOD_R = _SampleTexture2DLOD_RGBA.r; float _SampleTexture2DLOD_G = _SampleTexture2DLOD_RGBA.g; float _SampleTexture2DLOD_B = _SampleTexture2DLOD_RGBA.b; float _SampleTexture2DLOD_A = _SampleTexture2DLOD_RGBA.a;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Texture-2D-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Texture-2D-Node.html",
    "title": "Sample Texture 2D node | mmo-rpg-unity",
    "keywords": "Sample Texture 2D node The Sample Texture 2D node samples a Texture 2D asset and returns a Vector 4 color value. You can specify the UV coordinates for a texture sample and use a Sampler State node to define a specific Sampler State. A Sample Texture 2D node can also sample a normal map. For more information, see the Controls section, or Normal map (Bump mapping) in the Unity User manual. Note If you experience texture sampling errors for this node in a graph with Custom Function Nodes or Sub Graphs, upgrade to Shader Graph version 10.3 or later. Create Node menu category The Sample Texture 2D node is under the Input > Texture category in the Create Node menu. Compatibility The Sample Texture 2D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes With its default settings, this node can only connect to a Block node in the Fragment Context of a Shader Graph. To sample a Texture for the Vertex Context of a Shader Graph, set the Mip Sampling Mode to LOD. Inputs The Sample Texture 2D node has the following input ports: Name Type Binding Description Texture Texture 2D None The Texture 2D asset to sample. UV Vector 2 UV The UV coordinates to use to sample the texture. Sampler Sampler State Default Sampler State The Sampler State and settings to use to sample the texture. LOD Float LOD The specific mip to use when sampling the Texture. NOTE The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, refer to Additional node settings. Bias Float Bias NOTE: The Bias Input port only displays if Mip Sampling Mode is Bias. For more information, refer to Additional node settings. If Use Global Mip Bias is enabled, Unity adds this Bias amount to the Global Mip Bias for a texture's mip calculation. If Global Mip Bias is disabled, Unity uses this Bias amount instead of the Global Mip Bias. DDX Float DDY NOTE: The DDX Input port only displays if Mip Sampling Mode is Gradient. For more information, refer to Additional node settings. The specific DDX value to use to calculate the texture's mip when sampling. For more information on DDX values for mipmaps, refer to Mipmaps introduction in the Unity User Manual. DDY Float DDY NOTE The DDY Input port only displays if Mip Sampling Mode is Gradient. For more information, refer to Additional node settings. The specific DDY value to use to calculate the texture's mip when sampling. For more information on DDY values for mipmaps, refer to Mipmaps introduction> in the Unity User Manual. Controls The Sample Texture 2D node has the following controls: Name Type Description Type Dropdown Select whether the texture is a Texture asset or a normal map. Default The texture is a Texture asset. Normal The texture is a normal map. Space Dropdown When the node's Type is Normal to use a texture as a normal map, choose the Space for the normal map. Tangent Use a Tangent normal map whenever the mesh for a geometry needs to deform or change, such as when animating a character. With Tangent Space, the normal map's normals are relative to the existing vertex normals of any geometry rendered with your Shader Graph. Your Shader Graph only adjusts the vertex normals and not override them. Object Use an Object normal map whenever the mesh for a geometry is static and doesn't deform. With Object Space, the normal map's normals are explicit and override the normals of any geometry rendered with your Shader Graph. Because a static mesh's normals never change, an Object normal map also maintains consistent lighting across different levels of detail (LODs). For more information about normal maps, see Normal map (Bump mapping) in the User manual. Additional node settings The Sample Texture 2D node has some additional settings that you can access from the Graph Inspector: Name Type Description Use Global Mip Bias Toggle Enable Use Global Mip Bias to use the render pipeline's Global Mip Bias. This bias adjusts the percentage of texture information taken from a specific mip when sampling. For more information on mip bias, see Mipmaps introduction in the Unity User Manual. Enabled Shader Graph uses the render pipeline's Global Mip Bias to adjust the texture information taken when sampling. Disabled Shader Graph doesn't use the render pipeline's Global Mip Bias to adjust texture information when sampling. Mip Sampling Mode Dropdown Choose the sampling mode to use to calculate the mip level of the texture. Standard The render pipeline calculates and automatically selects the mip for the texture. LOD The render pipeline lets you set an explicit mip for the texture on the node. The texture will always use this mip, regardless of the DDX or DDY calculations between pixels. Set the Mip Sampling Mode to LOD to connect the node to a Block node in the Vertex Context. For more information on Block nodes and Contexts, see Master Stack. Gradient The render pipeline lets you set the DDX and DDY values to use for its mip calculation, instead of using the values calculated from the texture's UV coordinates. For more information on DDX and DDY values, see Mipmaps introduction in the User Manual. Bias The render pipeline lets you set a bias to adjust the calculated mip for a texture up or down. Negative values bias the mip to a higher resolution. Positive values bias the mip to a lower resolution. The render pipeline can add this value to the value of the Global Mip Bias, or use this value instead of its Global Mip Bias. For more information on mip bias, see Mipmaps introduction in the User Manual. Outputs The Sample Texture 2D node has the following output ports: Name Type Description RGBA Vector 4 The full RGBA Vector 4 color value of the texture sample. R Float The Red channel or X component of the texture sample. G Float The Green channel or Y component of the texture sample. B Float The Blue channel or Z component of the texture sample. A Float The Alpha channel or W component of the texture sample. Example graph usage In the following example, the Sample Texture 2D node uses a Subgraph node that generates UV coordinates in latitude and longitude format. These latitude and longitude UV coordinates help render the latlong_test 2D Texture asset, which was created and formatted with a latitude and longitude projection. The generated latitude and longitude UVs accurately map the 2D Texture asset onto a spherical geometry. If the Sample Texture 2D node uses the Standard Mip Sampling Mode, the Texture displays with a seam along the side of the sphere where the left and right sides of the texture meet. The latitude and longitude UV coordinates for sampling the texture jump from 0 to 1 at the seam on the model, which causes a problem with the mip level calculation in the sample. The error in the mip level calculation causes the seam. The texture requires a different mip sampling mode to remove the seam. When the Mip Sampling Mode is set to Gradient, the Sample Texture 2D node can use the standard set of UVs for the model in the mip level calculation, instead of the latitude and longitude UVs needed for sampling the texture. The new UV coordinates passed into the DDX and DDY input ports result in a continuous mip level, and remove the seam. Generated code example The following code represents this node in Unity's shader code, based on the selected Type on the Sample Texture 2D node: Default float4 _SampleTexture2D_RGBA = SAMPLE_TEXTURE2D(Texture, Sampler, UV); float _SampleTexture2D_R = _SampleTexture2D_RGBA.r; float _SampleTexture2D_G = _SampleTexture2D_RGBA.g; float _SampleTexture2D_B = _SampleTexture2D_RGBA.b; float _SampleTexture2D_A = _SampleTexture2D_RGBA.a; Normal float4 _SampleTexture2D_RGBA = SAMPLE_TEXTURE2D(Texture, Sampler, UV); _SampleTexture2D_RGBA.rgb = UnpackNormalmapRGorAG(_SampleTexture2D_RGBA); float _SampleTexture2D_R = _SampleTexture2D_RGBA.r; float _SampleTexture2D_G = _SampleTexture2D_RGBA.g; float _SampleTexture2D_B = _SampleTexture2D_RGBA.b; float _SampleTexture2D_A = _SampleTexture2D_RGBA.a; Related nodes The following nodes are related or similar to the Sample Texture 2D node: Sample Texture 2D Array node Sample Texture 3D node Sampler State node"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Texture-3D-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Texture-3D-Node.html",
    "title": "Sample Texture 3D node | mmo-rpg-unity",
    "keywords": "Sample Texture 3D node The Sample Texture 3D node samples a Texture 3D asset and returns a Vector 4 color value. You can specify the UV coordinates for a texture sample and use a Sampler State node to define a specific Sampler State. For more information about Texture 3D assets, see 3D textures in the Unity User manual. Note If you experience texture sampling errors for this node in a graph with Custom Function Nodes or Sub Graphs, upgrade to Shader Graph version 10.3 or later. Create Node menu category The Sample Texture 2D node is under the Input > Texture category in the Create Node menu. Compatibility The Sample Texture 3D node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes With its default settings, this node can only connect to a Block node in the Fragment Context of a Shader Graph. To sample a Texture for the Vertex Context of a Shader Graph, set the Mip Sampling Mode to LOD. Inputs The Sample Texture 3D node has the following input ports: Name Type Binding Description Texture Texture 3D None The 3D Texture asset to sample. UV Vector 3 None The 3D UV coordinates to use to sample the Texture. Sampler Sampler State Default Sampler State The Sampler State and settings to use to sample the texture. LOD Float LOD The specific mip to use when sampling the Texture. NOTE The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, refer to Additional node settings. Additional node settings The Sample Texture 3D node has some additional settings that you can access from the Graph Inspector: Name Type Description Mip Sampling Mode Dropdown Choose the sampling mode that the Sample Texture 3D node uses to calculate the mip level of the texture. Standard The mip is calculated and selected automatically for the texture. LOD Set an explicit mip for the texture. The texture will always use this mip, regardless of the DDX or DDY calculations between pixels. If the Mip Sampling Mode is set to LOD, you can connect the node to a Block node in the Vertex Context. For more information on Block nodes and Contexts, see Master Stack. Outputs The Sample Texture 3D node has the following output ports: Name Type Description RGBA Vector 4 The full RGBA Vector 4 color value of the texture sample. R Float The Red channel or X component of the texture sample. G Float The Green channel or Y component of the texture sample. B Float The Blue channel or Z component of the texture sample. A Float The Alpha channel or W component of the texture sample. Example graph usage In the following example, the Sample Texture 3D node samples a 3D fractal noise Texture asset. It takes its input UV coordinates from a Position node, set to Object Space. The Sample Texture 3D node needs a Vector 3 for its UV coordinate input, rather than a Vector 2, because the Texture asset exists as a volume in imaginary 3D space. The node uses the default Sampler State because there is no Sampler State node connected. This specific Texture 3D asset stores its Texture data in the Alpha channel, so the Sample Texture 3D node uses its A output port as an input for the Base Color Block node in the Fragment Context of the Master Stack: Generated code example The following code represents this node in Unity's shader code: float4 _SampleTexture3D_Out = SAMPLE_TEXTURE3D(Texture, Sampler, UV); Related nodes The following nodes are related or similar to the Sample Texture 3D node: Sample Texture 2D Array node Sample Texture 2D node Sampler State node"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Virtual-Texture-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sample-Virtual-Texture-Node.html",
    "title": "Sample Virtual Texture Node | mmo-rpg-unity",
    "keywords": "Sample Virtual Texture Node Description Samples a Virtual Texture and returns up to four Vector 4 color values for use in the shader. You can use the UV input to override the UV coordinate. The Sample Virtual Texture node takes one UV coordinate as the input, and uses that UV coordinate to sample all of the textures in the Virtual Texture. If you want to use the Sample Virtual Texture node to sample normal maps, navigate to each layer that you want to sample as a normal map, open the Layer Type drop-down menu, and select Normal. By default, you can only use this node in the fragment shader stage. For more information about how to use this node, or how to configure it for use in the vertex shader stage, see Using Streaming Virtual Texturing in Shader Graph. If you disable Virtual Texturing in your project, this node works the same way as the Sample 2D Texture Node, and performs standard 2D sampling on each texture. You must connect a Sample Virtual Texture node to a Virtual Texture property for the Shader Graph Asset to compile. If you don't connect the node to a property, an error appears, indicating that the node requires a connection. For information about Streaming Virtual Texturing, see Streaming Virtual Texturing. Ports Name Direction Type Binding Description UV Input Vector 2 UV The UV coordinate. VT Input Virtual Texture None The Virtual Texture to sample. Must be connected to a Virtual Texture property. Out Output Vector 4 None The output value of layer 1 as RGBA. Out2 Output Vector 4 None The output of layer 2 as RGBA. Out3 Output Vector 4 None The output of layer 3 as RGBA. Out4 Output Vector 4 None The output of layer 4 as RGBA. Settings The Sample Virtual Texture node has several settings available for you to specify its behavior. These settings work in combination with any scripts you might have set up in your project. To view the settings, select the node with the Graph Inspector open. For more information, see Streaming Virtual Texturing. Name Type Options Description Lod Mode Dropdown Automatic, Lod Level, Lod Bias, Derivatives Sets the specific Lod mode to use when sampling the textures. Quality Dropdown Low, High Sets the quality mode to use when sampling the textures. Automatic Streaming Toggle Enabled/Disabled Determines whether the node uses automatic streaming or manual streaming. Enable Global Mip Bias Toggle Enabled/Disabled Enables the global mipmap bias that Unity automatically imposes at runtime. Unity sets this bias during certain dynamic resolution scaling algorithms to improve detail reconstruction. Layer 1 Type Dropdown Default, Normal The texture type of layer 1. Layer 2 Type Dropdown Default, Normal The texture type of layer 2. Layer 3 Type Dropdown Default, Normal The texture type of layer 3. This option only appears if the Virtual Texture has at least 3 layers. Layer 4 Type Dropdown Default, Normal The texture type of layer 4. This option only appears if the Virtual Texture has at least 4 layers. Generated Code Example The following example code represents one possible outcome of this node. float4 SampleVirtualTexture(float2 uv, VTPropertyWithTextureType vtProperty, out float4 Layer0) { VtInputParameters vtParams; vtParams.uv = uv; vtParams.lodOrOffset = 0.0f; vtParams.dx = 0.0f; vtParams.dy = 0.0f; vtParams.addressMode = VtAddressMode_Wrap; vtParams.filterMode = VtFilter_Anisotropic; vtParams.levelMode = VtLevel_Automatic; vtParams.uvMode = VtUvSpace_Regular; vtParams.sampleQuality = VtSampleQuality_High; #if defined(SHADER_STAGE_RAY_TRACING) if (vtParams.levelMode == VtLevel_Automatic || vtParams.levelMode == VtLevel_Bias) { vtParams.levelMode = VtLevel_Lod; vtParams.lodOrOffset = 0.0f; } #endif StackInfo info = PrepareVT(vtProperty.vtProperty, vtParams); Layer0 = SampleVTLayerWithTextureType(vtProperty, vtParams, info, 0); return GetResolveOutput(info); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sampler-State-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sampler-State-Node.html",
    "title": "Sampler State Node | mmo-rpg-unity",
    "keywords": "Sampler State Node Description Defines a Sampler State for sampling textures. It should be used in conjunction with sampling Nodes such as the Sample Texture 2D Node. You can set a filter mode with the dropdown parameter Filter and a wrap mode with the dropdown parameter Wrap. When using a separate Sample State Node you can sample a Texture 2D twice, with different sampler parameters, without defining the Texture 2D itself twice. Not all filtering, wrap, and Anisotropic filtering modes are available on all platforms. Ports Name Direction Type Binding Description Out Output Sampler State None Output value Controls Name Type Options Description Filter Dropdown Linear, Point, Trilinear Specifies which filtering mode to use for sampling. Wrap Dropdown Repeat, Clamp, Mirror, MirrorOnce Specifies which wrap mode to use for sampling. Node Settings Controls The following control appears on the Node Settings tab of the Graph Inspector when you select the Sampler State Node. Name Type Options Description Anisotropic Filtering Dropdown None, x2, x4, x8, x16 Specifies the level of Anisotropic filtering to use to sample textures. Generated Code Example The following example code represents one possible outcome of this node. SamplerState _SamplerState_Out = _SamplerState_Linear_Repeat_sampler;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Saturate-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Saturate-Node.html",
    "title": "Saturate Node | mmo-rpg-unity",
    "keywords": "Saturate Node Description Returns the value of input In clamped between 0 and 1. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Saturate_float4(float4 In, out float4 Out) { Out = saturate(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Saturation-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Saturation-Node.html",
    "title": "Saturation Node | mmo-rpg-unity",
    "keywords": "Saturation Node Description Adjusts the saturation of input In by the amount of input Saturation. A Saturation value of 1 will return the input unaltered. A Saturation value of 0 will return the input completely desaturated. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Saturation Input Float None Saturation value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Saturation_float(float3 In, float Saturation, out float3 Out) { float luma = dot(In, float3(0.2126729, 0.7151522, 0.0721750)); Out = luma.xxx + Saturation.xxx * (In - luma.xxx); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sawtooth-Wave-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sawtooth-Wave-Node.html",
    "title": "Sawtooth Wave Node | mmo-rpg-unity",
    "keywords": "Sawtooth Wave Node Description Returns a sawtooth wave from the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SawtoothWave_float4(float4 In, out float4 Out) { Out = 2 * (In - floor(0.5 + In)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Scene-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Scene-Color-Node.html",
    "title": "Scene Color Node | mmo-rpg-unity",
    "keywords": "Scene Color Node Description Provides access to the current Camera's color buffer using input UV, which is expected to be normalized screen coordinates. The behavior of the Scene Color node isn't defined globally. The executed HLSL code for the Scene Color node is defined per Render Pipeline, and different Render Pipelines can produce different results. Custom Render Pipelines that wish to support the Scene Color node need to explicitly define the behavior for it. If the behavior is undefined, the Scene Color node returns 0 (black). In the Universal Render Pipeline the Scene Color node returns the value of the Camera Opaque Texture. Refer to the Universal Render Pipeline for more documentation on this feature. The contents of this texture are only available for Transparent objects. Set the Surface Type dropdown on the Material Options panel of the Master Node to Transparent to receive the correct values from this node. Note You can only use the Scene Color node in the Fragment Shader Stage. Supported Unity render pipelines The following table indicates which render pipelines support the Scene Color node. When used with unsupported render pipelines, the Scene Color node returns 0 (black). Pipeline Supported Built-in Render Pipeline No Universal Render Pipeline Yes High Definition Render Pipeline Yes Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Normalized screen coordinates Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SceneColor_float(float4 UV, out float3 Out) { Out = SHADERGRAPH_SAMPLE_SCENE_COLOR(UV); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Scene-Depth-Difference-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Scene-Depth-Difference-Node.html",
    "title": "Scene Depth Difference | mmo-rpg-unity",
    "keywords": "Scene Depth Difference Description Provide a difference between a World Space Position and a Depth value for a given UV. Ports Name Direction Type Binding Description Scene UV Input Vector4 None UV where to sample the depth. Position WS Input Vector3 None The world space position to compare with scene depth. Out Output Float None The difference between PositionWS and the depth. The difference is given relative to camera with Eye mode, in depth-buffer-value with Raw mode and in Linear value remap between 0 and 1 with the Linear01 Mode. Controls Name Type Options Description Mode Dropdown Select Linear01 to have a value between 0 and 1, Eye to have a World-Space value comparable to unit used on the scene and Raw if it's used with SceneDepthBuffer."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Scene-Depth-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Scene-Depth-Node.html",
    "title": "Scene Depth Node | mmo-rpg-unity",
    "keywords": "Scene Depth Node Description Provides access to the current Camera's depth buffer using input UV, which is expected to be normalized screen coordinates. Note: Depth buffer access requires depth buffer to be enabled on the active Render Pipeline. This process is different per Render Pipeline. It is recommended you read the documentation of your active Render Pipeline for information on enabling the depth buffer. If the depth buffer is unavailable this Node will return mid grey. Note: The executed HLSL code for this Node is defined per Render Pipeline, and different Render Pipelines may produce different results. Custom Render Pipelines that wish to support this Node will also need to explicitly define the behaviour for it. If undefined this Node will return 1 (white). NOTE: This Node can only be used in the Fragment Shader Stage and it is not guaranteed to work with an opaque material. Unity Render Pipelines Support High Definition Render Pipeline Universal Render Pipeline Ports Name Direction Type Binding Description UV Input Vector 4 Screen Position Normalized screen coordinates Out Output Float None Output value Depth Sampling modes Name Description Linear01 Linear depth value between 0 and 1 Raw Raw depth value Eye Depth converted to eye space units Generated Code Example The following example code represents one possible outcome of this node. void Unity_SceneDepth_Raw_float(float4 UV, out float Out) { Out = SHADERGRAPH_SAMPLE_SCENE_DEPTH(UV); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sclera-Iris-Blend-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sclera-Iris-Blend-Node.html",
    "title": "Sclera Iris Blend Node | mmo-rpg-unity",
    "keywords": "Sclera Iris Blend Node This node blends all the properties of the Iris and the Sclera so that they can be fed to the master node. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Sclera Iris Blend Node No Yes Ports name Direction type description Sclera Color Input Color Color of the sclera at the target fragment. Sclera Normal Input Vector3 Normal of the sclera at the target fragment. Sclera Smoothness Input float Smoothness of the sclera at the target fragment. Iris Color Input Color Color of the iris at the target fragment. Iris Normal Input Vector3 Normal of the iris at the target fragment. Cornea Smoothness Input float Smoothness of the cornea at the target fragment. IrisRadius Input float The radius of the Iris in the model. For the default model, this value should be 0.225. PositionOS Input Vector3 Position in object space of the current fragment to shade. Diffusion Profile Sclera Input Diffusion Profile Diffusion profile used to compute the subsurface scattering of the sclera. Diffusion Profile Iris Input Diffusion Profile Diffusion profile used to compute the subsurface scattering of the iris. EyeColor Output Color Final Diffuse color of the Eye. Surface Mask Output float Linear, normalized value that defines where the fragment is. On the Cornea, this is 1 and on the Sclera, this is 0. Diffuse Normal Output Vector3 Normal of the diffuse lobes. Specular Normal Output Vector3 Normal of the specular lobes. EyeSmoothness Output float Final smoothness of the Eye. SurfaceDiffusionProfile Output Diffusion Profile Diffusion profile of the target fragment."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sclera-Limbal-Ring-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sclera-Limbal-Ring-Node.html",
    "title": "Sclera Limbal Ring Node | mmo-rpg-unity",
    "keywords": "Sclera Limbal Ring Node Calculates the intensity of the Sclera ring, a darkening feature of eyes. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Sclera Limbal Ring Node No Yes Ports name Direction type description PositionOS Input Vector3 Position in object space of the current fragment to shade. View Direction OS Input Vector3 Direction of the incident ray in object space. Either from the camera in rasterization or from the previous bounce in ray tracing. IrisRadius Input float The radius of the Iris in the used model. For the default model, this value should be 0.225. LimbalRingSize Input float Normalized [0, 1] value that defines the relative size of the limbal ring. LimbalRingFade Input float Normalized [0, 1] value that defines strength of the fade out of the limbal ring.** LimbalRing Intensity Input float Positive value that defines how dark the limbal ring is. Iris Limbal Ring Color Output Color Intensity of the limbal ring (blackscale)."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sclera-UV-Location-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sclera-UV-Location-Node.html",
    "title": "Sclera UV Location Node | mmo-rpg-unity",
    "keywords": "Sclera UV Location Node This node converts the object position of the sclera to a UV Sampling coordinate. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Sclera UV Location Node No Yes Ports name Direction type description PositionOS Input Vector3 Position of the fragment to shade in object space. ScleraUV Output Vector2 Normalized UV coordinates that can be used to sample either a texture or procedurally generate a Sclera Texture."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Screen-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Screen-Node.html",
    "title": "Screen Node | mmo-rpg-unity",
    "keywords": "Screen Node Description Provides access to parameters of the screen. Unity Render Pipelines Support Universal Render Pipeline Note: when dynamic resolution is enabled, this node will return the current viewport of the rendering camera. After the upscaling pass, the output of this node will be equal to the screen size. Ports Name Direction Type Binding Description Width Output Float None Screen's width in pixels Height Output Float None Screen's height in pixels Generated Code Example The following example code represents one possible outcome of this node. float _Screen_Width = _ScreenParams.x; float _Screen_Height = _ScreenParams.y;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Screen-Position-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Screen-Position-Node.html",
    "title": "Screen Position Node | mmo-rpg-unity",
    "keywords": "Screen Position Node Description Provides access to the screen position of the mesh vertex or fragment. The X and Y values represent the horizontal and vertical positions respectively. Use the Mode dropdown control to select the mode of the output value. The available modes are as follows: Default - Returns X and Y values that represent the normalized Screen Position. The normalized Screen Position is the Screen Position divided by the clip space position W component. The X and Y value ranges are between 0 and 1 with position float2(0,0) at the lower left corner of the screen. The Z and W values aren't used in this mode, so they're always 0. Raw - Returns the raw Screen Position values, which are the Screen Position values before the clip space position W component is divided out. Position float2(0,0) is at the lower left corner of the screen. This mode is useful for projection. Center - Returns X and Y values that represent the normalized Screen Position offset so position float2(0,0) is at the center of the screen. The range of the X and Y values is –1 to 1. The Z and W values aren't used in this mode, so they're always 0. Tiled - Returns Screen Position offset so position float2(0,0) is at the center of the screen and tiled using frac. Pixel - Returns Screen Position in terms of the actual pixel width and height values of the screen. In this mode, position float2(0,0) is at the lower left corner of the screen. Whereas the range of Default mode is always 0 to 1, the range of Pixel mode depends on the screen resolution. The Z and W values aren't used in this mode, so they're always 0. Ports Name Direction Type Binding Description Out Output Vector 4 None Get the Screen Position of the mesh. Controls Name Type Options Description Mode Dropdown Default, Raw, Center, Tiled, Pixel Select which coordinate space to use for the Screen Position output. Generated Code Example The following code examples represent one possible outcome for each mode. Default float4 Out = float4(IN.NDCPosition.xy, 0, 0); Raw float4 Out = IN.ScreenPosition; Center float4 Out = float4(IN.NDCPosition.xy * 2 - 1, 0, 0); Tiled float4 Out = frac(float4((IN.NDCPosition.x * 2 - 1) * _ScreenParams.x / _ScreenParams.y, IN.{0}.y * 2 - 1, 0, 0)); Pixel float4 Out = float4(IN.PixelPosition.xy, 0, 0);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Asset.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Asset.html",
    "title": "Shader Graph Asset | mmo-rpg-unity",
    "keywords": "Shader Graph Asset Description The Shader Graph Asset is the new Asset type introduced with the shader graph. You can create a Shader Graph Asset from the Project Window from the Create menu. For convenience there is a Create menu entry for Blank Shader Graph and Sub-graph. They can be found in the Shader sub-menu. Additional options may be provided by render pipelines. These options will create a new Shader Graph with required settings and Block nodes in the Master Stack for the selected shading model. You can open the Shader Graph Window by double clicking a Shader Graph Asset or by clicking Open Shader Editor in the Inspector when the Shader Graph Asset is selected."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Preferences.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Preferences.html",
    "title": "Shader Graph Preferences | mmo-rpg-unity",
    "keywords": "Shader Graph Preferences To access the Shader Graph Project-wide settings, click Edit > Preferences, and then select Shader Graph. Settings Name Description Shader Variant Limit Enter a value to set the maximum number of shader variants. If your graph exceeds this maximum value, Unity throws the following error: Validation: Graph is generating too many variants. Either delete Keywords, reduce Keyword variants or increase the Shader Variant Limit in Preferences > Shader Graph. For more information about shader variants, see Making multiple shader program variants. Automatically Add or Remove Block Nodes Toggle either on or off. If this option is on, when changing Graph Settings any needed Block nodes will be added to the Master Stack. Any incompatible Block nodes that have no incoming connections will be removed from the Master Stack. If this option is off, no Block nodes will be added to or removed from the Master Stack. Enable Deprecated Nodes Enable this setting to turn off warnings for deprecated nodes and properties, which also allows you to create older versions of nodes and properties. If you don't enable this setting, Shader Graph displays warnings for deprecated nodes and properties, and any new nodes and properties you create use the latest version."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Feature-Examples.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Feature-Examples.html",
    "title": "Feature Examples | mmo-rpg-unity",
    "keywords": "Feature Examples The Shader Graph Feature Examples sample content is a collection of Shader Graph assets that demonstrate how to achieve common techniques and effects in Shader Graph. The goal of this sample pack is to help users see what is required to achieve specific effects and provide examples to make it easier for users to learn. The sample content is broken into the following categories: Blending Masks - these samples generate masks based on characteristics of the surface - such as height, facing angle, or distance from the camera. Custom Interpolator - here we show how to use the Custom Interpolator feature in Shader Graph to move calculations from the fragment stage to the vertex stage to save performance. Detail Mapping - techniques for adding additional detail to a surface that isn’t contained in the base set of texture maps. Procedural Noise and Shapes - methods for creating shapes or patterns that use math instead of texture samples. Shader Graph Feature Examples - examples of using specific Shader Graph features - such as the Custom Code node or the Custom Interpolator UV Projection - methods of creating texture coordinates to achieve specific effects such as parallax occlusion mapping, or triplanar projection Vertex Animation - techniques for adjusting the position of the vertices to create effects such as waves, animated flags, or camera-facing billboards. Particles - shows how a full-featured particle system can be built using just Shader Graph Conditions - demonstrates branching based on graphics quality setting and based on the active render pipeline. Custom Lighting - shows how Shader Graph can be used to build custom lighting models - including PBR, simple, and cel shading. Blend Masks A major part of creating shaders is determining where specific effects should be applied. This is done by creating a mask and then using the mask to separate areas where the effect should be applied versus where it should not be applied. This set of samples provides examples of various methods of creating these masks. Altitude Mask The Altitude Mask is black below the minimum altitude, transitions from black to white between the minimum and maximum altitudes, and then stays white above the maximum altitude. You can use the AltitudeMask subgraph to create this effect. The Altitude Mask example shows how to use the Altitude Mask subgraph in the shader to blend between two materials. Below the minimum altitude, the cobblestones material is used. Between minimum and maximum, the materials blend from cobblestones to gold, and then above the maximum, the gold material is used. You can use the Falloff Type dropdown on the Altitude subgraph node to select the type of blend ramp to use. Linear will make the mask a direct line from minimum to maximum, while Smoothstep will create smooth transitions using a more S shaped curve. Angle Mask The Angle Mask uses the direction that a surface is facing to determine if the mask should be black or white. If the surface is pointing in the direction of the given input vector, the mask is white. If it’s pointing away from the given vector, the mask is black. The Angle Mask example uses the AngleMask subgraph to generate a mask, and then the mask is used to blend between the cobblestones material and a white, snow-like material. In this example, the AngleMask subgraph node’s MaskVector input is set to 0,1,0 - which is a vector pointing in the up direction (positive Y). When the object’s surface is pointing in that direction, the mask is white. When the surface is pointing away from that direction, the mask is black. The Max and Min input values on the AngleMask subgraph are used to control the falloff of the mask. Both values should use numbers between zero and one. When the Max and Min values are close together (0.5 and 0.48 for example), the falloff will be sharper. When they’re farther apart (0.8 and 0.3 for example), the falloff will be more gradual and blurry. When Max and Min are closer to a value of 1, the surface direction must match the MaskVector much more closely for the mask to be white. When Max and Min are closer to a value of zero, the mask will be white even with a larger difference between the surface direction and the MaskVector. Camera Distance Mask The Camera Distance Mask uses the distance from the camera location to the object’s surface to determine if the mask should be black or white. When the camera is close to the surface, the mask is black and when it’s further away, the mask is white. In this example, we apply the cobblestones material when the camera is close to the object and as the camera moves away we blend to the gold material. The Start Distance and Length values on the CameraDistanceMask subgraph control how the mask functions. The Start Distance value controls where the mask starts the transition from black to white. In this case, it’s set to 2 meters - which means that between 0 and 2 meters, the mask will be black. The Length value controls how long the transition is between black and white. In this case, it’s also set to 2 meters, so from a 2 meter distance to a 4 meter distance the mask will transition from black to white. Any distance beyond 4 meters will create a white mask. Height Mask The Height Mask uses the material height data of two materials to blend them together, creating a much more realistic looking intersection between them. Instead of fading between two materials, we can apply one material in the cracks and crevices of the other. In this example, we use U texture coordinate as a smooth gradient mask, and then modify the mask using the heights of the two materials. Instead of a smooth blend, we end up with the gold material being applied in the lower areas of the cobblestones first and then gradually rising until just the tops of the cobblestones show before being replaced completely by the gold. In order for this effect to work correctly, one or both of the materials need good height data. This type of a transition works best on materials with varying heights - like the cobblestones. Materials that are mostly flat won’t generate interesting effects with this technique. Custom Interpolator The Custom Interpolator feature in Shader Graph allows you to do any type of calculation in the Vertex Stage and then interpolate the results to be used in the Fragment Stage. Doing calculations in the Vertex Stage can give a major performance boost since math is only done once per vertex instead of for every pixel. However, per-vertex calculations can cause artifacts as illustrated in the Artifacts example. Be careful to only do math with low-frequency variations to avoid these artifacts. Interpolation Artifacts This example shows the types of artifacts that can occur when we do math in the vertex stage. In order to be smooth, lighting needs to be calculated at each pixel - but here we’re doing the calculations per-vertex instead and then interpolating the results to the pixels. The interpolation is linear, so we don’t get enough accuracy and the result looks angular and jagged instead of smooth - especially on the specular highlight. Interpolation Savings This example demonstrates a use case where custom interpolators can be highly beneficial. When creating shaders, it's common to tile and offset UVs multiple times. This behavior can become quite costly, especially when scrolling UVs on a fairly large object. For instance, consider a water shader where the water plane covers most of the terrain. Tiling the UVs in the fragment stage means performing the calculation for every pixel the water plane covers. One way to optimize this is to use custom interpolators to calculate the UVs in the vertex stage first and then pass the data to the fragment stage. Since there are fewer vertices than pixels on the screen, the computational cost will be lower. In this case, unlike the Custom Interpolator NdotL example, we do the samping after so that the rendering results are almost unnoticeable. When \"InFragStage\" is set to \"true\", the UVs calculated in the fragment stage are used. When \"InFragStage\" is set to \"false\", the UVs are scrolled in the vertex stage. In this case, scrolling UVs in either the vertex or fragment stages won't cause a noticeable difference in the rendering result. However, it's much more cost-friendly to perform the calculations in the vertex stage and pass the data using custom interpolators. Detail Mapping Detail Mapping refers to a set of techniques where additional detail is added to the surface of a model that is not contained in the model’s base set of textures. These techniques are used when the camera needs to get closer to a model than the resolution of the textures would typically allow, or when the object is so large that the resolution of the base textures is insufficient. In the three Detail Mapping examples, we’re using a texture packing format for our detail texture called NOS - which is short for Normal, Occlusion, Smoothness. This indicates that the Normal is stored in the red and green channels of the texture, the ambient occlusion is stored in the blue channel, and the smoothness is stored in the alpha channel. Packing the data together in this way allows us to get maximum use from our single detail texture - and we can add detail to the color, normal, smoothness, and AO with just a single texture sample. To simplify the process, we use the UnpackDetailNOS subgraph to sample the NOS detail texture and unpack the data. Detail Map Color For the Color Detail Map example, we simply multiply the Albedo output of the UnpackDetailNOS subgraph with the base color texture. The NOS texture format stores ambient occlusion data in the blue channel of the detail texture - and this occlusion data is what the UnpackDetailNOS subgraph passes to the Albedo output port. So for color detail, we’re just multiplying our base color by the detail AO. Notice that the effect is quite subtle. In the past, when detail mapping was a new technique, most surfaces used only color textures - so color detail mapping was the main technique used. Now that materials use normals, smoothness, occlusion, etc, it works much better to use detail mapping for all of the maps instead of just the color. Detail Map Normal For the Detail Map Normal example we combine the Normal output of the UnpackDetailNOS subgraph with the base normal map. Here we’re using the Normal Blend node to combine the two normals together and we have the Reoriented mode selected for best quality. Notice that the Detail Map Normal example is significantly more impactful than the Detail Map Color example. The detail normals are changing the perceived shape of the surface - which has a very strong effect on the lighting, whereas the Color Detail example is only changing the color - which is less effective. This indicates that if you can only apply detail to one of the textures in your material, the normal is the most effective one to add detail to. If you wanted to make this effect slightly cheaper to render, you could set the Normal Blend node to the Default mode instead (which uses the Whiteout normal blend technique instead). For another optimization, you could also set the Quality dropdown on the UnpackDetailNOS subgraph to Fast instead of Accurate. Both of these optimizations together would reduce the number of instructions required to render the effect. The results would be slightly less accurate, but this might not be noticeable. Try it out in your own shaders and see. If you can’t tell the difference, use the cheaper techniques for better performance! Detail Map Full The Detail Map Full example adds detail to the color, normal, ambient occlusion, and smoothness components of the material - so we’re adding additional detail to almost all of the material components. This is the most effective way to add detail to a surface, but also a little more expensive than the Color or Normal examples. Take special note of the way that we’re blending each of the outputs of the UnpackDetailNOS subgraph with their counterparts in the main material. For color, we’re using Multiply - so the detail color data darkens the base color. For Normal, we’re using the Normal Blend node. For Ambient Occlusion, we’re using the Minimum node, so the result is whichever result is darker. We’re using the Minimum node instead of Multiply to prevent the ambient occlusion from getting too dark. And finally, for the smoothness, we’re using Add. This is because the Smoothness data is in the -0.5 to 0.5 range and adding this range to the base smoothness acts like an overlay with darks darkening and brights brightening. Procedural Noise and Shapes In shaders, the term “procedural” refers to techniques that generate shapes and patterns using a series of math formulas - computed in real-time - instead of sampling texture maps. Procedural noise patterns and shapes have various advantages over texture maps including using no texture memory, covering infinite surface area without repetition or tiling, and being independent of texture resolution. Hex Grid A Hexagon grid is useful for all types of projects so we decided to include one in the examples. In the example the Grid output port of the HexGrid subgraph is simply connected to the Base Color of the Master Stack. The HexGrid subgraph also has an EdgeDistance output port and a TileID output port. The Edge Distance output provides a signed distance field value that represents the distance to the nearest hexagon edge. So the pixels right in the center of each hexagon are white and then the closer you get to hexagon edges, the darker the pixels become. The TileID output port provides a different random value for each tile. The HexGrid subgraph node also has some useful input ports. The UV input allows you to control the UV coordinates that are used to generate the pattern. The Scale input gives you control over the dimensions of the effect on both the X and Y axis. Finally, the Line Width input controls the thickness of the grid outlines. Line Width only applied to the Grid output and does not change the output of Edge Distance or TileID. Procedural Brick The Procedural Brick example shows how a brick pattern can be generated using pure math and no texture samples. If you’re developing on a platform that is fast at doing math but slow at texture samples, sometimes it can be much more performant to generate patterns like bricks procedurally rather than by sampling textures. Another advantage is that the variations in the brick patterns don’t repeat - so if you need a pattern to cover a large area without any repetition, procedural generation might be your best option. SDF Shapes Shader Graph comes with a set of nodes for creating shapes procedurally (Ellipse, Polygon, Rectangle, Rounded Rectangle, Rounded Polygon) but frequently developers find that a signed distance field of the shape is more useful than the shape itself. SDFs can be joined together in interesting ways and give developers more flexibility and control in generating results than just having the shape itself. This is why we’ve included these SDF shapes in the examples. Shader Graph Feature Examples The Shader Graph tool has several more advanced features - such as port defaults and Custom Interpolators - that can be tricky to set up. This section contains examples for those features to help users know what is required to set up and use these more advanced features. Subgraph Dropdown When creating a subgraph node, it’s possible to add a dropdown control to allow users to make a selection. This is useful when there are several different methods of achieving a similar result and you want to allow the user of the subgraph to select which method to use. This example illustrates how to add a dropdown box to your subgraph. After creating your subgraph asset, open it in the editor and open the Blackboard panel. Click the plus icon at the top and select Dropdown at the bottom of the list of parameter types. Now give your dropdown a name. Once the dropdown parameter is named, select it and open the Graph Inspector. Here you can control the number and names of the options in the dropdown list. Use the plus and minus icons at the bottom of the list to add and remove items. And click on individual items in the list to change their names. Once you have the number of items you want in the list, go back to the Blackboard and drag and drop your Blackboard parameter into the graph. It will appear as a node with input ports to match the list items you created in the Graph Inspector. For each of the input ports, create a graph that generates the results that you want for that option. The dropdown node acts as a switch to switch between the inputs depending on what is selected with the dropdown. When the subgraph is added to a graph, the user will be able to select an option from the dropdown and the graph will use the branch of the graph that has been selected. Since the branch is static, only the selected branch will be included in the shader at runtime so no additional shader variants will be generated and no performance penalty will be incurred. Subgraph Port Defaults You can use the Branch on Input Connection node to set up defaults for the input ports of your subgraphs and even create large graph trees to use if nothing is connected to a specific input port. The Subgraph Port Defaults example shows how to do that. After creating your subgraph asset, open it in the editor and open the Blackboard panel. Click the plus icon at the top and select a data type. In our example, we selected a Vector 2 type because we’re making an input port for UV coordinates. Once you’ve selected a type, give your parameter a name. We named ours UV. Before adding the parameter to your graph, select it and open the Graph Inspector. In the Graph Inspector, check the “Use Custom Binding” checkbox and give the parameter a Label. This is the name that will show up as connected to the port when no external wires are connected. Now, drag and drop your parameter from the Blackboard into the graph. Next, hit the spacebar and add a Branch on Input Connection node. The node can be found in the Searcher under Utilities->Logic. This node will allow you to set up a default input value or graph branch to use when nothing is connected to the input port. Connect your input parameter’s output port to the Input and Connected input ports of the Branch on Input Connection node. This will allow the input port to function correctly when a wire is connected to it. Now you can connect a node or node tree to the NotConnected input port. Whatever is connected here will be what gets used when nothing is connected to this subgraph’s input port. In our example, we’ve connected the UV node and used the Swizzle node so only the X and Y coordinates are used. So with this setup, UV0 will be used if nothing is connected to the input port. UV Projection UV coordinates are used to translate the 3d surface area of models into 2d space that can be used to apply texture maps. This section contains a set of examples for creating, manipulating, and applying UV coordinates to achieve many different types of effects. Flipbook A flipbook is an effect where a series of frames is played back in sequence. The frames are arranged in a grid pattern on a texture map. Shader Graph has a built-in node that generates the UVs required to jump from one frame to the next on the texture. In this example, we show how to use Shader Graph’s built-in Flipbook node to create an animated effect. We also show that you can use a pair of Flipbook nodes to set up an effect that blends smoothly from one frame to the next instead of jumping. Notice that in the Blackboard, we’ve exposed a Texture parameter for selecting a flipbook texture, Rows and Columns parameters to describe the layout of the flipbook texture, a Speed parameter to control the playback rate of the frames, and a Flip Mode dropdown. With the Flip Mode dropdown, you can select to Flip from one frame to the next, or to Blend between frames. Notice that if you select the Blend option, the playback appears much more smooth even though the frame rate remains the same. Using this Blend mode is a good way to improve the appearance of the effect and make it feel less choppy, even if the frame rate is low. Flow Mapping Flow Mapping is a technique that creates the illusion of flowing movement in a texture. It’s achieved by warping the texture coordinates along a specific flow direction over time in two separate phases. When the warping of the first phase becomes too severe, we blend to the second phase which is not yet warped and then warp that while removing the warping from the first phase while it is not displayed. We can blend back and forth between the two phases over and over to create the illusion of motion. In the example, we’re using the UVFlowMap subgraph which does the main work of the effect. We give it a Flow Map - which is the direction to push the movement. In our case we’ve used a texture (similar to a normal map) to specify the direction. Then we give it a Strength value - which controls the distance that the UVs get warped. Flow Time can be as simple as just the Time node, but you can also connect a Flow Map Time subgraph which varies the time in different areas to break up the strobing effect. The UV input controls how the texture is applied. Notice that we’re using a Tiling And Offset node here to tile the texture 8 times. And finally the Offset value controls the midpoint of the stretching effect. The default value of 0.5 means that each of the phases starts out half stretched in the negative direction, moves to unstretched, and then moves to half stretched in the positive direction. This will give the best results in most cases. In our example, we have exposed a Temporal Mode dropdown which illustrates the usefulness of the Flow Map Time subgraph. When Temporal Mode is set to Time Only, we’re only using Time as the Flow Time input. There is a noticeable strobing effect where the entire model appears to be pulsing in rhythm. This is because the blending between phase 1 and phase 2 is happening uniformly across the whole surface. When we set Temporal Mode to Flow Map Time, we’re using the Flow Map Time subgraph as the Flow Time input. The Flow Map Time subgraph breaks up the phase blending into smooth gradients across the surface so that it’s non-uniform and removes the strobing effect. Interior Cube Mapping Interior Cube Mapping is a technique that creates the illusion of building interiors as seen through windows where no interior mesh exists. The effect can be used to make very simple exterior building meshes appear to have complex interiors and is much cheaper than actually modeling interiors. In our example, the UVInteriorCubemap subgraph generates the direction vector that we need for sampling our cube map. The cube map creates the illusion of the interiors. And then the rest of the graph creates the exterior building and windows. The UVInteriorCubemap subgraph has inputs for specifying the number of windows and controlling whether or not to randomize the walls of the cube map. The randomization rotates the walls of the cube map so that each interior has different walls on the sides and back. There is also a dropdown for controlling whether the projection is happening in object space or in UV space. Lat Long Projection The Lat Long Projection example demonstrates the math required to use a texture map in the Latitude Longitude format. Many high dynamic range environment images are stored in this format so it’s useful to know how to use this type of image. You can tell an image is in LatLong format because it has a 2 to 1 aspect ratio and usually has the horizon running through the middle. In our example, we’re using the UVLatLong subgraph. This node generates the UV coordinates needed to sample a texture map in the LatLong format. By default, the UVLatLong subgraph uses a reflection vector as input - so the result acts like a reflection on the surface of your model. But if you wanted the result to be stuck to the surface instead, you could use the Normal Vector. If you select the Sample Texture 2D node and open the Graph Inspector, notice that the Mip Sampling Mode is set to Gradient. With that setting, the Sample Texture 2D node has DDX and DDY input ports - which we have connected to the DDX and DDY nodes. We’re doing this because the texture coordinates generated for the LatLong projection have a hard seam where the left and right sides of the projection wrap around and come together. If we were to set the Mip Sampling Mode to Standard instead, we would end up with a hard seam where the texture sampler failed because there is a large discontinuity in the mip values of the texture coordinates. The Gradient Mip Sampling Mode allows us to manually calculate our own mip level with the DDX and DDY nodes instead of allowing the sampler to do it. Mat Cap (Sphere Mapping) The Mat Cap Material example demonstrates the math required to project a sphere map onto a surface. This effect is often called a Mat Cap - or material capture, because you can represent the properties of a material - like reflections or subsurface scattering - in the way the texture is created. Some 3d sculpting software uses MatCap projection to render objects. You can tell that a texture is a sphere map (or MatCap) because it looks a bit like a picture of a chrome ball. Sphere maps are the cheapest form of reflection - both in texture memory and in the low cost of math. But they’re not accurate because they always face the camera. In our example, we’re using the UVSphereMap subgraph to generate the texture coordinates to sample the sphere map. The subgraph has an input for the surface normal - and you can use the dropdown to select the space that the normal is in. By default, the Vertex Normal is used, but you could also connect a normal map to it if you wanted to give the surface more detail. Parallax Mapping There are many techniques that attempt to add more detail to the shape of a surface than is actually represented in the geometry of the surface. The Parallax Mapping example demonstrates three of these examples, and you can select which example to display with the Bump Type dropdown box in the material. Normal Only This technique is the cheapest and most common. It uses a normal map to change the apparent shape of the surface - where each pixel in the map represents the direction that the surface is facing at that point. Because there is no offsetting of the surface happening, this technique also looks fairly flat compared to the other two. Parallax Parallax Mapping samples a height map and then uses the value to offset the UV coordinates based on their height relative to the view direction. This causes parallax motion to occur on the surface and makes the surface feel like it has actual depth. However, when seen at steep angles, the effect often has artifacts. Where there are steep changes in the height map, there are visible stretching artifacts. Parallax Occlusion Parallax Occlusion Mapping samples a height map multiple times (based on the number of Steps) in a path along the view vector and reconstructs the scene depth of the surface. It uses this depth information to derive UV coordinates for sampling the textures. This process is expensive - especially with a high number of Steps, but can be made cheaper by creating a mask to reduce the number of Steps based on the camera distance and angle of the surface. Our example illustrates this technique. Triplanar Projection Triplanar projection projects a texture onto the surface of a model from the front, side, and top. It’s useful when you want to apply a texture but the model doesn’t have good UV coordinates, or when the UVs are laid out for something else. It’s also useful when you want to project the same texture or material on many objects in close proximity and have the projection be continuous across them. There are several methods for projecting a texture onto a surface. Our example shows four of them and you can select the method you want to see using the Projection Type dropdown in the material. They’re in order from most expensive to least. Triplanar Texture projection The Triplanar Textures technique uses the built-in Triplanar node in Shader Graph. This node samples each of your textures three times - for the top, front, and side projections and then blends between the three samples. This technique is the nicest looking since it blends between the samples, but it’s also the most expensive. Biplanar Texture projection This is a clever optimization to triplanar projection that uses two texture samples instead of three. The shader figures out which two faces are most important to the projection and only samples those two instead of all three. On most platforms, it will be cheaper than Triplanar Textures, but more expensive than Triplanar UVs. Depending on the textures you’re sampling, you may notice a small singularity artifact at the corner where the three faces come together. Triplanar UV projection The Triplanar UVs technique uses the UVTriplanar subgraph to project the UV coordinates from the top front and side and then use those to sample the textures only one time instead of three. Because it’s only sampling each texture one time, this technique is cheaper. The UV coordinates can’t be blended like the textures can - so this technique has hard seams where projections come together instead of blending like the Triplanar Textures technique. However, these seams aren’t very noticeable on some materials, so this may be an acceptable alternative if you need to do triplanar projection more cheaply. Notice that the normal map needs to be plugged into the UVTriplanarNormalTransform node when using this technique in order to get the normals transformed correctly. UV This option just applies the textures using standard UV coordinates. It’s here so that you can easily compare it with the other two techniques. Vertex Animation Generally, we think of shaders as changing the color and appearance of pixels. But shaders can also be applied to vertices - to change the position of the points of a mesh. The model’s vertices can be manipulated by a shader to create all sorts of animated effects - as shown in this section. Animated Flag This example shows a simple method for making a flag that ripples in the wind. The effect centers around the Sine node - which is what creates the rippling motion. We take the X position of the vertices and multiply them by a value that controls the length of the waves. We multiply that by Time and then pass that into the Sine node. Finally, we multiply the result of the Sine wave with a mask that goes from 0 at the point where the flag attaches to the pole, 1 at the tip of the flat where the effect should be strongest. The result is a simple rippling flag. You could add additional detail to this effect if you combined several different sine waves that move at different speeds and wavelengths to vary and randomize the results. But something as simple as this example may be all that is needed if your flag is seen at a distance. Bend Deformer - Grass This example shows the math required to bend a rectangle-shaped strip in an arc shape without changing its length. This can be used for animating blades of grass. The BendDeformer subgraph adjusts both the position and the normal of the vertices - so we get proper lighting on the updated shape. Billboard The billboard example illustrates the math that we use to make a flat plane face the camera. Notice that the Billboard subgraph has a dropdown that allows us to select the initial direction that our plane is facing. Selecting the correct option here will ensure that our plane turns toward the camera correctly and not some other direction. Gerstner Wave In this example, we use several instances of the GerstnerWave subgraph to animate waves in our mesh. The GerstnerWave subgraph does the math required to realistically simulate the movement of a single wave. Notice that each of the three instances has a different direction, wave length, and wave height. Combining these three different wave sizes together creates a really nice-looking wave simulation. The Offset values are added together and then added to the Position. The normals are combined using the Normal Blend node and then used directly as the Normal. Particles This example shows that it’s possible to create a simple particle system using nothing but Shader Graph! This method of creating particles is cheap because it’s done 100% on the GPU and almost all of the shader work happens in the vertex shader. This shader is not intended as a replacement for any of the other particle systems in Unity, but simply as an illustration of what’s possible to do with just Shader Graph alone. It could potentially be cheaper to make simple particle effects using this shader than with other methods. It’s definitely not as powerful or as full-featured as something made with VFX Graph, for example. We start by creating a stack of planes where each plane in the stack has a slightly different vertex color. We use this value as an ID to differentiate each plane in the stack. This sample set comes with 3 stacks of planes that can be used. One with 25 planes, one with 50 planes, and one with 100 planes. Note that most particle systems dynamically generate particles based on the number that the system needs, but we’re using static geometry, so we’re locked in to using the number of planes in the geometry we choose. If the system we create with the material parameters requires more particles, the only way to fix it is to swap out the mesh that we’re using - so this is one major downside to this method. We use the Billboard subgraph to make all of the planes face the camera and we use the Flipbook node to add an animated effect to the particles. We also add gravity and wind to control the movement of the particles. In the pixel shader, we expose control over the opacity and even fade out particle edges where they intersect with other scene geometry. Here’s a description of the exposed material parameters that control the appearance and behavior of the particles: Emitter Dimensions - controls the size of the particle emitter in X,Y, and Z. Particles will be born in random locations within the volume specified by these dimensions. Color This is a color value that gets multiplied by the FlipbookTexture color. The StartColor blends to the EndColor throughout the lifetime of the particle. The alpha value of the color gets multiplied by the alpha value of the FlipbookTexture to contribute to the opacity of the particles. Start Color - the color multiplier for the particle at the beginning of its life EndColor - the color multiplier for the particle at the end of its life Opacity These controls change the opacity/transparency behavior of the particles. Opacity - the overall opacity multiplier. Values above one are acceptable and can make subtle particles more visible. FadeInPower - controls the falloff curve of the particle fade-in. FadeOutPower - controls the falloff curve of the particle fade-out. SoftEdges - enables the soft edges feature which fades out the particles where they intersect with scene geometry. AlphaClipThreshold - controls the opacity cut-off below which pixels are discarded and not drawn. The higher this value is, the more pixels can be discarded to reduce particle overdraw. Scale Controls the size of the particles. Particles transition from the ParticleStartSize to the ParticleEndSize over their lifetime. ParticleStartSize - the size of the particle (in meters) when it is born. ParticleEndSize - the size of the particle (in meters) when it dies. Movement These controls affect the movement of the particles. ConstantFlow - the smoothness of the flow of the particles. A value of 1 distributes particle flow evenly over time. A value of 0 spawns all of the particles and once right at the beginning of the phase. Values in between make particle birthrate/flow more random and hitchy. ParticleSpeed - controls the overall speed of the particles ParticleDirection - the main direction of particle movement ParticleSpread - the width of the particle emission cone in degrees. A value of 0 will emit particles in single direction and a value of 360 will emit particles in all directions (a sphere) ParticleVelocityStart - controls how fast the particles are moving when they’re first born. ParticleVelocityEnd - controls how fast the particles are moving when they die. Rotation Controls the rotation behavior of the particles. Rotation - the static amount of rotation to apply to each particle in degrees. RotationRandomOffset - when checked, applies a random rotation amount to each particle RotationSpeed - the speed of rotation of each particle RandomizeRotationDirection - when true, each particle randomly either goes clockwise or counterclockwise. Flipbook Controls the behavior of the animated texture that is applied to the particles. FlipbookTexture - the flipbook texture to apply to the particles FlipbookDimensions - the number of rows and columns in the selected flipbook texture FlipbookSpeed - the playback frame rate of the flipbook. MatchParticlePhase - when true, the first frame of the flipbook will play when the particle is born and the last frame will play just before the particle dies - so the flipbook playback length will match the particle’s lifetime. Forces Control the external forces that affect the particle movement. Gravity - the pull of gravity on the particles. This is typically 0,-9.8, 0 - but some types of material, such as smoke or mist may be warm or lighter than air, which would cause them to move upward instead of getting pulled down by gravity. Wind - the direction and strength of the wind. Debug These controls allow you to debug specific parts of the particle system. DebugTime - When true, allows you to scrub time backwards and forward manually with the ManualTime slider. ManualTime - when DebugTime is true, you can use this slider to scrub time backwards and forward to see how the particles behave at different points during their lifetime. Conditions This section illustrates two ways to branch your shader. Branch On Render Pipeline Shader Graph allows you to create shaders that can be used in multiple render pipelines- Built-In, URP, and HDRP. This can be done by opening the shader in Shader Graph and adding the targets for all of the pipelines you want the shader to support in the Active Targets section under Graph Settings in the Graph Inspector window. When supporting multiple render pipelines, it’s occasionally necessary to do different things in the graph depending on which pipeline is being used. In order to do that, you need to branch the shader based on the active render pipeline. There isn’t an official node in Shader Graph for performing that branching operation, but it is possible to create a subgraph that contains a Custom Function node that does the branch. In this example, we use that Branch On RP to create a different outcome depending which render pipeline is active. In our simple example, we just make the cube a different color - green for URP, blue for HDRP, and yellow for the Built-In render pipeline - but you can do much more complex operations that are specific to each render pipeline using this same technique. Branch On Material Quality With Shader Graph, you can create one shader that has multiple different ways of achieving the same effect depending on how much GPU processing power you want to dedicate to it. This example illustrates that. We show three different methods of combining two normal maps together. The first method (at the top of the graph) is using the Normal Blend node set to Reoriented mode. This is the most accurate method that provides the best looking results, but it also requires the most compute power. The second method (in the middle of the graph) is almost as nice and a little bit cheaper. The third method (at the bottom of the graph) is the cheapest and produces the lowest quality result. On the right side of the graph, you can see that the three different methods are connected to the Material Quality node. You can add a Material Quality node by opening the Blackboard and selecting Keyword->Material Quality from the add menu. Then drag the Material Quality parameter from the Blackboard into your graph. This node will select the top, middle, or bottom part of the graph depending on the Quality level that is selected. In HDRP, the Quality setting is defined by the Default Material Quality Level setting found in the Material section of the HD Render Pipeline Asset. So for each Quality level, you define a pipeline asset, and that asset has the setting that controls which quality level the shader uses. In a URP project, you can use the SetGlobalShaderKeywords command in the script that gets run when the user selects options in the application’s UI. For example, the following command will set Material Quality to High: MaterialQualityUtilities.SetGlobalShaderKeywords( MaterialQuality.High ); Using the Material Quality node in Shader Graph enables you to provide the user with the ability to customize their experience in the application. They can choose to see higher quality visuals at a lower frame rate, or lower-quality visuals at a higher frame rate. And you control what these options do in the shader itself."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Decal.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Decal.html",
    "title": "Decals | mmo-rpg-unity",
    "keywords": "Decals Decals allow you to apply local material modifications to specific places in the world. You might think of things like applying graffiti tags to a wall or scattering fallen leaves below a tree. But decals can be used for a lot more. In these examples, we see decals making things look wet, making surfaces appear to have flowing water across them, projecting water caustics, and blending specific materials onto other objects. Decals are available to use in both HDRP and URP, but they need to be enabled in both render pipelines. To use decals, refer to the documentation in both HDRP and URP. Material Projection This decal uses triplanar projection to project a material in 3D space. It projects materials correctly onto any mesh that intersects the decal volume. It can be used to apply terrain materials on to other objects like rocks so that they blend in better with the terrain. Water Caustics When light shines through rippling water, the water warps and focuses the light, casting really interesting rippling patterns on surfaces under the water. This shader creates these rippling caustic patterns. If you place decals using this shader under your water planes, you’ll get projected caustics that imitate the behavior of light shining through the water. Running Water This decal creates the appearance of flowing water across whatever surfaces are inside the decal. It can be used on the banks of streams and around waterfalls to support the appearance of water flowing. With material parameters, you can control the speed of the water flow, the opacity of both the wetness and the water, and the strength of the flowing water normals. Water Wetness The wetness decal makes surfaces look wet by darkening color and increasing smoothness. It uses very simple math and no texture samples so it is very performance efficient. It can be used along the banks of bodies of water to better integrate the water with the environment."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Detail.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Detail.html",
    "title": "Production Ready Shaders | mmo-rpg-unity",
    "keywords": "Production Ready Shaders The Shader Graph Production Ready Shaders sample is a collection of Shader Graph shader assets that are ready to be used out of the box or modified to suit your needs. You can take them apart and learn from them, or just drop them directly into your project and use them as they are. The sample also includes a step-by-step tutorial for how to combine several of the shaders to create a forest stream environment. The sample content is broken into the following categories: Lit shaders - Introduces Shader Graph versions of the HDRP and URP Lit shaders. Users often want to modify the Lit shaders but struggle because they’re written in code. Now you can use these instead of starting from scratch. Decal shaders - Introduces shaders that allow you to enhance and add variety to your environment. Examples include running water, wetness, water caustics, and material projection. Detail shaders - Introduces shaders that demonstrate how to create efficient terrain details that render fast and use less texture memory. Examples include clover, ferns, grass, nettle, and pebbles Rock - A robust, modular rock shader that includes base textures, macro and micro detail, moss projection, and weather effects. Water - Water shaders for ponds, flowing streams, lakes, and waterfalls. These include depth fog, surface ripples, flow mapping, refraction and surface foam. Post-Process - Shaders to add post-processing effects to the scene, including edge detection, half tone, rain on the lens, an underwater look, and VHS video tape image degradation. Weather - Weather effects including rain drops, rain drips, procedural puddles, puddle ripples, and snow Miscellaneous - A couple of additional shaders - volumetric ice, and level blockout shader. Lit Shaders Both URP and HDRP come with code-based shaders. The most commonly used shader for each of the SRPs is called Lit. For projects that use it, it’s often applied to just about every mesh in the game. Both the HDRP and URP versions of the Lit shader are very full-featured. However, sometimes users want to add additional features to get just the look they’re trying to achieve, or remove unused features to optimize performance. For users who aren’t familiar with shader code, this can be very difficult. For that reason, we’ve included Shader Graph versions of the Lit shader for both URP and HDRP in this sample pack. Users will be able to make a copy of the appropriate Shader Graph Lit shader, and then change any material that’s currently referencing the code version of the Lit shader with the Shader Graph version. All of the material settings will correctly be applied and continue to work. They’ll then be able to make changes to the Shader Graph version as needed. Please note that most but not all of the features of the code-based shaders are duplicated in the Shader Graph versions. Some lesser-used features may be missing from the Shader Graph versions due to the differences in creating shader with Shader Graph vs creating them with code. Also note - If you’re going to use the Lit shader as is, we recommend sticking with the code version. Only swap out the shader for the Shader Graph version if you’re making changes. We also recommend removing unused features from the Shader Graph version for better performance. For example, if you’re not using Emissive or Detail Maps, you can remove those parts of the shader (both graph nodes and Blackboard parameters) for faster build times and better performance. The real power of Shader Graph is its flexibility and how easy it is to change, update, and improve shaders. URP Lit Just like the code version, this shader offers the Metallic workflow or the Specular workflow. Shaders can be either opaque or transparent, and there are options for Alpha Clipping, Cast Shadows, and Receive Shadows. For the main surface, users can apply a base map, metallic or specular map, normal map, height map, occlusion map, and emission map. Parameters are available to control the strength of the smoothness, height, normal, and occlusion and control the tiling and offset of the textures. Users can also add base and normal detail maps and mask off where they appear using the mask map. For more details on each of the parameters in the shader, see the Lit Shader documentation for URP. Shader Variant Limit In order to be able to use this shader, you’ll need to increase the Shader Variant Limit to at least 513. This should be done on both the Shader Graph tab in Project Settings as well as the Shader Graph tab in the Preferences. Custom Editor GUI In order to create a more compact and user-friendly GUI in the material, this shader uses the same Custom Editor GUI that the code version of the Lit shader uses. Open the Graph Inspector and look at the Graph Settings. At the bottom of the list, you’ll see the following under Custom Editor GUI: UnityEditor.Rendering.Universal.ShaderGUI.LitShader This custom GUI script enables the small texture thumbnails and other features in the GUI. If you need to add or remove parameters in the Blackboard, we recommend removing the Custom Editor GUI and just using Shader Graph’s default material GUI instead. The custom GUI depends on the existence of many of the Blackboard parameters and won’t function properly if they’re removed. HDRP Lit Just like the code version, this shader offers opaque and transparent options. It supports Pixel displacement (Parallax Occlusion mapping) and all of the parameters that go with it. (It does not support Material Types other than standard.) For the main surface, users can apply a base map, mask map, normal map, bent normal map, and height map. Options are also available to use a detail map and emissive map. For more details on each of the parameters in the shader, see the Lit Shader documentation for HDRP. Custom Editor GUI In order to create a more compact and user-friendly GUI in the material, this shader uses the same Custom Editor GUI that the code version of the Lit shader uses. Open the Graph Inspector and look at the Graph Settings. At the bottom of the list, you’ll see the following under Custom Editor GUI: Rendering.HighDefinition.LitGUI This custom GUI script enables the small texture thumbnails and other features in the GUI. If you need to add or remove parameters in the Blackboard, we recommend removing the Custom Editor GUI and just using Shader Graph’s default material GUI instead. The custom GUI depends on the existence of many of the Blackboard parameters and won’t function properly if they’re removed. Decals Decals allow you to apply local material modifications to specific places in the world. You might think of things like applying graffiti tags to a wall or scattering fallen leaves below a tree. But decals can be used for a lot more. In these examples, we see decals making things look wet, making surfaces appear to have flowing water across them, projecting water caustics, and blending specific materials onto other objects. Decals are available to use in both HDRP and URP, but they need to be enabled in both render pipelines. To use decals, see the documentation in both HDRP and URP. Material Projection This decal uses triplanar projection to project a material in 3D space. It projects materials correctly onto any mesh that intersects the decal volume. It can be used to apply terrain materials on to other objects like rocks so that they blend in better with the terrain. Water Caustics When light shines through rippling water, the water warps and focuses the light, casting really interesting rippling patterns on surfaces under the water. This shader creates these rippling caustic patterns. If you place decals using this shader under your water planes, you’ll get projected caustics that imitate the behavior of light shining through the water. Running Water This decal creates the appearance of flowing water across whatever surfaces are inside the decal. It can be used on the banks of streams and around waterfalls to support the appearance of water flowing. With material parameters, you can control the speed of the water flow, the opacity of both the wetness and the water, and the strength of the flowing water normals. Water Wetness The wetness decal makes surfaces look wet by darkening color and increasing smoothness. It uses very simple math and no texture samples so it is very performance efficient. It can be used along the banks of bodies of water to better integrate the water with the environment. Details In this context, Details refer to meshes that are added to terrain - such as grass, weeds, undergrowth, pebbles, etc. To learn more, read the terrain documentation on details. Detail meshes have some specific requirements for shaders. First, because of the high number of these meshes used on the terrain, we have to make their shaders as fast and efficient as possible. That mainly means keeping the number of texture samples low and doing more work in the vertex shader instead of the pixel shader. And second, because these meshes stop rendering and pop out at a specific distance, we have to use a method to dissolve them out to prevent the harsh pop and make it less obvious that they’re being removed. In each of the shaders, you’ll see the Distance Mask or Distance Cutoff node used to create a mask that dissolves away the mesh at a distance before the mesh stops rendering. Clover The shader for the clover uses just one single channel texture to reduce cost and save texture memory. Color is generated by lerping between a bright color and a dark color using the greyscale value from the texture. Each instance of clover uses a slightly different color variation. We generate a random value based on the position of each instance and that's used to give each instance a color variation. The Distance Mask is calculated in the vertex shader to save performance and then passed to the pixel shader where it’s combined with the texture and some screen space noise. Together, these elements are passed into the Fade Transition node which makes the mesh dissolve between the Clip Offset and Clip Distance values. Ferns The fern shader uses a color, normal, and mask texture to define the fern material. It animates the ferns based on wind settings. It also creates a subsurface scattering effect so that the fern fronds are illuminated on the reverse side from the sunlight. For ambient occlusion, we darken the AO close to the ground. As with the other detail shaders, we also dissolve the fern as we move away to prevent it from popping out. Grass Usually, grass is created with billboards using a grass texture. This shader is different. We use mesh for each individual blade of grass. To keep the meshes as cheap as possible, our grass blade meshes have only 12 vertices and 10 triangles. They don’t have UV coordinates, normals, or vertex colors - so the only data stored in the mesh is position. The meshes are as simple as they can possibly be. We also do as much work as possible in the vertex shader for lower cost. Wind, color, translucency, and distance fade are all calculated in the vertex shader. The shader generates wind forces and then uses them to bend the blades of grass. The wind forces vary in direction and gust strength so the movement of the blades feels natural. Nettle The nettle shader is for simple, broad-leaf undergrowth. It’s a variation of the fern shader - so it has similar features. The main difference is that it has been adapted to only use one texture sample to reduce both texture memory usage and shader cost. The texture has the normal X and Y in the red and green channels. The blue channel is a combination of the opacity and a grayscale mask that is used to modulate smoothness, AO, and color. Pebbles As with the rest of the detail shaders, the pebble shader is designed to be as cheap as possible. It only uses one small noise texture. It creates color variation using the noise texture and the instance IDs so that each pebble cluster has its own unique color. And it fades the pebbles out at a distance to prevent popping. Rock This is a full-featured, modular rock shader that can be used for everything from small pebbles to boulders up to large cliff faces. It has features that can be turned on and off in the material depending on the application. Each of the features is encapsulated in a subgraph so it’s easy to remove features that you don’t need. You can also add new features in the chain of modules if you need something else. Each module takes in color and smoothness in one input port and normal and ambient occlusion in a second input. Inside the subgraph, it alters these, and then it outputs the result again in the same format - color and smoothness in the first output port, and normal and AO in the second. Using this input/output port format keeps all of the modules organized and in a nice, neat line. To help with performance, the shader has an LOD0 boolean parameter exposed to the material. For materials applied to LOD0 of your rocks, this should be true. For materials applied to the other LODs, this boolean should be false. This feature turns off extra features that are only visible when the rock is close so that non-LOD0 versions of your rocks render faster. Additionally, this shader branches using the Material Quality built-in enum keyword. This means that the shader is already set up to create a low quality, medium quality, and high quality version of itself depending on project settings. Features will be turned on and off, or different variations of features will be used depending on the project’s Material Quality setting. Base Textures In order to reduce the total number of texture samples in the shader (sampling textures is the most expensive operation that shaders do, so reducing the number of texture samples can significantly improve shader performance), we’ve used a two-texture format for our base textures instead of 3. The format is as follows: CS Texture (BC7 format) - RGB - color, Alpha - smoothness NO Texture (BC7 format) - RGB - normal, Alpha - ambient occlusion Note that the NO texture is NOT saved as a normal map. If you set it to be a normal map, the ambient occlusion data in the alpha channel will be lost. Macro Detail The purpose of the Macro Detail module is to add large-scale details to the color, smoothness, normal, and ambient occlusion of the rock’s base material. For rocks that are large, a single texture set is often not high enough resolution and the base textures look blurry or blocky, even from a distance. The Macro Detail module solves this problem. For rocks that are smaller than 1 meter cubed, this feature should be turned off by unchecking Rock Features/MarcoDetail in the rock’s material. This feature references a texture - Rock_Macro_NOS - which you are welcome to use, or you can create your own. The texture format is as follows: R: normal X G: normal Y B: ambient occlusion A: smoothness/color overlay This texture needs to be set to Default 2D format with Compression set to High Quality. It is recommended to just use one single macro detail texture for all of the rocks in your project both to save on texture memory and to maintain a consistent visual style. For this reason, the texture itself is not exposed as a material parameter but is set directly in the shader. Color Projection For large boulders and cliff faces, you may want to add colored effects to the rocks such as bleaching. The Color Projection module can handle this. It projects color alterations using world space. The nice thing about this effect is that if your rock formation is made up of multiple rocks all jammed together, the color projection will tie them together and make them feel more cohesive - as if they’re one unified formation rather than just a collection of jammed-together rocks. This effect does use 5 texture samples, so if you don’t need it, or if you’re on a very performance sensitive platform such as a mobile device, you should definitely turn it off in the material to improve performance. Micro Detail The purpose of the Micro Detail module is to add small-scale details to the color, smoothness, normal, and ambient occlusion of the rock’s base material. When you get really close to the rocks, sometimes the resolution of the base textures is not high enough and they look blurry or blocky. The Micro Detail module solves this problem by adding very high resolution micro detail to the rock surface. This feature references a texture - Rock_Micro_NOS - which you are welcome to use, or you can create your own. The texture format is as follows: R: normal X G: normal Y B: ambient occlusion A: smoothness/color overlay This texture needs to be set to Default 2D format with Compression set to High Quality. It is recommended to just use one single micro detail texture for all of the rocks in your project both to save on texture memory and to maintain a consistent visual style. For this reason, the texture itself is not exposed as a material parameter but is set directly in the shader. Deposition Moss The Deposition Moss module applies moss to the tops of the rocks. To define the moss, it uses a Moss_CO texture (color with occlusion in the alpha channel) and a Moss_N texture (normal). The alpha channel of the Moss_CO texture is also used to create smoothness. It’s also possible to use this module to apply other types of materials to the tops of the rocks - such as sand, ash, snow, etc. To do that, you’d just need to set the Deposition Moss module to use textures for your chosen material instead. These textures are not exposed to the material, but they are available to be changed on the module. Rain When the IsRaining parameter is set to 1, the Rain module applies rain effects to the rocks, including animated rain drops on the tops of the rocks, and drips running down the sides of the rocks. The module also makes the rocks look wet. Water The sample set comes with four different water shaders. Each one uses reflection, refraction, surface ripples using scrolling normal maps, and depth fog. Each also uses a few additional features that are unique to that type of water. WaterLake This is the simplest water shader of the group. Because it’s meant to be applied to larger bodies of water, it has two different sets of scrolling normals for the surface ripples - one large, one small - to break up the repetition of the ripples. It also fades the ripples out at a distance both to hide the tiling patterns and to give the lake a mirror finish at a distance. WaterSimple_FoamMask This shader is intended to be used on ponds or other small bodies of non-flowing water. It uses 3 Gerstner waves subgraphs to animated the vertices in a chaotic wave pattern. It also adds foam around the edges of the water where it intersects with other objects. The unique thing about the foam implementation in this shader is that it allows you to additionally paint a texture mask that determines where foam can be placed manually. This manual placed foam could be used for a spot where a waterfall is hitting the water - for example. WaterStream The water stream shader is intended to be used on small, flowing bodies of water. Instead of standard scrolling normal maps for ripples, it uses flow mapping to make the water flow slowly along the edges of the stream and faster in the middle. It also uses the same animated foam technique as the WaterSimple shader - but without the mask. This shader uses the puddle_norm texture. Notice that we save a little bit of shader performance by NOT storing this texture as a normal map. After the two samples are combined, then we expand the data to the -1 to 1 range, so we don’t have to do it twice. WaterStreamFalls This is the same shader as the WaterStream, but it’s intended to be used on a waterfall mesh. It fades out at the start and the end of the mesh so that it can be blended in with the stream meshes at the top and bottom of the falls, and it adds foam where the falls are vertical. Post-Process The post process shaders can be used to apply modifications to the rendered image once the scene has been drawn. Edge Detection The edge detection shader checks the four neighboring pixels to the current one to find “edges” or places where the normal or depth has changed rapidly. It creates a mask where edges exist and then uses the mask to blend between the original scene color and the edge color. Half Tone The halftone shader turns the rendered image into a halftone image - simulating the pattern of larger and smaller circle patterns that you might see in newsprint or comic books. First it generates a procedural grid of signed distance field circles - one for each of red, green, and blue. Then it uses inverse lerp to convert the SDF circle grid into dots - where the size of the dot represents the brightness of the color at that location. Finally it combines the red, green, and blue dot grids into one color. Rain On Lens The rain-on-the-lens post process shader applies refraction to the rendered scene as if there were rain on the camera lens - so some areas of the image are warped by rain drops and other areas are distorted by drips running down the screen. Underwater The underwater post process shader makes the scene look like it’s under water by applying several effects including blurring the screen around the edges, distorting the image is large, ripple patterns, and applying a blue/green fog based on the scene depth. VHS The VHS post process shader mimics the appearance of the scene being played back on an old VHS video cassette recorder. Artifacts include scan line jitter, read head drift, chromatic aberration, and color degradation in the YIQ color space. Weather This sample comes with a full set of weather-related subgraphs (rain and snow) that can be mixed and matched depending on the requirements of the object type they’re applied to. Rain There are several subgraphs that generate rain effects. Each has a different subset of the available rain effects. Applying all of the effects at once is a bit expensive on performance, so it’s best to choose the option with just the effects you need for the specific type of object/surface. Rain The Rain subgraph combines all of the rain effect - drops, drips, puddles, wetness - to create a really nice rain weather effect - but it’s the most expensive on performance. Puddles are a bit expensive to generate as are drips, so this version should only be used on objects that will have both flat horizontal surfaces as well as vertical surfaces. Rain Floor The Rain Floor subgraph creates puddle and drop effects, but it does not have the drip effects that would run down vertical surfaces. This subgraph is best used for flat, horizontal surfaces. Rain Props The Rain Props subgraph has the drop and drip effects but does not include the puddles. It’s best for small prop objects. Rain Rocks The Rain Rocks subgraph has been specifically tuned for use on rocks. It includes drips and drops, but not puddles. It also includes the LOD0 parameter that is meant to turn off close-up features on LODs other than the first one. Components Puddles The puddles subgraph creates procedurally-generated puddles on flat, up-facing surfaces. It outputs a mask that controls where the puddles appear and normals from the puddles. It uses the PuddleWindRipples and RainRipples subgraph to generate both wind and rain ripples in the puddles. PuddleWindRipples The PuddleWindRipples subgraph creates puddle wind ripples by scrolling two normal map textures. It’s used by the Puddles subgraph. Rain_Drips This subgraph creates drips that drip down the sides of an object. The drips are projected in world space, so they work well for static objects but are not meant for moving objects. The speed of the drips is controlled by the permeability of the material. Smooth, impermeable surfaces have fast moving drips while permeable surfaces have slow-moving drips. Rain_DripsOnTheLens This subgraph is very similar to the Rain_Drips subgraph, but it’s adapted to work correctly for the RainOnTheLens post-process shader. Rain_Drops This subgraph applies animated rain drops to objects. The drops are projected in world space from the top down. Because of the world space projection, these rain drops are not designed to be added to objects that move in the scene but instead should be used for static objects. The IsRaining input port turns the effect on and off (when the input value is 1 and 0). Rain_Parameters A common set of rain parameters used by most of the rain subgraphs. Setting parameters once in this subgraph means you don’t have to set them all over in multiple places. RainDropsOnTheLens This subgraph is very similar to the RainDrops subgraph, but it’s adapted to work correctly for the RainOnTheLens post-process shader. RainRipple Creates an animated circular ripple pattern. This subgraph is used multiple times in the RainRipples subgraph to create a really nice-looking pattern of multiple overlapping ripples. RainRipples The RainRipples subgraph creates ripples from rain drops in a puddle or pool of water. It combines four instances of the RainRipple subgraph (each with its own scale, position, and timing offset) to create the chaotic appearance of multiple ripples all happening at once. It’s used by the Puddles subgraph to add rain ripples to the puddles. Wet This subgraph makes surfaces look wet by darkening and saturating their base color and by increasing their smoothness. The effect is different depending on how permeable the surface is. Snow The Snow subgraph creates a snow effect and applies it to the tops of objects. The snow material includes color, smoothness, normal, metallic, and emissive - where the emissive is used to apply sparkles to the snow. Miscellaneous shaders Blockout Grid Apply this simple shader to a 1 meter cube. You can then scale and stretch the cube to block out your level. The grid projected on the cube doesn't stretch but maintains its world-space projection so it's easy to see distances and heights. It's a great way to block out traversable paths, obstacles, and level layouts. Turn on the EnableSlopeWarning parameter to shade meshes red where they’re too steep to traverse. Ice This ice shader uses up to three layers of parallax mapping to create the illusion that the cracks and bubbles are embedded in the volume of the ice below the surface though there is no transparency or actual volume. It also uses a Fresnel effect to brighten the edges and create a frosted look. Forest Stream Construction Tutorial This tutorial shows you, step by step, how to use the assets included in this sample to construct a forest stream environment. Step 1 - Sculpt Terrain We start by blocking out the main shapes of the terrain. We use the Set Height brush to create a sloping terrain by creating a series of terraces and then using the Smooth brush to smooth out the hard edges between the terraces. Then we cut in our stream channel with the Set Height brush in several different tiers heading down the slope. After cutting in the stream, we smooth out the hard edges using the Smooth brush. We finalize the terrain shape by adding polish using the Raise/Lower Height brush and the Smooth brush to add touch-ups and variety. In this process, we start out with large brushes and end up using small ones. Once this step is done, we do revisit the terrain shape occasionally to add additional touch ups, especially after adding in the water meshes in steps 3 and 4, to ensure that the water meshes and terrain shape work together. Step 2 - Paint Terrain Materials Next, it’s time to add materials to our terrain. We have four material layers - cobblestone rocks for our stream bed, dry dirt, rocky moss, and mossy grass. To apply the materials, we begin by establishing guidelines. The stones material goes in the stream bed. The dirt material goes along the banks of the stream. As a transition between the first and the grass, we use the rocky moss material. And finally, we use the grass material for the background. We first block in the materials according to our guidelines with large, hard-edged brushes. Then we go back and blend the materials together using smaller brushes. We paint one material over the other using brushes with a low opacity value to blend the two materials together. Even though our terrain materials exhibit tiling artifacts by themselves, we’re able to hide the tiling by giving each material a different tiling frequency. When the materials are blended, they break up each others tiling artifacts. We also cover the terrain with detail meshes (step 7) which further hides the tiling. Step 3 - Add Water Planes The stream itself is constructed from simple planes that are added to the scene by right clicking in the Hierarchy panel and selecting 3D Object->Plane. Then we apply the WaterStream material. The planes are placed in the stream channel that’s cut into the terrain, and then scaled along the Z axis to stretch them along the length of the stream. Water flows in the local -Z direction of the planes. Planes are scaled as long as they need to be in order to reach from one stream height drop to the next. Notice that the edges of the stream mesh are transparent at the start and at the end. This is to allow the stream meshes to blend together correctly with the waterfall meshes that link the stream planes together. Step 4 - Add Waterfall Meshes The waterfall meshes are designed to connect one level of stream plane to the next lower level. They are placed at the end of a stream plane and slope down to connect to the next stream plane. We rotate the waterfall meshes around the Y axis to align the waterfall mesh between the two stream planes. The pivot point of the waterfall is lined up vertically with the top portion of the waterfall, so you can place the waterfall mesh at the exact same height as the top stream plane, and then scale the waterfall mesh so that the bottom portion of the waterfall mesh aligns with the lower stream plane. Notice that the Sorting Priority parameter in the Advanced Options of the material has been set to -1. This makes the waterfall meshes draw behind the stream meshes so there isn’t a draw order conflict. Step 5 - Add Rocks Streams are often filled with rocks that have been pushed by the current. To save memory and reduce draw calls, we’re just using two different rock meshes that both use the same texture set. The rocks are rotated and scaled to give a variety of appearances. Notice that we’ve created visual variety by creating two different sizes of rocks - large boulders, and smaller rocks. Overall, the rocks break up the shape of the stream and change the pattern of the foam on the water surface. Step 6 - Add Water Decals We use the Water Wetness and Water Caustics decal to more tightly integrate the stream water with the terrain and rocks. The Wetness decal makes the terrain and other meshes around the stream look like they’re wet, and the Caustics decal imitates the appearance of lighting getting refracted by the surface of the water and getting focused in animated patterns on the bottom of the stream. For the Wetness decal, it should be created and scaled so that the top of the decal extends around half a meter above the surface of the water. The top of the Caustics decal should be just under the water. For both decals, the decal volumes should be kept as small as possible in all three dimensions - just large enough to cover their intended use and no larger. You can also save some performance by lowering the Draw Distance parameter on each decal so they are not drawn at a distance. Step 7 - Add Reflection Probes Reflections are a critical component of realistic-looking water. To improve the appearance of the water reflections, we create a Reflection Probe for each of the stream segments and place it at about head height and in the middle of the stream. If were are objects like rocks and trees nearby, they will be captured in the Reflection Probes and then reflected more accurately in the water. Especially notice how water to the right of this point is correctly reflecting the high bank behind the signs while water to the left is only reflecting the sky. This additional realism is contributed by the Reflection Probes. Step 8 - Add Terrain Detail Meshes Our last step is to add detail meshes to the terrain. We have pebble meshes that are added everywhere, including under the water. We have broad-leaf nettle plants that are added around the edges of the water in the dirt areas. We have ferns (3 variations) that are added just above the nettle in the transition between dirt and grass, and we have clover that is added in between the ferns and the grass. For the grass, we have three different meshes that each fade out at a different distance from the camera to soften the fade-out so that it doesn’t happen all at once. The most dense grass is only visible at 10 meters from the camera to improve performance. The three different grass layers are painted somewhat randomly with all three layers being applied where the terrain grass material is most dense and the most sparse grass being painted around the edges. Each grass mesh also has slightly different wind direction and intensity values in the material to give variety to the grass appearance. Only one of the three grass meshes has shadows turned on - which gives the impression of grass shadows without paying the full performance cost. To save on performance, our terrain is set to fade out the detail meshes at 30 meters. This allows us to achieve a nice density of meshes up close and then get rid of them further away where they’re not as visible. We hide the transition by dither fading the meshes in the shader before the 30 meter point so there’s not popping. Additional Ideas We have a pretty nice looking environment here, but there’s a lot more that could be done. You could complete this environment by adding your own trees, stumps and fallen logs."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Lit.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Lit.html",
    "title": "Lit Shaders | mmo-rpg-unity",
    "keywords": "Lit Shaders Both URP and HDRP come with code-based shaders. The most commonly used shader for each of the SRPs is called Lit. For projects that use it, it’s often applied to just about every mesh in the game. Both the HDRP and URP versions of the Lit shader are very full-featured. However, sometimes users want to add additional features to get just the look they’re trying to achieve, or remove unused features to optimize performance. For users who aren’t familiar with shader code, this can be very difficult. For that reason, we’ve included Shader Graph versions of the Lit shader for both URP and HDRP in this sample pack. Users will be able to make a copy of the appropriate Shader Graph Lit shader, and then change any material that’s currently referencing the code version of the Lit shader with the Shader Graph version. All of the material settings will correctly be applied and continue to work. They’ll then be able to make changes to the Shader Graph version as needed. Please note that most but not all of the features of the code-based shaders are duplicated in the Shader Graph versions. Some lesser-used features may be missing from the Shader Graph versions due to the differences in creating shader with Shader Graph vs creating them with code. Also note - If you’re going to use the Lit shader as is, we recommend sticking with the code version. Only swap out the shader for the Shader Graph version if you’re making changes. We also recommend removing unused features from the Shader Graph version for better performance. For example, if you’re not using Emissive or Detail Maps, you can remove those parts of the shader (both graph nodes and Blackboard parameters) for faster build times and better performance. The real power of Shader Graph is its flexibility and how easy it is to change, update, and improve shaders. URP Lit Just like the code version, this shader offers the Metallic workflow or the Specular workflow. Shaders can be either opaque or transparent, and there are options for Alpha Clipping, Cast Shadows, and Receive Shadows. For the main surface, users can apply a base map, metallic or specular map, normal map, height map, occlusion map, and emission map. Parameters are available to control the strength of the smoothness, height, normal, and occlusion and control the tiling and offset of the textures. Users can also add base and normal detail maps and mask off where they appear using the mask map. For more details on each of the parameters in the shader, refer to the Lit Shader documentation for URP. Shader Variant Limit In order to be able to use this shader, you’ll need to increase the Shader Variant Limit to at least 513. This should be done on both the Shader Graph tab in Project Settings as well as the Shader Graph tab in the Preferences. Custom Editor GUI In order to create a more compact and user-friendly GUI in the material, this shader uses the same Custom Editor GUI that the code version of the Lit shader uses. Open the Graph Inspector and look at the Graph Settings. At the bottom of the list, you’ll see the following under Custom Editor GUI: UnityEditor.Rendering.Universal.ShaderGUI.LitShader This custom GUI script enables the small texture thumbnails and other features in the GUI. If you need to add or remove parameters in the Blackboard, we recommend removing the Custom Editor GUI and just using Shader Graph’s default material GUI instead. The custom GUI depends on the existence of many of the Blackboard parameters and won’t function properly if they’re removed. HDRP Lit Just like the code version, this shader offers opaque and transparent options. It supports Pixel displacement (Parallax Occlusion mapping) and all of the parameters that go with it. (It does not support Material Types other than standard.) For the main surface, users can apply a base map, mask map, normal map, bent normal map, and height map. Options are also available to use a detail map and emissive map. For more details on each of the parameters in the shader, refer to the Lit Shader documentation for HDRP. Custom Editor GUI In order to create a more compact and user-friendly GUI in the material, this shader uses the same Custom Editor GUI that the code version of the Lit shader uses. Open the Graph Inspector and look at the Graph Settings. At the bottom of the list, you’ll see the following under Custom Editor GUI: Rendering.HighDefinition.LitGUI This custom GUI script enables the small texture thumbnails and other features in the GUI. If you need to add or remove parameters in the Blackboard, we recommend removing the Custom Editor GUI and just using Shader Graph’s default material GUI instead. The custom GUI depends on the existence of many of the Blackboard parameters and won’t function properly if they’re removed."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Misc.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Misc.html",
    "title": "Miscellaneous shaders | mmo-rpg-unity",
    "keywords": "Miscellaneous shaders Blockout Grid Apply this simple shader to a 1 meter cube. You can then scale and stretch the cube to block out your level. The grid projected on the cube doesn't stretch but maintains its world-space projection so it's easy to see distances and heights. It's a great way to block out traversable paths, obstacles, and level layouts. Turn on the EnableSlopeWarning parameter to shade meshes red where they’re too steep to traverse. Ice This ice shader uses up to three layers of parallax mapping to create the illusion that the cracks and bubbles are embedded in the volume of the ice below the surface though there is no transparency or actual volume. It also uses a Fresnel effect to brighten the edges and create a frosted look."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Post.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Post.html",
    "title": "Post-Process | mmo-rpg-unity",
    "keywords": "Post-Process The post process shaders can be used to apply modifications to the rendered image once the scene has been drawn. Edge Detection The edge detection shader checks the four neighboring pixels to the current one to find “edges” or places where the normal or depth has changed rapidly. It creates a mask where edges exist and then uses the mask to blend between the original scene color and the edge color. Half Tone The halftone shader turns the rendered image into a halftone image - simulating the pattern of larger and smaller circle patterns that you might see in newsprint or comic books. First it generates a procedural grid of signed distance field circles - one for each of red, green, and blue. Then it uses inverse lerp to convert the SDF circle grid into dots - where the size of the dot represents the brightness of the color at that location. Finally it combines the red, green, and blue dot grids into one color. Rain On Lens The rain-on-the-lens post process shader applies refraction to the rendered scene as if there were rain on the camera lens - so some areas of the image are warped by rain drops and other areas are distorted by drips running down the screen. Underwater The underwater post process shader makes the scene look like it’s under water by applying several effects including blurring the screen around the edges, distorting the image is large, ripple patterns, and applying a blue/green fog based on the scene depth. VHS The VHS post process shader mimics the appearance of the scene being played back on an old VHS video cassette recorder. Artifacts include scan line jitter, read head drift, chromatic aberration, and color degradation in the YIQ color space."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Rock.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Rock.html",
    "title": "Rock | mmo-rpg-unity",
    "keywords": "Rock This is a full-featured, modular rock shader that can be used for everything from small pebbles to boulders up to large cliff faces. It has features that can be turned on and off in the material depending on the application. Each of the features is encapsulated in a subgraph so it’s easy to remove features that you don’t need. You can also add new features in the chain of modules if you need something else. Each module takes in color and smoothness in one input port and normal and ambient occlusion in a second input. Inside the subgraph, it alters these, and then it outputs the result again in the same format - color and smoothness in the first output port, and normal and AO in the second. Using this input/output port format keeps all of the modules organized and in a nice, neat line. To help with performance, the shader has an LOD0 boolean parameter exposed to the material. For materials applied to LOD0 of your rocks, this should be true. For materials applied to the other LODs, this boolean should be false. This feature turns off extra features that are only visible when the rock is close so that non-LOD0 versions of your rocks render faster. Additionally, this shader branches using the Material Quality built-in enum keyword. This means that the shader is already set up to create a low quality, medium quality, and high quality version of itself depending on project settings. Features will be turned on and off, or different variations of features will be used depending on the project’s Material Quality setting. Base Textures In order to reduce the total number of texture samples in the shader (sampling textures is the most expensive operation that shaders do, so reducing the number of texture samples can significantly improve shader performance), we’ve used a two-texture format for our base textures instead of 3. The format is as follows: CS Texture (BC7 format) - RGB - color, Alpha - smoothness NO Texture (BC7 format) - RGB - normal, Alpha - ambient occlusion [!NOTE] <The NO texture is NOT saved as a normal map. If you set it to be a normal map, the ambient occlusion data in the alpha channel will be lost.> Macro Detail The purpose of the Macro Detail module is to add large-scale details to the color, smoothness, normal, and ambient occlusion of the rock’s base material. For rocks that are large, a single texture set is often not high enough resolution and the base textures look blurry or blocky, even from a distance. The Macro Detail module solves this problem. For rocks that are smaller than 1 meter cubed, this feature should be turned off by unchecking Rock Features/MarcoDetail in the rock’s material. This feature references a texture - Rock_Macro_NOS - which you are welcome to use, or you can create your own. The texture format is as follows: R: normal X G: normal Y B: ambient occlusion A: smoothness/color overlay This texture needs to be set to Default 2D format with Compression set to High Quality. It is recommended to just use one single macro detail texture for all of the rocks in your project both to save on texture memory and to maintain a consistent visual style. For this reason, the texture itself is not exposed as a material parameter but is set directly in the shader. Color Projection For large boulders and cliff faces, you may want to add colored effects to the rocks such as bleaching. The Color Projection module can handle this. It projects color alterations using world space. The nice thing about this effect is that if your rock formation is made up of multiple rocks all jammed together, the color projection will tie them together and make them feel more cohesive - as if they’re one unified formation rather than just a collection of jammed-together rocks. This effect does use 5 texture samples, so if you don’t need it, or if you’re on a very performance sensitive platform such as a mobile device, you should definitely turn it off in the material to improve performance. Micro Detail The purpose of the Micro Detail module is to add small-scale details to the color, smoothness, normal, and ambient occlusion of the rock’s base material. When you get really close to the rocks, sometimes the resolution of the base textures is not high enough and they look blurry or blocky. The Micro Detail module solves this problem by adding very high resolution micro detail to the rock surface. This feature references a texture - Rock_Micro_NOS - which you are welcome to use, or you can create your own. The texture format is as follows: R: normal X G: normal Y B: ambient occlusion A: smoothness/color overlay This texture needs to be set to Default 2D format with Compression set to High Quality. It is recommended to just use one single micro detail texture for all of the rocks in your project both to save on texture memory and to maintain a consistent visual style. For this reason, the texture itself is not exposed as a material parameter but is set directly in the shader. Deposition Moss The Deposition Moss module applies moss to the tops of the rocks. To define the moss, it uses a Moss_CO texture (color with occlusion in the alpha channel) and a Moss_N texture (normal). The alpha channel of the Moss_CO texture is also used to create smoothness. It’s also possible to use this module to apply other types of materials to the tops of the rocks - such as sand, ash, snow, etc. To do that, you’d just need to set the Deposition Moss module to use textures for your chosen material instead. These textures are not exposed to the material, but they are available to be changed on the module. Rain When the IsRaining parameter is set to 1, the Rain module applies rain effects to the rocks, including animated rain drops on the tops of the rocks, and drips running down the sides of the rocks. The module also makes the rocks look wet."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Tutorial.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Tutorial.html",
    "title": "Forest Stream Construction Tutorial | mmo-rpg-unity",
    "keywords": "Forest Stream Construction Tutorial This tutorial shows you, step by step, how to use the assets included in this sample to construct a forest stream environment. Sculpt Terrain Paint Terrain Materials Add Water Planes Add Waterfall Meshes Add Rocks Add Water Decals Add Reflection Probes Add Terrain Detail Meshes Additional Ideas Step 1 - Sculpt Terrain Start by blocking out the main shapes of the terrain. Use the Set Height brush to create a sloping terrain by creating a series of terraces and then use the Smooth brush to smooth out the hard edges between the terraces. Cut in the stream channel with the Set Height brush in several different tiers heading down the slope. After you cut in the stream, smooth out the hard edges with the Smooth brush. Add polish to finalize the terrain shape. Use the Raise/Lower Height brush and the Smooth brush to add touch-ups and variety. In this process, start out with large brushes and end with the small ones. When this step is done, you can revisit the terrain shape occasionally to add additional touch ups, especially after adding in the water meshes in steps 3 and 4, to ensure that the water meshes and terrain shape work together. Step 2 - Paint Terrain Materials Next, it’s time to add materials to our terrain. We have four material layers - cobblestone rocks for our stream bed, dry dirt, rocky moss, and mossy grass. To apply the materials, we begin by establishing guidelines. The stones material goes in the stream bed. The dirt material goes along the banks of the stream. As a transition between the first and the grass, we use the rocky moss material. And finally, we use the grass material for the background. First block in the materials according to the guidelines with large, hard-edged brushes. Then we go back and blend the materials together using smaller brushes. Paint one material over the other using brushes with a low opacity value to blend the two materials together. Even though our terrain materials exhibit tiling artifacts by themselves, we’re able to hide the tiling by giving each material a different tiling frequency. When the materials are blended, they break up each others tiling artifacts. We also cover the terrain with detail meshes (step 7) which further hides the tiling. Step 3 - Add Water Planes The stream itself is constructed from simple planes that are added to the scene. Right-click in the Hierarchy panel and select 3D Object>Plane. Then apply the WaterStream material. Place the planes in the stream channel that’s cut into the terrain. Scale the planes along the Z axis to stretch them along the length of the stream. Water flows in the local -Z direction of the planes. Planes are scaled as long as they need to be in order to reach from one stream height drop to the next. Notice that the edges of the stream mesh are transparent at the start and at the end. This is to allow the stream meshes to blend together correctly with the waterfall meshes that link the stream planes together. Step 4 - Add Waterfall Meshes The waterfall meshes are designed to connect one level of stream plane to the next lower level. Place the waterfall meshes at the end of a stream plane. They slope down to connect to the next stream plane. Rotate the waterfall meshes around the Y axis to align the waterfall mesh between the two stream planes. Scale the waterfall mesh on the Y axis so that the bottom portion of the waterfall mesh aligns with the lower stream plane. The pivot point of the waterfall is lined up vertically with the top portion of the waterfall, so you can place the waterfall mesh at the exact same height as the top stream plane, and then scale to meet the lower stream plane. Notice that the Sorting Priority parameter in the Advanced Options of the material has been set to -1. This makes the waterfall meshes draw behind the stream meshes so there isn’t a draw order conflict. Step 5 - Add Rocks Streams are often filled with rocks that have been pushed by the current. To save memory and reduce draw calls, we’re just using two different rock meshes that both use the same texture set. Place rocks at random intervals along the length of the stream. Rotate and scale the rocks to give a variety of appearances. Notice that we’ve created visual variety by creating two different sizes of rocks - large boulders, and smaller rocks. Overall, the rocks break up the shape of the stream and change the pattern of the foam on the water surface. Step 6 - Add Water Decals We use the Water Wetness and Water Caustics decal to more tightly integrate the stream water with the terrain and rocks. The Wetness decal makes the terrain and other meshes around the stream look like they’re wet, and the Caustics decal imitates the appearance of lighting getting refracted by the surface of the water and getting focused in animated patterns on the bottom of the stream. Create and scale the Wetness decals so that the top of the decal extends around half a meter above the surface of the water. The top of the Caustics decal should be just under the water. Create and scale the caustics decals so that the caustic patterns are only projected under the water planes. For both decals, the decal volumes should be kept as small as possible in all three dimensions - just large enough to cover their intended use and no larger. You can also save some performance by lowering the Draw Distance parameter on each decal so they are not drawn at a distance. Step 7 - Add Reflection Probes Reflections are a critical component of realistic-looking water. To improve the appearance of the water reflections, create a Reflection Probe for each of the stream segments and place it at about head height and in the middle of the stream. If there are objects like rocks and trees nearby, they will be captured in the Reflection Probes and then reflected more accurately in the water. Especially notice how water to the right of this point correctly reflects the high bank behind the signs while water to the left only reflects the sky. The Reflection Probes contribute this additional realism. Step 8 - Add Terrain Detail Meshes Our last step is to add detail meshes to the terrain. Add pebble meshes everywhere, including under the water. Add broad-leaf nettle plants around the edges of the water in the dirt areas. Add ferns (3 variations) just above the nettle in the transition between dirt and grass. Add clover in between the ferns and the grass. For the grass, add the three different meshes. Each of them fade out at a different distance from the camera to soften the fade-out so that it doesn’t happen all at once. The most dense grass is only visible at 10 meters from the camera to improve performance. Paint the three different grass layers somewhat randomly with all three layers being applied where the terrain grass material is most dense and the most sparse grass being painted around the edges. Each grass mesh also has slightly different wind direction and intensity values in the material to give variety to the grass appearance. Only one of the three grass meshes has shadows turned on - which gives the impression of grass shadows without paying the full performance cost. To save on performance, our terrain is set to fade out the detail meshes at 30 meters. This allows us to achieve a nice density of meshes up close and then get rid of them further away where they’re not as visible. We hide the transition by dither fading the meshes in the shader before the 30 meter point so there’s no popping. Additional Ideas We have a pretty nice looking environment here, but there’s a lot more that could be done. You could complete this environment by adding your own trees, stumps and fallen logs."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Water.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Water.html",
    "title": "Water | mmo-rpg-unity",
    "keywords": "Water The sample set comes with four different water shaders. Each one uses reflection, refraction, surface ripples using scrolling normal maps, and depth fog. Each also uses a few additional features that are unique to that type of water. WaterLake This is the simplest water shader of the group. Because it’s meant to be applied to larger bodies of water, it has two different sets of scrolling normals for the surface ripples - one large, one small - to break up the repetition of the ripples. It also fades the ripples out at a distance both to hide the tiling patterns and to give the lake a mirror finish at a distance. WaterSimple_FoamMask This shader is intended to be used on ponds or other small bodies of non-flowing water. It uses 3 Gerstner waves subgraphs to animated the vertices in a chaotic wave pattern. It also adds foam around the edges of the water where it intersects with other objects. The unique thing about the foam implementation in this shader is that it allows you to additionally paint a texture mask that determines where foam can be placed manually. This manual placed foam could be used for a spot where a waterfall is hitting the water - for example. WaterStream The water stream shader is intended to be used on small, flowing bodies of water. Instead of standard scrolling normal maps for ripples, it uses flow mapping to make the water flow slowly along the edges of the stream and faster in the middle. It also uses the same animated foam technique as the WaterSimple shader - but without the mask. This shader uses the puddle_norm texture. Notice that we save a little bit of shader performance by NOT storing this texture as a normal map. After the two samples are combined, then we expand the data to the -1 to 1 range, so we don’t have to do it twice. WaterStreamFalls This is the same shader as the WaterStream, but it’s intended to be used on a waterfall mesh. It fades out at the start and the end of the mesh so that it can be blended in with the stream meshes at the top and bottom of the falls, and it adds foam where the falls are vertical."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Weather.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready-Weather.html",
    "title": "Weather | mmo-rpg-unity",
    "keywords": "Weather This sample comes with a full set of weather-related subgraphs (rain and snow) that can be mixed and matched depending on the requirements of the object type they’re applied to. Rain There are several subgraphs that generate rain effects. Each has a different subset of the available rain effects. Applying all of the effects at once is a bit expensive on performance, so it’s best to choose the option with just the effects you need for the specific type of object/surface. Rain The Rain subgraph combines all of the rain effect - drops, drips, puddles, wetness - to create a really nice rain weather effect - but it’s the most expensive on performance. Puddles are a bit expensive to generate as are drips, so this version should only be used on objects that will have both flat horizontal surfaces as well as vertical surfaces. Rain Floor The Rain Floor subgraph creates puddle and drop effects, but it does not have the drip effects that would run down vertical surfaces. This subgraph is best used for flat, horizontal surfaces. Rain Props The Rain Props subgraph has the drop and drip effects but does not include the puddles. It’s best for small prop objects. Rain Rocks The Rain Rocks subgraph has been specifically tuned for use on rocks. It includes drips and drops, but not puddles. It also includes the LOD0 parameter that is meant to turn off close-up features on LODs other than the first one. Components Puddles The puddles subgraph creates procedurally-generated puddles on flat, up-facing surfaces. It outputs a mask that controls where the puddles appear and normals from the puddles. It uses the PuddleWindRipples and RainRipples subgraph to generate both wind and rain ripples in the puddles. PuddleWindRipples The PuddleWindRipples subgraph creates puddle wind ripples by scrolling two normal map textures. It’s used by the Puddles subgraph. Rain_Drips This subgraph creates drips that drip down the sides of an object. The drips are projected in world space, so they work well for static objects but are not meant for moving objects. The speed of the drips is controlled by the permeability of the material. Smooth, impermeable surfaces have fast moving drips while permeable surfaces have slow-moving drips. Rain_DripsOnTheLens This subgraph is very similar to the Rain_Drips subgraph, but it’s adapted to work correctly for the RainOnTheLens post-process shader. Rain_Drops This subgraph applies animated rain drops to objects. The drops are projected in world space from the top down. Because of the world space projection, these rain drops are not designed to be added to objects that move in the scene but instead should be used for static objects. The IsRaining input port turns the effect on and off (when the input value is 1 and 0). Rain_Parameters A common set of rain parameters used by most of the rain subgraphs. Setting parameters once in this subgraph means you don’t have to set them all over in multiple places. RainDropsOnTheLens This subgraph is very similar to the RainDrops subgraph, but it’s adapted to work correctly for the RainOnTheLens post-process shader. RainRipple Creates an animated circular ripple pattern. This subgraph is used multiple times in the RainRipples subgraph to create a really nice-looking pattern of multiple overlapping ripples. RainRipples The RainRipples subgraph creates ripples from rain drops in a puddle or pool of water. It combines four instances of the RainRipple subgraph (each with its own scale, position, and timing offset) to create the chaotic appearance of multiple ripples all happening at once. It’s used by the Puddles subgraph to add rain ripples to the puddles. Wet This subgraph makes surfaces look wet by darkening and saturating their base color and by increasing their smoothness. The effect is different depending on how permeable the surface is. Snow The Snow subgraph creates a snow effect and applies it to the tops of objects. The snow material includes color, smoothness, normal, metallic, and emissive - where the emissive is used to apply sparkles to the snow."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Sample-Production-Ready.html",
    "title": "Production Ready Shaders | mmo-rpg-unity",
    "keywords": "Production Ready Shaders The Shader Graph Production Ready Shaders sample is a collection of Shader Graph shader assets that are ready to be used out of the box or modified to suit your needs. You can take them apart and learn from them, or just drop them directly into your project and use them as they are. The sample also includes a step-by-step tutorial for how to combine several of the shaders to create a forest stream environment. In URP, in order to see the content correctly, please make the following changes to your project's settings: Open your Project Settings (Edit > Project Settings) and select the ShaderGraph tab. Set Shader Variant Limit to 513. (This will allow the URP Lit shader to work correctly.) Select your project's SRP Settings asset and enable Depth Texture and Opaque Texture. (This will allow the water shaders to render correctly.) Select your project's Renderer Data asset. Hit the Add Renderer Feature button at the bottom and add the Decal feature. (This will allow the decal shaders to render correctly.) The sample content is broken into the following categories: Topic Description Lit shaders Introduces Shader Graph versions of the HDRP and URP Lit shaders. Users often want to modify the Lit shaders but struggle because they’re written in code. Now you can use these instead of starting from scratch. Decal shaders Introduces shaders that allow you to enhance and add variety to your environment. Examples include running water, wetness, water caustics, and material projection. Detail shaders Introduces shaders that demonstrate how to create efficient terrain details that render fast and use less texture memory. Examples include clover, ferns, grass, nettle, and pebbles. Rock A robust, modular rock shader that includes base textures, macro and micro detail, moss projection, and weather effects. Water Water shaders for ponds, flowing streams, lakes, and waterfalls. These include depth fog, surface ripples, flow mapping, refraction and surface foam. Post-Process Shaders to add post-processing effects to the scene, including edge detection, half tone, rain on the lens, an underwater look, and VHS video tape image degradation. Weather Weather effects including rain drops, rain drips, procedural puddles, puddle ripples, and snow. Miscellaneous A couple of additional shaders - volumetric ice, and level blockout shader. Forest Stream Construction Tutorial A tutorial that describes how to combine multiple assets from this sample to create a forest stream."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Window.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Graph-Window.html",
    "title": "Shader Graph Window | mmo-rpg-unity",
    "keywords": "Shader Graph Window Description The Shader Graph Window contains the workspace for creating shaders using the Shader Graph system. To open the Shader Graph Window you must first create a Shader Graph Asset. For more information see the Getting Started section. The Shader Graph window contains various individual elements such as the Blackboard, Graph Inspector, and Main Preview. These elements can be moved inside the workspace. They will automatically anchor to the nearest corner when scaling the Shader Graph Window. Title Bar The title bar at the top of the Shader Graph Window contains actions that can be performed on the Graph. Item Description Save Asset Saves the graph to update the Shader Graph Asset Save As Opens a file dialog that allows the user to save out the Shader Graph Asset under a new name. Show In Project Highlights the Shader Graph Asset in the Project Window Check Out If version control is enabled, this will check out the Shader Graph Asset from the source control provider. Color Mode Provides the drop down menu to select a Color Mode for the graph. Blackboard Toggles visibility of the Blackboard. Graph Inspector Toggles visibility of the Graph Inspector. Main Preview Toggles visbility of the Main Preview. Workspace The workspace is where you create Node networks. You can navigate the workspace by holding Alt and left mouse button to pan and zoom with the scroll wheel. You can hold left mouse button and drag to select multiple Nodes with a marquee. There are also various shortcut keys to use for better workflow. Hotkey Windows OSX Description Cut Ctrl + X Command + X Cuts selected Nodes to the clipboard Copy Ctrl + C Command + C Copies selected Nodes to the clipboard Paste Ctrl + V Command + V Pastes Nodes in the clipboard Focus F F Focus the workspace on all or selected Nodes Create Node Spacebar Spacebar Opens the Create Node Menu Context Menu Right clicking within the workspace will open a context menu. Note that right clicking on an item within the workspace, such as a Node, will open the context menu for that item and not the workspace. Item Description Create Node Opens the Create Node Menu Create Sticky Note Creates a new Sticky Note on the Graph. Collapse All Previews Collapses previews on all Nodes Cut Cuts selected Nodes to the clipboard Copy Copies selected Nodes to the clipboard Paste Pastes Nodes in the clipboard Delete Deletes selected Nodes Duplicate Duplicates selected Nodes Select / Unused Nodes Selects all nodes on the graph that are not contributing to the final shader output from the Master Stack. View / Collapse Ports Collapses unused ports on all selected Nodes View / Expand Ports Expands unused ports on all selected Nodes View / Collapse Previews Collapses previews on all selected Nodes View / Expand Previews Expands previews on all selected Nodes Precision / Inherit Sets precision of all selected Nodes to Inherit. Precision / Float Sets precision on all selected nodes to Float. Precision / Half Sets precision on all selected nodes to Half."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Stage.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Shader-Stage.html",
    "title": "Shader Stage | mmo-rpg-unity",
    "keywords": "Shader Stage Description Shader Stage refers to the part of the shader pipeline a Node or Port is part of. For example, Vertex or Fragment. In Shader Graph, Shader Stage is defined per port but often all ports on a node are locked to the same Shader Stage. Ports on some nodes are unavailable in certain Shader Stages due to limitations in the underlying shader language. See the Node Library documentation for nodes that have Shader Stage restrictions. Shader Stage List Name Description Vertex Operations calculated per vertex Fragment Operations calculated per fragment"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/ShaderGraph-Samples.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/ShaderGraph-Samples.html",
    "title": "Shader Graph samples | mmo-rpg-unity",
    "keywords": "Shader Graph samples Description The Shader Graph package offers sample Assets, which you can download through Package Manager. When you import these samples, Unity places the files in your Project's Asset folder. The files contain examples that demonstrate how to use Shader Graph features. Add samples To add samples to your Project, go to Window > Package Manager. Locate Shader Graph in the list of available packages, and select it. Under the package description, there is list of available samples. Click the Import into Project button next to the sample you wish to add. Unity places imported samples in your Project's Asset folder under Assets > Samples > Shader Graph > [version number] > [sample name]. The example below shows the samples for Procedural Patterns. Available samples The following samples are currently available for Shader Graph. Procedural Patterns This collection of Assets showcases various procedural techniques possible with Shader Graph. Use them directly in your Project, or edit them to create other procedural patterns. The patterns in this collection are: Bacteria, Brick, Dots, Grid, Herringbone, Hex Lattice, Houndstooth, Smooth Wave, Spiral, Stripes, Truchet, Whirl, Zig Zag. Node Reference This set of Shader Graph assets provides reference material for the nodes available in the Shader Graph node library. Each graph contains a description for a specific node, examples of how it can be used, and useful tips. Some example assets also show a break-down of the math that the node is doing. You can use these samples along with the documentation to learn more about the behavior of individual nodes. Feature Examples This is a collection of over 30 Shader Graph files. Each file demonstrates a specific shader technique such as angle blending, triplanar projection, parallax mapping, and custom lighting. While you won’t use these shaders directly in your project, you can use them to quickly learn and understand the various techniques, and recreate them into your own work. Each file contains notes that describe what the shader is doing, and most of the shaders are set up with the core functionality contained in a subgraph that’s easy to copy and paste directly into your own shader. The sample also has extensive documentation describing each of the samples to help you learn. Production Ready Shaders The Shader Graph Production Ready Shaders sample is a collection of Shader Graph shader assets that are ready to be used out of the box or modified to suit your needs. You can take them apart and learn from them, or just drop them directly into your project and use them as they are. The sample includes the Shader Graph versions of the HDRP and URP Lit shaders. It also includes a step-by-step tutorial for how to combine several of the shaders to create a forest stream environment."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sign-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sign-Node.html",
    "title": "Sign Node | mmo-rpg-unity",
    "keywords": "Sign Node Description Per component, returns -1 if the value of input In is less than zero, 0 if equal to zero and 1 if greater than zero. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Sign_float4(float4 In, out float4 Out) { Out = sign(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Simple-Noise-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Simple-Noise-Node.html",
    "title": "Simple Noise Node | mmo-rpg-unity",
    "keywords": "Simple Noise Node Description Generates a simple, or Value, noise based on input UV. The scale of the generated noise is controlled by input Scale. You can also choose to use two different hashing methods for calculating the noise. As of Unity version 2021.2, the Simple Noise node defaults to the Deterministic hash, to ensure consistent results for noise generation across platforms. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Scale Input Float None Noise scale Out Output Float None Output value Controls Name Type Options Description Hash Type Dropdown Deterministic, LegacySine Selects the hash function used to generate random numbers for noise generation. Generated Code Example The following example code represents one possible outcome of this node. inline float unity_noise_randomValue (float2 uv) { return frac(sin(dot(uv, float2(12.9898, 78.233)))*43758.5453); } inline float unity_noise_interpolate (float a, float b, float t) { return (1.0-t)*a + (t*b); } inline float unity_valueNoise (float2 uv) { float2 i = floor(uv); float2 f = frac(uv); f = f * f * (3.0 - 2.0 * f); uv = abs(frac(uv) - 0.5); float2 c0 = i + float2(0.0, 0.0); float2 c1 = i + float2(1.0, 0.0); float2 c2 = i + float2(0.0, 1.0); float2 c3 = i + float2(1.0, 1.0); float r0 = unity_noise_randomValue(c0); float r1 = unity_noise_randomValue(c1); float r2 = unity_noise_randomValue(c2); float r3 = unity_noise_randomValue(c3); float bottomOfGrid = unity_noise_interpolate(r0, r1, f.x); float topOfGrid = unity_noise_interpolate(r2, r3, f.x); float t = unity_noise_interpolate(bottomOfGrid, topOfGrid, f.y); return t; } void Unity_SimpleNoise_float(float2 UV, float Scale, out float Out) { float t = 0.0; float freq = pow(2.0, float(0)); float amp = pow(0.5, float(3-0)); t += unity_valueNoise(float2(UV.x*Scale/freq, UV.y*Scale/freq))*amp; freq = pow(2.0, float(1)); amp = pow(0.5, float(3-1)); t += unity_valueNoise(float2(UV.x*Scale/freq, UV.y*Scale/freq))*amp; freq = pow(2.0, float(2)); amp = pow(0.5, float(3-2)); t += unity_valueNoise(float2(UV.x*Scale/freq, UV.y*Scale/freq))*amp; Out = t; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sine-Node.html",
    "title": "Sine Node | mmo-rpg-unity",
    "keywords": "Sine Node Description Returns the sine of the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value in radians. Out Output Dynamic Vector Output value. Range (-1 to +1). Generated Code Example The following example code represents one possible outcome of this node. void Unity_Sine_float4(float4 In, out float4 Out) { Out = sin(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Slider-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Slider-Node.html",
    "title": "Slider Node | mmo-rpg-unity",
    "keywords": "Slider Node Description Defines a constant Float value in the shader using a Slider field. Can be converted to a Float type Property with a Mode setting of Slider via the Node's context menu. Ports Name Direction Type Binding Description Out Output Float None Output value Controls Name Type Options Description Slider Defines the output value. Min Float Defines the slider parameter's minimum value. Max Float Defines the slider parameter's maximum value. Generated Code Example The following example code represents one possible outcome of this node. float _Slider_Out = 1.0;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Smoothstep-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Smoothstep-Node.html",
    "title": "Smoothstep Node | mmo-rpg-unity",
    "keywords": "Smoothstep Node Description Returns the result of a smooth Hermite interpolation between 0 and 1, if the value of input In is between the values of inputs Edge1 and Edge2 respectively. Returns 0 if the value of input In is less than the value of input Edge1 and 1 if greater than the value of input Edge2. The Smoothstep node is similar to the Lerp Node but there are two notable differences. Firstly, with the Smoothstep node, the user specifies the range and the return value is between 0 and 1. You can consider this the opposite of the Lerp Node. Secondly, the Smoothstep node uses smooth Hermite interpolation instead of linear interpolation, which means the interpolation gradually speeds up from the start and slows down toward the end. This interpolation is useful for creating natural-looking animation, fading, and other transitions. Ports Name Direction Type Description Edge1 Input Dynamic Vector Minimum step value Edge2 Input Dynamic Vector Maximum step value In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Smoothstep_float4(float4 Edge1, float4 Edge2, float4 In, out float4 Out) { Out = smoothstep(Edge1, Edge2, In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/SpeedTree8-SubGraphAssets.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/SpeedTree8-SubGraphAssets.html",
    "title": "SpeedTree 8 Sub Graph Assets | mmo-rpg-unity",
    "keywords": "SpeedTree 8 Sub Graph Assets Prerequisite information This documentation assumes that you are already familiar with the concepts described in the following pages: SpeedTree Sub Graph Nodes Sub Graph Assets Keywords The documentation on ShaderLab material properties might also be contextually helpful. Description SpeedTree is a third-party solution that includes both ready-to-use tree assets, and modeling software for creating your own tree assets. Shader Graph has three built-in SpeedTree Sub Graph Assets: SpeedTree8ColorAlpha SpeedTree8Wind SpeedTree8Billboard These Sub Graph Assets provide SpeedTree 8 functionality for both the Universal Render Pipeline (URP) and High Definition Render Pipeline (HDRP), so that you can work with SpeedTree 8 assets and create your own custom SpeedTree 8 Shader Graphs. Note: The URP-specific versions of these SpeedTree 8 Sub Graph Assets use transparent billboard back faces instead of culling billboard back faces. These Sub Graph Assets can only replace their URP equivalents as a default once URP supports per-material culling overrides in Shader Graphs. SpeedTree8ColorAlpha Each SpeedTree asset has four maps: a basemap (color/albedo), bump map (which provides surface normals), extra map (which provides metallic and ambient occlusion data), and subsurface map (which provides the subsurface scattering color). The basemap provides input color and alpha data. This Sub Graph Asset applies all SpeedTree 8 features that modify the basemap's color and alpha data. These features are particularly useful for the following actions: Tinting the basemap color Varying tree hues Crossfading between levels of detail (LODs) Hiding geometry seams Tinting the basemap color You can use the SpeedTree8ColorAlpha Sub Graph Asset to apply a tint to the basemap color. This is useful if, for example, you want to adjust tree colors for different seasons of the year. Property Support Purpose Behavior _ColorTint URP, HDRP Tint the basemap. Multiplies the _ColorTint property value by the basemap color. Varying tree hues To improve the visual diversity of SpeedTrees, you can use this Sub Graph Asset to modify the color of each tree instance. Both _OldHueVarBehavior and _HueVariationColor use the tree’s absolute world-space position to determine a pseudorandomized hue variation intensity value. Property Support Purpose Behavior _OldHueVarBehavior URP To match the behavior of URP-specific and Built-In SpeedTree 8 shaders. Uses the pseudorandom hue variation intensity value to parameterize the linear interpolation between the basemap color (t=0) and HueVariation color (t=1) . _HueVariationColor URP, HDRP To provide SpeedTrees with more hue diversity. Uses the pseudorandom hue variation intensity value as its opacity and applies that to the basemap color as an overlay blend. A more subtle effect than that provided by _OldHueBehavior. EFFECT_HUE_VARIATION N/A N/A This keyword was used in handwritten SpeedTree 8 shaders, but it's not used in these SpeedTree 8 Shader Graphs. This is to ensure compliance with the default shader variant limit. _HueVariationKwToggle URP, HDRP, Built-In Only to support upgrade functionality. See SpeedTreeImporter.hueVariation. Crossfading between levels of detail (LODs) Crossfading dithers between different levels of detail (LODs) to minimize popping during abrupt transitions. The SpeedTree8ColorAlpha Sub Graph Asset uses a Custom Function Node for that purpose. This Custom Function Node is not SpeedTree-specific. Enable Animate Cross-fading and select an LOD Fade setting to use it with any asset that has the LOD Group component. See Transitioning between LOD levels for more information. Hiding geometry seams The SpeedTree8ColorAlpha Sub Graph asset applies an alpha gradient to soften the transitions between geometry segments that sample different parts of the basemap. SpeedTree8Wind The SpeedTree8Wind Sub Graph Asset uses a Custom Function Node to deform the vertices of SpeedTree 8 models in response to your application’s wind data. You can use this to make trees appear to bend in the wind. Unity applies wind data to the SpeedTree8Wind Sub Graph Asset is as follows: When a WindZone affects a SpeedTree 8 GameObject that has Wind enabled, Unity generates SpeedTree 8 wind simulation data. Unity populates the SpeedTreeWind Cbuffer with that wind simulation data. The SpeedTree8Wind Sub Graph Asset bases its deformation behavior on the data in the SpeedTreeWind Cbuffer. This asset includes automated LOD vertex interpolation when LOD Fade is set to SpeedTree. However, it does not support instancing. SpeedTree8Billboard The SpeedTree8Billboard Sub Graph Asset calculates billboard normals from a SpeedTree 8 model's bump map, geometric tangent, and bitangent data. It includes dithering functionality to improve the appearance of billboards at view angles diagonal to the model. The keyword toggle associated with this feature is named EFFECT_BILLBOARD.This supports backwards compatibility with previous versions of ShaderGraph, which require keywords and their toggling properties to have identical names. SpeedTree 8 InterpolatedNormals All SpeedTree 8 shaders that Unity provides interpolate geometric normals, tangents, and bitangents in the vertex stage, because this results in a better visual appearance than the per-pixel data that Shader Graph nodes provide. You do not need to use this feature if your SpeedTree 8 Shader Graph does not include custom interpolators. HDRP and URP do not have identical backface normal transformation behavior. This can become a problem when you use Custom Interpolators for geometric normal, tangent, and bitangent data. The purpose of the SpeedTree 8 InterpolatedNormals Sub Graph Asset is to allow for that difference. It combines geometric normal data with bump maps in a way that is compatible with the target pipeline's backface normal transformation behavior."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sphere-Mask-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sphere-Mask-Node.html",
    "title": "Sphere Mask Node | mmo-rpg-unity",
    "keywords": "Sphere Mask Node Description Creates a sphere mask originating from input Center. The sphere is calculated using Distance and modified using the Radius and Hardness inputs. Sphere mask functionality works in both 2D and 3D spaces, and is based on the vector coordinates in the Coords input. These vector coordinates can either be 3D like world space position, or 2D like UV coordinates. Ports Name Direction Type Binding Description Coords Input Dynamic Vector None Coordinate space input Center Input Dynamic Vector None Coordinates of the sphere origin Radius Input Float None Radius of the sphere Hardness Input Float None Soften falloff of the sphere Out Output Dynamic Vector None Output mask value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SphereMask_float4(float4 Coords, float4 Center, float Radius, float Hardness, out float4 Out) { Out = 1 - saturate((distance(Coords, Center) - Radius) / (1 - Hardness)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Spherize-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Spherize-Node.html",
    "title": "Spherize Node | mmo-rpg-unity",
    "keywords": "Spherize Node Description Applies a spherical warping effect similar to a fisheye camera lens to the value of input UV. The center reference point of the warping effect is defined by input Center and the overall strength of the effect is defined by the value of input Strength. Input Offset can be used to offset the individual channels of the result. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center reference point Strength Input Float None Strength of the effect Offset Input Vector 2 None Individual channel offsets Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Spherize_float(float2 UV, float2 Center, float Strength, float2 Offset, out float2 Out) { float2 delta = UV - Center; float delta2 = dot(delta.xy, delta.xy); float delta4 = delta2 * delta2; float2 delta_offset = delta4 * Strength; Out = UV + delta * delta_offset + Offset; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Split-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Split-Node.html",
    "title": "Split Node | mmo-rpg-unity",
    "keywords": "Split Node Description Splits the input vector In into four Float outputs R, G, B and A. These output vectors are defined by the individual channels of the input In; red, green, blue and alpha respectively. If the input vector In's dimension is less than 4 (Vector 4) the output values not present in the input will be 0. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value R Output Float None Red channel from input G Output Float None Green channel from input B Output Float None Blue channel from input A Output Float None Alpha channel from input Generated Code Example The following example code represents one possible outcome of this node. float _Split_R = In[0]; float _Split_G = In[1]; float _Split_B = 0; float _Split_A = 0;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Split-Texture-Transform-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Split-Texture-Transform-Node.html",
    "title": "Split Texture Transform Node | mmo-rpg-unity",
    "keywords": "Split Texture Transform Node Description This node makes it possible to separately output tiling, offset, and texture data for a Texture 2D asset. That enables you to present an asset differently in a specific context—to warp it in a mirror, for example—and put it into the UV without modifying the original asset. This node outputs the texture with its tiling set to (0,0) and scale set to (1,1). That activates the shader property NoScaleOffset, which enables you to modify Tiling Offset values via the Material Inspector. Another term you may hear for tiling in this context is scale. Both terms refer to the size of the texture tiles. Ports Name Direction Type Description In Input Texture2D The Texture 2D Node input. Tiling Output Vector 2 Amount of tiling to apply per channel, set via the Material Inspector. Offset Output Vector 2 Amount of offset to apply per channel, set via the Material Inspector. Texture Only Output Vector 2 The input Texture2D, without tiling and offset data."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Square-Root-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Square-Root-Node.html",
    "title": "Square Root Node | mmo-rpg-unity",
    "keywords": "Square Root Node Description Returns the square root of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SquareRoot_float4(float4 In, out float4 Out) { Out = sqrt(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Square-Wave-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Square-Wave-Node.html",
    "title": "Square Wave Node | mmo-rpg-unity",
    "keywords": "Square Wave Node Description Returns a square wave from the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_SquareWave_float4(float4 In, out float4 Out) { Out = 1.0 - 2.0 * round(frac(In)); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Step-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Step-Node.html",
    "title": "Step Node | mmo-rpg-unity",
    "keywords": "Step Node Description Per component, returns 1 if the value of input In is greater than or equal to the value of input Edge, otherwise returns 0. Ports Name Direction Type Description Edge Input Dynamic Vector Step value In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Step_float4(float4 Edge, float4 In, out float4 Out) { Out = step(Edge, In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sticky-Notes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sticky-Notes.html",
    "title": "Sticky Notes | mmo-rpg-unity",
    "keywords": "Sticky Notes Sticky Notes are objects in a graph view that you can write in. They are the graph view equivalent of a comment in code, and consist of a title and body. You can create as many as you want in the graph, and use them for a variety of purposes, for example: To describe how a section of your graph works. To leave notes for yourself or others collaborating in your Unity Project. As a to-do list that includes tasks to complete at a later date. Using Sticky Notes To create a Sticky Note, right-click an empty space in the graph view and, in the context menu, click Create Sticky Note. You can then customize and add content to the new Sticky Note. There are two text areas that you can write in: Title: The text area at the top of the Sticky Note is the title. You can use it to concisely describe what information the Sticky Note contains. Body: The larger text area below the title area is the body. You can write the full contents of the note here. Editing text To edit text on a Sticky Note, double-click on a text area. This also selects the entire text area, so be sure to move the cursor before you edit the text. Moving and resizing You can move Sticky Notes anywhere on the graph. You can also click and drag to manually resize Sticky Notes, or have a Sticky Note automatically resize itself to fit the content. For information on how to make the Sticky Note resize itself, see Fit To Text in the Context menu section below. Duplicating Use the following keyboard shortcuts to cut, copy, paste, and duplicate Sticky Notes. Copy: Ctrl+C Cut: Ctrl+X Paste: Ctrl+V Duplicate: Ctrl+D Context menu To open the context menu for a Sticky Note, right-click anywhere on it. The options in the context menu are as follows. Option Description Dark Theme/Light Theme Toggles the color theme of the Sticky Note between light theme and dark theme. Text Size Resizes the font in the text areas to the following point values. Small Title: 20, Body: 11 Medium Title: 40, Body: 24 Large Title: 60, Body: 36 Huge Title: 80, Body: 56 Fit To Text Resizes the Sticky Note so that it precisely fits the text areas. If your title exceeds a single line, Unity resizes the Sticky Note such that title text fits on a single line. Delete Deletes the Sticky Note you selected. Group Selection Places any Sticky Notes you select in a group. Ungroup Selection Removes any Sticky Notes you select from the group."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sub-Graph-Dropdown-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sub-Graph-Dropdown-Node.html",
    "title": "Subgraph Dropdown node | mmo-rpg-unity",
    "keywords": "Subgraph Dropdown node The Subgraph Dropdown node is a node representation of a Dropdown property. It allows you to create a custom dropdown menu on a Subgraph node in its parent Shader Graph. You can specify the number of options that appear in the dropdown menu, and their names. After you create a Dropdown property and add a Dropdown node to a Subgraph, the Subgraph node in any parent Shader Graph displays with a dropdown control: Create Node menu category The Subgraph Dropdown node isn't accessible from the Create Node menu. To add a Subgraph Dropdown node to a Subgraph: In the Shader Graph window, open a Subgraph. In the Blackboard, select Add (+) and select Dropdown. Enter a name for your new Dropdown property, and press Enter. Select your Dropdown property and drag it onto your graph to create a new Subgraph Dropdown node. Select your new Dropdown node in your graph or the Dropdown property in the Blackboard and open the Graph Inspector. Select the Node Settings tab. In the Entries table, select Add to the list (+) to add a new option to your dropdown. Each Entry adds a corresponding input port to your node. To remove an Entry, select its handle in the list and select Remove selection from the list (-). (Optional) In the Default list, select the default Entry that you want Shader Graph to select on your property. Compatibility The Subgraph Dropdown node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes Ports Note The Subgraph Dropdown node's number of input ports and their names directly correspond to the settings you specify in the Graph Inspector's Node Settings tab. The node always has one output port. A Subgraph Dropdown node's input ports always have the DynamicVector type. This means that you can make a connection to an input port from any node that outputs a float, Vector 2, Vector 3, Vector 4, or Boolean value. For more information, see Dynamic Data Types. It has one output port: Name Type Description Out DynamicVector The selected option from the dropdown menu on the parent Shader Graph's Subgraph node. This value can also be the specified Default for the property in the Graph Inspector's Node Settings tab. Example graph usage In the following example, a Subgraph Dropdown node changes the UV channel it sends to the Subgraph's Output node. The selection on the Subgraph node in the parent graph changes whether the Subgraph outputs UV1 or UV0. If the Subgraph is used in multiple Shader Graphs, the Subgraph Dropdown node can change the UV channel output without changing the Subgraph: Related nodes The following nodes are related or similar to the Subgraph Dropdown node: Subgraph node"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sub-graph-Asset.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sub-graph-Asset.html",
    "title": "Subgraph Asset | mmo-rpg-unity",
    "keywords": "Subgraph Asset Description The Subgraph Asset is a new Asset type introduced with the Shader Graph. A Subgraph Asset defines a Subgraph. This is different to a Shader Graph. You can create a Subgraph Asset from the Project window from the Create menu via Subgraph in the Shader sub-menu. You can open the Shader Graph Window by double clicking a Subgraph Asset or by clicking Open Shader Editor in the Inspector when the Subgraph Asset is selected."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sub-graph-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sub-graph-Node.html",
    "title": "Subgraph node | mmo-rpg-unity",
    "keywords": "Subgraph node Description Provides a reference to a Subgraph Asset. All ports on the reference node are defined by the properties and outputs defined in the Subgraph Asset. This is useful for sharing functionality between graphs or duplicating the same functionality within a graph. The preview used for a Subgraph Node is determined by the first port of that Subgraph Output node. Valid Data Types for the first port are Float, Vector 2, Vector 3, Vector 4, Matrix2, Matrix3, Matrix4, and Boolean. Any other data type will produce an error in the preview shader and the Subgraph will become invalid. Subgraph Nodes and Shader Stages If a Node within a Subgraph specifies a Shader Stage, such as how Sample Texture 2D Node specifies the fragment Shader Stage, then that entire Subgraph) is now locked to that stage. As such a Subgraph node that references the graph will also be locked to that Shader Stage. Furthermore, when an Edge connected to an output Port on a Subgraph Node flows into a port on the Master Stack that Subgraph Node is now locked to the Shader Stage of that Block Node in the Master Stack."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sub-graph.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Sub-graph.html",
    "title": "Sub Graph | mmo-rpg-unity",
    "keywords": "Sub Graph Description A Sub Graph is a special type of Shader Graph, which you can reference from inside other graphs. This is useful when you wish to perform the same operations multiple times in one graph or across multiple graphs. A Sub Graph differs from a Shader Graph in three main ways: Properties in the Blackboard of a Sub Graph define the input Ports of a Sub Graph Node when you reference the Sub Graph from inside another graph. A Sub Graph has its own Asset type. For more information, including instructions on how to make a new Sub Graph, see Sub Graph Asset. A Sub Graph does not have a Master Stack. Instead, it has a Node called Output. For information about the components of a Sub Graph, see Sub Graph Asset. Output Node The Output Node defines the output ports of a Sub Graph Node when you reference the Sub Graph from inside another graph. To add and remove ports, use the Custom Port Menu in the Node Settings tab of the Graph Inspector by clicking on the Sub Graph Output node. The preview used for Sub Graphs is determined by the first port of the Output Node. Valid Data Types for the first port are Float, Vector 2, Vector 3, Vector 4, Matrix2, Matrix3, Matrix4, and Boolean. Any other data type will produce an error in the preview shader and the Sub Graph will become invalid. Sub Graphs and shader stages If a Node within a Sub Graph specifies a shader stage (for example, how the Sample Texture 2D Node specifies the fragment shader stage), the Editor locks the entire Sub Graph to that stage. You cannot connect any Nodes that specify a different shader stage to the Sub Graph Output Node, and the Editor locks any Sub Graph Nodes that references the graph to that shader stage. From 10.3 onward, Texture and SamplerState type inputs and outputs to Sub Graphs benefit from an improved data structure. For a detailed explanation, see Custom Function Node. Sub Graphs and Keywords Keywords that you define on the Blackboard in a Sub Graph behave similarly to those in regular Shader Graphs. When you add a Sub Graph Node to a Shader Graph, Unity defines all Keywords in that Sub Graph in the Shader Graph as well, so that the Sub Graph works as intended. To use a Sub Graph Keyword inside a Shader Graph, or to expose that Keyword in the Material Inspector, copy it from the Sub Graph to the Shader Graph's Blackboard."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Subtract-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Subtract-Node.html",
    "title": "Subtract Node | mmo-rpg-unity",
    "keywords": "Subtract Node Description Returns the result of input A minus input B. Ports Name Direction Type Description A Input Dynamic Vector First input value B Input Dynamic Vector Second input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Subtract_float4(float4 A, float4 B, out float4 Out) { Out = A - B; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Swizzle-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Swizzle-Node.html",
    "title": "Swizzle Node | mmo-rpg-unity",
    "keywords": "Swizzle Node Description Creates a new vector from the reordered elements of the input vector. This is called swizzling. To specify how input elements should be swizzled, enter a formatting string in the input mask. To invert the order of the input elements, for example, use the string \"wzyx\" or \"abgr\". The length of the input mask determines the dimensions of the output vector. The error \"Invalid Mask\" indicates an input mask value which includes one or more channels that do not exist in the input vector. To output a vector3 with the x, y and z elements of the input vector, for example, use the input mask “xyz” or “rgb”. Ports Name Direction Type Binding Description In Input Dynamic Vector None Input value Out Output Dynamic Vector None Output value Controls Name Type Options Description Mask Inputfield x, y, z, w (depending on input vector dimension) The swizzle mask is a combination of one to four characters that can be x, y, z, w (or r, g, b, a). The size of output value depends on the length of the mask input. Generated Code Example The following example code represents one possible outcome of this node. float4 _Swizzle_Out = In.wzyx;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "About Shader Graph Getting started with Shader Graph Creating a new Shader Graph Asset My first Shader Graph Shader Graph Window Blackboard Main Preview Graph Inspector Create Node Menu Graph Settings Tab Master Stack Sticky Notes Sub Graph Color Modes Precision Modes Preview Mode Control Custom Function Node Shader Graph Preferences Samples Feature Examples Production Ready Shaders Lit Shaders Decal shaders Detail shaders Rock shaders Water shaders Post-process shaders Weather shaders Miscellaneous shaders Forest Stream Construction Tutorial Material Variants Upgrade Guides Upgrade to Shader Graph 10.0.x Inside Shader Graph Shader Graph Asset Graph Target Sub Graph Asset SpeedTree 8 Sub Graph Assets Node Port Custom Port Menu Edge Property Types Keywords Data Types Port Bindings Shader Stage Surface options Custom Interpolators Node Library Artistic Adjustment Channel Mixer Contrast Hue Invert Colors Replace Color Saturation White Balance Blend Blend Filter Dither Fade Transition Mask Channel Mask Color Mask Normal Normal Blend Normal From Height Normal From Texture Normal Reconstruct Z Normal Strength Normal Unpack Utility Colorspace Conversion Channel Combine Flip Split Swizzle Input Basic Boolean Color Constant Integer Slider Time Float Vector 2 Vector 3 Vector 4 Geometry Bitangent Vector Instance ID Normal Vector Position Screen Position Tangent Vector UV Vertex Color Vertex ID View Direction View Vector Gradient Blackbody Gradient Sample Gradient High Definition Render Pipeline Custom Color Buffer Custom Depth Buffer Diffusion Profile Exposure HD Scene Color HD Scene Depth HD Sample Buffer Lighting Ambient Baked GI Main Light Direction Reflection Probe Matrix Matrix 2x2 Matrix 3x3 Matrix 4x4 Transformation Matrix Mesh Deformation Compute Deformation Linear Blend Skinning PBR Dielectric Specular Metal Reflectance Fresnel Equation Scene Camera Eye Index Fog Object Scene Color Scene Depth Scene Depth Difference Screen Texture Calculate Level Of Detail Texture 2D Node Cubemap Asset Gather Texture 2D Node Sample Cubemap Sample Reflected Cubemap Sample Texture 2D Sample Texture 2D Array Sample Texture 2D LOD Sample Texture 3D Sample Virtual Texture Sampler State Split Texture Transform Texture 2D Array Asset Texture 2D Asset Texture 3D Asset Texture Size Math Advanced Absolute Exponential Length Log Modulo Negate Normalize Posterize Reciprocal Reciprocal Square Root Basic Add Divide Multiply Power Square Root Subtract Derivative DDX DDXY DDY Interpolation Inverse Lerp Lerp Smoothstep Matrix Matrix Construction Matrix Determinant Matrix Split Matrix Transpose Range Clamp Fraction Maximum Minimum One Minus Random Range Remap Saturate Round Ceiling Floor Round Sign Step Truncate Trigonometry Arccosine Arcsine Arctangent Arctangent2 Cosine Degrees To Radians Hyperbolic Cosine Hyperbolic Sine Hyperbolic Tangent Radians To Degrees Sine Tangent Vector Cross Product Distance Dot Product Fresnel Effect Projection Reflection Refract Rejection Rotate About Axis Sphere Mask Transform Wave Noise Sine Wave Sawtooth Wave Square Wave Triangle Wave Procedural Noise Gradient Noise Simple Noise Voronoi Shapes Ellipse Polygon Rectangle Rounded Polygon Rounded Rectangle Checkerboard Utility Logic All And Any Branch Branch On Input Connection Comparison Is Front Face Is Infinite Is NaN Nand Not Or High Definition Render Pipeline Emission Eye CirclePupilAnimation CorneaRefraction EyeSurfaceTypeDebug IrisLimbalRing IrisOffset IrisOutOfBoundColorClamp IrisUVLocation ScleraIrisBlend ScleraLimbalRing ScleraUVLocation Water Compute Vertex Position Evaluate Foam Data Evaluate Refraction Data Evaluate Scattering Color Evaluate Simulation Additional Data Evaluate Simulation Caustics Evaluate Simulation Displacement Evaluate Tip Thickness Pack Water Vertex Data Unpack Water Data Fabric *ThreadMapDetail UVCombine Custom Function Keyword Preview Subgraph Subgraph Dropdown node UV Flipbook Polar Coordinates Radial Shear Rotate Spherize Tiling And Offset Triplanar Twirl Parallax Mapping Parallax Occlusion Mapping Block Nodes Built In Blocks"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Tangent-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Tangent-Node.html",
    "title": "Tangent Node | mmo-rpg-unity",
    "keywords": "Tangent Node Description Returns the tangent of the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Tangent_float4(float4 In, out float4 Out) { Out = tan(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Tangent-Vector-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Tangent-Vector-Node.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Description Provides access to the mesh vertex or fragment's Tangent Vector. The coordinate space of the output value can be selected with the Space dropdown parameter. Ports Name Direction Type Binding Description Out Output Vector 3 None Mesh's Tangent Vector. Parameters Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of Tangent Vector to output."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Texture-2D-Array-Asset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Texture-2D-Array-Asset-Node.html",
    "title": "Texture 2D Array Asset Node | mmo-rpg-unity",
    "keywords": "Texture 2D Array Asset Node Description Defines a constant Texture 2D Array Asset for use in the shader. To sample the Texture 2D Array Asset it should be used in conjunction with a Sample Texture 2D Array Node. When using a separate Texture 2D Array Asset Node, you can sample a Texture 2D Array twice, with different parameters, without defining the Texture 2D Array itself twice. Ports Name Direction Type Description Out Output Texture 2D Array Output value Controls Name Type Options Description Object Field (Texture 2D Array) Defines the texture 2D array asset from the project. Generated Code Example The following example code represents one possible outcome of this node. TEXTURE2D_ARRAY(_Texture2DArrayAsset); SAMPLER(sampler_Texture2DArrayAsset);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Texture-2D-Asset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Texture-2D-Asset-Node.html",
    "title": "Texture 2D Asset Node | mmo-rpg-unity",
    "keywords": "Texture 2D Asset Node Description Defines a constant Texture 2D Asset for use in the shader. To sample the Texture 2D Asset it should be used in conjunction with a Sample Texture 2D Node. When using a separate Texture 2D Asset Node, you can sample a Texture 2D twice, with different parameters, without defining the Texture 2D itself twice. Ports Name Direction Type Description Out Output Texture 2D Output value Controls Name Type Options Description Object Field (Texture) Select which texture 2D asset to use from the project. Generated Code Example The following example code represents one possible outcome of this node. TEXTURE2D(_Texture2DAsset); SAMPLER(sampler_Texture2DAsset);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Texture-3D-Asset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Texture-3D-Asset-Node.html",
    "title": "Texture 3D Asset Node | mmo-rpg-unity",
    "keywords": "Texture 3D Asset Node Description Defines a constant Texture 3D Asset for use in the shader. To sample the Texture 3D Asset it should be used in conjunction with a Sample Texture 3D Node. When using a separate Texture 3D Asset Node, you can sample a Texture 3D twice, with different parameters, without defining the Texture 3D itself twice. Ports Name Direction Type Description Out Output Texture 3D Output value Controls Name Type Options Description Object Field (Texture 3D) Defines the texture 3D asset from the project. Generated Code Example The following example code represents one possible outcome of this node. TEXTURE3D(_Texture3DAsset); SAMPLER(sampler_Texture3DAsset);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Texture-Size-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Texture-Size-Node.html",
    "title": "Texture Size Node | mmo-rpg-unity",
    "keywords": "Texture Size Node The Texture Size node takes a Texture 2D input and returns the width and height texel resolution of the texture. It also returns the width and height size of each texel of the texture. The node uses the built in variable {texturename}_TexelSize to access the special properties of the given Texture 2D input. The term \"texel\" is short for \"texture element\" or \"texture pixel.\" It represents a single pixel in the texture. So, for example, if Texture resolution is 512x512 texels, the texture is sampled over the range [0-1] in UV space, so each texel is 1/512 x 1/512 in size in UV coordinates. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, you can resolve them by upgrading your version of Shader Graph to version 10.3 or later. Note Don't use the default input to reference your Texture 2D, as this affects the performance of your graph. Connect a Texture 2D Asset Node to the Texture Size node's Texture input port and re-use this definition for sampling. Create Node menu category The Texture Size node is under the Input > Texture category in the Create Node menu. Compatibility The Texture Size node is compatible with all render pipelines. Ports Name Direction Type Binding Description Texture Input Texture None The Texture 2D asset to measure. Width Output Float None The width of the Texture 2D asset in texels. Height Output Float None The height of the Texture 2D asset in texels. Texel Width Output Float None The texel width of the Texture 2D asset in UV coordinates. Texel Height Output Float None The texel height of the Texture 2D asset in UV coordinates. Generated Code Example The following example code represents one possible outcome of this node. float _TexelSize_Width = Texture_TexelSize.z; float _TexelSize_Height = Texture_TexelSize.w;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/ThreadMapDetail-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/ThreadMapDetail-Node.html",
    "title": "ThreadMapDetail node | mmo-rpg-unity",
    "keywords": "ThreadMapDetail node The ThreadMapDetail node adds tileable thread map detail information to a fabric material. The node outputs a thread map that you can apply to a fabric material. Note This node is a Subgraph node: it represents a Subgraph instead of directly representing Unity's shader code. Double-click the node in any Shader Graph to view its Subgraph. A thread map is a Texture with 4 channels. Like a detail map, a thread map contains information about ambient occlusion, the normal x-axis and normal y-axis, and smoothness. For more information on Detail maps, see Secondary Maps (Detail Maps) & Detail Mask in the Unity User Manual. Create Node menu category The ThreadMapDetail node is under the Utility > High Definition Render Pipeline > Fabric category in the Create Node menu. Compatibility node is supported on the following render pipelines: Built-in Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) No No Yes For more information on the HDRP, see Unity's HDRP package documentation. node can also be connected to any Block node in either Context. For more information on Block nodes and Contexts, see Master Stack. Inputs node has the following input ports: Name Type Binding Description Use Thread Map Boolean None Use the port's default input to enable or disable the ThreadMapDetail node. You can also connect a node that outputs a Boolean to choose when to enable or disable the thread map. ThreadMap Texture 2D None The texture that contains the detailed information of a fabric's thread pattern. The texture should contain 4 channels: R - The ambient occlusion G - The normal Y-axis B - The smoothness A - The normal X-axis UV Vector 2 UV The UV coordinates the ThreadMapDetail node should use to map the ThreadMap texture on the geometry. Normals Vector 3 None The base normal map that you want your Shader Graph to apply to the geometry before it applies the thread map. Smoothness Float None The base smoothness value that you want your Shader Graph to apply to the geometry before it applies the thread map. Alpha Float None The base alpha value that you want your Shader Graph to apply to the geometry before it applies the thread map. Ambient Occlusion Float None The base ambient occlusion value that you want your Shader Graph to apply to the geometry before it applies the thread map. Thread AO Strength Float None Specify a value of 0 or 1 to determine how the ThreadMap's ambient occlusion should impact the final shader result: If you provide a value of 0, the ThreadMap's ambient occlusion has no effect on the final output of the shader. If you provide a value of 1, Shader Graph multiplies your base Ambient Occlusion value by the ambient occlusion value specified in your ThreadMap to determine the final output of the shader. Thread Normal Strength Float None Specify a value of 0 or 1 to determine how the ThreadMap's normal should impact the final shader result: If you provide a value of 0, the ThreadMap's normal has no effect on the final output of the shader. If you provide a value of 1, Shader Graph blends the values from your base Normals with the normal specified in your ThreadMap to determine the final output of the shader. Thread Smoothness Strength Float None Specify a value of 0 or 1 to determine how the ThreadMap's smoothness should impact the final shader result: If you provide a value of 0, the ThreadMap's smoothness value has no effect on the final output of the shader. If you provide a value of 1, Shader Graph adds the smoothness value specified in your ThreadMap to your base Smoothness value to determine the final output of the shader. For this calculation, Shader Graph remaps the value of your ThreadMap's smoothness from (0,1) to (-1, 1). Outputs node has the following output ports: Name Type Description Normal Vector 3 The final normal output of the thread map. Smoothness Float The final smoothness output of the thread map. Ambient Occlusion Float The final ambient occlusion output of the thread map. Alpha Float The final alpha output of the thread map. Shader Graph calculates this alpha value by multiplying the input Alpha value by the Thread AO Strength value. Example graph usage For an example use of the ThreadMapDetail node, see either of the HDRP's Fabric shaders. To view these Shader Graphs: Create a new material and assign it the HDRP > Fabric > Silk or HDRP > Fabric > CottonWool shader, as described in the Unity User Manual section Creating a material asset, and assigning a shader to it. Next to the Shader dropdown, select Edit. Your chosen Fabric's Shader Graph opens. You can view the ThreadMapDetail node, its Subgraph, and the other nodes that create HDRP's Fabric shaders."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Tiling-And-Offset-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Tiling-And-Offset-Node.html",
    "title": "Tiling And Offset Node | mmo-rpg-unity",
    "keywords": "Tiling And Offset Node Description Tiles and offsets the value of input UV by the inputs Tiling and Offset respectively. This is commonly used for detail maps and scrolling textures over Time. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Tiling Input Vector 2 None Amount of tiling to apply per channel Offset Input Vector 2 None Amount of offset to apply per channel Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_TilingAndOffset_float(float2 UV, float2 Tiling, float2 Offset, out float2 Out) { Out = UV * Tiling + Offset; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Time-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Time-Node.html",
    "title": "Time Node | mmo-rpg-unity",
    "keywords": "Time Node Description Provides access to various Time parameters in the shader. Ports Name Direction Type Binding Description Time Output Float None Time value Sine Time Output Float None Sine of Time value Cosine Time Output Float None Cosine of Time value Delta Time Output Float None Current frame time Smooth Delta Output Float None Current frame time smoothed Generated Code Example The following example code represents one possible outcome of this node. float Time_Time = _Time.y; float Time_SineTime = _SinTime.w; float Time_CosineTime = _CosTime.w; float Time_DeltaTime = unity_DeltaTime.x; float Time_SmoothDelta = unity_DeltaTime.z;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Transform-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Transform-Node.html",
    "title": "Transform Node | mmo-rpg-unity",
    "keywords": "Transform Node Description Returns the result of transforming the input value (In) from one coordinate space to another. Select dropdown options on the node to define which spaces to transform from and to. Ports Name Direction Type Description In Input Vector 3 Input value Out Output Vector 3 Output value Controls Name Type Options Description From Dropdown Object, View, World, Tangent, Absolute World, Screen Select the space to convert from. To Dropdown Object, View, World, Tangent, Absolute World, Screen Select the space to convert to. Type Dropdown Position, Direction, Normal Select how you want to handle the conversion. Node Settings Controls The following control appears on the Node Settings tab of the Graph Inspector when you select the Direction or Normal conversion types for the Transform Node. The Normalize Output setting helps to improve performance as you can disable it if the output is already normalized, or if you don't need the output to remain normalized. Name Type Description Normalize Output Checkbox Reduces the length of the output vector to 1. World and Absolute World Use the World and Absolute World space options to transform the coordinate space of position values. The World space option uses the Scriptable Render Pipeline default world space to convert position values. The Absolute World space option uses absolute world space to convert position values in all Scriptable Render Pipelines. If you use the Transform Node to convert coordinate spaces that aren't for position values, Unity recommends that you use the World space option. Using Absolute World on values that don't represent position might result in unexpected behavior. Conversion type Select the Position type to apply translation to the transformation. Select Direction if the input doesn't describe a surface normal (the direction a surface faces). Select Normal if the input describes a surface normal (the direction the surface faces). Generated Code Example The following example code represents one possible outcome of this node per Base mode. World > World float3 _Transform_Out = In; World > Object float3 _Transform_Out = TransformWorldToObject(In); World > Tangent float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(In, tangentTransform_World); World > View float3 _Transform_Out = TransformWorldToView(In); World > Absolute World float3 _Transform_Out = GetAbsolutePositionWS(In); World > Screen float4 hclipPosition = TransformWorldToHClipDir(In); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); Object > World float3 _Transform_Out = TransformObjectToWorld(In); Object > Object float3 _Transform_Out = In; Object > Tangent float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(TransformObjectToWorld(In), tangentTransform_World); Object > View float3 _Transform_Out = TransformWorldToView(TransformObjectToWorld(In)); Object > Absolute World float3 _Transform_Out = GetAbsolutePositionWS(TransformObjectToWorld(In)); Object > Screen float4 hclipPosition = TransformObjectToHClip(In); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); Tangent > World float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float3 _Transform_Out = mul(In, transposeTangent).xyz; Tangent > Object float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float3 _Transform_Out = TransformWorldToObject(mul(In, transposeTangent).xyz); Tangent > Tangent float3 _Transform_Out = In; Tangent > View float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float3 _Transform_Out = TransformWorldToView(mul(In, transposeTangent).xyz); Tangent > Absolute World float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float3 _Transform_Out = GetAbsolutePositionWS(mul(In, transposeTangent)).xyz; Tangent > Screen float3x3 transposeTangent = transpose(float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal)); float4 hclipPosition = TransformWorldToHClipDir(mul(In, transposeTangent).xyz); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); View > World float3 _Transform_Out = mul(UNITY_MATRIX_I_V, float4(In, 1)).xyz; View > Object float3 _Transform_Out = TransformWorldToObject(mul(UNITY_MATRIX_I_V, float4(In, 1) ).xyz); View > Tangent float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(mul(UNITY_MATRIX_I_V, float4(In, 1) ).xyz, tangentTransform_World); View > View float3 _Transform_Out = In; View > Absolute World float3 _Transform_Out = GetAbsolutePositionWS(mul(UNITY_MATRIX_I_V, float4(In, 1))).xyz; View > Screen float4 hclipPosition = TransformWViewToHClip(In); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); Absolute World > World float3 _Transform_Out = GetCameraRelativePositionWS(In); Absolute World > Object float3 _Transform_Out = TransformWorldToObject(In); Absolute World > Object (in the High Definition Render Pipeline) float3 _Transform_Out = TransformWorldToObject(GetCameraRelativePositionWS(In)); Absolute World > Tangent float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(In, tangentTransform_World); Absolute World > View float3 _Transform_Out = GetCameraRelativePositionWS(In) Absolute World > Absolute World float3 _Transform_Out = In; Absolute World > Screen float4 hclipPosition = TransformWorldToHClip(GetCameraRelativePositionWS(In)); float3 screenPos = hclipPosition.xyz / hclipPosition.w; float3 _Transform_Out = float3(screenPos.xy * 0.5 + 0.5, screenPos.z); Screen > World float3 _Transform_Out = ComputeWorldSpacePosition(In.xy, In.z, UNITY_MATRIX_I_VP); Screen > Object float3 worldPos = ComputeWorldSpacePosition(In.xy, In.z, UNITY_MATRIX_I_VP); float3 _Transform_Out = TransformWorldToObject(worldPos); Screen > Tangent float3 worldPos = ComputeWorldSpacePosition(In.xy, In.z, UNITY_MATRIX_I_VP); float3x3 tangentTransform_World = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); float3 _Transform_Out = TransformWorldToTangent(worldPos, tangentTransform_World); Screen > View float4 positionCS = ComputeClipSpacePosition(In.xy, In.z); float4 result = mul(UNITY_MATRIX_I_V, positionCS); float3 _Transform_Out = result.xyz / result.w; Screen > Absolute World float3 _Transform_Out = GetAbsolutePositionWS(ComputeWorldSpacePosition(In.xy, In.z, UNITY_MATRIX_I_VP));"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Transformation-Matrix-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Transformation-Matrix-Node.html",
    "title": "Transformation Matrix Node | mmo-rpg-unity",
    "keywords": "Transformation Matrix Node Description Defines a constant Matrix 4x4 value for a common Transformation Matrix in the shader. The Transformation Matrix can be selected from the dropdown parameter. Two output value options for this node, Inverse Projection and Inverse View Projection, are not compatible with the Built-In Render Pipeline target. When you choose either of these options and target the Built-In Render Pipeline, this node produces an entirely black result. Ports Name Direction Type Binding Description Out Output Matrix 4 None Output value Controls Name Type Options Description Dropdown Model, InverseModel, View, InverseView, Projection, InverseProjection, ViewProjection, InverseViewProjection Sets output value Generated Code Example The following example code represents one possible outcome of this node per mode. Model float4x4 _TransformationMatrix_Out = UNITY_MATRIX_M; InverseModel float4x4 _TransformationMatrix_Out = UNITY_MATRIX_I_M; View float4x4 _TransformationMatrix_Out = UNITY_MATRIX_V; InverseView float4x4 _TransformationMatrix_Out = UNITY_MATRIX_I_V; Projection float4x4 _TransformationMatrix_Out = UNITY_MATRIX_P; InverseProjection float4x4 _TransformationMatrix_Out = UNITY_MATRIX_I_P; ViewProjection float4x4 _TransformationMatrix_Out = UNITY_MATRIX_VP; InverseViewProjection float4x4 _TransformationMatrix_Out = UNITY_MATRIX_I_VP;"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Triangle-Wave-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Triangle-Wave-Node.html",
    "title": "Triangle Wave Node | mmo-rpg-unity",
    "keywords": "Triangle Wave Node Description Returns a triangle wave from the value of input In. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_TriangleWave_float4(float4 In, out float4 Out) { Out = 2.0 * abs( 2 * (In - floor(0.5 + In)) ) - 1.0; }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Triplanar-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Triplanar-Node.html",
    "title": "Triplanar Node | mmo-rpg-unity",
    "keywords": "Triplanar Node Description Generates UVs and samples a texture by projecting in world space. This method is commonly used to texture large models such as terrain, where hand authoring UV coordinates would either be problematic or not performant. Samples the input Texture 3 times, once in each of the world x, y, and z axes. The resulting information is planar projected onto the model, blended by the normal, or surface angle. You can scale the generated UVs with the input Tile and you can control the final blending strength with the input Blend. Blend controls the way the normal affects the blending of each plane sample and should be greater than or equal to 0. The larger Blend is, the more contribution will be given to the sample from the plane towards which the normal is most oriented. (The maximum blend exponent is between 17 and 158 depending on the platform and the precision of the node.) A Blend of 0 makes each plane get equal weight regardless of normal orientation. To choose the projection, change the Input Space. You can also modify the projection via the inputs Position and Normal. Use the Type dropdown to change the expected type of the input Texture. If set to Normal, the Out port returns the blended normals in Normal Output Space. If you experience texture sampling errors while using this node in a graph which includes Custom Function Nodes or Sub Graphs, upgrade to version 10.3 or later. NOTE: You can only use the Triplanar Node in the Fragment shader stage. Ports Name Direction Type Binding Description Texture Input Texture None Input texture value Sampler Input Sampler State None Sampler for input Texture Position Input Vector 3 Input Space Position Fragment position Normal Input Vector 3 Input Space Normal Fragment normal Tile Input Float None Tiling amount for generated UVs Blend Input Float None Blend factor between different samples Out Output Vector 4 None Output value Controls Name Type Options Description Type Dropdown Default, Normal Type of input Texture Node Settings Controls The following controls appear on the Node Settings tab of the Graph Inspector, when you select the Triplanar Node. Name Type Options Description Input Space Dropdown Object, View, World, Tangent, AbsoluteWorld Controls the coordinate space used by the input ports Position and Normal. When you change the Input Space value, it changes the bindings on the Position and Normal ports to use the specified space. The default value is AbsoluteWorld. Normal Output Space Dropdown Object, View, World, Tangent, AbsoluteWorld Controls the coordinate space used for the Out port. The Normal Output Space control is only available when Type is set to Normal. The default value is Tangent. Generated Code Example The following example code represents one possible outcome of this node. Default float3 Node_UV = Position * Tile; float3 Node_Blend = pow(abs(Normal), Blend); Node_Blend /= dot(Node_Blend, 1.0); float4 Node_X = SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.zy); float4 Node_Y = SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.xz); float4 Node_Z = SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.xy); float4 Out = Node_X * Node_Blend.x + Node_Y * Node_Blend.y + Node_Z * Node_Blend.z; Normal float3 Node_UV = Position * Tile; float3 Node_Blend = max(pow(abs(Normal), Blend), 0); Node_Blend /= (Node_Blend.x + Node_Blend.y + Node_Blend.z ).xxx; float3 Node_X = UnpackNormal(SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.zy)); float3 Node_Y = UnpackNormal(SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.xz)); float3 Node_Z = UnpackNormal(SAMPLE_TEXTURE2D(Texture, Sampler, Node_UV.xy)); Node_X = float3(Node_X.xy + Normal.zy, abs(Node_X.z) * Normal.x); Node_Y = float3(Node_Y.xy + Normal.xz, abs(Node_Y.z) * Normal.y); Node_Z = float3(Node_Z.xy + Normal.xy, abs(Node_Z.z) * Normal.z); float4 Out = float4(normalize(Node_X.zyx * Node_Blend.x + Node_Y.xzy * Node_Blend.y + Node_Z.xyz * Node_Blend.z), 1); float3x3 Node_Transform = float3x3(IN.WorldSpaceTangent, IN.WorldSpaceBiTangent, IN.WorldSpaceNormal); Out.rgb = TransformWorldToTangent(Out.rgb, Node_Transform);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Truncate-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Truncate-Node.html",
    "title": "Truncate Node | mmo-rpg-unity",
    "keywords": "Truncate Node Description Returns the integer, or whole number, component of the value of input In. For example, given an input value of 1.7, this node will return the value 1.0. Ports Name Direction Type Description In Input Dynamic Vector Input value Out Output Dynamic Vector Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Truncate_float4(float4 In, out float4 Out) { Out = trunc(In); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Twirl-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Twirl-Node.html",
    "title": "Twirl Node | mmo-rpg-unity",
    "keywords": "Twirl Node Description Applies a twirl warping effect similar to a black hole to the value of input UV. The center reference point of the warping effect is defined by input Center and the overall strength of the effect is defined by the value of input Strength. Input Offset can be used to offset the individual channels of the result. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Center Input Vector 2 None Center reference point Strength Input Float None Strength of the effect Offset Input Vector 2 None Individual channel offsets Out Output Vector 2 None Output UV value Generated Code Example The following example code represents one possible outcome of this node. void Unity_Twirl_float(float2 UV, float2 Center, float Strength, float2 Offset, out float2 Out) { float2 delta = UV - Center; float angle = Strength * length(delta); float x = cos(angle) * delta.x - sin(angle) * delta.y; float y = sin(angle) * delta.x + cos(angle) * delta.y; Out = float2(x + Center.x + Offset.x, y + Center.y + Offset.y); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/UV-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/UV-Node.html",
    "title": "UV Node | mmo-rpg-unity",
    "keywords": "UV Node Description Provides access to the mesh vertex or fragment's UV coordinates. The coordinate channel of the output value can be selected with the Channel dropdown parameter. Ports Name Direction Type Binding Description Out Output Vector 4 None Mesh's UV coordinates. Controls Name Type Options Description Channel Dropdown UV0, UV1, UV2, UV3 Selects coordinate channel of UV to output."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/UV-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/UV-Nodes.html",
    "title": "UV Nodes | mmo-rpg-unity",
    "keywords": "UV Nodes Flipbook Polar Coordinates Creates a flipbook, or texture sheet animation, of the UVs supplied to input In. Converts the value of input UV to polar coordinates. Radial Shear Rotate Applies a radial shear warping effect similar to a wave to the value of input UV. Rotates the value of input UV around a reference point defined by input Center by the amount of input Rotation. Spherize Tiling and Offset Applies a spherical warping effect similar to a fisheye camera lens to the value of input UV. Tiles and offsets the value of input UV by the inputs Tiling and Offset respectively. Triplanar Twirl A method of generating UVs and sampling a texture by projecting in world space. Applies a twirl warping effect similar to a black hole to the value of input UV. Parallax Mapping Parallax Occlusion Mapping Creates a parallax effect that displaces a material's UVs. Creates a parallax effect that displaces a material's UVs and depth."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/UVCombine-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/UVCombine-Node.html",
    "title": "UVCombine node | mmo-rpg-unity",
    "keywords": "UVCombine node The UVCombine node lets you select which UV channel you want to use for mapping your shader to geometry in your application. You can also choose to apply tiling and offset to your UV coordinates. Note This node is a Subgraph node: it represents a Subgraph instead of directly representing Unity's shader code. Double-click the node in any Shader Graph to view its Subgraph. Create Node menu category The UVCombine node is under the Utility > High Definition Render Pipeline category in the Create Node menu. Compatibility node is supported on the following render pipelines: Built-in Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) No No Yes For more information on the HDRP, see Unity's HDRP package documentation. node can also be connected to any Block node in either Context. For more information on Block nodes and Contexts, see Master Stack. Inputs node has the following input ports: Name Type Description UV Channel Mask Vector 4 Select which UV channel you want to use for your UV coordinates by entering a 1 in the corresponding default input on the port: X: UV channel 0 Y: UV channel 1 Z: UV channel 2 W: UV channel 3 Set all other default inputs to 0. You can also connect a node that outputs a Vector 4. UV Tile and Offset Vector 4 Use the port's default input to specify the amount of offset or tiling that you want to apply to your shader's UV coordinates: Use X and Y to specify the tiling. Use W and Z to specify the offset. You can also connect a node that outputs a Vector 4. Outputs node has one output port: Name Type Binding Description UV Vector 2 UV The final UV output, after selecting a UV channel and, if specified, any tiling or offset. Example graph usage For an example use of the UVCombine node, see either of the HDRP's Fabric shaders. To view these Shader Graphs: Create a new material and assign it the HDRP > Fabric > Silk or HDRP > Fabric > CottonWool shader, as described in the Unity User Manual section Creating a material asset, and assigning a shader to it. Next to the Shader dropdown, select Edit. Your chosen Fabric's Shader Graph opens. You can view the UVCombine node, its Subgraph, and the other nodes that create HDRP's Fabric shaders."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Unpack-Data-Water-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Unpack-Data-Water-Node.html",
    "title": "Unpack Water Data | mmo-rpg-unity",
    "keywords": "Unpack Water Data This node unpacks and outputs water properties for the fragment context. See the HDRP documentation for more information about the Water System. Render pipeline compatibility Node Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Unpack Water Data No Yes Ports Name Direction Type Description LowFrequencyHeight Output Float The vertical displacement of the water surface. This doesn't include ripples. HorizontalDisplacement Output Float The horizontal displacement of the water surface. SSSMask Output Float A mask that defines where the water surface has subsurface scattering."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Upgrade-Guide-10-0-x.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Upgrade-Guide-10-0-x.html",
    "title": "Upgrade to version 10.0.x of Shader Graph | mmo-rpg-unity",
    "keywords": "Upgrade to version 10.0.x of Shader Graph Renamed Vector 1 property and Float precision Shader Graph has renamed the Vector 1 property as Float in both the Vector 1 node and the exposed parameter list. The Float precision was also renamed as Single. Behavior is exactly the same, and only the names have changed. Renamed Sample Cubemap Node Shader Graph has renamed the previous Sample Cubemap Node to Sample Reflected Cubemap Node, and has added a new Sample Cubemap Node, which uses world space direction. Master Stack graph output Shader Graph has removed the Master Nodes and introduced a more flexible Master Stack solution for defining graph output in 10.0. You can still open all graphs created in previous versions, because Shader Graph automatically upgrades them. This page describes the expected behavior and explains when you might need to perform manual upgrade steps. Automatic upgrade from Master Nodes Upgrade one Master Node to the Master Stack If your graph only has one Master Node, Shader Graph automatically upgrades all of the data from that Master Node to a Master Stack output, as described in this section. Shader Graph automatically adds the correct Targets to the Graph Settings tab of the Graph Inspector. It also copies all settings from the Master Node settings menu (gear icon) that describe surface options from the Master Node to the Target Settings. Shader Graph then adds a Block node for each port on the Master Node to the Master Stack. It connects any nodes that you connected to the Master Node ports to the corresponding Block node. Also, Shader Graph copies any values that you entered into the default value inputs of the Master Node ports to the corresponding Block node. After this upgrade process, the final shader is identical in appearance. Upgrade multiple Master Nodes to the Master Stack If your graph has more than one Master Node, Shader Graph applies the above process for automatically upgrading one Master Node to the currently selected Active Master Node. When you upgrade to the Master Stack format, Shader Graph removes any inactive Master Nodes from your graph, and you might lose this data. If you plan to upgrade a graph with multiple Master Nodes, it's best practice to keep a record of the ports, connected nodes, and any non-default settings in the settings menu (gear icon) of inactive Master Nodes. After the upgrade, you can add any required Block nodes that went missing, and reconnect the nodes to the Master Stack. You also need to go to the Graph Inspector > Graph Settings tab > settings menu (gear icon), and manually enter the settings for inactive Master Nodes in the corresponding Target Setting. Upgrade cross-pipeline Master Nodes to the Master Stack If your graph contains PBR or Unlit Master Nodes that are compatible with both the Universal Render Pipeline (URP) and the High Definition Render Pipeline (HDRP), Shader Graph automatically upgrades them to the Master Stack based on the render pipeline currently available in your project. With Master Stacks, when you switch from one render pipeline to another, you must reimport your Shader Graph assets to update the Material Inspector for any Materials in your project. In URP, you can now find all PBR Master Node settings in the URP Lit Target. The Unlit Master Node settings are in the URP Unlit Target. These settings are the same, and the final shader should appear the same as before the upgrade. In HDRP, settings from the PBR and Unlit Master Nodes are not the same as the HDRP Lit and Unlit Targets. Thus, there might be unexpected behavior when you upgrade PBR or Unlit Master Nodes to HDRP Lit and Unlit Master Stacks. The final shader might not appear the same as before the upgrade. When this happens, you can use the Bug Reporter to submit your upgrade issue, but keep in mind that some upgrade paths don't have immediate automated solutions and will require manual adjustments. \"View Generated Shader\" has moved Previously, you could right-click the Master Node to bring up a context menu, and select View Generated Shader to preview the generated shader. In 10.0, you must now use the Unity Inspector, and click the View Generated Shader button on the Shader Graph asset. Settings in Graph Inspector Shader Graph introduced an internal Graph Inspector in version 10.0. The Graph Inspector is a floating window that displays settings related to objects you select in the graph. Graph settings Graph-wide settings are now available only in the Graph Inspector's Graph Settings tab. Most notably, you can now go to the Graph Settings tab to access the Precision toggle, which was previously located on the Shader Graph Toolbar. There were no changes to data, and things like the Precision setting of the graph remain the same. In the Graph Settings tab, you can also find settings that describe surface options for each Target, which were previously located in the Master Node cog menu. For more information about how Shader Graph automatically upgrades this data, see Automatic upgrade from Master Nodes above. Property settings Property settings that were previously in Blackboard foldouts are now available in the Graph Inspector. You can now select multiple properties from the Blackboard and edit them all at the same time. There were no changes to data, and all settings you made on properties of the graph remain the same. Per-Node settings All per-node settings that you previously managed by opening a settings (gear icon) sub-menu are now accessible through the Graph Inspector. There were no changes to data, and all settings you previously set on nodes, such as precision settings and Custom Function Node settings, remain the same. Any settings on the Master Node that define surface options are now located in the Graph Inspector’s Graph Settings tab. For more information, see Automatic upgrade from Master Nodes above. Custom Function Nodes and Shader Graph Preview To avoid errors in the preview shader compilation for Custom Function Nodes, you might need to use keywords for the in-graph preview rendering. If you have any Custom Function Nodes with custom Shader Graph Preview code that uses #if SHADERGAPH_PREVIEW, you need to upgrade it to an #ifdef declaration, as follows. #ifdef SHADERGAPH_PREVIEW Out = 1; #else Out = MainLight; #endif Deprecated node and property behaviors Previously, some nodes and properties such as the Color Node didn't behave as intended, but they now work correctly in Shader Graph version 10.0. Older graphs that rely on the incorrect behavior still function the same as before, and you can choose to individually upgrade any deprecated nodes and properties. If you don't enable Allow Deprecated Behaviors in Shader Graph Preferences, newly-created nodes and properties use the latest version node and property behaviors. For deprecated nodes, (Deprecated) appears after the node title in the main graph view. For deprecated properties, (Deprecated) appears after the property name in the Blackboard. When you select a deprecated node or property, a warning appears in the Internal Inspector along with an Update button that allows you to upgrade the selection. You can use undo/redo to reverse this upgrade process. If you enable Allow Deprecated Behaviors in Shader Graph Preferences, Shader Graph displays the version of the deprecated node or property, and doesn't display any warnings even though the Update button appears. You can also use the Blackboard or Searcher to create deprecated nodes and properties."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Utility-Nodes.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Utility-Nodes.html",
    "title": "Utility Nodes | mmo-rpg-unity",
    "keywords": "Utility Nodes Preview Sub-Graph Provides a preview window and passes the input value through without modification. Provides a reference to a Sub-graph asset. Logic All And Returns true if all components of the input In are non-zero. Returns true if both the inputs A and B are true. Any Branch Returns true if any of the components of the input In are non-zero. Provides a dynamic branch to the shader. Comparison Is Infinite Compares the two input values A and B based on the condition selected on the dropdown. Returns true if any of the components of the input In is an infinite value. Is NaN Nand Returns true if any of the components of the input In is not a number (NaN). Returns true if both the inputs A and B are false. Not Or Returns the opposite of input In. If In is true, the output is false. Otherwise, it returns true. Returns true if either input A or input B is true."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vector-2-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vector-2-Node.html",
    "title": "Vector 2 Node | mmo-rpg-unity",
    "keywords": "Vector 2 Node Description Defines a Vector 2 value in the shader. If Ports X and Y are not connected with Edges this Node defines a constant Vector 2, otherwise this Node can be used to combine various Float values. Ports Name Direction Type Binding Description X Input Float None Input x component value Y Input Float None Input y component value Out Output Vector 2 None Output value Generated Code Example The following example code represents one possible outcome of this node. float2 _Vector2_Out = float2(X, Y);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vector-3-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vector-3-Node.html",
    "title": "Vector 3 Node | mmo-rpg-unity",
    "keywords": "Vector 3 Node Description Defines a Vector 3 value in the shader. If Ports X, Y and Z are not connected with Edges this Node defines a constant Vector 3, otherwise this Node can be used to combine various Float values. Ports Name Direction Type Binding Description X Input Float None Input x component value Y Input Float None Input y component value Z Input Float None Input z component value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. float3 _Vector3_Out = float3(X, Y, Z);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vector-4-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vector-4-Node.html",
    "title": "Vector 4 Node | mmo-rpg-unity",
    "keywords": "Vector 4 Node Description Defines a Vector 4 value in the shader. If Ports X, Y, Z and W are not connected with Edges this Node defines a constant Vector 4, otherwise this Node can be used to combine various Float values. Ports Name Direction Type Binding Description X Input Float None Input x component value Y Input Float None Input y component value Z Input Float None Input z component value W Input Float None Input w component value Out Output Vector 4 None Output value Generated Code Example The following example code represents one possible outcome of this node. float4 _Vector4_Out = float4(X, Y, Z, W);"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vertex-Color-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vertex-Color-Node.html",
    "title": "Vertex Color Node | mmo-rpg-unity",
    "keywords": "Vertex Color Node Description Provides access to the mesh vertex or fragment's Vertex Color value. Ports Name Direction Type Binding Description Out Output Vector 4 None Vertex Color for the Mesh Vertex/Fragment."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vertex-ID-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Vertex-ID-Node.html",
    "title": "Vertex ID Node | mmo-rpg-unity",
    "keywords": "Vertex ID Node Description Provides access to the mesh vertex or fragment's Vertex ID value. Ports Name Direction Type Binding Description Out Output Float None Vertex ID for the Mesh Vertex/Fragment."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/View-Direction-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/View-Direction-Node.html",
    "title": "View Direction Node | mmo-rpg-unity",
    "keywords": "View Direction Node Description Provides access to the mesh vertex or fragment's View Direction vector. This is the vector from the vertex or fragment to the camera. Select a Space to modify the coordinate space of the output value. Prior to version 11.0, the View Direction Node works differently in HDRP than in URP. In URP, it only stored Object space vectors normalized. HDRP stores all vectors normalized. From 11.0 onwards, this node stores all vectors normalized in both the High-Definition Render Pipeline and the Universal Render Pipeline. If you want to keep using the old behavior in URP outside of object space, replace this node with a View Vector Node. Ports Name Direction Type Binding Description Out Output Vector 3 None View Vector for the Mesh Vertex/Fragment. Controls Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of View Direction to output."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/View-Vector-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/View-Vector-Node.html",
    "title": "View Vector Node | mmo-rpg-unity",
    "keywords": "View Vector Node Description This node provides access to an unnormalized version of the mesh vertex or fragment's View Direction vector. It does not normalize any of the values it stores. For a normalized option, see View Direction Node. Select a Space to modify the output value's coordinate space. Ports Name Direction Type Binding Description Out Output Vector 3 None View Vector for the Mesh Vertex/Fragment. Controls Name Type Options Description Space Dropdown Object, View, World, Tangent Selects coordinate space of View Direction to output."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Voronoi-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/Voronoi-Node.html",
    "title": "Voronoi Node | mmo-rpg-unity",
    "keywords": "Voronoi Node Description Generates a Voronoi, or Worley, noise based on input UV. Voronoi noise is generated by calculating distances between a pixel and a lattice of points. By offsetting these points by a pseudo-random number, controlled by input Angle Offset, a cluster of cells can be generated. The scale of these cells, and the resulting noise, is controlled by input Cell Density. The output Cells contains the raw cell data. You can also choose to use two different hashing methods for calculating the noise. As of Unity version 2021.2, the Voronoi node defaults to the Deterministic hash, to ensure consistent results for noise generation across platforms. Ports Name Direction Type Binding Description UV Input Vector 2 UV Input UV value Angle Offset Input Float None Offset value for points Cell Density Input Float None Density of cells generated Out Output Float None Output noise value Cells Output Float None Raw cell data Controls Name Type Options Description Hash Type Dropdown Deterministic, LegacySine Selects the hash function used to generate random numbers for noise generation. Generated Code Example The following example code represents one possible outcome of this node. inline float2 unity_voronoi_noise_randomVector (float2 UV, float offset) { float2x2 m = float2x2(15.27, 47.63, 99.41, 89.98); UV = frac(sin(mul(UV, m)) * 46839.32); return float2(sin(UV.y*+offset)*0.5+0.5, cos(UV.x*offset)*0.5+0.5); } void Unity_Voronoi_float(float2 UV, float AngleOffset, float CellDensity, out float Out, out float Cells) { float2 g = floor(UV * CellDensity); float2 f = frac(UV * CellDensity); float t = 8.0; float3 res = float3(8.0, 0.0, 0.0); for(int y=-1; y<=1; y++) { for(int x=-1; x<=1; x++) { float2 lattice = float2(x,y); float2 offset = unity_voronoi_noise_randomVector(lattice + g, AngleOffset); float d = distance(lattice + offset, f); if(d < res.x) { res = float3(d, offset.x, offset.y); Out = res.x; Cells = res.y; } } } }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/White-Balance-Node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/White-Balance-Node.html",
    "title": "White Balance Node | mmo-rpg-unity",
    "keywords": "White Balance Node Description Adjusts the temperature and tint of input In by the amount of inputs Temperature and Tint respectively. Temperature has the effect of shifting the values towards yellow or blue. Tint has the effect of shifting towards pink or green. Ports Name Direction Type Binding Description In Input Vector 3 None Input value Temperature Input Float None Temperature offset value Tint Input Float None Tint offset value Out Output Vector 3 None Output value Generated Code Example The following example code represents one possible outcome of this node. void Unity_WhiteBalance_float(float3 In, float Temperature, float Tint, out float3 Out) { // Range ~[-1.67;1.67] works best float t1 = Temperature * 10 / 6; float t2 = Tint * 10 / 6; // Get the CIE xy chromaticity of the reference white point. // Note: 0.31271 = x value on the D65 white point float x = 0.31271 - t1 * (t1 < 0 ? 0.1 : 0.05); float standardIlluminantY = 2.87 * x - 3 * x * x - 0.27509507; float y = standardIlluminantY + t2 * 0.05; // Calculate the coefficients in the LMS space. float3 w1 = float3(0.949237, 1.03542, 1.08728); // D65 white point // CIExyToLMS float Y = 1; float X = Y * x / y; float Z = Y * (1 - x - y) / y; float L = 0.7328 * X + 0.4296 * Y - 0.1624 * Z; float M = -0.7036 * X + 1.6975 * Y + 0.0061 * Z; float S = 0.0030 * X + 0.0136 * Y + 0.9834 * Z; float3 w2 = float3(L, M, S); float3 balance = float3(w1.x / w2.x, w1.y / w2.y, w1.z / w2.z); float3x3 LIN_2_LMS_MAT = { 3.90405e-1, 5.49941e-1, 8.92632e-3, 7.08416e-2, 9.63172e-1, 1.35775e-3, 2.31082e-2, 1.28021e-1, 9.36245e-1 }; float3x3 LMS_2_LIN_MAT = { 2.85847e+0, -1.62879e+0, -2.48910e-2, -2.10182e-1, 1.15820e+0, 3.24281e-4, -4.18120e-2, -1.18169e-1, 1.06867e+0 }; float3 lms = mul(LIN_2_LMS_MAT, In); lms *= balance; Out = mul(LMS_2_LIN_MAT, lms); }"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/index.html",
    "title": "About Shader Graph | mmo-rpg-unity",
    "keywords": "About Shader Graph Description Shader Graph enables you to build shaders visually. Instead of writing code, you create and connect nodes in a graph framework. Shader Graph gives instant feedback that reflects your changes, and it’s simple enough for users who are new to shader creation. For an introduction to Shader Graph, see Getting Started. Shader Graph is available through the Package Manager window in supported versions of the Unity Editor. If you install a Scriptable Render Pipeline (SRP) such as the Universal Render Pipeline (URP) or the High Definition Render Pipeline (HDRP), Unity automatically installs Shader Graph in your project. Shader Graph package versions on Unity Engine 2018.x are Preview versions, which do not receive bug fixes and feature maintenance. To work with an actively supported version of Shader Graph, use Unity Engine 2019.1 or higher. SRP packages are part of the core With the release of Unity 2021.1, graphics packages are relocating to the core of Unity. This move simplifies the experience of working with new Unity graphics features, as well as ensuring that your projects are always running on the latest verified graphics code. For each release of Unity (alpha / beta / patch release) graphics packages are embedded within the main Unity installer. When you install the latest release of Unity, you also get the latest Universal Render Pipeline (URP), High Definition Render Pipeline (HDRP), Shader Graph, Visual Effect (VFX) Graph packages, among others. Tying graphics packages to the main Unity release allows better testing to ensure that the graphics packages you use have been tested extensively with the version of Unity you have downloaded. You can also use a local copy or a custom version of the graphics packages with an override in the manifest file. For more information, see the following post on the forum: SRP v11 beta is available now."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/materialvariant-SG.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/materialvariant-SG.html",
    "title": "Material Variants | mmo-rpg-unity",
    "keywords": "Material Variants When you create materials in a project, you might want to create variations based on a single material: outfits with different color schemes, damaged and undamaged versions of scenery, or shiny and weathered instances of props. You can use Material Variants to manage these variations. For more information on Material Variants in Unity, see Material Variants in the Unity User Manual. You can create a Material Variant from any Shader Graph material. For more information on how to create a Material Variant, see Create, modify, and apply Material Variants in the User Manual."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/hdrp-latest-link.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/hdrp-latest-link.html",
    "title": "hdrp-latest-link | mmo-rpg-unity",
    "keywords": "For more information on the HDRP, see Unity's HDRP package documentation."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-additional-settings.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-additional-settings.html",
    "title": "nodes-additional-settings | mmo-rpg-unity",
    "keywords": "node has some additional settings that you can access from the Graph Inspector:"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-all-contexts.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-all-contexts.html",
    "title": "nodes-all-contexts.md | mmo-rpg-unity",
    "keywords": "node can also be connected to any Block node in either Context. For more information on Block nodes and Contexts, see Master Stack."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-compatibility-all.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-compatibility-all.html",
    "title": "nodes-compatibility-all | mmo-rpg-unity",
    "keywords": "node is supported on the following render pipelines: Built-In Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) Yes Yes Yes"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-compatibility-hdrp.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-compatibility-hdrp.html",
    "title": "nodes-compatibility-hdrp | mmo-rpg-unity",
    "keywords": "node is supported on the following render pipelines: Built-in Render Pipeline Universal Render Pipeline (URP) High Definition Render Pipeline (HDRP) No No Yes"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-controls.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-controls.html",
    "title": "nodes-controls | mmo-rpg-unity",
    "keywords": "node has the following controls:"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-fragment-only.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-fragment-only.html",
    "title": "nodes-fragment-only | mmo-rpg-unity",
    "keywords": "node can only be connected to a Block node in the Fragment Context. For more information on Block nodes and Contexts, refer to Master Stack."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-generated-code.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-generated-code.html",
    "title": "nodes-generated-code | mmo-rpg-unity",
    "keywords": "The following code represents this node in Unity's shader code"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-inputs.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-inputs.html",
    "title": "nodes-inputs | mmo-rpg-unity",
    "keywords": "node has the following input ports:"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-outputs.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-outputs.html",
    "title": "nodes-outputs | mmo-rpg-unity",
    "keywords": "node has the following output ports:"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-related.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-related.html",
    "title": "nodes-related | mmo-rpg-unity",
    "keywords": "The following nodes are related or similar to the"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-single-control.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-single-control.html",
    "title": "nodes-single-control | mmo-rpg-unity",
    "keywords": "node has one control:"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-single-input.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-single-input.html",
    "title": "nodes-single-input | mmo-rpg-unity",
    "keywords": "node has one input port:"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-single-output.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-single-output.html",
    "title": "nodes-single-output | mmo-rpg-unity",
    "keywords": "node has one output port:"
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-subgraph-node.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/nodes-subgraph-node.html",
    "title": "nodes-subgraph-node | mmo-rpg-unity",
    "keywords": "Note This node is a Subgraph node: it represents a Subgraph instead of directly representing Unity's shader code. Double-click the node in any Shader Graph to view its Subgraph."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-errors.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-errors.html",
    "title": "nodes-sample-errors | mmo-rpg-unity",
    "keywords": "Note If you experience texture sampling errors for this node in a graph with Custom Function Nodes or Sub Graphs, upgrade to Shader Graph version 10.3 or later."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-fragment-lod.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-fragment-lod.html",
    "title": "nodes-sample-fragment-lod | mmo-rpg-unity",
    "keywords": "With its default settings, this node can only connect to a Block node in the Fragment Context of a Shader Graph. To sample a Texture for the Vertex Context of a Shader Graph, set the Mip Sampling Mode to LOD."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-mip-bias-sample-mode-table.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-mip-bias-sample-mode-table.html",
    "title": "nodes-sample-mip-bias-sample-mode-table.md | mmo-rpg-unity",
    "keywords": "Name Type Description Use Global Mip Bias Toggle Enable Use Global Mip Bias to use the render pipeline's Global Mip Bias. This bias adjusts the percentage of texture information taken from a specific mip when sampling. For more information on mip bias, see Mipmaps introduction in the Unity User Manual. Enabled Shader Graph uses the render pipeline's Global Mip Bias to adjust the texture information taken when sampling. Disabled Shader Graph doesn't use the render pipeline's Global Mip Bias to adjust texture information when sampling. Mip Sampling Mode Dropdown Choose the sampling mode to use to calculate the mip level of the texture. Standard The render pipeline calculates and automatically selects the mip for the texture. LOD The render pipeline lets you set an explicit mip for the texture on the node. The texture will always use this mip, regardless of the DDX or DDY calculations between pixels. Set the Mip Sampling Mode to LOD to connect the node to a Block node in the Vertex Context. For more information on Block nodes and Contexts, see Master Stack. Gradient The render pipeline lets you set the DDX and DDY values to use for its mip calculation, instead of using the values calculated from the texture's UV coordinates. For more information on DDX and DDY values, see Mipmaps introduction in the User Manual. Bias The render pipeline lets you set a bias to adjust the calculated mip for a texture up or down. Negative values bias the mip to a higher resolution. Positive values bias the mip to a lower resolution. The render pipeline can add this value to the value of the Global Mip Bias, or use this value instead of its Global Mip Bias. For more information on mip bias, see Mipmaps introduction in the User Manual."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-mip-mode-table.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-mip-mode-table.html",
    "title": "nodes-sample-mip-mode-table | mmo-rpg-unity",
    "keywords": "LOD Float LOD NOTE The LOD Input port only displays if Mip Sampling Mode is LOD. For more information, see Additional Node Settings. The specific mip that the node uses when sampling the Texture. Bias Float Bias NOTE The Bias Input port only displays if Mip Sampling Mode is Bias. For more information, see Additional Node Settings. If Use Global Mip Bias is enabled, Unity adds this Bias amount to the Global Mip Bias for a texture's mip calculation. If Global Mip Bias is disabled, Unity uses this Bias amount instead of the Global Mip Bias. DDX Float DDX NOTE The DDX Input port only displays if Mip Sampling Mode is Gradient. For more information, see Additional Node Settings. The specific DDX value to use to calculate the Texture's mip when sampling. For more information on DDX values for mipmaps, see Mipmaps introduction in the Unity User Manual.. DDY Float DDY NOTE The DDY Input port only displays if Mip Sampling Mode is Gradient. For more information, see Additional Node Settings. The specific DDY value to use to calculate the Texture's mip when sampling. For more information on DDY values for mipmaps, see Mipmaps introduction in the Unity User Manual."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-rgba-output-table.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sample-nodes/nodes-sample-rgba-output-table.html",
    "title": "nodes-sample-rgba-output-table | mmo-rpg-unity",
    "keywords": "Name Type Description RGBA Vector 4 The full RGBA Vector 4 color value of the texture sample. R Float The Red channel or X component of the texture sample. G Float The Green channel or Y component of the texture sample. B Float The Blue channel or Z component of the texture sample. A Float The Alpha channel or W component of the texture sample."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sg-node-fragment-only.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/snippets/sg-node-fragment-only.html",
    "title": "node-fragment-only | mmo-rpg-unity",
    "keywords": "node can only connect to a Block node in the Fragment Context of your Shader Graph. For more information on Block nodes and Contexts, see Master Stack."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/surface-options.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/Documentation~/surface-options.html",
    "title": "Modify surface options without changing your graph | mmo-rpg-unity",
    "keywords": "Modify surface options without changing your graph Description Enable Allow Material Override to modify a specific set of properties for Universal Render Pipeline Lit and Unlit Shader Graphs and for Built-In Render Pipeline Shader Graphs in the Material Inspector. Property URP Lit URP Unlit Built-In Render Pipeline Workflow Mode See the URP documentation for the Lit URP Shader. Not applicable. Not applicable. Receive Shadows Cast Shadows This property is only exposed if Allow Material Override is enabled for this Shader Graph. Enable this property to make it possible for a GameObject using this shader to cast shadows onto itself and other GameObjects. This corresponds to the SubShader Tag ForceNoShadowCasting. Not applicable. Surface Type See the URP documentation for the Lit and Unlit Shaders. In the Built-In Render Pipeline, this feature has the same behavior as in URP. Consult the URP documentation. Render Face In the Built-In Render Pipeline, this feature has the same behavior as in URP. Consult the URP documentation. Alpha Clipping In the Built-In Render Pipeline, this feature has the same behavior as in URP. Consult the URP documentation. Depth Write This property is only exposed if Allow Material Override is enabled for this Shader Graph. Use this property to determine whether the GPU writes pixels to the depth buffer when it uses this shader to render geometry. Options: Auto (default): Unity writes pixels to the depth buffer for opaque materials, but not for transparent materials. Force Enabled Unity always writes pixels to the depth buffer. Force Disabled Unity never writes pixels to the depth buffer. This option's functionality corresponds to the command ZWrite in ShaderLab. To override this setting in a RenderStateBlock, set the depthState. Depth Test This property is only exposed if Allow Material Override is enabled for this Shader Graph. Use this property to set the conditions under which pixels pass or fail depth testing. The GPU does not draw pixels that fail a depth test. If you choose anything other than LEqual (the default setting for this property), consider also changing the rendering order of this material. Options: LEqual (default): Unity draws the pixel, if its depth value is less than or equal to the value on the depth texture. Less: Unity draws pixels of the affected surface if their coordinates are less than the current depth buffer value. Never: Unity never draws the pixels of the affected surface. Less: Unity draws pixels of the affected surface if their coordinates are less than the current depth buffer value. Greater: Unity draws pixels of the affected surface if their coordinates are greater than the current depth buffer value. GEqual: Unity draws pixels of the affected surface if their coordinates are greater than or equal to the current depth buffer value. Equal: Unity draws pixels of the affected surface if their coordinates are equal to the current depth buffer value. NotEqual: Unity draws pixels of the affected surface if their coordinates are not the same as the current depth buffer value. Always: Unity draws this surface to your screen regardless of its z-coordinate. This option's functionality corresponds to the command ZTest in ShaderLab. To override this setting in a RenderStateBlock, set the depthState property. Support VFX Graph This property is only available if the Visual Effect Graph package is installed. Indicates whether this Shader Graph supports the Visual Effect Graph. If you enable this property, output contexts can use this Shader Graph to render particles. The internal setup that Shader Graph does to support visual effects happens when Unity imports the Shader Graph. This means that if you enable this property, but don't use the Shader Graph in a visual effect, there is no impact on performance. It only affects the Shader Graph import time. Not applicable. How to use To use the Material Override feature: Create a new graph in Shader Graph. Save this graph. Open the Graph Inspector. Set Active Targets to Universal or Built In. In the Graph Inspector’s Universal or Built In section, enable Allow Material Override. Create or select a Material or GameObject which uses your Shader Graph. In the Material Inspector, modify Surface Options for the target Material or GameObject."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.shadergraph copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.shadergraph@14.0.11/README.html": {
    "href": "Library/PackageCache/com.unity.shadergraph@14.0.11/README.html",
    "title": "Shader Graph | mmo-rpg-unity",
    "keywords": "Shader Graph A Shader Graph enables you to build shaders visually. Instead of hand writing code you create and connect nodes in a graph network. The graph framework gives instant feedback on the changes, and it’s simple enough that new users can become involved in shader creation. Unless you intend to modify Shader Graph or want to try out the latest and unsupported features, Unity recommends that you install Shader Graph through the Unity Package Manager: Open a Unity project. Open the Package Manager window (Window > Package Manager). In the Package Manager window, in the Packages menu, select Unity Registry. Do one of the following, based on your project needs: To use Shader Graph and the Universal Render Pipeline (URP) in your project, select Universal RP. To use Shader Graph and the High Definition Render Pipeline (HDRP), select High Definition RP. To use Shader Graph with Unity's Built-In Render Pipeline, select Shader Graph. Unity recommends using Shader Graph with URP or HDRP. Instructions If you want to try out the latest features, we recommend obtaining the most recent version of Shader Graph through the Unity Scriptable Render Pipeline (SRP) repository, which includes the Shader Graph project as a Git submodule. For more information on Git submodules, see Git's documentation on Submodules. If you don't install Shader Graph through the SRP repository, you don't have any Master Node backends available and your shaders are invalid. Invalid shaders appear pink in the Unity Editor. Installing through the repository also ensures you have a compatible set of render pipeline and Shader Graph versions. For more detailed instructions for installing from the repository, see the SRP repository's README."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [1.1.33] - 2022-07-12 Fixed an issue where using Assert.Expect with the same string multiple times can lead to incorrect errors in some cases (DSTR-442). Improved the logging when using multiple Assert.Expect that the logs appear in another order than expected (DSTR-442). Moved the targetPlatform specified when running tests in the TestRunnerApi from the Filter to the ExecutionSettings (DSTR-186). Fixed an issue where an inheritance of UnityPlatformAttribute which was not working (ESTT-70). Fixed the log of excluded platforms which was not displaying the right information. Added filename and linenumber to test finished message (DSTR-505). Add the possibility of running tests in a specified order from a test list (DSTR-494). [1.1.32] - 2022-04-06 Ensured that BuildTargetGroup is set correctly before TestPlayerBuildModifier is invoked (DSTR-394). Added a TestSetting that allows to build an Android App Bundle instead of APK. [1.1.31] - 2022-02-03 Fixed \"Open source code\" on tests when located inside a package. Added editor analytics events. Added buildPlayerPath argument. Path to where built player with tests is saved. [1.1.30] - 2021-10-15 Added validation of IEnumerator return type for parameterized tests with UnityTest attribute (DSTP-743). Fixed runInBackground reset to original value after finishing to run playmode tests (DSTR-248). Fixed issue with circular assembly references when constructing the test tree (DSTR-300). [1.1.29] - 2021-08-12 Nested enumerator execution order fix (DSTR-227). Fix UI not running any tests if run select on a nested namespaces (DSTR-256). [1.1.28] - 2021-06-25 Fix CountDownEvent reference due to com.unity.ext.nunit update. Various performance optimization to fix \"Test execution timed out. No activity received from the player in 600 seconds.\"(DSTR-100). [1.1.27] - 2021-06-15 Fix empty reason on passed tests results xml (DSTR-63) Fix Repeat and Retry attribute for UnityTest in PlayMode (DSTR-237). Remove XDK Xbox One platform after Unity 2020.3 Fixed issue when . suffix was applied to BuildTargets without extension. Added support for GameCoreXboxOne and GameCoreXboxSeries reduced location path length. [1.1.26] - 2021-05-25 Fix html bug in TestRunnerApi API code snippet (DS-1973). Fix typo bug in PreBuildSetup code example (DS-1974). Fix incorrect syntax in command line reference (DS-1971). Fixed a bug where test filter would match project or player path (DSTP-412). Added playerGraphicsAPI TestSettings parameter [1.1.25] - 2021-05-05 Fixed a bug where test filter would match project or player path (DSTP-412). Added playerGraphicsAPI TestSettings parameter [1.1.24] - 2021-03-04 Improving UTF documentation(DSTR-120) Updated \"Actions outside of tests\" section of user manual. Added flow charts to clarify execution order for SetUp/TearDown, TestActions, and complete flow (DSTR-121). Fixed accepted values for scriptingBackend argument to be string literals instead of int values (DSTR-122). Fixed possible values of ResultState to be Passed, Failed, Skipped, Inconclusive, plus labels instead of Success and Failure (DSTR-125). Added NUNit version information (DSTR-130). Added namespace information for LogAsset in user manual (DSTR-124). Added instructions for creating additional sets of tests (DSTR-129). Added information on testResults XML output format and exit codes (DSTR-131). Updated description of testPlatform command line argument to clarify accepted values and their meaning (DSTR-123). Reduce time taken by filtering operations when only a subset of tests is run. Reduced the time taken to rebuild the test tree and to scan for assets a test created but did not delete. Reduce the per-test overhead of running tests in the editor. Added profiler markers around test setup, teardown, and execution. Fixed unstable timeout bug (DSTR-21). [1.1.23] - 2021-01-21 Improving UTF documentation(DSTR-120) Updated \"Actions outside of tests\" section of user manual. Added flow charts to clarify execution order for SetUp/TearDown, TestActions, and complete flow (DSTR-121). Fixed accepted values for scriptingBackend argument to be string literals instead of int values (DSTR-122). Fixed possible values of ResultState to be Passed, Failed, Skipped, Inconclusive, plus labels instead of Success and Failure (DSTR-125). Added NUNit version information (DSTR-130). Added namespace information for LogAsset in user manual (DSTR-124). Added instructions for creating additional sets of tests (DSTR-129). Added information on testResults XML output format and exit codes (DSTR-131). Updated description of testPlatform command line argument to clarify accepted values and their meaning (DSTR-123). [1.1.22] - 2021-01-21 Fixed issue where test result of an explicit test was set to skipped in case it was passing and running from command line with testfilter set to the explicit test (DS-1236). Fixed an issue where tests located in assemblies that did not directly reference any test assemblies were not included (DSTR-30). Fixed an issue where UnitySetup methods were incorrectly being rerun when entering playmode, rather than being skipped (DSTR-68). Internal: Remove ##utp message AssemblyCompilationErrors (DS-1277) Fixed issue where if the timeout was exceeded in SetUp the timeout exception was not thrown(DSTR-21). Removed ability to Enable playmode tests for all assemblies from the TestRunner UI, since it is a deprecated behavior. It enforces to use of assembly definition files (DSTR-45). Fixed typo in LogAssert.cs documentation. [1.1.21] - 2020-12-04 Fixed issue where test result of an explicit test was set to skipped in case it was passing and running from command line with testfilter set to the explicit test (DS-1236). Fixed an issue where tests located in assemblies that did not directly reference any test assemblies were not included (DSTR-30). Fixed an issue where UnitySetup methods were incorrectly being rerun when entering playmode, rather than being skipped (DSTR-68). Internal: Remove ##utp message AssemblyCompilationErrors (ds-1277) Fixed issue where if the timeout was exceeded in SetUp the timeout exception was not thrown(DSTR-21). Removed ability to Enable playmode tests for all assemblies from the TestRunner UI, since it is a deprecated behavior. It enforces to use of assembly definition files (DSTR-45). [1.1.20] - 2020-12-04 The logscope is now available in OneTimeTearDown. Fixed an issue where failing tests would not result in the correct exit code if a domain reload happens after the test has run (DS-1304). If a player build fails, the test specific build settings should be cleaned up and the original values restored as intended (DS-1001). Added better error message when using TestRunCallbackAttribute and the implementation is stripped away (DS-454). Fixed an issue where the test results xml would have a zero end-time for tests executed before a domain reload (DSTR-63). Fixed OpenSource in case of a Test in a nested class (DSTR-6) UnityTests with a domain reload now works correctly in combination with Retry and Repeat attributes (DS-428). Fixed OpenSource in case of Tests located inside a package (DS-432) [1.1.19] - 2020-11-17 Command line runs with an inconclusive test result now exit with exit code 2 (case DS-951). Fixed timeout during UnitySetUp which caoused test to pass instead of failing due to wrong time format. Timeout exeption thrown when timeout time is exeded in the UnitySetup when using WaitForSeconds(n). Updating com.unity.ext.nunit version Method marked with UnityTest that are not returning IEnumerator is now giving a proper error (DS-1059). [1.1.18] - 2020-10-07 Fixed issue of timeout during UnitySetUp which wasn't detected and allowed the test to pass instead of failing (case DSTR-21) [1.1.17] - 2020-10-05 Fixed an issue where the WaitForDomainReload yield instruction would sometimes let the test continue for one frame before the domain reload. Added support for negation in filters using !. E.g. !CategoryToExclude. Fixed an issue where if the first test enters PlayMode from UnitySetup then the test body will not run on consecutive runs (case 1260901). Clear Results button clears the test results in the GUI (DSTR-16) Improved UI in Test Runner window, added new options: Run Selected Tests in player Build/Export project with all tests in player Build/Export project with selected tests in player Fixed issue on loading EditMode or Playmode test tree in the wrong tab when switching between tabs when TestRunner is loading (DS-865) [1.1.16] - 2020-07-09 Follow up on fix when UTF picks up on outdated compilation errors [1.1.15] - 2020-07-02 Fixed an issue where an exception is thrown on getting the enumerator of a UnityTest would result in stopping the test run instead of failing it (case 1212000). Including a trailing semi-colon in a testName filter no longer results in all tests being run (case 1171200). Fixed and issue when Unity Test Framework exits editor on an outdated script compilation error (during api updates) [1.1.14] - 2020-04-03 Added the 'assemblyNames' command line argument for filtering on the assembly level. The dll and project level of the tree view should now correctly show the results when running tests in a player (case 1197026). Optimize usage of player connection when transfering test results (case 1229200). Ignore internal test framework tests assertions (case 1206961). [1.1.13] - 2020-03-16 Fixed an issue where a combination of Entering / Exiting playmode and recompiling scripts would result in the test run repeating (case 1213958). Fixed a regression from 1.1.12 where prefabs left in the scene would be cleaned up to aggressively. Fixed Test execution timed out. No activity received from the player in 600 seconds error when player is not supposed to start (case 1225147) [1.1.12] - 2020-03-02 Now 'Open error line' for a failed UTF test does not throw exceptions for corrupted testable pdb in Editor release mode (case 1118259) Fixed an issue where running a test fixture would also run other fixtures with the same full name (namespace plus classname) in other assemblies (case 1197385). Running tests with the same full name, with a domain reload inbetween, will no longer fail to initialize the fixture of the second class (case 1205240). Running a playmode tests with \"Maximize on Play\" will now correctly show the result of the tests in the test runner window (case 1014908). Fixed an issue where leaving a game object in a scene with a DontSaveInEditor hideFlags would result in an error on cleanup (case 1136883). Now ITestPlayerBuildModifier.ModifyOptions is called as expected when running tests on a device (case 1213845) [1.1.11] - 2020-01-16 Fixed test runner dlls got included into player build (case 1211624) Passing a non-full-path of XML file for -testResults in Unity Batchmode issue resolved, now passing \"result.xml\" creates the result file in the project file directory (case 959078) Respect Script Debugging build setting when running tests [1.1.10] - 2019-12-19 Introduced PostSuccessfulLaunchAction callback Fixed an issue where canceling a UnityTest while it was running would incorrectly mark it as passed instead of canceled. Added command line argument for running tests synchronously. The test search bar now handles null values correctly. The test output pane now retains its size on domain reloads. [1.1.9] - 2019-12-12 Rolled back refactoring to the test run system, as it caused issues in some corner cases. [1.1.8] - 2019-11-15 Ensured that a resumed test run is continued instantly. [1.1.7] - 2019-11-14 Fixed an issue with test runs after domain reload. [1.1.6] - 2019-11-12 Building a player for test will no longer look in unrelated assemblies for relevant attributes. [1.1.5] - 2019-10-23 Fixed a regression to synchronous runs introduced in 1.1.4. [1.1.4] - 2019-10-15 Running tests in batch mode now correctly returns error code 3 (RunError) when a timeout or a build error occurs. Fixed an issue where a test run in a player would time out, if the player takes longer than 10 minutes to run. Added command line argument and api setting for specifying custom heartbeat timeout for running on players. [1.1.3] - 2019-09-23 Fixed a regression where tests in a player would report a timeout after a test run is finished. Made it possible for the ui to change its test items when the test tree changes without script compilation. Added synchronous runs as an option to the TestRunnerApi. [1.1.2] - 2019-09-11 Fixed an issue where Run Selected would run all tests in the category, if a category filter was selected, regardless of what tests were selected. Unsupported attributes used in UnityTests now give an explicit error. Added support for the Repeat and Retry attributes in UnityTests (case 1131940). Tests with a explicit timeout higher than 10 minutes, no longer times out after running longer than 10 minutes when running from command line (case 1125991). Fixed a performance regression in the test runner api result reporting, introduced in 2018.3 (case 1109865). Fixed an issue where parameterized test fixtures would not run if selected in the test tree (case 1092244). Pressing Clear Results now also correctly clears the counters on the test list (case 1181763). Prebuild setup now handles errors logged with Debug.LogError and stops the run if any is logged (case 1115240). It now also supports LogAssert.Expect. [1.1.1] - 2019-08-07 Tests retrieved as a test list with the test runner api incorrectly showed both mode as their TestMode. Fixed a compatibility issue with running tests from rider. [1.1.0] - 2019-07-30 Introduced the TestRunnerApi for running tests programmatically from elsewhere inside the Editor. Introduced yield instructions for recompiling scripts and awaiting a domain reload in Edit Mode tests. Added a button to the Test Runner UI for clearing the results. [1.0.18] - 2019-07-15 Included new full documentation of the test framework. [1.0.17] - 2019-07-11 Fixed an issue where the Test Runner window wouldn’t frame selected items after search filter is cleared. Fixed a regression where playmode test application on the IOS platform would not quit after the tests are done. [1.0.16] - 2019-06-20 Fixed an issue where the Test Runner window popped out if it was docked, or if something else was docked next to it, when re-opened (case 1158961) Fixed a regression where the running standalone playmode tests from the ui would result in an error. [1.0.15] - 2019-06-18 Added new [TestMustExpectAllLogs] attribute, which automatically does LogAssert.NoUnexpectedReceived() at the end of affected tests. See docs for this attribute for more info on usage. Fixed a regression where no tests would be run if multiple filters are specified. E.g. selecting both a whole assembly and an individual test in the ui. Fixed an issue where performing Run Selected on a selected assembly would run all assemblies. Introduced the capability to do a split build and run, when running playmode tests on standalone devices. Fixed an error in ConditionalIgnore, if the condition were not set. [1.0.14] - 2019-05-27 Fixed issue preventing scene creation in IPrebuildSetup.Setup callback when running standalone playmode tests. Fixed an issue where test assemblies would sometimes not be ordered alphabetically. Added module references to the package for the required modules: imgui and jsonserialize. Added a ConditionalIgnore attribute to help ignoring tests only under specific conditions. Fixed a typo in the player test window (case 1148671). [1.0.13] - 2019-05-07 Fixed a regression where results from the player would no longer update correctly in the UI (case 1151147). [1.0.12] - 2019-04-16 Added specific unity release to the package information. [1.0.11] - 2019-04-10 Fixed a regression from 1.0.10 where test-started events were triggered multiple times after a domain reload. [1.0.10] - 2019-04-08 Fixed an issue where test-started events would not be fired correctly after a test performing a domain reload (case 1141530). The UI should correctly run tests inside a nested class, when that class is selected. All actions should now correctly display a prefix when reporting test result. E.g. \"TearDown :\". Errors logged with Debug.LogError in TearDowns now append the error, rather than overwriting the existing result (case 1114306). Incorrect implementations of IWrapTestMethod and IWrapSetUpTearDown now gives a meaningful error. Fixed a regression where the Test Framework would run TearDown in a base class before the inheriting class (case 1142553). Fixed a regression introduced in 1.0.9 where tests with the Explicit attribute could no longer be executed. [1.0.9] - 2019-03-27 Fixed an issue where a corrupt instance of the test runner window would block for a new being opened. Added the required modules to the list of package requirements. Fixed an issue where errors would happen if the test filter ui was clicked before the ui is done loading. Fix selecting items with duplicate names in test hierarchy of Test Runner window (case 987587). Fixed RecompileScripts instruction which we use in tests (case 1128994). Fixed an issue where using multiple filters on tests would sometimes give an incorrect result. [1.0.7] - 2019-03-12 This is the first release of Unity Package com.unity.test-framework. Migrated the test-framework from the current extension in unity."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/CONTRIBUTING.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/CONTRIBUTING.html",
    "title": "Contributing | mmo-rpg-unity",
    "keywords": "Contributing If you are interested in contributing, here are some ground rules: ... Define guidelines & rules for what contributors need to know to successfully make Pull requests against your repo ... All contributions are subject to the Unity Contribution Agreement(UCA) By making a pull request, you are confirming agreement to the terms and conditions of the UCA, including that your Contributions are your original creation and that you have complete right and authority to make your Contributions. Once you have a change ready following these ground rules. Simply make a pull request"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Unity Test Framework overview Edit Mode vs. Play Mode tests Getting started with UTF How to create a new test assembly How to create a test How to run a test How to create a Play Mode test How to run a Play Mode test as standalone Resources Extending UTF How to split the build and run process for standalone Play Mode tests How to run tests programmatically How to get test results How to retrieve the list of tests Reference Running tests from the command-line UnityTest attribute Setup and cleanup at build time IPrebuildSetup IPostBuildCleanup Actions outside of tests Action execution order UnitySetUp and UnityTearDown OuterUnityTestAction Domain Reloads Custom attributes ConditionalIgnore attribute PostBuildCleanup attribute PrebuildSetup attribute TestMustExpectAllLogs attribute TestPlayerBuildModifier attribute TestRunCallback attribute UnityPlatform attribute UnitySetUp attribute UnityTearDown attribute UnityTest attribute Custom equality comparers ColorEqualityComparer FloatEqualityComparer QuaternionEqualityComparer Vector2EqualityComparer Vector3EqualityComparer Vector4EqualityComparer Custom equality comparers with equals operator Test Utils Custom yield instructions IEditModeTestYieldInstruction EnterPlayMode ExitPlayMode RecompileScripts WaitForDomainReload Custom assertion LogAssert Custom constraints Is Parameterized tests MonoBehaviour tests MonoBehaviourTest<T> IMonoBehaviourTest TestRunnerApi ExecutionSettings Filter ITestRunSettings ICallbacks IErrorCallbacks"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/edit-mode-vs-play-mode-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/edit-mode-vs-play-mode-tests.html",
    "title": "Edit Mode vs. Play Mode tests | mmo-rpg-unity",
    "keywords": "Edit Mode vs. Play Mode tests Let’s clarify a bit what Play Mode and Edit Mode test means from the Unity Test Framework perspective: Edit Mode tests Edit Mode tests (also known as Editor tests) are only run in the Unity Editor and have access to the Editor code in addition to the game code. With Edit Mode tests it is possible to test any of your Editor extensions using the UnityTest attribute. For Edit Mode tests, your test code runs in the EditorApplication.update callback loop. Note: You can also control entering and exiting Play Mode from your Edit Mode test. This allow your test to make changes before entering Play Mode. Edit Mode tests should meet one of the following conditions: They should have an assembly definition with reference to nunit.framework.dll and has only the Editor as a target platform: \"includePlatforms\": [ \"Editor\" ], Legacy condition: put tests in the project’s Editor folder. Play Mode tests You can run Play Mode tests as a standalone in a Player or inside the Editor. Play Mode tests allow you to exercise your game code, as the tests run as coroutines if marked with the UnityTest attribute. Play Mode tests should correspond to the following conditions: Have an assembly definition with reference to nunit.framework.dll. Have the test scripts located in a folder with the .asmdef file. The test assembly should reference an assembly within the code that you need to test. \"references\": [ \"NewAssembly\" ], \"optionalUnityReferences\": [ \"TestAssemblies\" ], \"includePlatforms\": [], Recommendations Attributes Use the NUnit Test attribute instead of the UnityTest attribute, unless you need to yield special instructions, in Edit Mode, or if you need to skip a frame or wait for a certain amount of time in Play Mode. References It is possible for your Test Assemblies to reference the test tools in UnityEngine.TestRunner and UnityEditor.TestRunner. The latter is only available in Edit Mode. You can specify these references in the Assembly Definition References on the Assembly Definition."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/extending.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/extending.html",
    "title": "Extending Unity Test Framework | mmo-rpg-unity",
    "keywords": "Extending Unity Test Framework It is possible to extend the Unity Test Framework (UTF) in many ways, for custom workflows for your projects and for other packages to build on top of UTF. These extensions are a supplement to the ones already offered by NUnit. Some workflows for extending UTF include: How to split the build and run process for standalone Play Mode tests How to run tests programmatically How to get test results How to retrieve the list of tests"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/extension-get-test-results.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/extension-get-test-results.html",
    "title": "How to get test results | mmo-rpg-unity",
    "keywords": "How to get test results You can receive callbacks when the active test run, or individual tests, starts and finishes. You can register callbacks by invoking RegisterCallbacks on the TestRunnerApi with an instance of a class that implements ICallbacks. There are four ICallbacks methods for the start and finish of both the whole run and each level of the test tree. Example An example of how listeners can be set up: Note: Listeners receive callbacks from all test runs, regardless of the registered TestRunnerApi for that instance. public void SetupListeners() { var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.RegisterCallbacks(new MyCallbacks()); } private class MyCallbacks : ICallbacks { public void RunStarted(ITestAdaptor testsToRun) { } public void RunFinished(ITestResultAdaptor result) { } public void TestStarted(ITestAdaptor test) { } public void TestFinished(ITestResultAdaptor result) { if (!result.HasChildren && result.ResultState != \"Passed\") { Debug.Log(string.Format(\"Test {0} {1}\", result.Test.Name, result.ResultState)); } } } Note: The registered callbacks are not persisted on domain reloads. So it is necessary to re-register the callback after a domain reloads, usually with InitializeOnLoad. It is possible to provide a priority as an integer as the second argument when registering a callback. This influences the invocation order of different callbacks. The default value is zero. It is also possible to provide RegisterCallbacks with a class instance that implements IErrorCallbacks that is an extended version of ICallbacks. IErrorCallbacks also has a callback method for OnError that invokes if the run fails to start, for example, due to compilation errors or if an IPrebuildSetup throws an exception."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/extension-retrieve-test-list.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/extension-retrieve-test-list.html",
    "title": "How to retrieve the list of tests | mmo-rpg-unity",
    "keywords": "How to retrieve the list of tests It is possible to use the TestRunnerApi to retrieve the test tree for a given test mode (Edit Mode or Play Mode). You can retrieve the test tree by invoking RetrieveTestList with the desired TestMode and a callback action, with an ITestAdaptor representing the test tree. Example The following example retrieves the test tree for Edit Mode tests and prints the number of total test cases: var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.RetrieveTestList(TestMode.EditMode, (testRoot) => { Debug.Log(string.Format(\"Tree contains {0} tests.\", testRoot.TestCaseCount)); });"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/extension-run-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/extension-run-tests.html",
    "title": "How to run tests programmatically | mmo-rpg-unity",
    "keywords": "How to run tests programmatically Filters Run tests by calling Execute on the TestRunnerApi, and provide some execution settings that consists of a Filter. The Filter specifies what tests to run. Example The following is an example of how to run all Play Mode tests in a project: var testRunnerApi = ScriptableObject.CreateInstance<TestRunnerApi>(); var filter = new Filter() { testMode = TestMode.PlayMode }; testRunnerApi.Execute(new ExecutionSettings(filter)); Multiple filter values It is possible to specify a more specific filter by filling out the fields on the Filter class in more detail. Many of the fields allow for multiple values. The runner tries to match tests against at least one of the values provided and then runs any tests that match. Example In this example, the API runs tests with full names that fit either of the two names provided: var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.Execute(new ExecutionSettings(new Filter() { testNames = new[] {\"MyTestClass.NameOfMyTest\", \"SpecificTestFixture.NameOfAnotherTest\"} })); Multiple filter fields If using multiple different fields on the filter, then it matches against tests that fulfill all the different fields. Example In this example, it runs any test that fits either of the two test names, and that also belongs to a test assembly that fits the given name. var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.Execute(new ExecutionSettings(new Filter() { assemblyNames = new [] {\"MyTestAssembly\"}, testNames = new [] {\"MyTestClass.NameOfMyTest\", \"MyTestClass.AnotherNameOfATest\"} })); Multiple constructor filters The execution settings take one or more filters in its constructor. If there is no filter provided, then it runs all Edit Mode tests by default. If there are multiple filters provided, then a test runs if it matches any of the filters. Example In this example, it runs any tests that are either in the assembly named MyTestAssembly or if the full name of the test matches either of the two provided test names: var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.Execute(new ExecutionSettings( new Filter() { assemblyNames = new[] {\"MyTestAssembly\"}, }, new Filter() { testNames = new[] {\"MyTestClass.NameOfMyTest\", \"MyTestClass.AnotherNameOfATest\"} } )); Note: Specifying different test modes or platforms in each Filter is not currently supported. The test mode and platform is from the first Filter only and defaults to Edit Mode, if not supplied."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/getting-started.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/getting-started.html",
    "title": "Getting started with Unity Test Framework | mmo-rpg-unity",
    "keywords": "Getting started with Unity Test Framework To access the Unity Test Framework (UTF) in the Unity Editor, open the Test Runner window; go to Window > General > Test Runner. To get started with UTF, follow the workflows below: How to create a new test assembly How to create a test How to run a test How to create a Play Mode test How to run a Play Mode test as standalone For further information, see the resources and reference sections."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/index.html",
    "title": "About Unity Test Framework | mmo-rpg-unity",
    "keywords": "About Unity Test Framework The Unity Test Framework (UTF) enables Unity users to test their code in both Edit Mode and Play Mode, and also on target platforms such as Standalone, Android, iOS, etc. This package provides a standard test framework for users of Unity and developers at Unity so that both benefit from the same features and can write tests the same way. UTF uses a Unity integration of NUnit library, which is an open-source unit testing library for .Net languages. UTF currently uses NUnit version 3.5. For more information about NUnit, see the official NUnit website and the NUnit documentation. Note: UTF is not a new concept or toolset; it is an adjusted and more descriptive naming for the toolset otherwise known as Unity Test Runner, which is now available as this package. Installing Unity Test Framework To install this package, follow the instructions in the Package Manager documentation. Note: Search for the Test Framework package. In Unity 2019.2 and higher, you may need to enable the package before use. Using Unity Test Framework To learn how to use the Unity Test Framework package in your project, read the manual. Technical details Requirements This version of the Unity Test Framework is compatible with the following versions of the Unity Editor: 2019.2 and later. Known limitations Unity Test Framework version 1.0.18 includes the following known limitations: The UnityTest attribute does not support WSA platform. The UnityTest attribute does not support Parameterized tests (except for ValueSource). The UnityTest attribute does not support the NUnit Repeat attribute. Nested test fixture cannot run from the Editor UI. When using the NUnit Retry attribute in PlayMode tests, it throws InvalidCastException. Async tests are not supported in the current version of UTF. Package contents The following table indicates the root folders in the package where you can find useful resources: Location Description /com.unity.test-framework/Documentation~ Contains the documentation for the package. Document revision history Date Reason February 4, 2021 Applied user feedback to the documentation. Matches package version 1.1.22 August 23, 2019 Applied feedback to the documentation July 25, 2019 Documentation updated to include features in version 1.1.0 July 11, 2019 Documentation updated. Matches package version 1.0.18 May 27, 2019 Documentation created. Matches package version 1.0.14"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/manual.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/manual.html",
    "title": "Unity Test Framework manual | mmo-rpg-unity",
    "keywords": "Unity Test Framework manual This is the manual for the Unity Test Framework (UTF): Introduction Unity Test Framework overview Edit Mode vs. Play Mode tests Getting started Getting started with UTF Workflows: How to create a new test assembly How to create a test How to run a test How to create a Play Mode test How to run a Play Mode test in player Resources Extending UTF Extending UTF Workflows: How to split the build and run process for standalone Play Mode tests How to run tests programmatically How to get test results How to retrieve the list of tests Reference Running tests from the command-line UnityTest attribute Setup and cleanup at build time IPrebuildSetup IPostBuildCleanup Actions outside of tests Action execution order UnitySetUp and UnityTearDown OuterUnityTestAction Domain Reloads Custom attributes ConditionalIgnore attribute PostBuildCleanup attribute PrebuildSetup attribute TestMustExpectAllLogs attribute TestPlayerBuildModifier attribute TestRunCallback attribute UnityPlatform attribute UnitySetUp attribute UnityTearDown attribute UnityTest attribute Custom equality comparers ColorEqualityComparer FloatEqualityComparer QuaternionEqualityComparer Vector2EqualityComparer Vector3EqualityComparer Vector4EqualityComparer Custom equality comparers with equals operator Test Utils Custom yield instructions IEditModeTestYieldInstruction EnterPlayMode ExitPlayMode Custom assertion LogAssert Custom constraints Is Parameterized tests MonoBehaviour tests MonoBehaviourTest IMonoBehaviourTest TestRunnerApi ExecutionSettings Filter ITestRunSettings ICallbacks IErrorCallbacks"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-actions-outside-tests.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-actions-outside-tests.html",
    "title": "Actions outside of tests | mmo-rpg-unity",
    "keywords": "Actions outside of tests When writing tests, it is possible to avoid duplication of code by using the SetUp and TearDown methods built into NUnit. The Unity Test Framework has extended these methods with extra functionality, which can yield commands and skip frames, in the same way as UnityTest. Action execution order The actions related to a test run in the following order: Attributes implementing IApplyToContext Any attribute implementing OuterUnityTestAction has its BeforeTest invoked Tests with UnitySetUp methods in their test class Attributes implementing IWrapSetUpTearDown Any method with the [SetUp]) attribute Action attributes have their BeforeTest method invoked Attributes implementing IWrapTestMethod The test itself runs Action attributes have their AfterTest method invoked Any method with the TearDown attribute Tests with UnityTearDown methods in their test class Any OuterUnityTestAction has its AfterTest invoked The list of actions is the same for both Test and UnityTest. Execution order flow Note: Some browsers do not support SVG image files. If the image above does not display properly (for example, if you cannot see any text), please try another browser, such as Google Chrome or Mozilla Firefox. Domain Reloads In Edit Mode tests it is possible to yield instructions that can result in a domain reload, such as entering or exiting Play Mode (see Custom yield instructions). When a domain reload happens, all non-Unity actions (such as OneTimeSetup and Setup) are rerun before the code, which initiated the domain reload, continues. Unity actions (such as UnitySetup) are not rerun. If the Unity action is the code that initiated the domain reload, then the rest of the code in the UnitySetup method runs after the domain reload."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-conditionalignore.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-conditionalignore.html",
    "title": "ConditionalIgnore attribute | mmo-rpg-unity",
    "keywords": "ConditionalIgnore attribute This attribute is an alternative to the standard Ignore attribute in NUnit. It allows for ignoring tests only under a specified condition. The condition evaluates during OnLoad, referenced by ID. Example The following example shows a method to use the ConditionalIgnore attribute to ignore a test if the Unity Editor is running macOS: using UnityEditor; using NUnit.Framework; using UnityEngine.TestTools; [InitializeOnLoad] public class OnLoad { static OnLoad() { var editorIsOSX = false; #if UNITY_EDITOR_OSX editorIsOSX = true; #endif ConditionalIgnoreAttribute.AddConditionalIgnoreMapping(\"IgnoreInMacEditor\", editorIsOSX); } } public class MyTestClass { [Test, ConditionalIgnore(\"IgnoreInMacEditor\", \"Ignored on Mac editor.\")] public void TestNeverRunningInMacEditor() { Assert.Pass(); } } Note: You can only use InitializeOnLoad in Edit Mode tests."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-testmustexpectalllogs.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-testmustexpectalllogs.html",
    "title": "TestMustExpectAllLogs attribute | mmo-rpg-unity",
    "keywords": "TestMustExpectAllLogs attribute The presence of this attribute causes the Test Runner to expect every single log. By default, the Test Runner only fails on error logs, but TestMustExpectAllLogs fails on warnings and info level messages as well. It is the same as calling the method LogAssert.NoUnexpectedReceived at the bottom of every affected test. Assembly-wide usage You can apply this attribute to test assemblies (that affects every test in the assembly), fixtures (affects every test in the fixture), or on individual test methods. It is also inherited from base fixtures. The MustExpect property (true by default) lets you enable or disable the higher level value. For example when migrating an assembly to this more strict checking method, you might attach [assembly:TestMustExpectAllLogs] to the assembly itself, but then whitelist failing fixtures and test methods with [TestMustExpectAllLogs(MustExpect=false)] until you have migrated them. This also means new tests in that assembly would have the more strict checking."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-testplayerbuildmodifier.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-testplayerbuildmodifier.html",
    "title": "TestPlayerBuildModifier attribute | mmo-rpg-unity",
    "keywords": "TestPlayerBuildModifier attribute You can use the TestPlayerBuildModifier attribute to accomplish a couple of different scenarios: Modify the Player build options for Play Mode tests It is possible to change the BuildPlayerOptions for the test Player, to achieve custom behavior when running Play Mode tests. Modifying the build options allows for changing the target location of the build as well as changing BuildOptions. To modify the BuildPlayerOptions, do the following: Implement the ITestPlayerBuildModifier Reference the implementation type in a TestPlayerBuildModifier attribute on an assembly level. Example using UnityEditor; using UnityEditor.TestTools; [assembly:TestPlayerBuildModifier(typeof(BuildModifier))] public class BuildModifier : ITestPlayerBuildModifier { public BuildPlayerOptions ModifyOptions(BuildPlayerOptions playerOptions) { if (playerOptions.target == BuildTarget.iOS) { playerOptions.options |= BuildOptions.SymlinkLibraries; // Enable symlink libraries when running on iOS } playerOptions.options |= BuildOptions.AllowDebugging; // Enable allow Debugging flag on the test Player. return playerOptions; } } Note: When building the Player, it includes all TestPlayerBuildModifier attributes across all loaded assemblies, independent of the currently used test filter. As the implementation references the UnityEditor namespace, the code is typically implemented in an Editor only assembly, as the UnityEditor namespace is not available otherwise. Split build and run It is possible to use the Unity Editor for building the Player with tests, without running the tests. This allows for running the Player on e.g. another machine. In this case, it is necessary to modify the Player to build and implement a custom handling of the test result. By using TestPlayerBuildModifier, you can alter the BuildOptions to not start the Player after the build as well as build the Player at a specific location. Combined with PostBuildCleanup, you can automatically exit the Editor on completion of the build. Example using System; using System.IO; using System.Linq; using Tests; using UnityEditor; using UnityEditor.TestTools; using UnityEngine; using UnityEngine.TestTools; [assembly:TestPlayerBuildModifier(typeof(HeadlessPlayModeSetup))] [assembly:PostBuildCleanup(typeof(HeadlessPlayModeSetup))] namespace Tests { public class HeadlessPlayModeSetup : ITestPlayerBuildModifier, IPostBuildCleanup { private static bool s_RunningPlayerTests; public BuildPlayerOptions ModifyOptions(BuildPlayerOptions playerOptions) { // Do not launch the player after the build completes. playerOptions.options &= ~BuildOptions.AutoRunPlayer; // Set the headlessBuildLocation to the output directory you desire. It does not need to be inside the project. var headlessBuildLocation = Path.GetFullPath(Path.Combine(Application.dataPath, \".//..//PlayModeTestPlayer\")); var fileName = Path.GetFileName(playerOptions.locationPathName); if (!string.IsNullOrEmpty(fileName)) { headlessBuildLocation = Path.Combine(headlessBuildLocation, fileName); } playerOptions.locationPathName = headlessBuildLocation; // Instruct the cleanup to exit the Editor if the run came from the command line. // The variable is static because the cleanup is being invoked in a new instance of the class. s_RunningPlayerTests = true; return playerOptions; } public void Cleanup() { if (s_RunningPlayerTests && IsRunningTestsFromCommandLine()) { // Exit the Editor on the next update, allowing for other PostBuildCleanup steps to run. EditorApplication.update += () => { EditorApplication.Exit(0); }; } } private static bool IsRunningTestsFromCommandLine() { var commandLineArgs = Environment.GetCommandLineArgs(); return commandLineArgs.Any(value => value == \"-runTests\"); } } } If the Editor is still running after the Play Mode tests have run, the Player tries to report the results back, using PlayerConnection, which has a reference to the IP address of the Editor machine, when built. To implement a custom way of reporting the results of the test run, let one of the assemblies in the Player include a TestRunCallback. At RunFinished, it is possible to get the full test report as XML from the NUnit test result by calling result.ToXml(true). You can save the result and then save it on the device or send it to another machine as needed."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-testruncallback.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-testruncallback.html",
    "title": "TestRunCallback attribute | mmo-rpg-unity",
    "keywords": "TestRunCallback attribute It is possible for the test framework to invoke callbacks as the current test run progresses. To do this, there is a TestRunCallback attribute which takes the type of ITestRunCallback implementation. You can invoke the callbacks with NUnit ITest and ITestResult classes. At the RunStarted and RunFinished methods, the test and test results are for the whole test tree. These methods invoke at each node in the test tree; first with the whole test assembly, then with the test class, and last with the test method. From these callbacks, it is possible to read the partial or the full results, and it is furthermore possible to save the XML version of the result for further processing or continuous integration. Example using NUnit.Framework.Interfaces; using UnityEngine; using UnityEngine.TestRunner; [assembly:TestRunCallback(typeof(MyTestRunCallback))] public class MyTestRunCallback : ITestRunCallback { public void RunStarted(ITest testsToRun) { } public void RunFinished(ITestResult testResults) { } public void TestStarted(ITest test) { } public void TestFinished(ITestResult result) { if (!result.Test.IsSuite) { Debug.Log($\"Result of {result.Name}: {result.ResultState.Status}\"); } } } Note: The TestRunCallback does not need any references to the UnityEditor namespace and is thus able to run in standalone Players, on the Player side."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-unityplatform.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-unityplatform.html",
    "title": "UnityPlatform attribute | mmo-rpg-unity",
    "keywords": "UnityPlatform attribute Use this attribute to define a specific set of platforms you want or do not want your test(s) to run on. You can use this attribute on the test method, test class, or test assembly level. Use the supported RuntimePlatform enumeration values to specify the platforms. You can also specify which platforms to test by passing one or more RuntimePlatform values along with or without the include or exclude properties as parameters to the Platform attribute constructor. The test(s) skips if the current target platform is: Not explicitly specified in the included platforms list In the excluded platforms list using UnityEngine; using UnityEngine.TestTools; using NUnit.Framework; [TestFixture] public class TestClass { [Test] [UnityPlatform(RuntimePlatform.WindowsPlayer)] public void TestMethod() { Assert.AreEqual(Application.platform, RuntimePlatform.WindowsPlayer); } } Properties Syntax Description RuntimePlatform[] exclude List the platforms you do not want to have your tests run on. RuntimePlatform[] include A subset of platforms you need to have your tests run on."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-unitytest.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-attribute-unitytest.html",
    "title": "UnityTest attribute | mmo-rpg-unity",
    "keywords": "UnityTest attribute UnityTest attribute is the main addition to the standard NUnit library for the Unity Test Framework. This type of unit test allows you to skip a frame from within a test (so background tasks can finish) or give certain commands to the Unity Editor, such as performing a domain reload or entering Play Mode from an Edit Mode test. In Play Mode, the UnityTest attribute runs as a coroutine. Whereas Edit Mode tests run in the EditorApplication.update callback loop. The UnityTest attribute is, in fact, an alternative to the NUnit Test attribute, which allows yielding instructions back to the framework. Once the instruction is complete, the test run continues. If you yield return null, you skip a frame. That might be necessary to ensure that some changes do happen on the next iteration of either the EditorApplication.update loop or the game loop. Edit Mode example The most simple example of an Edit Mode test could be the one that yields null to skip the current frame and then continues to run: [UnityTest] public IEnumerator EditorUtility_WhenExecuted_ReturnsSuccess() { var utility = RunEditorUtilityInTheBackground(); while (utility.isRunning) { yield return null; } Assert.IsTrue(utility.isSuccess); } Play Mode example In Play Mode, a test runs as a coroutine attached to a MonoBehaviour. So all the yield instructions available in coroutines, are also available in your test. From a Play Mode test you can use one of Unity’s Yield Instructions: WaitForFixedUpdate: to ensure changes expected within the next cycle of physics calculations. WaitForSeconds: if you want to pause your test coroutine for a fixed amount of time. Be careful about creating long-running tests. The simplest example is to yield to WaitForFixedUpdate: [UnityTest] public IEnumerator GameObject_WithRigidBody_WillBeAffectedByPhysics() { var go = new GameObject(); go.AddComponent<Rigidbody>(); var originalPosition = go.transform.position.y; yield return new WaitForFixedUpdate(); Assert.AreNotEqual(originalPosition, go.transform.position.y); }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-command-line.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-command-line.html",
    "title": "Running tests from the command line | mmo-rpg-unity",
    "keywords": "Running tests from the command line It’s pretty simple to run a test project from the command line. Here is an example in Windows: Unity.exe -runTests -batchmode -projectPath PATH_TO_YOUR_PROJECT -testResults C:\\temp\\results.xml -testPlatform PS4 Note: Use the -batchmode option when running tests on the command line to remove the need for manual user inputs. For more information, see Unity Command line arguments. Test Framework command line arguments forgetProjectPath Don't save your current Project into the Unity launcher/hub history. runTests Runs tests in the Project. testCategory A semicolon-separated list of test categories to include in the run. A semi-colon separated list should be formatted as a string enclosed in quotation marks, e.g. testCategory \"firstCategory;secondCategory\". If using both testFilter and testCategory, then only tests that match both are run. This argument supports negation using '!'. If using '!MyCategory' then no tests with the 'MyCategory' category will be included in the run. testFilter A semicolon-separated list of test names to run, or a regular expression pattern to match tests by their full name. A semi-colon separated list should be formatted as a string enclosed in quotation marks, e.g. testFilter \"Low;Medium\". This argument supports negation using '!'. If using the test filter '!MyNamespace.Something.MyTest', then all tests except that test will be run. testPlatform The platform to run tests on. Accepted values: EditMode Edit Mode tests. Equivalent to running tests from the EditMode tab of the Test Runner window. PlayMode Play Mode tests that run in the Editor. Equivalent to running tests from the PlayMode tab of the Test Runner window. Any value from the BuildTarget enum. Play Mode tests that run on a player built for the specified platform. Equivalent to using the Run all tests (<target_platform>) dropdown in the PlayMode tab of the Test Runner window. Note: If no value is specified for this argument, tests run in Edit Mode. assemblyNames A semicolon-separated list of test assemblies to include in the run. A semi-colon separated list should be formatted as a string enclosed in quotation marks, e.g. assemblyNames \"firstAssembly;secondAssembly\". testResults The path where Unity should save the result file. By default, Unity saves it in the Project’s root folder. Test results follow the XML format as defined by NUnit, see the NUnit documentation. There is currently no common definition for exit codes reported by individual Unity components under test. The best way to understand the source of a problem is the content of error messages and stack traces. playerHeartbeatTimeout The time, in seconds, the editor should wait for heartbeats after starting a test run on a player. This defaults to 10 minutes. runSynchronously If included, the test run will run tests synchronously, guaranteeing that all tests runs in one editor update call. Note that this is only supported for EditMode tests, and that tests which take multiple frames (i.e. [UnityTest] tests, or tests with [UnitySetUp] or [UnityTearDown] scaffolding) will be filtered out. testSettingsFile Path to a TestSettings.json file that allows you to set up extra options for your test run. An example of the TestSettings.json file could look like this: { \"scriptingBackend\":\"WinRTDotNET\", \"Architecture\":null, \"apiProfile\":0 } apiProfile The .Net compatibility level. Set to one of the following values: 1 - .Net 2.0 2 - .Net 2.0 Subset 3 - .Net 4.6 5 - .Net micro profile (used by Mono scripting backend if Stripping Level is set to Use micro mscorlib) 6 - .Net Standard 2.0 appleEnableAutomaticSigning Sets option for automatic signing of Apple devices. appleDeveloperTeamID Sets the team ID for the apple developer account. architecture Target architecture for Android. Set to one of the following values: None = 0 ARMv7 = 1 ARM64 = 2 X86 = 4 All = 4294967295 iOSManualProvisioningProfileType Set to one of the following values: 0 - Automatic 1 - Development 2 - Distribution iOSManualProvisioningProfileID scriptingBackend Set to one of the following values, which should be given as a string literal enclosed in quotes: Mono2x IL2CPP WinRTDotNET playerGraphicsAPI Set graphics API that will be used during test execution in the player. Value can be any GraphicsDeviceType as a string literal enclosed in quotes. Value will only be set if it is supported on the target platform. androidBuildAppBundle A boolean setting that allows to build an Android App Bundle (AAB) instead of APK for tests."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-color.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-color.html",
    "title": "ColorEqualityComparer | mmo-rpg-unity",
    "keywords": "ColorEqualityComparer Use this class to compare two Color objects. ColorEqualityComparer.Instance has default calculation error value set to 0.01f. To set a test specific error value instantiate a comparer instance using the one argument constructor. Static properties Syntax Description Instance A singleton instance of the comparer with a default error value set to 0.01f. Constructors Syntax Description ColorEqualityComparer(float error) Creates an instance of the comparer with a custom error value. Public methods Syntax Description bool Equals(Color expected, Color actual); Compares the actual and expected Color objects for equality using Utils.AreFloatsEqualAbsoluteError to compare the RGB and Alpha attributes of Color. Returns true if expected and actual objects are equal otherwise, it returns false. Example [TestFixture] public class ColorEqualityTest { [Test] public void GivenColorsAreEqual_WithAllowedCalculationError() { // Using default error var firstColor = new Color(0f, 0f, 0f, 0f); var secondColor = new Color(0f, 0f, 0f, 0f); Assert.That(firstColor, Is.EqualTo(secondColor).Using(ColorEqualityComparer.Instance)); // Allowed error 10e-5f var comparer = new ColorEqualityComparer(10e-5f); firstColor = new Color(0f, 0f, 0f, 1f); secondColor = new Color(10e-6f, 0f, 0f, 1f); Assert.That(firstColor, Is.EqualTo(secondColor).Using(comparer)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-equals.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-equals.html",
    "title": "Custom equality comparers with equals operator | mmo-rpg-unity",
    "keywords": "Custom equality comparers with equals operator If you need to compare Vectors using the overloaded operator == (see Vector2.operator ==, Vector3.operator ==, and Vector4.operator ==) you should use the respective comparer implementations: Vector2ComparerWithEqualsOperator Vector3ComparerWithEqualsOperator Vector4ComparerWithEqualsOperator The interface is the same as for other equality comparers except the public constructor error parameter is inapplicable in this case. Example [TestFixture] public class Vector3Test { [Test] public void VerifyThat_TwoVector3ObjectsAreEqual() { var actual = new Vector3(10e-7f, 10e-7f, 10e-7f); var expected = new Vector3(0f, 0f, 0f); Assert.That(actual, Is.EqualTo(expected).Using(Vector3ComparerWithEqualsOperator.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-float.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-float.html",
    "title": "FloatEqualityComparer | mmo-rpg-unity",
    "keywords": "FloatEqualityComparer Use this class to compare two float values for equality with NUnit constraints. Use FloatEqualityComparer.Instance comparer to have the default error value set to 0.0001f. For any other error, use the one argument constructor to create a comparer. Static Properties Syntax Description Instance A singleton instance of the comparer with a default error value set to 0.0001f. Constructors Syntax Description FloatEqualityComparer(float allowedError) Creates an instance of the comparer with a custom error value. Public methods Syntax Description bool Equals(float expected, float actual); Compares the actual and expected float values for equality using Utils.AreFloatsEqual. Example [TestFixture] public class FloatsTest { [Test] public void VerifyThat_TwoFloatsAreEqual() { var comparer = new FloatEqualityComparer(10e-6f); var actual = -0.00009f; var expected = 0.00009f; Assert.That(actual, Is.EqualTo(expected).Using(comparer)); // Default relative error 0.0001f actual = 10e-8f; expected = 0f; Assert.That(actual, Is.EqualTo(expected).Using(FloatEqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-quaternion.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-quaternion.html",
    "title": "QuaternionEqualityComparer | mmo-rpg-unity",
    "keywords": "QuaternionEqualityComparer Use this utility to compare two Quaternion objects for equality with NUnit assertion constraints. Use the static instance QuaternionEqualityComparer.Instance to have the default calculation error value set to 0.00001f. For any other custom error value, use the one argument constructor. Static properties Syntax Description Instance A comparer instance with the default error value 0.00001f. Constructors Syntax Description QuaternionEqualityComparer(float allowedError) Creates an instance of the comparer with a custom allowed error value. Public methods Syntax Description bool Equals(Quaternion expected, Quaternion actual) Compares the actual and expected Quaternion objects for equality using the Quaternion.Dot method. Example [TestFixture] public class QuaternionTest { [Test] public void VerifyThat_TwoQuaternionsAreEqual() { var actual = new Quaternion(10f, 0f, 0f, 0f); var expected = new Quaternion(1f, 10f, 0f, 0f); var comparer = new QuaternionEqualityComparer(10e-6f); Assert.That(actual, Is.EqualTo(expected).Using(comparer)); //Using default error 0.00001f actual = new Quaternion(10f, 0f, 0.1f, 0f); expected = new Quaternion(1f, 10f, 0.1f, 0f); Assert.That(actual, Is.EqualTo(expected).Using(QuaternionEqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-vector2.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-vector2.html",
    "title": "Vector2EqualityComparer | mmo-rpg-unity",
    "keywords": "Vector2EqualityComparer Use this class to compare two Vector2 objects for equality with NUnit constraints. Use the static Vector2EqualityComparer.Instance to have the calculation error value set to default 0.0001f. For any other error value, instantiate a new comparer object with the one argument constructor. Static properties Syntax Description Instance A comparer instance with the default error value set to 0.0001f. Constructors Syntax Description Vector2EqualityComparer(float error) Creates an instance with a custom error value. Public methods Syntax Description Equals(Vector2 expected, Vector2 actual) Compares the actual and expected Vector2 objects for equality using the Utils.AreFloatsEqual method. Example [TestFixture] public class Vector2Test { [Test] public void VerifyThat_TwoVector2ObjectsAreEqual() { // Custom calculation error var actual = new Vector2(10e-7f, 10e-7f); var expected = new Vector2(0f, 0f); var comparer = new Vector2EqualityComparer(10e-6f); Assert.That(actual, Is.EqualTo(expected).Using(comparer)); //Default error 0.0001f actual = new Vector2(0.01f, 0.01f); expected = new Vector2(0.01f, 0.01f); Assert.That(actual, Is.EqualTo(expected).Using(Vector2EqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-vector3.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-vector3.html",
    "title": "Vector3EqualityComparer | mmo-rpg-unity",
    "keywords": "Vector3EqualityComparer Use this class to compare two Vector3 objects for equality with NUnit constraints. Call Vector3EqualityComparer.Instance comparer to perform a comparison with the default calculation error value 0.0001f. To specify a different error value, use the one argument constructor to instantiate a new comparer. Static properties Syntax Description Instance A comparer instance with the default calculation error value equal to 0.0001f. Constructors Syntax Description Vector3EqualityComparer(float allowedError) Creates an instance with a custom error value. Public methods Syntax Description bool Equals(Vector3 expected, Vector3 actual) Compares the actual and expected Vector3 objects for equality using Utils.AreFloatsEqual to compare the x, y, and z attributes of Vector3. Example [TestFixture] public class Vector3Test { [Test] public void VerifyThat_TwoVector3ObjectsAreEqual() { // Custom error 10e-6f var actual = new Vector3(10e-8f, 10e-8f, 10e-8f); var expected = new Vector3(0f, 0f, 0f); var comparer = new Vector3EqualityComparer(10e-6f); Assert.That(actual, Is.EqualTo(expected).Using(comparer)); //Default error 0.0001f actual = new Vector3(0.01f, 0.01f, 0f); expected = new Vector3(0.01f, 0.01f, 0f); Assert.That(actual, Is.EqualTo(expected).Using(Vector3EqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-vector4.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-comparer-vector4.html",
    "title": "Vector4EqualityComparer | mmo-rpg-unity",
    "keywords": "Vector4EqualityComparer Use this class to compare two Vector4 objects for equality with NUnit constraints. Call Vector4EqualityComparer.Instance to perform comparisons using default calculation error value 0.0001f. To set a custom test value, instantiate a new comparer using the one argument constructor. Static Properties Syntax Description Vector4EqualityComparer Instance A comparer instance with the default calculation error value set to 0.0001f. Constructors Syntax Description Vector4EqualityComparer(float allowedError) Creates an instance with a custom error value. Public methods Syntax Description bool Equals(Vector4 expected, Vector4 actual); Compares the actual and expected Vector4 objects for equality using Utils.AreFloatsEqual to compare the x, y, z, and w attributes of Vector4. Example [TestFixture] public class Vector4Test { [Test] public void VerifyThat_TwoVector4ObjectsAreEqual() { // Custom error 10e-6f var actual = new Vector4(0, 0, 1e-6f, 1e-6f); var expected = new Vector4(1e-6f, 0f, 0f, 0f); var comparer = new Vector4EqualityComparer(10e-6f); Assert.That(actual, Is.EqualTo(expected).Using(comparer)); // Default error 0.0001f actual = new Vector4(0.01f, 0.01f, 0f, 0f); expected = new Vector4(0.01f, 0.01f, 0f, 0f); Assert.That(actual, Is.EqualTo(expected).Using(Vector4EqualityComparer.Instance)); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-assertion.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-assertion.html",
    "title": "Custom assertion | mmo-rpg-unity",
    "keywords": "Custom assertion A test fails if Unity logs a message other than a regular log or warning message. Use LogAssert to check for an expected message in the log so that the test does not fail when Unity logs the message. Use LogAssert.Expect before running the code under test, as the check for expected logs runs at the end of each frame. A test also reports a failure, if an expected message does not appear, or if Unity does not log any regular log or warning messages. Example [Test] public void LogAssertExample() { // Expect a regular log message LogAssert.Expect(LogType.Log, \"Log message\"); // The test fails without the following expected log message Debug.Log(\"Log message\"); // An error log Debug.LogError(\"Error message\"); // Without expecting an error log, the test would fail LogAssert.Expect(LogType.Error, \"Error message\"); } LogAssert LogAssert lets you expect Unity log messages that would otherwise cause the test to fail. It is available under the namespace UnityEngine.TestTools, see the Scripting API for more details. Static properties Syntax Description bool ignoreFailingMessages Set this property to true to prevent unexpected error log messages from triggering an assertion. By default, it is false. Static Methods Syntax Description void Expect(LogType type, string message); void Expect(LogType type, Regex message); Verifies that a log message of a specified type appears in the log. A test won’t fail from an expected error, assertion, or exception log message. It does fail if an expected message does not appear in the log. void NoUnexpectedReceived(); Triggers an assertion when receiving any log messages and fails the test if some are unexpected messages. If multiple tests need to check for no received unexpected logs, consider using the TestMustExpectAllLogs attribute instead. Expect string message void Expect(LogType type, string message); Parameters Syntax Description LogType type A type of log to expect. It can take one of the LogType enum values. string message A string value that should equate to the expected message. Expect Regex message void Expect(LogType type, Regex message); Parameters Syntax Description LogType type A type of log to expect. It can take one of the LogType enum values. Regex message A regular expression pattern to match the expected message."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-attributes.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-attributes.html",
    "title": "Custom attributes | mmo-rpg-unity",
    "keywords": "Custom attributes As a part of UTF’s public API we provide the following attributes: ConditionalIgnore attribute PostBuildCleanup attribute PrebuildSetup attribute TestMustExpectAllLogs attribute TestPlayerBuildModifier attribute TestRunCallback attribute UnityPlatform attribute UnitySetUp attribute UnityTearDown attribute UnityTest attribute"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-constraints.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-constraints.html",
    "title": "Custom constraints | mmo-rpg-unity",
    "keywords": "Custom constraints NUnit allows you to write test assertions in a more descriptive and human readable way using the Assert.That mechanism, where the first parameter is an object under test and the second parameter describes conditions that the object has to meet. Is We’ve extended NUnit API with a custom constraint type and declared an overlay Is class. To resolve ambiguity between the original implementation and the custom one you must explicitly declare it with a using statement or via addressing through the full type name UnityEngine.TestTools.Constraints.Is. Static Methods Syntax Description AllocatingGCMemory A constraint type that invokes the delegate you provide as the parameter of Assert.That and checks whether it causes any GC memory allocations. It passes if any GC memory is allocated and fails if not. Example using Is = UnityEngine.TestTools.Constraints.Is; class MyTestClass { [Test] public void MyTest() { Assert.That(() => { var i = new int[500]; }, Is.AllocatingGCMemory()); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-equality-comparers.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-equality-comparers.html",
    "title": "Custom equality comparers | mmo-rpg-unity",
    "keywords": "Custom equality comparers To enable easier verification of custom Unity type values in your tests we provide you with some custom equality comparers: ColorEqualityComparer FloatEqualityComparer QuaternionEqualityComparer Vector2EqualityComparer Vector3EqualityComparer Vector4EqualityComparer Use these classes to compare two objects of the same type for equality within the range of a given tolerance using NUnit or custom constraints . Call Instance to apply the default calculation error value to the comparison. To set a specific error value, instantiate a new comparer object using a one argument constructor ctor(float error). Static properties Syntax Description Instance A singleton instance of the comparer with a predefined default error value. Constructors Syntax Description ctor(float error) Creates an instance of comparer with a custom error value.allowedError. The relative error to be considered while comparing two values. Public methods Syntax Description bool Equals(T expected, T actual); Compares the actual and expected objects for equality using a custom comparison mechanism. Returns true if expected and actual objects are equal, otherwise it returns false."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-yield-instructions.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-custom-yield-instructions.html",
    "title": "Custom yield instructions | mmo-rpg-unity",
    "keywords": "Custom yield instructions By implementing this interface below, you can define custom yield instructions in Edit Mode tests. IEditModeTestYieldInstruction In an Edit Mode test, you can use IEditModeTestYieldInstruction interface to implement your own instruction. There are also a couple of commonly used implementations available: EnterPlayMode ExitPlayMode RecompileScripts WaitForDomainReload Example [UnityTest] public IEnumerator PlayOnAwakeDisabled_DoesntPlayWhenEnteringPlayMode() { var videoPlayer = PrefabUtility.InstantiatePrefab(m_VideoPlayerPrefab.GetComponent<VideoPlayer>()) as VideoPlayer; videoPlayer.playOnAwake = false; yield return new EnterPlayMode(); var videoPlayerGO = GameObject.Find(m_VideoPlayerPrefab.name); Assert.IsFalse(videoPlayerGO.GetComponent<VideoPlayer>().isPlaying); yield return new ExitPlayMode(); Object.DestroyImmediate(GameObject.Find(m_VideoPlayerPrefab.name)); } Properties Syntax Description bool ExpectDomainReload Returns true if the instruction expects a domain reload to occur. bool ExpectedPlaymodeState Returns true if the instruction expects the Unity Editor to be in Play Mode. Methods Syntax Description IEnumerator Perform() Used to define multi-frame operations performed when instantiating a yield instruction. EnterPlayMode Implements IEditModeTestYieldInstruction. Creates a yield instruction to enter Play Mode. When creating an Editor test that uses the UnityTest attribute, use this to trigger the Editor to enter Play Mode. Throws an exception if the Editor is already in Play Mode or if there is a script compilation error. ExitPlayMode Implements IEditModeTestYieldInstruction. A new instance of the class is a yield instruction to exit Play Mode. Throws an exception if the Editor is not in Play Mode."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-execution-settings.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-execution-settings.html",
    "title": "ExecutionSettings | mmo-rpg-unity",
    "keywords": "ExecutionSettings The ExecutionSettings is a set of filters and other settings provided when running a set of tests from the TestRunnerApi. Constructors Syntax Description ExecutionSettings(params Filter[] filtersToExecute) Creates an instance with a given set of filters, if any. Fields Syntax Description Filter[] filters A collection of Filters to execute tests on. ITestRunSettings overloadTestRunSettings An instance of ITestRunSettings to set up before running tests on a Player. bool runSynchronously If true, the call to Execute() will run tests synchronously, guaranteeing that all tests have finished running by the time the call returns. Note that this is only supported for EditMode tests, and that tests which take multiple frames (i.e. [UnityTest] tests, or tests with [UnitySetUp] or [UnityTearDown] scaffolding) will be filtered out. 'int playerHeartbeatTimeout' The time, in seconds, the editor should wait for heartbeats after starting a test run on a player. This defaults to 10 minutes."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-filter.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-filter.html",
    "title": "Filter | mmo-rpg-unity",
    "keywords": "Filter The filter class provides the TestRunnerApi with a specification of what tests to run when running tests programmatically. Fields Syntax Description TestMode testMode An enum flag that specifies if Edit Mode or Play Mode tests should run. Applying both Edit Mode and Play Mode is currently not supported when running tests from the API. string[] testNames The full name of the tests to match the filter. This is usually in the format FixtureName.TestName. If the test has test arguments, then include them in parenthesis. E.g. MyTestClass2.MyTestWithMultipleValues(1). string[] groupNames The same as testNames, except that it allows for Regex. This is useful for running specific fixtures or namespaces. E.g. \"^MyNamespace\\\\.\" Runs any tests where the top namespace is MyNamespace. string[] categoryNames The name of a Category to include in the run. Any test or fixtures runs that have a Category matching the string. string[] assemblyNames The name of assemblies included in the run. That is the assembly name, without the .dll file extension. E.g., MyTestAssembly. BuildTarget? targetPlatform The BuildTarget platform to run the test on. If set to null, then the Editor is the target for the tests."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-icallbacks.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-icallbacks.html",
    "title": "ICallbacks | mmo-rpg-unity",
    "keywords": "ICallbacks An interface for receiving callbacks when running tests. All test runs invoke the callbacks until the next domain reload. The RunStarted method runs when the whole test run starts. Then the TestStarted method runs with information about the tests it is about to run on an assembly level. Afterward, it runs on a test fixture level and then on the individual test. If the test is a parameterized test, then it is also invoked for each parameter combination. After each part of the test tree have completed running, the corresponding TestFinished method runs with the test result. At the end of the run, the RunFinished event runs with the test result. An extended version of the callback, IErrorCallbacks, extends this ICallbacks to receive calls when a run fails due to a build error. Public methods Syntax Description void RunStarted(ITestAdaptor testsToRun) Invoked when the test run starts. The ITestAdaptor represents the tree of tests to run. void RunFinished(ITestResultAdaptor result) Invoked when the test run finishes. The ITestResultAdaptor represents the results of the set of tests that have run. void TestStarted(ITestAdaptor test) Invoked on each node of the test tree, as that part of the tree starts to run. void TestFinished(ITestResultAdaptor result) Invoked on each node of the test tree once that part of the test tree has finished running. The ITestResultAdaptor represents the results of the current node of the test tree. Example An example that sets up a listener on the API. The listener prints the number of failed tests after the run has finished: public void SetupListeners() { var api = ScriptableObject.CreateInstance<TestRunnerApi>(); api.RegisterCallbacks(new MyCallbacks()); } private class MyCallbacks : ICallbacks { public void RunStarted(ITestAdaptor testsToRun) { } public void RunFinished(ITestResultAdaptor result) { Debug.Log(string.Format(\"Run finished {0} test(s) failed.\", result.FailCount)); } public void TestStarted(ITestAdaptor test) { } public void TestFinished(ITestResultAdaptor result) { } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-ierror-callbacks.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-ierror-callbacks.html",
    "title": "IErrorCallbacks | mmo-rpg-unity",
    "keywords": "IErrorCallbacks An extended version of the ICallbacks, which get invoked if the test run fails due to a build error or if any IPrebuildSetup has a failure. Public methods Syntax Description void OnError(string message) The error message detailing the reason for the run to fail."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-itest-adaptor.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-itest-adaptor.html",
    "title": "ITestAdaptor | mmo-rpg-unity",
    "keywords": "ITestAdaptor ITestAdaptor is a representation of a node in the test tree implemented as a wrapper around the NUnit ITest interface. Properties Syntax Description string Id The ID of the test tree node. The ID can change if you add new tests to the suite. Use UniqueName, if you want to have a more permanent point of reference. string Name The name of the test. E.g., MyTest. string FullName The full name of the test. E.g., MyNamespace.MyTestClass.MyTest. int TestCaseCount The total number of test cases in the node and all sub-nodes. bool HasChildren Whether the node has any children. bool IsSuite Whether the node is a test suite/fixture. IEnumerable<ITestAdaptor> Children The child nodes. ITestAdaptor Parent The parent node, if any. int TestCaseTimeout The test case timeout in milliseconds. Note that this value is only available on TestFinished. ITypeInfo TypeInfo The type of test class as an NUnit ITypeInfo. If the node is not a test class, then the value is null. IMethodInfo Method The Nunit IMethodInfo of the test method. If the node is not a test method, then the value is null. string[] Categories An array of the categories applied to the test or fixture. bool IsTestAssembly Whether the node represents a test assembly. RunState RunState The run state of the test node. Either NotRunnable, Runnable, Explicit, Skipped, or Ignored. string Description The description of the test. string SkipReason The skip reason. E.g., if ignoring the test. string ParentId The ID of the parent node. string ParentFullName The full name of the parent node. string UniqueName A unique generated name for the test node. E.g., Tests.dll/MyNamespace/MyTestClass/[Tests][MyNamespace.MyTestClass.MyTest]. string ParentUniqueName A unique name of the parent node. E.g., Tests.dll/MyNamespace/[Tests][MyNamespace.MyTestClass][suite]. int ChildIndex The child index of the node in its parent. TestMode TestMode The mode of the test. Either Edit Mode or Play Mode. Note: Some properties are not available when receiving the test tree as a part of a test result coming from a standalone Player, such as TypeInfo and Method."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-itest-result-adaptor.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-itest-result-adaptor.html",
    "title": "ITestResultAdaptor | mmo-rpg-unity",
    "keywords": "ITestResultAdaptor The ITestResultAdaptor is the representation of the test results for a node in the test tree implemented as a wrapper around the NUnit ITest interface. Properties Syntax Description ITestAdaptor Test The test details of the test result tree node as a TestAdaptor. string Name The name of the test node. string FullName Gets the full name of the test result string ResultState The state of the result as a string. E.g., Success, Skipped, Failure, Explicit, Cancelled. TestStatus TestStatus The status of the test as an enum. Either Inconclusive, Skipped, Passed, or Failed. double Duration Gets the elapsed time for running the test in seconds. DateTime StartTime Gets or sets the time the test started running. DateTime EndTime Gets or sets the time the test finished running. string Message Gets the message associated with a test failure or with not running the test string StackTrace Gets any stack trace associated with an error or failure. Not available in the Compact Framework 1.0. int AssertCount Gets the number of asserts that ran during the test and all its children. int FailCount Gets the number of test cases that failed when running the test and all its children. int PassCount Gets the number of test cases that passed when running the test and all its children. int SkipCount Gets the number of test cases skipped when running the test and all its children. int InconclusiveCount Gets the number of test cases that were inconclusive when running the test and all its children. bool HasChildren Indicates whether this result has any child results. Accessing HasChildren should not force the creation of the Children collection in classes implementing this interface. IEnumerable<ITestResultAdaptor> Children Gets the collection of child results. string Output Gets any text output written to this result. TNode ToXml Gets the test results as an NUnit XML node. Use this to save the results to an XML file."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-itest-run-settings.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-itest-run-settings.html",
    "title": "ITestRunSettings | mmo-rpg-unity",
    "keywords": "ITestRunSettings ITestRunSettings lets you set any of the global settings right before building a Player for a test run and then reverts the settings afterward. ITestRunSettings implements IDisposable, and runs after building the Player with tests. Public methods Syntax Description void Apply() A method called before building the Player. void Dispose() A method called after building the Player or if the build failed. Example The following example sets the iOS SDK version to be the simulator SDK and resets it to the original value after the run. public class MyTestSettings : ITestRunSettings { private iOSSdkVersion originalSdkVersion; public void Apply() { originalSdkVersion = PlayerSettings.iOS.sdkVersion; PlayerSettings.iOS.sdkVersion = iOSSdkVersion.SimulatorSDK; } public void Dispose() { PlayerSettings.iOS.sdkVersion = originalSdkVersion; } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-outerunitytestaction.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-outerunitytestaction.html",
    "title": "OuterUnityTestAction | mmo-rpg-unity",
    "keywords": "OuterUnityTestAction OuterUnityTestAction is a wrapper outside of the tests, which allows for any tests with this attribute to run code before and after the tests. This method allows for yielding commands in the same way as UnityTest. The attribute must inherit the NUnit attribute and implement IOuterUnityTestAction. OuterUnityTestAction Example using System.Collections; using NUnit.Framework; using NUnit.Framework.Interfaces; using UnityEngine; using UnityEngine.TestTools; public class MyTestClass { [UnityTest, MyOuterActionAttribute] public IEnumerator MyTestInsidePlaymode() { Assert.IsTrue(Application.isPlaying); yield return null; } } public class MyOuterActionAttribute : NUnitAttribute, IOuterUnityTestAction { public IEnumerator BeforeTest(ITest test) { yield return new EnterPlayMode(); } public IEnumerator AfterTest(ITest test) { yield return new ExitPlayMode(); } } Execution order Unity outer test action is not rerun on domain reload but non-Unity action attributes are: Note: Some browsers do not support SVG image files. If the image above does not display properly (for example, if you cannot see any text), please try another browser, such as Google Chrome or Mozilla Firefox. Test actions with domain reload example using NUnit.Framework.Interfaces; public class TestActionOnSuiteAttribute : NUnitAttribute, ITestAction { public void BeforeTest(ITest test) { Debug.Log(\"TestAction OnSuite BeforeTest\"); } public void AfterTest(ITest test) { } public ActionTargets Targets { get { return ActionTargets.Suite; } } } public class TestActionOnTestAttribute : NUnitAttribute, ITestAction { public void BeforeTest(ITest test) { Debug.Log(\"TestAction OnTest BeforeTest\"); } public void AfterTest(ITest test) { Debug.Log(\"TestAction OnTest AfterTest\"); } public ActionTargets Targets { get { return ActionTargets.Test; } } } public class OuterTestAttribute : NUnitAttribute, IOuterUnityTestAction { public IEnumerator BeforeTest(ITest test) { Debug.Log(\"OuterTestAttribute BeforeTest\"); yield return null; } public IEnumerator AfterTest(ITest test) { Debug.Log(\"OuterTestAttribute AfterTest\"); yield return null; } } [TestActionOnSuite] public class ActionOrderTestBase { [Test, OuterTest, TestActionOnTest] public void UnitTest() { Debug.Log(\"Test\"); } [UnityTest, OuterTest, TestActionOnTest] public IEnumerator UnityTestWithDomainReload() { Log(\"Test part 1\"); yield return new EnterPlayMode(); //Domain reload yield return new ExitPlayMode(); Log(\"Test part 2\"); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-recompile-scripts.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-recompile-scripts.html",
    "title": "RecompileScripts | mmo-rpg-unity",
    "keywords": "RecompileScripts RecompileScripts is an IEditModeTestYieldInstruction that you can yield in Edit Mode tests. It lets you trigger a recompilation of scripts in the Unity Editor. Constructors Syntax Description RecompileScripts(bool expectScriptCompilation = true, bool expectScriptCompilationSuccess = true) Creates a new instance of the RecompileScripts yield instruction. The parameter expectScriptCompilation indicates if you expect a script compilation to start (defaults to true). If a script compilation does not start and expectScriptCompilation is true, then it throws an exception. Example [UnitySetUp] public IEnumerator SetUp() { using (var file = File.CreateText(\"Assets/temp/myScript.cs\")) { file.Write(\"public class ATempClass { }\"); } AssetDatabase.Refresh(); yield return new RecompileScripts(); }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-setup-and-cleanup.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-setup-and-cleanup.html",
    "title": "Setup and cleanup at build time | mmo-rpg-unity",
    "keywords": "Setup and cleanup at build time In some cases, it is relevant to perform changes to Unity or the file system before building the tests. In the same way, it may be necessary to clean up such changes after the test run. In response to such needs, you can incorporate the pre-build setup and post-build cleanup concepts into your tests in one of the following ways: Via implementation of IPrebuildSetup and IPostBuildCleanup interfaces by a test class. Via applying the PrebuildSetup attribute and PostBuildCleanup attribute on your test class, one of the tests or the test assembly, providing a class name that implements the corresponding interface as an argument (fx [PrebuildSetup(\"MyTestSceneSetup\")]). Execution order All setups run in a deterministic order one after another. The first to run are the setups defined with attributes. Then any test class implementing the interface runs, in alphabetical order inside their namespace, which is the same order as the tests run. Note: Cleanup runs right away for a standalone test run, but only after related tests run in the Unity Editor. PrebuildSetup and PostBuildCleanup Both PrebuildSetup and PostBuildCleanup attributes run if the respective test or test class is in the current test run. The test is included either by running all tests or setting a filter that includes the test. If multiple tests reference the same pre-built setup or post-build cleanup, then it only runs once. IPrebuildSetup Implement this interface if you want to define a set of actions to run as a pre-build step. Public methods Syntax Description void Setup() Implement this method to call actions automatically before the build process. IPostBuildCleanup Implement this interface if you want to define a set of actions to execute as a post-build step. Cleanup runs right away for a standalone test run, but only after all the tests run within the Editor. Public methods Syntax Description void Cleanup() Implement this method to specify actions that should run as a post-build cleanup step. Example [TestFixture] public class CreateSpriteTest : IPrebuildSetup { Texture2D m_Texture; Sprite m_Sprite; public void Setup() { #if UNITY_EDITOR var spritePath = \"Assets/Resources/Circle.png\"; var ti = UnityEditor.AssetImporter.GetAtPath(spritePath) as UnityEditor.TextureImporter; ti.textureCompression = UnityEditor.TextureImporterCompression.Uncompressed; ti.SaveAndReimport(); #endif } [SetUp] public void SetUpTest() { m_Texture = Resources.Load<Texture2D>(\"Circle\"); } [Test] public void WhenNullTextureIsPassed_CreateShouldReturnNullSprite() { // Check with Valid Texture. LogAssert.Expect(LogType.Log, \"Circle Sprite Created\"); Sprite.Create(m_Texture, new Rect(0, 0, m_Texture.width, m_Texture.height), new Vector2(0.5f, 0.5f)); Debug.Log(\"Circle Sprite Created\"); // Check with NULL Texture. Should return NULL Sprite. m_Sprite = Sprite.Create(null, new Rect(0, 0, m_Texture.width, m_Texture.height), new Vector2(0.5f, 0.5f)); Assert.That(m_Sprite, Is.Null, \"Sprite created with null texture should be null\"); } } Tip: Use #if UNITY_EDITOR if you want to access Editor only APIs, but the setup/cleanup is inside a Play Mode assembly."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-test-runner-api.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-test-runner-api.html",
    "title": "TestRunnerApi | mmo-rpg-unity",
    "keywords": "TestRunnerApi The TestRunnerApi retrieves and runs tests programmatically from code inside the project, or inside other packages. TestRunnerApi is a ScriptableObject. You can initialize the API like this: var testRunnerApi = ScriptableObject.CreateInstance<TestRunnerApi>(); Note: You can subscribe and receive test results in one instance of the API, even if the run starts from another instance. The TestRunnerApi supports the following workflows: How to run tests programmatically How to get test results How to retrieve the list of tests Public methods Syntax Description void Execute(ExecutionSettings executionSettings) Starts a test run with a given set of ExecutionSettings. void RegisterCallbacks(ICallbacks testCallbacks, int priority = 0) Sets up a given instance of ICallbacks to be invoked on test runs. void UnregisterCallbacks(ICallbacks testCallbacks) Unregisters an instance of ICallbacks to no longer receive callbacks from test runs. void RetrieveTestList(TestMode testMode, Action<ITestAdaptor> callback) Retrieve the full test tree as ITestAdaptor for a given test mode."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-test-utils.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-test-utils.html",
    "title": "Test Utils | mmo-rpg-unity",
    "keywords": "Test Utils This contains test utility functions for float value comparison and creating primitives. Static Methods Syntax Description bool AreFloatsEqual(float expected, float actual, float allowedRelativeError) Relative epsilon comparison of two float values for equality. allowedRelativeError is the relative error to be used in relative epsilon comparison. The relative error is the absolute error divided by the magnitude of the exact value. Returns true if the actual value is equivalent to the expected value. bool AreFloatsEqualAbsoluteError(float expected, float actual, float allowedAbsoluteError) Compares two floating point numbers for equality under the given absolute tolerance. allowedAbsoluteError is the permitted error tolerance. Returns true if the actual value is equivalent to the expected value under the given tolerance. GameObject CreatePrimitive( type) Creates a GameObject with a primitive MeshRenderer. This is an analogue to the GameObject.CreatePrimitive, but creates a primitive MeshRenderer with a fast Shader instead of the default built-in Shader, optimized for testing performance. type is the primitive type of the required GameObject. Returns a GameObject with primitive MeshRenderer and Collider. Example [TestFixture] class UtilsTests { [Test] public void CheckThat_FloatsAreEqual() { float expected = 10e-8f; float actual = 0f; float allowedRelativeError = 10e-6f; Assert.That(Utils.AreFloatsEqual(expected, actual, allowedRelativeError), Is.True); } [Test] public void CheckThat_FloatsAreAbsoluteEqual() { float expected = 0f; float actual = 10e-6f; float error = 10e-5f; Assert.That(Utils.AreFloatsEqualAbsoluteError(expected, actual, error), Is.True); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-tests-monobehaviour.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-tests-monobehaviour.html",
    "title": "MonoBehaviour tests | mmo-rpg-unity",
    "keywords": "MonoBehaviour tests MonoBehaviourTest is a coroutine and a helper for writing MonoBehaviour tests. Yield a MonoBehaviourTest when using the UnityTest attribute to instantiate the MonoBehaviour you wish to test and wait for it to finish running. Implement the IMonoBehaviourTest interface on the MonoBehaviour to state when the test completes. Example [UnityTest] public IEnumerator MonoBehaviourTest_Works() { yield return new MonoBehaviourTest<MyMonoBehaviourTest>(); } public class MyMonoBehaviourTest : MonoBehaviour, IMonoBehaviourTest { private int frameCount; public bool IsTestFinished { get { return frameCount > 10; } } void Update() { frameCount++; } } MonoBehaviourTest<T> This is a wrapper that allows running tests on MonoBehaviour scripts. Inherits from CustomYieldInstruction. Properties Syntax Description T component A MonoBehaviour component created for the test and attached to the test’s GameObject. GameObject gameObject A GameObject created as a container for the test component. bool keepWaiting (Inherited) Returns true if the test is not finished yet, which keeps the coroutine suspended. IMonoBehaviourTest An interface implemented by a MonoBehaviour test. Properties Syntax Description bool IsTestFinished Indicates when the test is considered finished."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-tests-parameterized.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-tests-parameterized.html",
    "title": "Parameterized tests | mmo-rpg-unity",
    "keywords": "Parameterized tests For data-driven testing, you may want to have your tests parameterized. You may use both the NUnit attributes TestCase and ValueSource with a unit test. Note: With UnityTest it is recommended to use ValueSource since TestCase is not supported. Example static int[] values = new int[] { 1, 5, 6 }; [UnityTest] public IEnumerator MyTestWithMultipleValues([ValueSource(\"values\")] int value) { yield return null; }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-unitysetup-and-unityteardown.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-unitysetup-and-unityteardown.html",
    "title": "UnitySetUp and UnityTearDown | mmo-rpg-unity",
    "keywords": "UnitySetUp and UnityTearDown The UnitySetUp and UnityTearDown attributes are identical to the standard SetUp and TearDown attributes, with the exception that they allow for yielding instructions. The UnitySetUp and UnityTearDown attributes expect a return type of IEnumerator. UnitySetUp and UnityTeardown example public class SetUpTearDownExample { [UnitySetUp] public IEnumerator SetUp() { yield return new EnterPlayMode(); } [Test] public void MyTest() { Debug.Log(\"This runs inside playmode\"); } [UnityTearDown] public IEnumerator TearDown() { yield return new ExitPlayMode(); } } Execution order UnitySetUp and UnityTearDown can be used with either the Test or UnityTest test attributes. In both cases the relative execution order of Unity and non-Unity SetUp and TearDown attributes is the same. The only difference is that a UnityTest allows for yielding instructions during the test that can result in a domain reload, in which case the non-Unity SetUp and TearDown methods are re-run before proceeding to the second part of the test. Note: Some browsers do not support SVG image files. If the image above does not display properly (for example, if you cannot see any text), please try another browser, such as Google Chrome or Mozilla Firefox. Base and Derived classes The term base in the execution order denotes a base class from which a test class inherits. UnitySetUp and UnityTearDown follow the same pattern as NUnit SetUp and TearDown attributes in determining execution order between base classes and their derivatives. SetUp methods are called on base classes first, and then on derived classes. TearDown methods are called on derived classes first, and then on the base class. See the NUnit Documentation for more details. Base and Derived class example public class BaseClass { [OneTimeSetUp] public void OneTimeSetUp() { Debug.Log(\"OneTimeSetUp Base\"); } [SetUp] public void SetUp() { Debug.Log(\"SetUp Base\"); } [UnitySetUp] public IEnumerator UnitySetUp() { Debug.Log(\"UnitySetup Base\"); yield return null; } [TearDown] public void TearDown() { Debug.Log(\"TearDown Base\"); } [UnityTearDown] public IEnumerator UnityTearDown() { Debug.Log(\"UnityTearDown Base\"); yield return null; } } public class DerivedClass: BaseClass { [OneTimeSetUp] public new void OneTimeSetUp() { Debug.Log(\"OneTimeSetUp\"); } [SetUp] public new void SetUp() { Debug.Log(\"SetUp\"); } [UnitySetUp] public new IEnumerator UnitySetUp() { Debug.Log(\"UnitySetup\"); yield return null; } [Test] public void UnitTest() { Debug.Log(\"Test\"); } [UnityTest] public IEnumerator UnityTest() { Debug.Log(\"UnityTest before yield\"); yield return null; Debug.Log(\"UnityTest after yield\"); } [TearDown] public new void TearDown() { Debug.Log(\"TearDown\"); } [UnityTearDown] public new IEnumerator UnityTearDown() { Debug.Log(\"UnityTearDown\"); yield return null; } [OneTimeTearDown] public void OneTimeTearDown() { Debug.Log(\"OneTimeTearDown\"); } } Domain reload example public class BaseClass { [OneTimeSetUp] public void OneTimeSetUp() { Debug.Log(\"OneTimeSetUp Base\"); } [SetUp] public void SetUp() { Debug.Log(\"SetUp Base\"); } [UnitySetUp] public IEnumerator UnitySetUp() { Debug.Log(\"UnitySetup Base\"); yield return null; } [TearDown] public void TearDown() { Debug.Log(\"TearDown Base\"); } [UnityTearDown] public IEnumerator UnityTearDown() { Debug.Log(\"UnityTearDown Base\"); yield return null; } } public class DerivedClass: BaseClass { [OneTimeSetUp] public new void OneTimeSetUp() { Debug.Log(\"OneTimeSetUp\"); } [SetUp] public new void SetUp() { Debug.Log(\"SetUp\"); } [UnitySetUp] public new IEnumerator UnitySetUp() { Debug.Log(\"UnitySetup\"); yield return null; } [Test] public void UnitTest() { Debug.Log(\"Test\"); } [UnityTest] public IEnumerator UnityTest() { Debug.Log(\"UnityTest before yield\"); yield return new EnterPlayMode(); //Domain reload happening yield return new ExitPlayMode(); Debug.Log(\"UnityTest after yield\"); } [TearDown] public new void TearDown() { Debug.Log(\"TearDown\"); } [UnityTearDown] public new IEnumerator UnityTearDown() { Debug.Log(\"UnityTearDown\"); yield return null; } [OneTimeTearDown] public void OneTimeTearDown() { Debug.Log(\"OneTimeTearDown\"); } }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-wait-for-domain-reload.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/reference-wait-for-domain-reload.html",
    "title": "WaitForDomainReload | mmo-rpg-unity",
    "keywords": "WaitForDomainReload WaitForDomainReload is an IEditModeTestYieldInstruction that you can yield in Edit Mode tests. It delays the execution of scripts until after an incoming domain reload. If the domain reload results in a script compilation failure, then it throws an exception. Constructors Syntax Description WaitForDomainReload() Create a new instance of the WaitForDomainReload yield instruction. Example [UnitySetUp] public IEnumerator SetUp() { File.Copy(\"Resources/MyDll.dll\", @\"Assets/MyDll.dll\", true); // Trigger a domain reload. AssetDatabase.Refresh(); yield return new WaitForDomainReload(); }"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/resources.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/resources.html",
    "title": "Resources | mmo-rpg-unity",
    "keywords": "Resources Here you can find other related resources to the Unity Test Framework: Performance Benchmarking in Unity: How to Get Started [Blog] Testing Test-Driven Development with the Unity Test Runner [Blog]"
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-create-playmode-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-create-playmode-test.html",
    "title": "Workflow: How to create a Play Mode test | mmo-rpg-unity",
    "keywords": "Workflow: How to create a Play Mode test To create a Play Mode test, you can follow a similar process as when you want to create an Edit Mode test. Start with switching to the PlayMode tab in the Test Runner window. Create a test assembly folder (see How to create a new test assembly). The folder name is Tests by default (or Tests 1, Tests 2, etc. if the preceding name is already in use). Note: If you don’t see the Create Play Mode Test Assembly Folder button enabled, make sure that in the Project window you navigate out of a folder with another .asmdef (such as one for Edit Mode tests). When you have your Play Mode test assembly folder ready, then create your Play Mode test. Note: Pre-defined Unity assemblies (such as Assembly-CSharp.dll) do not reference your new assembly. References and builds Unity Test Framework adds a reference to TestAssemblies in the Assembly Definition file but does not include any other references (e.g., to other scripting assemblies within the Unity project). To test other assemblies, you need to add them to the assembly definition yourself. For how to add assembly references, see Assembly Definition. We recommend putting tests into separate assemblies and using assembly definitions files. This way you will have more control over which assemblies need to reference test related dlls. Playmode build with TestsAssemblies Note: Enabling Play Mode tests for all assemblies includes additional assemblies in your project build, which can increase the project’s size as well as the build time. The supported workflow is to exclude TestAssemblies from Player builds. You can choose to enable playmode tests for all assemblies to run your tests inside the Editor, but this should be disabled again before building the Player to prevent build failures. To enable play mode tests for all assemblies you need to set the flag playModeTestRunnerEnabled to 1 inside the ProjectSettings/ProjectSetting.asset file in your project. Before building the Player you must disable it again, either by setting the flag back to 0 or by clicking on Disable playmode tests for all assemblies in the dropdown menu, accessed by right-clicking on the Test Runner window tab. For more information, see Edit Mode vs. Play Mode tests."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-create-test-assembly.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-create-test-assembly.html",
    "title": "Workflow: How to create a new test assembly | mmo-rpg-unity",
    "keywords": "Workflow: How to create a new test assembly Unity Test Framework looks for a test inside any assembly that references NUnit. We refer to such assemblies as TestAssemblies. The Test Runner UI can help you set up TestAssemblies. Play Mode and Edit Mode tests need to be in separate assemblies. In the Test Runner window, you will see an EditMode tab enabled by default, as well as a Create EditMode Test Assembly Folder button. Click the button to create a Tests folder with a respective .asmdef file by default. Change the name of the new Assembly Definition, if necessary, and press Enter to accept it. In the Inspector window, it should have references to nunit.framework.dll*,* UnityEngine.TestRunner, and UnityEditor.TestRunner assemblies, as well as Editor preselected as a target platform. Note: The UnityEditor.TestRunner reference is only available for Edit Mode tests."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-create-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-create-test.html",
    "title": "Workflow: How to create a test | mmo-rpg-unity",
    "keywords": "Workflow: How to create a test To create a test, do the following: Create your Test assembly folder and select it in the Project window. Click the button Create Test Script in current folder option in the Test Runner window. It creates a NewTestScript.cs file in the Tests folder. Change the name of the script, if necessary, and press Enter to accept it. Now you’ll see two sample tests in the Test Runner window: Now you can open the tests in your favorite script editor. You can also create test scripts by navigating to Assets > Create > Testing > C# Test Script, unless adding a test script would result in a compilation error. Note: Unity does not include TestAssemblies (NUnit, Unity Test Framework, and user script assemblies) when using the normal build pipeline, but does include them when using Run on <Platform> in the Test Runner window. Create additional tests To create another set of tests: In the Project window, select Assets. Create a new test assembly folder (menu: Assets > Create> Testing > Tests Assembly Folder). In the Project window, select the new folder. Create a new test script in the folder (menu: Assets > Create > Testing > C# Test Script). The assembly definition is assigned the same name as your new asset. To rename it, change the Name in the Insepctor window. Assembly definition names must be unique. Note: Changing the file name of the assembly definition file does not affect the value of the Name property in the file. Use the Inspector window to make sure the name is properly changed. By default Any Platform is preselected as the target platform for the new assembly, which means the test script appears as a PlayMode test in the TestRunner window. To change it to an EditMode test, in the Inspector window select Editor only under Platforms. New assemblies created through the Assets menu should automatically include references to UnityEngine.TestRunner and UnityEditor.TestRunner. If these references are missing, add them in the Inspector window under Assembly Definition References: Filters If you have a lot of tests, and you only want to view/run a sub-set of them, you can filter them in three ways (see image above): Type in the search box in the top left Click a test class or fixture (such as NewTestScript in the image above) Click one of the test result icon buttons in the top right For more information, see Edit Mode vs. Play Mode tests."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-run-playmode-test-standalone.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-run-playmode-test-standalone.html",
    "title": "Workflow: How to run a Play Mode test in player | mmo-rpg-unity",
    "keywords": "Workflow: How to run a Play Mode test in player If you run a Play Mode test in the same way as an Editor test, it runs inside the Unity Editor. You can also run Play Mode tests on specific platforms. Click Run all in the player to build and run your tests on the currently active target platform. Note: Your current platform displays in brackets on the button. For example, in the image above, the button reads Run all in player (StandaloneWindows), because the current platform is Windows. The target platform is always the current Platform selected in Build Settings (menu: File > Build Settings). The test result displays in the build once the test completes: The application running on the platform reports back the test results to the Editor UI then displays the executed tests and shuts down. To make sure you receive the test results from the Player on your target platform back into the Editor that’s running the test, both should be on the same network. Note: Some platforms do not support shutting down the application with Application.Quit, so it will continue running after reporting the test results. If Unity cannot instantiate the connection, you can see the tests succeed in the running application. Running tests on platforms with arguments, in this state, does not provide XML test results. For more information, see Edit Mode vs Play Mode tests."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-run-test.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/Documentation~/workflow-run-test.html",
    "title": "Workflow: How to run a test | mmo-rpg-unity",
    "keywords": "Workflow: How to run a test To run a test, you need to double-click on the test or test fixture name in the Test Runner window. You can also use one of the buttons on the top bar, Run All or Run Selected. As a result, you’ll see the test status icon changed and a counter in the top right corner updated: You may also use a context menu option Run, right-click on any item in the test tree to have it (with all its children if any) run. Run tests within Rider It is possible to run unit tests in the Unity Test Framework directly from JetBrains Rider. For more information, see the JetBrains official documentation and their blog post Run Unity tests in Rider 2018.1."
  },
  "Library/PackageCache/com.unity.test-framework@1.1.33/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.test-framework@1.1.33/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Test Framework copyright © 2020 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.textmeshpro@3.0.6/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.textmeshpro@3.0.6/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog These are the release notes for the TextMesh Pro UPM package which was first introduced with Unity 2018.1. Please see the following link for the Release Notes for prior versions of TextMesh Pro. http://digitalnativestudios.com/forum/index.php?topic=1363.0 [3.0.6] - 2021-04-23 [2.1.6] [1.5.6] Changes Added compiler conditional to exclude reference to PS5 in Unity 2019.4.22f1 or older and similar for Unity 2020.2.2f1 or older. [3.0.5] - 2021-04-09 [2.1.5] [1.5.5] Changes Added compiler conditional to address error related to missing RectMask2D padding property which was added in Unity 2019.4.12f1. See forum post for details. Fixed GetPreferredValues(string text) and GetPreferredValues(string text, float width, float height) incorrectly changing the text. See forum post for details. Fixed potential crash when FontEngine.GetGlyphIndex is called on a font asset that was previously unloaded or deleted. See forum post for details. Fixed potential crash when trying to add new glyphs to a dynamic font asset whose atlas texture is set to non readable. Case #1319567 Fixed Format Exception error when using the Project Text Spacing Conversion Tool when the Language Region Format is not English. Case #1320544 Fixed text rendering issue due to incorrectly SDF scaling when using a CanvasScaler and resizing the game view. Fixed TextMeshPro component Sorting Layer field in the Inspector's Extra Settings not showing the correct layer. Case #1326985 Fixed m_AlphaTweenRunner not initialized in TMP_Dropdown when Reload Domain is disabled in the Editor Enter Play Mode Settings. See forum post for details. Added support for PS4 and PS5 to TMP Input Field. [3.0.4] - 2021-02-19 [2.1.4] [1.5.4] Changes Improved sprite tag anim functionality to take into consideration the sprite character and glyph scale. Case #1309707 Improved Ellipsis character insertion handling to prevent potential issues when the Ellipsis glyph ascender and descender exceed those of the primary font asset. See forum post for details. Fixed text object margin handles in Scene view not behaving correctly as a result of lossy scale or object rotation. Case #1295523 The <mark> tag padding attribute can now be defined using font units (em). Fixed text parsing issue related to recent memory overhead optimizations. Case #1295755 Updated TMP Essential Resources and TMP Examples & Extras. Updated TMP Sprite shader to add support for Single Pass Stereo rendering. Fixed potential iOS build failure. Case #1298753 Fixed a few missing Profiler.EndSample() in the TMP_FontAsset.cs file. See forum post for details. Fixed SetText() with formatting issue where large numbers would show a leading zero. See forum post for details. Updated profiling code to use the new and more efficient ProfilerMarker. Fixed incorrect text bounds. See forum post for details. Fixed OutOfRangeException error that could occur in the TMP Input Field when selecting all and inserting characters using IME. Case #1301059 Fixed incorrect handling of Surrogate Pairs in the TMP Input Field. Case #1299798 Fixed Font Asset Creator incorrectly leaving the Readable state of font asset atlas textures to readable where it should be set to non readable for static font assets. Case #1305520 Added Multi Select functionality to the \"Create - TextMesh Pro - Font Asset\" context menu option. Case #1303074 Revised internal handling of the various text input methods to ensure the text property is always reflective of the text content in the Inspector Text Input Box in the Editor and via the text property getter even when using a combination of the various SetText methods or the text property setter. Case #1294998 Please note that using the text property getter when the text was updated via one of the SetText methods will results a string allocation. Fixed incorrect line spacing caused by preceding <size=x.x> tag. See forum post for details. Revised how the Bold Spacing which is defined per font asset will affect spacing between bold characters to ensure more uniform spacing. This change may require users to manually adjust the bold spacing value of their font assets to maintain similar spacing / layout results. Fixed linked text components not updating correctly when setting the text to null or empty. Case #1305832 The vertexBufferAutoSizeReduction property will now be set to false by default. This property is used to determine if the internal data structures used in the parsing of the text should be resized when the text content shrinks by more than 256 characters which results in CG. Case #1305311 Fixed animated sprites not behaving correctly when using text overflow mode Ellipsis and Truncate. Case #1303672 Fixed TMP Resource Importer window stealing focus when Inspector Layout Property window is open when TMP Essential Resources have not been imported into the project. Case #1300462 Fixed minor UI cosmetic issue affecting text spacing properties alignment in the Quick Search window. Case #1299587 Fixed minor UI cosmetic issue in the Font Asset inspector related to the positioning of the warning when changing Generation Settings. Fixed issue where the material properties of fallback font assets are not updated when changing the material properties of the primary font asset via code. Case #1271468 Fixed an issue with Text Overflow Linked mode where text would not flow correctly from one component to the other when the last character present at the break point was a linefeed \"\\n\" or vertical tab \"\\v\". See forum post for details. [3.0.3] - 2020-10-27 [2.1.3] [1.5.3] Changes Fixed potential null reference exception in the Input Field that can occur as a result of using a workflow that involves enabling and disabling Canvases. See forum post for details. Fixed potential Invalid AssetDatabase path warning that can be issued when assets are imported from outside the project. See forum post for details. Fixed <TextMeshProUGUI> objects not being created correctly in Prefab isolation mode when using the Create context menu. See forum post for details. Case #1266096 Fixed an issue where nesting <uppercase> and <lowercase> tags didn't behaves as expected. See forum post for details. Fixed Input Field incorrect handling of validation with text selection. Case #1267777 Fixed potential null reference exception that could occur in the Input Field when hiding the soft keyboard on iOS or Android. Case #1273631 Fixed OnScroll event not getting passed to potential parent ScrollRect when the Input Field is in Single Line mode. Case #1270241 Fixed Prefab override context menu to override or revert changes not being available for some text object properties. Case #1271420 The sampling point size in the Font Asset Creator will now be limited to a maximum of 16,384 points for SDF over-sampled modes. This means a maximum point size of 2048 for SDF8, 1024 for SDF16 and 512 for SDF32. Case #1253370 Fixed Margin widget in the scene view not working correctly when the text object is rotated on the z-axis. Case #1263001 Fixed Input Field Scrollbar not behaving correctly when set to Bottom to Top direction. Case #1179982 Fixed minor UI cosmetic issue in the StyleSheet inspector. Case #1258771 Fixed minor UI cosmetic issue in Material inspector texture properties. Case #1163983 Fixed potential IndexOutOfRangeException that could occur when duplicating text objects that have more than 8 sub text objects. Revised and improved Input Field with Scrollbar behavior with respect to text alignment. Case #1272647 Improved Input Field Name validation including adding the ability to use Hyphens. Case #1277951 Fixed state of MeshRenderer potentially not being mirrored on sub text objects. Case #1278329 Fixed GetPreferredValues() function returning incorrect values when called consecutively. See forum post for details. Initial pass at revising some of the data structures used in the text parsing and layout process to reduce text object memory overhead. Fixed incorrect positioning of IME window when using a canvas in World Space when no camera is assigned to the canvas. Case #1043535 Added new option to Font Asset Generation Settings to automatically clear dynamic data and atlas texture when creating a build. Replaced the automatic removal of the CanvasRenderer from <TextMeshPro> components with a warning to manually remove this now unnecessary component. Fixed text object properties not being applied correctly when instantiating a text prefab prior to importing TMP Essential Resources. Case #1271192 Fixed default text object properties potentially not being set correctly when instantiating a prefab. Case #1286412 Fixed incorrect parsing and display of UTF32 characters. See forum post for details. Fixed potential material error when updating a font asset generation settings when the font asset is using a non SDF shader. Case #1286132 Fixed minor UI cosmetic issue in the Sprite Asset Sprite Glyph Table inspector. Case #1285022 [3.0.1] - 2020-07-26 [2.1.1] [1.5.1] Changes Addressed compiler warning related to the new virtual event OnPreRenderText. Added one additional layer of missing character search where in the even the missing glyph character \\u0000 or space character \\u0020 is not available in any font asset or potential fallbacks, the End of Text (ETX) \\u0003 will be used instead. Input Field Integer or Decimal validation will now take into account the current culture. See forum post for details. Added Editor only font asset post processor to handle font assets being modified outside of the Unity Editor. Fixed potential Array Out of Bounds error that could occur when using </style> without first using a valid <style>. Case #1263787 and See forum post for details. Fixed potential issue when using multiple <font> tag in the same text object where these referencing several font assets derived from the same font file. Since their Default Material all have the same name, this was causing an issue in the Material Reference Manager. See forum post for details. Case #1264596. [3.0.0] - 2020-06-30 [2.1.0] [1.5.0] Changes Added support to control if a text object is Maskable and affected by UI Mask components. The new setting is found in the Extra Settings section of the <TextMeshProUGUI> component inspector. Fixed potential Null Reference Exception when trying to add characters and / or glyphs to a font asset via scripting and before it has been initialized or ReadFontAssetDefinition() has been called. Fixed incorrect preferred width values when using alternative font weight font assets. Case #1255336 Enabling or disabling the Mesh Renderer of a <TextMeshPro> text object should now also mirror that state on any sub text object renderers as well. Fixed <sprite> incorrect position when this sprite is the only character in the text and when the sprite asset face info has not been defined. Fixed potential Null Reference Exception related to culling when entering play mode. Added OnPreRenderText event delegate to allow potential modification of the text geometry before it is uploaded to the mesh and rendered. Fixed missing warning when the requested character is missing from the font asset or any potential fallbacks. Case #1256879 Fixed potential issue with Underline and StrikeThrough when using alternative typeface. Case #1255336 Fixed potential errors in the Text StyleSheet Inspector when adding or removing Text Styles after resetting the asset. Case #1254602 Fixed text Margin property values not being draggable in the Extra Settings section of the text inspector. Case #1253447 It will no longer be possible to create Editor Presets for the TMP_FontAsset, TMP_SpriteAsset, TMP_StyleSheet, TMP_ColorGradient and TMP_Settings as these are persistent and runtime assets. Case #1251229 [3.0.0-preview.14] - 2020-06-08 [2.1.0-preview.14] [1.5.0-preview.14] Changes Fixed sprite character and sprite glyph scale not being reflected in the text layout. See forum post for details. Fixed potential null reference exception in the CrossFadeColor or CrossFadeAlpha functions. See forum post for details. Minor improvements to the Sprite Asset Importer to improve allocations and address potential error encountered when creating multiple sprite assets. TMP GUID Remapping Tool - Removed \"UnityEditor.Animations.AnimatorController\" from the exclusion search list. Fixed potential culling issue when dynamically updating the content of child text objects of RectMask2D components. Case #1253625 Fixed InvalidOperationException that could occur when changing text Overflow linked components via code. Case #1251283 [3.0.0-preview.13] - 2020-05-22 [2.1.0-preview.13] [1.5.0-preview.13] Changes Fixed potential issue where the Font Asset Creator could get stuck in the packing phase of the atlas generation process. See forum post for details. Fixed issue potentially affecting text layout as a result of the width of the RectTransform being incorrectly reported. See forum post for details. Previously created prefabs containing sub text objects will now have their HideFlags updated to HideFlags.DontSave to be consistent with newly created prefabs whose sub text objects are no longer serialized. Case #1247184 Fixed culling issue where lossy scale was not considered in the determination of the bounds of the text geometry. [3.0.0-preview.12] - 2020-05-09 [2.1.0-preview.12] [1.5.0-preview.12] Changes Added synchronization of the RaycastTarget property of the parent <TextMeshProUGUI> with potential child sub text objects. Case #1240784 Fixed Font Asset Bold Spacing adjustment scaling based on the text object point size instead of current point size. Case #1241132 Improved text alignment when using RTL in conjunction with character, word and other spacing adjustments. Fixed TMP Input Field caret potentially not being visible when reaching the right side of the viewport. See forum post for more details. Fixed TMP Input Field incorrect text RectTransform horizontal adjustment when using the Backspace key. See forum post for more details. Fixed potential null reference in the TextMeshProUGUI.Cull function when using a workflow that involves enabling / disabling Canvases in the scene. Fixed ArgumentOutOfRangeException when using the \"Update Sprite Asset\" inspector option on a sprite asset that does not contain any sprites. Case #1242936 Fixed incorrect culling of the text geometry by the RectMask2D component on newly created text objects. Case #1245445 It is now possible to use the Material Context Menu options to Copy / Paste Material Properties or Atlas Texture originally created for TMP with all other non TMP specific materials. Case #1242671 Fixed NullReferenceException when setting the Atlas Texture to None in the Debug Settings of the Material Inspector of a text object. Case #1245104 [3.0.0-preview.11] - 2020-04-22 [2.1.0-preview.11] [1.5.0-preview.11] Changes Fixed incorrect culling of text object by RectMask2D component when the parent Canvas Render Mode is set to Screen Space - Camera or World Space. Case #1240595 Added special handling to ForceMeshUpdate() when the parent Canvas is disabled. [3.0.0-preview.10] - 2020-04-21 [2.1.0-preview.10] [1.5.0-preview.10] Changes Revised caching of Preferred Width and Height to further reduce the amount of time it has to be recomputed when using a complex structure of Layout components. Fixed potential issue when using Text Overflow Ellipsis and Truncate modes when the text contains characters using superscript, subscript or using the <voffset> tag. Revised culling of text objects when using a RectMask2D where the bounds of the text geometry instead of the RectTransform define the culling rect. Added HDR support to material preset colors. Fixed various formatting issues in this ChangeLog. Added the ability to define a unicode value for a missing sprite character in the TMP Settings. Added support for displaying a missing sprite character when the requested sprite character is not present in the sprite asset or potential fallback(s). This new functionality is only available when trying to reference a sprite by name. Sprite Characters will now have a default Unicode value of 0xFFFE (Private NonCharacter) instead of a Unicode value of 0x0 (default unicode value for missing character). Using the sprite asset context menu option \"Update Sprite Asset\" will now remap sprite characters with unicode value of 0x0 to 0xFFFE in addition to its currently functionality. Updating TMP Essential Resources via the \"Window - TextMeshPro - Import TMP Essential Resources\" menu option will no longer override existing TMP Settings. Minor optimization where SDF Scale on some text objects could be unnecessarily updated due to floating point rounding errors in their lossy scale. Case #1230799 Fixed minor issue where text objects created before importing the required TMP Essential Resources would have no default text. Improvements to line breaking for CJK and mixed Latin and CJK characters. See the following forum post for more details. Fixed potential NullReferenceException that could occur in the TMP InputField on some platforms if the InputSystem reference is null. Case #1232433 Added small padding to bitmap character geometry to prevent potential clipping. Added optimization to ignore very small RectTransform pivot changes that are usually the result of rounding errors when using Layout Components. Case #1237700 Sorting Layer ID and Sorting Order properties located in the Extra Settings of <TextMeshPro> text objects will now serialized when creating Editor Presets. Case #1215750 TextMeshProUGUI sub text objects will now be set as first sibling of their parent to prevent them from being rendered over other non text object child in the scene hierarchy. Fixed text objects becoming visible when set to empty or null as a result of a scale change. Case #1238408 Fixed useMaxVisibleDescender property now getting set properly via scripting. Case #1218526 Fixed SortingLayerID and SortingOrder not getting set correctly when multiple <TextMeshPro> objects are selected. Case #1171272 Fixed default settings getting applied to disabled text objects in the scene hierarchy whose text property was set to null. Case #1151621 Fixed mouse cursor flickering when hovering the Text Input Box of a text prefab with RTL enabled. Case #1206395 [3.0.0-preview.8] - 2020-03-14 [2.1.0-preview.8] [1.5.0-preview.8] Changes Fixed a minor issue where the preferred width of a text object can be incorrect when using multiple font assets, fallbacks and sprites in the same line of text. Added Alpha Fade Speed property to the TMP_DropDown inspector. Minor improvements to the LogWarning related to missing characters in a font asset or fallback being replaced by a space character. Fixed text object geometry not getting clipped when object is outside of RectMask2D. Improved search for potential missing character to include the primary font asset and potential fallbacks when the current font asset is not the primary. Ignorable / Synthesized characters in font assets will only be created if they do not exist in the source font file. Trying to use Text Overflow Ellipsis mode when no Ellipsis character is available in the primary font asset or potential fallbacks will now issue a warning and switch Text Overflow mode to Truncate. Added &ltcolor=lightblue&gt and &ltcolor=grey&gt to pre-defined rich text tag colors. Fixed compatibility issue when using TexturePacker - JSON (Array) mode and the TMP Sprite Asset Importer to create SpriteAssets. Simple fix to prevent the underline rich text tag becoming visible in the TMP Input Field when in IME composition mode with Rich Text disabled on the TMP Input Field. This is a temporary fix until a more robust and flexible solution is implemented. Case #1219969 Sub Text Objects which are created when the text requires the use of a fallback font asset or sprite asset will now use HideFlags.DontSave to prevent them from being save with Prefabs as they are created on demand. Fix incorrect material reference when current font asset is not the primary or a fallback that is missing a character which is present in the primary font asset. [3.0.0-preview.7] - 2020-03-07 [2.1.0-preview.7] [1.5.0-preview.7] Changes Reverted recent change to the TMP_SubMeshUI OnDisable() function that could result in a Missing Reference Exception in the GraphicRaycaster.cs script. See the following forum post. Fixed glyph drawing issue in the Font Asset Inspector Glyph Adjustment Table when Multi Atlas Texture is enabled and the glyph is not located in the main atlas texture or at atlasTextures[0]. Added support for &ltZWSP&gt tag which is internally replaced by a zero width space or \\u200B. Improved line breaking handling when using &ltNBSP&gt and / or &ltNOBR&gt tags where instead of breaking these line segments per character, they will break at any possible soft breaking space when these segments exceed the width of the text container. Improved PreferredHeight calculations and handling when using Text Auto Size. Fixed incorrect color being applied to the underline or strikethrough line segments when using and / or tags along with a tag while at the same time applying an Underline or Strikethrough font style on the whole text object. Fixed SDF Scale not getting updated when using SetText() with StringBuilder when the lossyScale of the text object changes. Case #1216007 Added Non Breaking Space \\u00A0 and Soft Hyphen \\u00AD to list of synthesized characters in the event they are not present in the source font file. Fixed stack overflow issue when using TMP_FontAsset.HasCharacter and TMP_FontAsset.HasCharacters function on font assets that have circular fallback references. Case #1222574 Fixed atlas texture not getting set correctly to IsReadable when switching a static font asset to dynamic in the Generation Settings of the Font Asset Inspector. Added check for RectTransform.sizeDelta change when OnRectTransformDimensionsChange() is called by the Canvas system to get around potential rounding error that erroneously trigger this callback when the RectTransform is using Stretch Anchor mode. As requested by a few users, TMP_FontAsset.faceInfo setter is now public instead of internal. [3.0.0-preview.5] - 2020-02-25 [2.1.0-preview.5] [1.5.0-preview.5] Changes Revised SetText function formatting options to including ability to specify padding for integral part of the value. Revised format is as follows: {Arg Index:Integral Padding.Decimal Precision} Example: TMP_Text.SetText(\"Value = {0:000.00}\", 10.375f); result in \"Value = 010.38\". Fixed issue where text objects isTextObjectScaleStatic property would be ignored when OnCanvasHierarchyChanged() is called. Added a Character, Glyph and Record count to those respective tables in the Font Asset Inspector. Fixed potential Null Reference Exception that would occur when using text Overflow Ellipsis mode with a primary font asset that doesn't contain the Ellipsis character. Case #1209771 Fixed a potential Editor lockup when using text Overflow Page mode. Case #1219055 Fixed Input Field incorrect caret vertical alignment when using the Midline / Vertical Geometry alignment option. Added initial / minimal support for the New Input System. Please use with caution and report any issues. Changes to Font Asset Generation Settings via the Font Asset Inspector will now update the existing glyphs and characters for the new settings instead of clearing them. Text object InternalUpdate() used to handle potential scale changes of text objects now uses willRenderCanvases event instead of onPreCull. This avoids a potential one frame delay in updating of objects and no impact on objects. Case #1216007 [3.0.0-preview.4] - 2020-01-31 [2.1.0-preview.4] [1.5.0-preview.4] Changes Fixed Input Field issue where scrolling events could prevent OnEndEdit event from firing. See forum post for details. Improved Input Field handling of Vertical Scrollbar in conjunction with the ResetOnDeActivation property. Using the Vertical Scrollbar no longer triggers OnEndEdit event. Fixed potential Missing Component Exception that could occur when a TMP_SubMeshUI object is created. Fixed MissingReferenceException when deleting a TMP prefab that is part of a nested prefab. Case #1207793 Improved handling of allocations of newly created text objects with large amount of text. As a result of these revisions, allocations will potentially be reduce by 10X. See #1205923 Fixed potential Null Reference Exception with the TMP DropDown that could occur when using the experimental Editor \"Enter Play Mode\" feature. Case #1207915 Fixed potential issue with the assignment of sub text object materials. Add support for hiding the soft keyboard for Switch in the TMP Input Field. Fixed incorrect Preferred Height when Word Wrapping is disabled on text objects. See forum post for details. Added support for the new Selected state and color to the TMP Input Field. Case #1210496 Fixed additional instances of TMP Resource Importer window being created when deleting the \"TextMesh Pro\" folder just after having imported them. Case #1205848 Added public ITextPreprocessor textPreprocessor; property to allow setting the text preprocessor for a given text component. [3.0.0-preview.3] - 2019-12-16 [2.1.0-preview.3] [1.5.0-preview.3] Changes Fixed potential issue with TMP Dropdown where calling Show() and Hide() in very short interval could result in additional Blockers. Case #1194114 Fixed potential issues that could occur when upgrading to version 1.5.0-preview.2 or newer of the TMP package without also updating the TMP Essential Resources in the project. Added check and warning when trying to create a font asset whose source font file has \"Incl. Font Data\" disabled in the Font Import Settings. Case #1198587 and #1198112 Fixed Ellipsis overflow mode issue when using small caps. Case #1198392 Fixed potential layout issue when adding a Layout Group to the text object itself. Case #1197614 Fixed Font Asset Creator issue where too many adjustment records with adjustment value of zero were added to the font asset. Added support for Line Separator \\u2028 and Paragraph Separator \\u2029. TMP shaders have been moved from \"TextMesh Pro/Resources/Shaders\" folder to \"TextMesh Pro/Shaders\" folder. See the following post for details. Added new experimental SDF and Mobile SDF Shaders that use Screen Space Derivatives (SSD) where these shaders no longer require SDF Scale to be passed via Vertex Attributes. These shaders have higher performance overhead but are more flexible. This overhead should only be noticeable on mobile platforms. Fixed potential text alignment issue where upgrading from package version 1.4.1 to 1.5.0-preview.2 would result in incorrect alignment on prefabs. Case #1198833 Added \\u061C Arabic Letter Mark, \\u200E Left-to-Right Mark and \\u200F Right-to-Left Mark to list of control and non renderable characters. Fixed Missing Reference Exception that would appear when expanding the Extra Settings of a TextMeshPro Preset asset. Case #1201072 Fixed Missing Reference Exception that would appear when editing the Vertex Color or Color Gradient of a TMP component Preset asset. Case #1201069 Fixed Inspector layout issue preventing enabling or disabling the Outline, Underlay, Lighting and Glow features when selecting a Preset asset material. Case #1196963 Revised the Create Material Preset context menu option to issue a warning and ignore materials outside the project. Case #1200109 Added experimental ITextPreprocessor interface to allow users to create custom components to handle text preprocessing and shaping. This interface includes a PreprocessText(string text) function that is called when the object contains a component that inherits from this interface. Added support for Unity Presets in the Editor for both and components. Case #1191793 Fixed missing CanvasRenderer component issue on the Input Field Caret object. Added padding to the 2DRectMask on the TMP Input Field - Text Area object. Optimization to ensure the TMP Update Manager only rebuilds text objects once per frame regardless of the number of cameras in the scene. [2.1.0-preview.2] - 2019-10-30 [1.5.0-preview.2] Changes Fixed Input Field issue when Read Only flag is set preventing the initial setting of the text. Also fixed Read Only flag not being respected when using IME input. Fixed potential infinite loop when using text overflow mode ScrollRect. See Case #1188867 Fixed Input Field culling related issue(s) where text would be incorrectly culled. See https://forum.unity.com/threads/version-1-5-0-2-1-0-preview-1-now-available-for-testing.753587/#post-5023700 Revised handling and referencing of the CanvasRenderer in anticipation of an incoming change to the MaskableGraphic class where it will no longer automatically add a CanvasRenderer to components inheriting from it. As a result, objects will no longer have a CanvasRenderer. Fixed potential NRE when using Overflow Truncate mode with sprites. See https://forum.unity.com/threads/tmpro-stackoverflow-caused-by-tmpro-textmeshprougui-generatetextmesh.750398/page-2#post-5042822 Fixed issue when using font weights in combination of font styles in the editor. Fixed for potential incorrect preferred height. Improved handling of StyleSheet options to reorder, add or delete styles. Fixed Input Field Caret & Selection Highlight potential culling issue when the object was instantiated outside the culling region. Fixed potential issue with registration of text objects in the TMP_UpdateManager. Optimization to suppress callback to InternalUpdate when parent Canvas is disabled. Case #1189820 Fixed Fallback material not getting updated correctly when changing Generation Settings on the Fallback Font Asset. Fixed a typo in the Font Weight section of the Font Asset Editor. Fixed potential ArgumentOutOfRangeException in the Input Field when using Hide Mobile Input and deleting a long string. Case #1162514 Added \"Is Scale Static\" option in the Extra Settings to exclude text objects from InternalUpdate callbacks to improve performance when the object's scale is static. This InternalUpdate callback is used to track potential changes to the scale of text objects to update their SDF Scale. Added the ability to control culling modes for the TMP Shaders. This new option is available in the Debug section of the Material Inspector. New feature requires updating the TMP Essential Resources. See the following post https://forum.unity.com/threads/not-see-textmeshpro-rendering-from-the-back.767510/#post-5112461. Fixed Material Inspector issue when toggling the Record button in the Animation window. Case #1174960 Improved Line Breaking handling for CJK. This also addresses a few reported issues. Case #1171603 Added support for &ltNBSP&gt tag which is internally replaced by a non-breaking space or \\u00A0. Improved performance when retrieving glyph adjustment records when using dynamic font assets. Fixed potential Null Reference Exception in the Editor when assigning new font asset to disabled game object when no previous font asset was assigned. [2.1.0-preview.1] - 2019-09-30 [1.5.0-preview.1] Changes Fixed an issue when using Overflow Ellipsis mode where the Ellipsis character would not be displayed correctly when the preceding character is a sprite. Added the ability to define the Resource path for Style Sheets in the TMP Settings. TMP Style Sheets can now be assigned to text objects in the Extra Settings section of the text object inspector. Added the ability to assign a Style to text objects using the new Text Style property in the text object inspector. A new public property TMP_Text.textStyle was also added. Improved Style Sheet editor to allow sorting of styles in the style sheet. Improved handling of nested styles. Added public TMP_Style GetStyle(string name) to get the potential style by name. Revised the ForceMeshUpdate() function as follows: public void ForceMeshUpdate(bool ignoreActiveState = false, bool forceTextReparsing = false). Fixed SubMeshUI objects text disappearing when saving a scene. Creating Material Presets via the Material Context menu with multi selection will now work as expected and assign the newly created material preset to all selected text objects. Fixed minor issue when changing Material Preset in prefab isolation mode with multiple text objects selected where the new material preset would not be assigned to disabled text objects. Revised Character, Word, Line and Paragraph spacing adjustments to be in font units (em) where a value of 1 represents 1/100 em. Added TMP_Text.onFontAssetRequest and TMP_Text.onSpriteAssetRequest events to allow users to implement custom asset loading when using the &ltfont=\"Font Asset Name\"&gt and &ltsprite=\"Sprite Asset Name\"&gt tags. Additional Shader Channels on the Canvas will be set to TexCoord1, Normal and Tangents or Mixed when using TMP Surface Shaders. Otherwise it will be set to TexCoord1 only. Case #1100696 Added new attribute to the &ltmark&gt tag to allow users to define a padding value for the mark / highlight region. Example: &ltmark color=#FFFF0080 padding=\"1.0,1.0,0.0,0.0\"&gt where padding=\"Left, Right, Top, Bottom\". Fixed an issue which could result in out of range exception when referencing sprites contained in fallback sprite assets using unicode values. Fixed an issue in the Font Asset Creator where the source font file property of the newly created font asset was not getting set. Added .blend files to exclusion asset scan list of the Project GUID Remapping tool. Fixed issue where Caret position would be incorrect when using IME. Case #1146626 Clamped Outline Softness to a value of 0-1 in the TMP Distance Field shader which makes it consistent with other SDF Shaders. Case #1136161 Text Auto-Sizing Min and Max values are now clamped between 0 and 32767. Case #1067717 Text Font Size Min and Max values are now clamped between 0 and 32767. Case #1164407 Rich Text Tag values are now limited to a maximum value of 32767. Added Placeholder option to TMP Dropdown. Placeholder text is displayed when selection value is -1. Also added example scene in the TMP Examples & Extras. Added the ability to define Face Info metrics per Sprite Assets. This will provide for more consistent scaling of the sprites regardless of the font asset used. Sprite Assets with undefined Face Info will continue to inherit the Face Info metrics of the current font asset. Added Update Sprite Asset option in the header of the Sprite Asset inspector. This increases the discoverability of this option already available via the Sprite Asset Context Menu. Revised the text auto-sizing handling in regards to maximum iteration threshold which could result in a crash on some Android devices. Case #1141328 Font Asset Generation Settings are now disabled in the inspector if the Source Font File is missing or if the Atlas Population Mode is set to static. Fixed vertical alignment issue when using Overflow Page mode. Improved handling of text auto-size line adjustment spacing resulting in fewer iterations and more accurate resulting point size. Added support for Layout Elements to the TMP Input Field. = Fixed text alignment issue with TMP Input Field when using Center alignment on the underlying text component. Setting ContentType.Custom on the TMP Input Field will no longer hide the Soft Keyboard. The Soft Keyboard can now be control independently via the shouldHideSoftKeyboard property. Added new Font Asset Context Menu option \"Force Upgrade To Version 1.1.0\" for convenience purposes in case a font asset didn't get upgraded automatically when migrating from version 1.3.0 to 1.4.x or 2.0.x. The &ltgradient&gt tag now as an optional attribute \"tint=0\" or \"tint=1\" controlling whether or not the gradient will be affect by vertex color. The alpha of the gradient will continue to be affected by the vertex color alpha. Added new angle=x attribute to the &lti&gt tag where the value of x define the italic slant angle. Since the legacy TextContainer used by TMP has been deprecated, it was removed from the Layout Context Menu options. Improved character positioning when using italic text where large angle / slant would potentially result in uneven spacing between normal and italic blocks of text. Fixed an issue where &ltmspace&gt and &ltcspace&gt tags would not be handled correctly in conjunction with word wrapping. Fixed issue in the TMP_Dropdown.cs that was affecting navigation. Case 1162600. See https://forum.unity.com/threads/huge-bug-missing-a-code-line-since-1-4-0.693421/ Fixed an issue related to kerning where the glyph adjustment values did not account for the upsampling of the legacy SDF modes like SDF8 / SDF16 and SDF32. Made the TMP_Text.text property virtual. Fixed Material Preset of fallback materials getting modified when the TMP Settings Match Material Preset option is disabled. Added ShaderUtilities.ID_GlowInner to list of material property IDs. Fixed potential null reference exception when creating new text objects when no default font asset has been assigned in the TMP Settings and the LiberationSans SDF font asset has been deleted from the project. Case #1161120 Fixed import TMP Essential Resources button being disabled when importing the TMP Examples & Extras first. Case #1163979 Fixed potential ArgumentOutOfRangeException when Hide Mobile Input is enabled and deleting the last character in the text. Case #1162514 Improved handling of manual addition of glyph positional adjustment pairs for both dynamic and static font assets. Case #1165763 Fixed issue where text in the TMP_InputField would disappear due to incorrect culling. Case #1164096 Fixed potential IndexOutOfRangeException that could be thrown when using the Pinyin IME interface and typing very fast to enter Chinese text. Case #1164383 Added support for Vertical Tab \\v which inserts a line break but not a paragraph break. Added support for Shift Enter in the TMP Input Field which inserts a Vertical Tab in the text in Multi Line mode. Fixed text horizontal alignment when lines of text only contain the Ellipsis \\u2026 Unicode character. Case #1162685 Text alignment is now serialized into separate fields for horizontal and vertical alignment and can now be get / set independently via TMP_Text.horizontalAlignment and TMP_Text.verticalAlignment. The TMP_Text.alignment property remains and uses the new serialized fields for horizontal and vertical alignment. Improved handling of Soft Hyphens when using Text Auto-Size. Fixed Null character being passed to Validate method of the TMP_InputField. Case #1172102 Fixed an issue where the Preferred Width and Height were not correct when using Tabs. The Cull Transparent Mesh flag on TMP_SubMeshUI objects will now mirror the settings on the parent text object's CanvasRenderer. Updated Sprite Importer to improve compatibility with Texture Packer Json Array export format. Newly created StyleSheets will be pinged in the project tab. Case #1182117 Added new option in the TMP Settings to control line breaking rules for Hangul to enabled Modern line breaking or traditional line breaking. Fixed potential issue related to SDF Scaling when the scale of the text object is negative. See https://forum.unity.com/threads/version-1-4-1-preview-1-with-dynamic-sdf-for-unity-2018-3-now-available.622420/page-5#post-4958240 for details. Added validation check for Sprite Data Source file in the Sprite Asset Importer. Case #1186620 Added warning when using Create - TextMeshPro - Sprite Asset menu when no valid texture is selected. Case #1163982 Fixed potential cosmetic issue in the text component inspector when using Overflow Linked mode. Case #1177640 [1.4.1] - 2019-04-12 Changes Improved handling of font asset automatic upgrade to version 1.1.0 which is required to support the new Dynamic SDF system. Made release compatible with .Net 3.5 scripting runtime. [1.4.0] - 2019-03-07 Changes Same release as 1.4.0-preview.3a. [1.4.0-preview.3a] - 2019-02-28 Changes Improved performance of the Project Files GUID Remapping Tool. Fixed an issue with the TMP_FontAsset.TryAddCharacters() functions which was resulting in an error when added characters exceeded the capacity of the atlas texture. Updated TMP_FontAsset.TryAddCharacters functions to add new overloads returning list of characters that could not be added. Added function in OnEnable of FontAsset Editor's to clean up Fallback list to remove any null / empty entries. Added support for Stereo rendering to the TMP Distance Field and Mobile Distance Field shaders. [1.4.0-preview.2a] - 2019-02-14 Changes Fixed an issue with SDF Scale handling where the text object would not render correctly after the object scale had been set to zero. Fixed an issue with the TMP_UpdateManager where text objects were not getting unregistered correctly. Any changes to Font Asset Creation Settings' padding, atlas width and / or atlas height will now result in all Material Presets for the given font asset to also be updated. Added new section in the TMP Settings related to the new Dynamic Font System. Added new property in the Dynamic Font System section to determine if OpenType Font Features will be retrieved from source font files at runtime as new characters are added to font assets. Glyph Adjustment Data (Kerning) is the only feature currently supported. Fix an issue where font assets created at runtime were not getting their asset version number set to \"1.1.0\". Improved parsing of the text file used in the Font Asset Creator and \"Characters from File\" option to handle UTF16 \"\\u\" and UTF32 \"\\U\" escape character sequences. Fixed a Null Reference Error (NRE) that could occur when using the &ltfont&gt tag with an invalid font name followed by the &ltsprite&gt tag. The Glyph Adjustment Table presentation and internal data structure has been changed to facilitate the future addition of OpenType font features. See https://forum.unity.com/threads/version-1-4-0-preview-with-dynamic-sdf-for-unity-2018-3-now-available.622420/#post-4206595 for more details. Fixed an issue with the &ltrotate&gt tag incorrectly affecting character spacing. [1.4.0-preview.1] - 2019-01-30 Changes Renamed TMPro_FontUtilities to TMP_FontAssetCommon to more accurately reflect the content of this file. Accessing the TextMesh Pro Settings via the new Edit - Settings menu when TMP Essential Resources have not yet been imported in the project will no longer open a new window to provide the options to import these resources. Fixed an issue where using int.MaxValue, int.MinValue, float.MaxValue and float.MinValue in conjunction with SetText() would display incorrect numerical values. Case #1078521. Added public setter to the TMP Settings' missingGlyphCharacter to allow changing which character will be used for missing characters via scripting. Fixed a potential Null Reference Exception related to loading the Default Style Sheet. Added compiler conditional to TMP_UpdateManager.cs to address changes to SRP. Improved the &ltmargin&gt tag to make it possible to define both left and right margin values. Example: &ltmargin left=10% right=10px&gt. Added new menu option to allow the quick creation of a UI Button using TMP. New menu option is located in Create - UI - Button (TextMeshPro). Renamed TMP related create menu options. Fixed TMP object creation handling when using Prefab isolation mode. Case #1077392 Fixed another issue related to Prefabs where some serialized properties of the text object would incorrectly show up in the Overrides prefab options. Case #1093101 Fixed issue where changing the Sorting Layer or Sorting Order of a object would not dirty the scene. Case #1069776 Fixed a text alignment issue when setting text alignment on disabled text objects. Case #1047771 Fixed an issue where text object bounds were not set correctly on newly created text objects or in some cases when setting the text to null or string.empty. Case #1093388 Fixed an issue in the IntToString() function that could result in Index Out Of Bounds error. Case #1102007 Changed the TMP_InputField IsValidChar function to protected virtual. The \"Allow Rich Text Editing\" property of the TMP_InputField is now set to false by default. Added new option to the Sprite Asset context menu to make it easier to update sprite glyphs edited via the Unity Sprite Editor. Added new Sharpness slider in the Debug section of the SDF Material inspector. Fixed an error that would occur when using the context menu Reset on text component. Case #1044726 Fixed issue where CharacterInfo.index would be incorrect as a result of using Surrogate Pairs in the text. Case #1037828 The TMP_EditorPanel and TMP_UiEditorPanel now have their \"UseForChildren\" flag set to true to enable user / custom inspectors to inherit from them. Fixed an issue where rich text tags using pixel (px) or font units (em) were not correctly accounting for orthographic camera mode. This change only affects the normal TMP text component. Fixed an inspector issue related to changes to the margin in the TMP Extra Settings panel. Case #1114253 Added new property to Glyph Adjustment Pairs which determines if Character Spacing Adjustments should affect the given pair. Updated the Glyph Adjustment Table where ID now represents the unicode (hex) value for the character instead of its decimal value. Added new SetValueWithoutNotify() function to TMP_DropDown and SetTextWithoutNotify() function to TMP_InputField allowing these to be set without triggering OnValueChanged event. Geometry buffer deallocation which normally takes place when current allocations exceed those of the new text by more than 256 characters will no longer occur if the new text is set to null or string.empty. Fixed a minor issue where the underline SDF scale would be incorrect when the underline text sequence contained normal size characters and ended with a subscript or superscript character. Fixed an error that would occur when using the Reset Context menu on a Material using the SDF Surface or Mobile SDF Surface Shaders. Case #1122279 Resolved a Null Reference Error that would appear when cycling through the text overflow modes. Case #1121624 [1.3.0] - 2018-08-09 Changes Revamped UI to conform to Unity Human Interface Guidelines. Updated the title text on the Font Asset Creator window tab to \"Font Asset Creator\". Using TMP_Text.SetCharArray() with an empty char[] array will now clear the text. Made a small improvement to the TMP Input Field when using nested 2d RectMasks. Renamed symbol defines used by TMP to append TMP_ in front of the define to avoid potential conflicts with user defines. Improved the Project Files GUID Remapping tool to allow specifying a target folder to scan. Added the ability to cancel the scanning process used by the Project Files GUID Remapping tool. Moved TMP Settings to universal settings window in 2018.3 and above. Changing style sheet in the TMP Settings will now be reflected automatically on existing text objects in the editor. Added new function TMP_StyleSheet.UpdateStyleSheet() to update the internal reference to which style sheet text objects should be using in conjunction with the style tag. [1.2.4] - 2018-06-10 Changes Fixed a minor issue when using Justified and Flush alignment in conjunction with \\u00A0. The Font Asset creationSettings field is no longer an Editor only serialized field. [1.2.3] - 2018-05-29 Changes Added new bitmap shader with support for Custom Font Atlas texture. This shader also includes a new property \"Padding\" to provide control over the geometry padding to closely fit a modified / custom font atlas texture. Fixed an issue with ForceMeshUpdate(bool ignoreActiveState) not being handled correctly. Cleaned up memory allocations from repeated use of the Font Asset Creator. Sprites are now scaled based on the current font instead of the primary font asset assigned to the text object. It is now possible to recall the most recent settings used when creating a font asset in the Font Asset Creator. Newly created font assets now contain the settings used when they were last created. This will make the process of updating / regenerating font assets much easier. New context menu \"Update Font Asset\" was added to the Font Asset inspector which will open the Font Asset Creator with the most recently used settings for that font asset. New Context Menu \"Create Font Asset\" was added to the Font inspector panel which will open the Font Asset Creator with this source font file already selected. Fixed 3 compiler warnings that would appear when using .Net 4.x. Modified the TMP Settings to place the Missing Glyph options in their own section. Renamed a symbol used for internal debugging to avoid potential conflicts with other user project defines. TMP Sprite Importer \"Create Sprite Asset\" and \"Save Sprite Asset\" options are disabled unless a Sprite Data Source, Import Format and Sprite Texture Atlas are provided. Improved the performance of the Project Files GUID Remapping tool. Users will now be prompted to import the TMP Essential Resources when using the Font Asset Creator if such resources have not already been imported. [1.2.2] - 2018-03-28 Changes Calling SetAllDirty() on a TMP text component will now force a regeneration of the text object including re-parsing of the text. Fixed potential Null Reference Exception that could occur when assigning a new fallback font asset. Removed public from test classes. Fixed an issue where using nested links (which doesn't make sense conceptually) would result in an error. Should accidental use of nested links occurs, the last / most nested ends up being used. Fixed a potential text alignment issue where an hyphen at the end of a line followed by a new line containing a single word too long to fit the text container would result in miss alignment of the hyphen. Updated package license. Non-Breaking Space character (0xA0) will now be excluded from word spacing adjustments when using Justified or Flush text alignment. Improved handling of Underline, Strikethrough and Mark tag with regards to vertex color and Color tag alpha. Improved TMP_FontAsset.HasCharacter(char character, bool searchFallbacks) to include a recursive search of fallbacks as well as TMP Settings fallback list and default font asset. The &ltgradient&gt tag will now also apply to sprites provided the sprite tint attribute is set to a value of 1. Ex. &ltsprite=\"Sprite Asset\" index=0 tint=1&gt. Updated Font Asset Creator Plugin to allow for cancellation of the font asset generation process. Added callback to support the Scriptable Render Pipeline (SRP) with the normal TextMeshPro component. Improved handling of some non-breaking space characters which should not be ignored at the end of a line. Sprite Asset fallbacks will now be searched when using the &ltsprite&gt tag and referencing a sprite by Unicode or by Name. Updated EmojiOne samples from https://www.emojione.com/ and added attribution. Removed the 32bit versions of the TMP Plugins used by the Font Asset Creator since the Unity Editor is now only available as 64bit. The isTextTruncated property is now serialized. Added new event handler to the TMP_TextEventHandler.cs script included in Example 12a to allow tracking of interactions with Sprites. [1.2.1] - 2018-02-14 Changes Package is now backwards compatible with Unity 2018.1. Renamed Assembly Definitions (.asmdef) to new UPM package conventions. Added DisplayName for TMP UPM package. Revised Editor and Playmode tests to ignore / skip over the tests if the required resources are not present in the project. Revised implementation of Font Asset Creator progress bar to use Unity's EditorGUI.ProgressBar instead of custom texture. Fixed an issue where using the material tag in conjunction with fallback font assets was not handled correctly. Fixed an issue where changing the fontStyle property in conjunction with using alternative typefaces / font weights would not correctly trigger a regeneration of the text object. [1.2.0] - 2018-01-23 Changes Package version # increased to 1.2.0 which is the first release for Unity 2018.2. [1.1.0] - 2018-01-23 Changes Package version # increased to 1.1.0 which is the first release for Unity 2018.1. [1.0.27] - 2018-01-16 Changes Fixed an issue where setting the TMP_InputField.text property to null would result in an error. Fixed issue with Raycast Target state not getting serialized properly when saving / reloading a scene. Changed reference to PrefabUtility.GetPrefabParent() to PrefabUtility.GetCorrespondingObjectFromSource() to reflect public API change in 2018.2 Option to import package essential resources will only be presented to users when accessing a TMP component or the TMP Settings file via the project menu. [1.0.26] - 2018-01-10 Added Removed Tizen player references in the TMP_InputField as the Tizen player is no longer supported as of Unity 2018.1. [1.0.25] - 2018-01-05 Added Fixed a minor issue with PreferredValues calculation in conjunction with using text auto-sizing. Improved Kerning handling where it is now possible to define positional adjustments for the first and second glyph in the pair. Renamed Kerning Info Table to Glyph Adjustment Table to better reflect the added functionality of this table. Added Search toolbar to the Glyph Adjustment Table. Fixed incorrect detection / handling of Asset Serialization mode in the Project Conversion Utility. Removed SelectionBase attribute from TMP components. Revised TMP Shaders to support the new UNITY_UI_CLIP_RECT shader keyword which can provide a performance improvement of up to 30% on some devices. Added TMP_PRESENT define as per the request of several third party asset publishers. [1.0.23] - 2017-11-14 Added New menu option added to Import Examples and additional content like Font Assets, Materials Presets, etc for TextMesh Pro. This new menu option is located in \"Window -> TextMeshPro -> Import Examples and Extra Content\". New menu option added to Convert existing project files and assets created with either the Source Code or DLL only version of TextMesh Pro. Please be sure to backup your project before using this option. The new menu option is located in \"Window -> TextMeshPro -> Project Files GUID Remapping Tool\". Added Assembly Definitions for the TMP Runtime and Editor scripts. Added support for the UI DirtyLayoutCallback, DirtyVerticesCallback and DirtyMaterialCallback."
  },
  "Library/PackageCache/com.unity.textmeshpro@3.0.6/Documentation~/TextMeshPro.html": {
    "href": "Library/PackageCache/com.unity.textmeshpro@3.0.6/Documentation~/TextMeshPro.html",
    "title": "TextMesh Pro User Guide | mmo-rpg-unity",
    "keywords": "TextMesh Pro User Guide Overview This User Guide was designed to provide first time users of TextMesh Pro with a basic overview of the features and functionality of the tool. Installation The TextMesh Pro UPM package is already included with the Unity Editor and as such does not require installation. TextMesh Pro \"TMP\" does however require adding resources to your project which are essential for using TextMesh Pro. To import the \"TMP Essential Resources\", please use the \"Window -> TextMeshPro -> Import TMP Essential Resources\" menu option. These resources will be added at the root of your project in the \"TextMesh Pro\" folder. The TextMesh Pro package also includes additional resources and examples that will make discovering and learning about TextMesh Pro's powerful features easier. It is strongly recommended that first time users import these additional resources. To import the \"TMP Examples & Extras\", please use the \"Window -> TextMeshPro -> Import TMP Examples & Extras\" menu option. These resources will also be added in the same \"TextMesh Pro\" folder inside your project. Quick Start There are two TextMesh Pro components available. The first TMP text component is of type <TextMeshPro> and designed to work with the MeshRenderer. This component is an ideal replacement for the legacy TextMesh component. To add a new <TextMeshPro> text object, go to: �GameObject->3D Object->TextMeshPro Text�. The second TMP text component is of type <TextMeshProUGUI> and designed to work with the CanvasRenderer and Canvas system. This component is an ideal replacement for the UI.Text component. To add a new <TextMeshProUGUI> text object, go to: �GameObject->UI->TextMeshPro Text�. You may also wish to watch this Getting Started short video which covers this topic. We strongly recommend that you also watch the Font Asset Creation video as well as the Working with Material Presets as these two topics is also key to working and getting the most out of TextMesh Pro. As mentionned in the Installation section of this guide, it is recommended that you import the \"TMP Examples & Extras\" and take the time to explore each of the examples as they provide a great overview of the functionality of the tool and the many text layout and rich text tags available in TextMesh Pro. Support & API Documentation Should you have questions or require assistance, please visit the Unity UI & TextMesh Pro section of the Unity forum as well as the TextMesh Pro User Forum where you will find additional information, Video Tutorials and FAQ. In the event you are unable to find the information you seek, always feel free to post on the Unity UI & TextMesh Pro section user forum. Online Documentation is also available on TextMesh Pro including Rich Text tags, Shaders, Scripting API and more."
  },
  "Library/PackageCache/com.unity.textmeshpro@3.0.6/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.textmeshpro@3.0.6/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "TextMesh Pro copyright © 2021 Unity Technologies ApS Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog All notable changes to this package will be documented in this file. The format is based on Keep a Changelog [1.7.6] - 2023-10-05 Fixed Fixed issue where a warning would be logged in the console for TrackAsset (TB-229). Fixed issue where changing the name of a group track was not undoable (TB-218). Fixed performance regression when rebuilding the playable graph. [1.7.5] - 2023-06-15 Fixed Fixed issue where exceptions were thrown when different ControlTracks are referencing the same TimelineAsset (IN-21163). The Text Track sample has been updated to use the com.unity.ugui package. Removed usage of deprecated API: UnityEditor.MemoryProfiler [1.7.4] - 2023-03-08 Fixed Fixed issue where previewing the Timeline would create prefab property modifications [1.7.3] - 2023-01-31 Fixed Fixed issue where modifying curves on an animation clip did not trigger an evaluation of the graph when the Timeline Window is hidden. (TB-117) [1.7.2] - 2022-09-12 Fixed Fixed an issue where menu items related to track, marker and clip types in contextual menus would be in arbitrary order in some versions of Unity. Menu items related to types will now be sorted based on their full names, including the assembly name. Fix post-extrapolation mode change not recalculating previous clip pre-extrapolation time. ([ATL-1291]) Fixed an issue where prefab overrides would be created when keyframing a prefab instance in Timeline. ([TB-108]) Fixed an issue where a warning would be raised when using the undo history to undo multiple timeline interactions([TB-119]) Fixed an issue where in some cases a NullReferenceException would be thrown in the PlayableDirector inspector after a TimelineAsset would be unloaded in the Editor([TB-129]) Fixed an issue with the NoFoldOut attribute drawer, which was behaving incorrectly when used outside of the sample context. ([TB-132]) [1.7.1] - 2022-03-07 Fixed Fixed warnings related to meta files related to missing folders. [1.7.0] - 2022-02-21 Added Added TimelinePlaybackControls Editor API: The Playback controls API lets you drive the Timeline Window playback controls from code. From this API, you can Change the current Time/Frame Query the current Time/Frame Start/Stop playback of the currently shown Timeline Go to First or Last frame Go to previous or next frame. Use it to accelerate your workflow, or build your own workflows on top of Timeline. Changed [Requires Unity 2021.2] Fixed an issue where the last frame of a Timeline was not guaranteed to be executed when the Playable Director had Wrap Mode None. License file header changed from \"Timeline copyright © 2021 Unity Technologies ApS\" to \"Timeline copyright © 2021 Unity Technologies\" Fixed Fixed an issue where unused TrackAssets would be saved in the TimelineAsset file after removing tracks. Fixed an issue where grouped markers at time zero would sometimes disappear after clicking on them (https://issuetracker.unity3d.com/issues/timeline-markers-disappear-when-double-clicking-on-stacked-markers-at-0-frames) Fixed an issue where selecting a prefab in the project view could trigger an exception when parenting the prefab to a prefab sub-object. (1386125) Fixed an issue where duplicated or pasted tracks that were part of group tracks would lose their associated bindings (https://issuetracker.unity3d.com/issues/duplicated-track-groups-lose-their-nester-tracks-game-object-assignments) Fixed an issue where pasting a track after changing scenes would lose PlayableAsset references in clips (https://issuetracker.unity3d.com/issues/animation-tracks-copy-loses-its-properties-when-its-pasted-from-another-scene) Fixed an issue where the Timeline Window play range would not be serialized and persisted. Fixed an issue where clicking on a clip during Play Mode would evaluate the Timeline unnecessarily. (https://issuetracker.unity3d.com/issues/timeline-rebuilds-playable-graph-when-selecting-a-timeline-clip-during-play-mode) Fixed an issue where control clips would behave inconsistently if the clip was set to hold, but the PlayableDirector was set to not extrapolate. (https://issuetracker.unity3d.com/product/unity/issues/guid/1375771) Fixed issue where a warning would appear in 2022.1 regarding AnimationWindowState.SnapMode. [Requires Unity 2021.2] Fixed an issue where the last frame of a Timeline was not guaranteed to be executed when the Playable Director had Wrap Mode None. Fixed an issue where the Timeline Window's UI would not update until the user clicked in the window if the TimelineAsset's file contents were changed on disk, such as during a version control operation 1357110 [1.6.3] - 2021-10-20 Fixed Fixed an issue where the Timeline Window would not work correctly with read-only source controlled files. Fixed an issue where the a MissingReferenceException would be thrown when an IAnimationWindowPreview component previewed by Timeline would be destroyed. (https://issuetracker.unity3d.com/issues/missingreferenceexception-is-thrown-when-using-rigbuilder-inside-a-prefab) Fixed an issue where the \"Match Content\" action would not apply on all selected clips. (1368028) [1.6.2] - 2021-08-05 Fixed Fixed an issue where copy-pasting Timeline Clips that contain Generic Lists of ExposedReferences would cause a NullReferenceException (1332377) [1.6.1] - 2021-06-22 Added ClipDrawOptions.hideScaleIndicator can now be used to disable the clip scale indicator. Added an asterisk to the Timeline Window when the currently edited Timeline Asset is dirty (has unsaved changes). (1024230) Added the IInspectorChangeHandler interface to change what happens when a UI component in the inspector is modified. (1283486) (Unity 2020.2+ only) The Timeline window title displays an asterisk when there are unsaved changes. Double click now toggles the collapsed state of group tracks. A keyboard shortcut can now be mapped to expand or collapse group tracks. Added displayClipName property to ClipDrawOption. Use displayClipName to display (true) or hide (false) the clip name. New API added to TimelineEditorWindow: TimelineNavigator. Enables navigation between timelines and nested timelines through code for automation purposes. Gives access to Timeline window breadcrumbs. (Unity 2021.2+ only) Added Framelocked preview option in Timeline preferences. Added framerate display with standard framerates. TimelineAsset framerate can be set with a StandardFramerate value. (TimelineAsset.SetStandardFramerate) Changed Removed non-working PlayRange options (Loop/Hold) as both were actually mapping to Loop behaviour and always have been. Timeline settings menu has been modified to use standard framerates in framerate submenu. TimelineAsset.fps is obsolete and is replaced by TimelineAsset.frameRate. TimelineProjectSettings.assetDefaultFramerate is obsolete and is replaced by TimelineProjectSettings.defaultFramerate. Fixed Removed GC allocations in PlayableDirector.duration when a timeline asset is assigned. (1298818) Removed warnings with AnimationWindowState snap mode. (1306205) Fixed issue where the \"Navigate Right\" (default key: Right Arrow ▶) would not behave consistently. The correct order of operations should now always be, in order: expand group, select first track of group, then select first item of the track. Fixed frame display not rounding up correctly. (1333009) Fixed an issue where TimelinePlayable duration would not be initialized if the playable is not created from the PlayableDirector. (1329151) Fixed memory leak in custom playable inspectors. (1332377) Fixed exception when using the Key All Animated shortcut with no Timeline selected. (1334339) Fixed issue where a warning would appear regarding obsolete AnimationWindowState.SnapMode values. [1.5.5] - 2021-04-30 Fixed Fixed an issue in the Curves view where the color indicator was sized incorrectly on high-res displays. (1318782) Fixed a rare issue where keyframes were created for Playable Curves when switching to play mode. (1319124) Fixed an issue where clearing the Unity selection did not refresh the Timeline window. (1320260) Fixed an issue with IAnimationWindowPreview.StartPreview not getting called for sub timelines. (1322571) Fixed an issue where the curve color identifiers would overlap property names when the Timeline window was resized. (1323591) Fixed a regression where changes made to clip curves would not be processed until another modification caused a graph rebuild. Fixed compilation issue on 2020.1 due to incorrect version checks. Fixed issue where text labels were incorrectly displayed when the mouse pointer was located above a clip. [1.5.4] - 2021-03-10 Fixed Fixed issue where the horizontal scrollbar could not be moved or resized. [1.5.3] - 2021-03-05 Changed Disabled edition of Track Asset Inspector Script field as it could break Timeline Assets. Fixed Fixed issue where the timeline header track would automatically open during a drag and drop operation. (1305436) Fixed a rare issue where some broken tracks could not be removed. (1305388) Fixed rare issue where the time field could not be edited after opening a timeline. (1312198) Fixed cosmetic issue where the duration marker was drawn over the scroll bar. Fixed issue where times without a decimal separator (. or , depending on locale) would not be interpreted correctly by the time field. (1315605) Fixed issue where a selection rectangle could not be made when started inside a track. (1315840) Performing Undo/Redo will not affect Timeline window selection when the window is locked. (Selecting sub-timelines can still be undone). (1313515) Fixed an issue where text would be clipped in the track header binding. (1302401) Fixed issue where clicking in the Timeline window while there is no active timeline would throw an exception. [1.5.2] - 2021-01-08 Added During recording, there are new ways to key animated properties: A new Inspector context menu has been added (Key All Animated) that sets a key to all currently animated properties. It is possible to make a multi-selection of tracks to set a keyframe to all currently animated properties. If no track is selected, all recording tracks are keyed. If properties are selected in the curve editor, only those properties are keyed. TimelineEditor.GetWindow and TimelineEditor.GetOrCreateWindow to get the current Timeline window or create a Timeline window. TimelineEditorWindow.SetCurrentTimeline to change which timeline asset is opened in the Timeline window. TimelineEditorWindow.lock to lock or unlock the Timeline window. TrackExtensions.GetCollapsed, TrackExtensions.SetCollapsed, TrackExtensions.IsVisibleRecursive to get and change the visibility state of a track. AnimationTrackExtensions.IsRecording, AnimationTrackExtensions.SetRecording, AnimationTrackExtensions.SupportsRecording to get or change the recording state of an Animation track. Added two methods in TrackEditor to control how an object is bound to a track: IsBindingAssignableFrom and GetBindingFrom. Added Japanese translation. The Timeline window will automatically rebuild the graph when a notifications's properties are changed. The Timeline window will be automatically refreshed when a marker's properties are changed. Added TimelineEditor.GetInspectedTimeFromMasterTime and TimelineEditor.GetMasterTimeFromInspectedTime to convert time from master to inspected timeline and vice versa when using sub-timelines. Added API to improve how to get/set a TimelineClip's parent track: TimelineClip.GetParentTrack (replaces obsolete property getter) ItemsUtils.SetParentTrack (extension method thar replaces obsolete property setter) Added a new Seconds time display mode and renamed previous Seconds mode to Timecode. TimelinePreferences.timeFormat field, UnityEditor.Timeline.TimeFormat enum. Added API for the user to clip to the track area: API: Relevant member to MarkerOverlayRegion, API: MarkerOverlayRegion.trackRegion, API: MarkerOverlayRegion constructor. Added Gameplay sequence sample. This sample demonstrates how Timeline can be used to create a small in-game moment, using built-in tracks. Added Customization sample. This sample demonstrates how to create custom tracks, clips, markers and actions. Changed The binding field on a track header will change its background color when dragging a valid object on it. Timeline marker track is now selectable. TimelineClip property parentTrack is now obsolete. TimelinePreferences.timeUnitInFrames is now obsolete. Fixed Fixed a bug affecting the conversion between seconds and frames in the inspector. Fixed issue where KeyAllAnimated was available when right-clicking on markers and tracks that were not in record mode. (1270304) Fixed issue where the mouse cursor would stay stuck to a resize icon when resizing the track header. (1076031) Fixed case where an animation event at time 0 would not fire on a timeline loop. (1184106) Fixed issue where Timeline objects (ie. TrackAsset, ControlTrack, SignalAsset, etc.) would have incorrect links to the documentation pages. Available starting from Unity 2021.1. (1082941) Fixed multiple issues related to blends Fix display of blends when clips have ease-in/ease-out (1178066) Fix clip disappearing when dragging it from left to right completely inside another clip. Fix select and drag clip discarding foreground display rule of selected clip after releasing the drag. Fix fully blended clips selection not available. (1289912) Fixed issue where the clip display would flicker when moving two clips that are completely overlapped. (1085679) The Timeline window will no longer revert to editing only the asset if the user uses the Timeline selector to pick a game object and switches focus. (1291455) Create button on timeline panel no longer defaults to an invalid path. (1289923) Fixed issue where Timeline's bindings field would loses names and bindings when selecting clips. (1293941) Make Timeline's duration result displayed in the Inspector, when switching from duration mode: Based On Clips to Fixed Length, closer to the actual duration. (1156920) Copy/Paste of clips in the Timeline Window will no longer paste clips at an invalid time in mix-mode. (1289925) [1.4.5] - 2020-11-19 Fixed Fixed issue where changing a clip's extrapolation values would clear the current clip selection. (936046) Fixed multiple issues related to the curves view: Fixed curve removal not functioning with PlayableAssets (clips & tracks curves). (1231002) Fixed inconsistent icon display on curves. Fixed incorrect ordering of properties. Properties now have a object/type/property ordering. Fixed unnecessary grouping of fields. Changed context menu from Remove Properties to Remove Curves to better reflect the change in functionality between curves for GameObjects and curves for PlayableAssets. Fixed behaviour where removing a single field in a Position, Rotation or Scale group would remove the entire group. Fixed case where pausing in Playmode and switching the active director in editor could pause the director. (1263707) Material properties are now displayed by their shader name in the curves view when possible. (1115961) Fixed issue where a signal could be pasted on a track that doesn't support notifications. (1283763) Fixed issue where a clip could be paseted on an incompatible track. (1283763) Fixed errors when leaving prefab mode when a timeline is opened. (1280331) No preview will be shown when the PlayableDirector is disabled. (1286198) Fixed issue where an infinite clip's Foot Ik property was not visible in the Inspector when selecting its track. (1279824) Fixed issue where child particle systems were not controlled correctly when they are not subemitters. (1212943) Fixed inconsistent recording behaviour on audio tracks and PlayableAssets. Default values are changed when a value is not recorded, and the key added/updated when a value is already animated. (1283453) Fixed issue where the curves view for tracks and PlayableAssets would not update when changed externally (such as from the Animation window). Fixed Add Key/Remove Key context menus not being properly enabled in some cases when using tracks and PlayableAssets. Fixed simulation of subemitters when scrubbing a timeline. (1142781) Fixed choppy playback of particles with a large fixed time step. (1262234) [1.4.4] - 2020-10-09 Fixed Disable drag and drop of Signal asset on Control Track. (1222760) Fixed system locale causing issues when keying float values on custom clips. (1190877) Fixed issue where recording to a clip would place keys on the frame. (1274892) Fixed keyboard clip selection from locked tracks. (1233612) Fixed issue where the Timeline window would stay locked even when no timeline asset is shown. (1278598) Fixed issue where invoking SelectLeft or SelectRight shortcuts on a group track, the group would not collapse or expand. (1279379) Fixed Blend Curve Editor from the clip's inspector that was not responding correctly to undo and redo commands. (978673) Fixed issue where the Frame All action would not frame keys outside of clips when the curve display is collapsed. (1273725, #295) Scrolling the horizontal scrollbar of the timeline to the right edge will no longer prevent the user from dragging left again. (1127199, #301) Splitting a clip with an ease in or out value now ensures ease duration stays on correct side of split. (1279350) Fixed delay when zooming in after reaching Timeline window's maximum and then zooming back. (1214228) Prevent creation of presets with Group Tracks. (1281056) Fixed issue where markers placed on top of clips could not be selected. (1284807, #314) Fixed issue where multiple markers placed on top of each other could not be selected. (1284801, #314) [1.4.3] - 2020-08-26 Fixed Fixed incorrect selection when clicking on a clip's blend. (1178052) Fixed issue where an exception was thrown when drawing an Audio clip's waveform when that clip wasn't in the AssetDatabase. (1268868) When choosing Add Signal Emitter from Signal Asset, closing the Object Selector window will not add an empty Signal Emitter. (1261553) Fixed issue where an error would appear when editing keys in the Animation window if the Timeline window is opened. (1269829) Fixed issue where the Frame All operation would continually increase the zoom value when only empty tracks are added to the timeline (1273540). [1.4.2] - 2020-08-04 Fixed Fixed double-click not opening the AnimationWindow on clips with animated parameters. (1262950) Fixed issue where the Timeline window would rebuild its Playable Graph every time an AnimationClip would be added, changed or deserialized. (1265314, 1267055) [1.4.1] - 2020-07-15 Fixed Fixed IndexOutOfRangeException exception being thrown when editing inspector curves. (1259902) Fixed IndexOutOfRangeException exception being thrown when the New Signal dialog replaces an existing signal. (1241170) Fixed signal state being reset on paused timelines. (1257208) Fixed nested custom types not updating animation values in the inspector. (1239893) Fixed AnimationTracks SceneOffset mode incorrectly overriding root transform on tracks without root transform in editor. (1237704) The DisplayName attribute is now supported when used with TrackAssets. (1253397) Fixed NullReference exception being thrown when clicking on the Scene Preview checkbox if the Timeline window was closed. (1261543) [1.4.0] - 2020-06-26 Added Added ClipCaps.AutoScale to automatically change the speed multiplier value when the clip is trimmed in the Timeline window. Added a DeleteClip method in TrackAsset. Added dependency on Animation, Audio, Director and Particle System modules. (1229825) Added an option in TimelineAsset.EditorSettings to disable scene preview. Added base classes to define custom actions: TimelineAction TrackAction ClipAction MarkerAction Added the following attributes that can be used with action classes: ApplyDefaultUndo to automatically manage undo operations. ActiveInMode to control in which Timeline mode the action is valid. MenuEntry to add the action to the context menu. TimelineShortcut can be added to a static method to invoke the action with a shortcut. Invoker to invoke actions using Timeline's selection or context. MenuOrder contains menu priority values, to be used with MenuEntry. TimelineModes to specify in which mode an action is valid, to be used with MenuEntry. ActionContext to provide a context to invoke TimelineActions. ActionValidity to specify is an action is valid for a given context. UndoExtension to manage undo operations with common Timeline types. Changed Improved performance with ControlTracks in preview mode for cases where multiple Control Tracks are assigned to the same PlayableDirector. Improved layout and appearance of track header buttons. Reduced icons' file size without any quality loss. A track's binding will be duplicated when pasting or duplicating a track. When creating a new timeline asset, the \"Timeline\" suffix will not be added to the file name twice. ClipCaps.All now includes the new Autoscale feature. To get the previous ClipCaps.All behaviour on clips, use ClipCaps.Looping | ClipCaps.Extrapolation | ClipCaps.ClipIn | ClipCaps.SpeedMultiplier | ClipCaps.Blending Inline curve selection is now synced with the clip's selection. Selecting a curve view property will also select the corresponding curve view. Clicking and holding the Command or Control key on a curve view will deselect it if it was already selected. Improved Timeline window UI performance. Fixed Selecting clips from locked tracks is not allowed anymore when using the playhead's context menu. Inserting gaps in locked tracks is not allowed anymore. When adding an Activation track, the viewport is adjusted to show the new Activation clip. Fixed issue where trimming AnimationClips would also change the speed multiplier. [1.3.4] - 2020-06-09 Fixed Fix a Control Track bug that caused the first frame of an animation to evaluated incorrectly when scrubbing forwards and backwards. (1253485) Fixed memory leak where the most recently played timeline would not get unloaded. (1214752 and 1253974) [1.3.3] - 2020-05-29 Fixed Fixed regression where animation tracks were writing root motion when the animation clip did not contain root transform values (1249355) [1.3.2] - 2020-04-02 Fixed Fixed issue where the clip Inspector's curve preview would close when clicking on the curve. (1228127) Fixed issue where the curves view was not synced between Animation and Timeline windows. (1213937) Fixed issue where play range didn't loop when range ends on the final frame. (1215926) Fixed issue where displaying an array in the curves view generated errors. (1178251) [1.3.1] - 2020-03-13 Fixed Fixed issue where the curves view would flicker when editing multiple keys. (1217326) Fixed issue where adding a keyframe in the curves view at the end of a clip would not place the keyframe at the correct position. (1221337) [1.3.0] - 2020-02-26 Added Inline Curve Properties can be removed. Tracks can be individually resized. Changed Creating a new Timeline will no longer automatically add an Animation Track and an Animator to the target GameObject. Ease-in and ease-out values for clips are no longer restricted to 50% of the clip's duration. The resize handle for inline curves has been moved to the track header area. Reduced the minimum width of the track header area. Trimming the left edge of a clip while pressing the Shift key will change the Speed Multiplier value. Fixed Fixed humanoid characters going to default pose during initial root motion recording. (1174752) Fixed Override Tracks not masking RootTransform when an AvatarMask without the Root Node is applied. (1190600) Fixed preview of Avatar Masks on base level Animation Tracks. (1190600) [1.2.13] - 2020-02-24 Fixed Fixed Performance issue where Control Tracks would resimulate during the tail of a non-looping particle clip. (1216702) Fixed adjacent recording clips highlighting the wrong clip. (1210312) Fixed timescale drawing to only draw visible lines which avoids a hang with very large clips. (1213189) Fixed SignalReceiver.ChangeSignalAtIndex incorrectly throwing exception when multiple entries are set to null. (1210877) Fixed a memory leak with Animation Clips in Edit mode. Fixed issue where changes to a Signal Receiver component in a prefab were reverted. (1210883) Fixed avatar mask reassignment not causing immediate re-evaluation. (1219326) Fixed issues related to recursive control tracks. (1178423) Fixed issue where using the HideInMenu attribute in combination with a class inheriting from Marker would not hide the marker from the Timeline context menus. (1221054) [1.2.12] - 2020-02-21 Fixed Fixed issue where the curves view would change its framing when moving a clip. (1217353) [1.2.11] - 2020-01-22 Fixed Fixed Control Track inspector dropdown not opening. (1208943) Fixed issue where applying the Match content command on subtimeline clip with a newly created subtimeline with no duration makes the clip disappear. (1203662) Fixed issue where the opened timeline is changed to another timeline when switching focus from Unity to a different application. (1087348) Fixed issue where the keys in the inline curves view were incorrectly positioned (1205835) Changed ControlPlayableAsset.searchHierarchy (a.k.a. Control Children) now defaults to false. [1.2.10] - 2019-12-08 Fixed Fixed issue where object selectors on tracks did not show bound objects. (1202853) Fixing inspector blend graph display for animation clips. (1201474) Fixed Timeline Window lock state when restarting Unity and no timeline are selected. (1201405) [1.2.9] - 2019-12-06 Fixed Added missing high-resolution icons for Personal Skin. [1.2.8] - 2019-11-21 Fixed Fixed issue where recording couldn't be turned on for override tracks. (1199389) Fixed overlay bug when panning. (1198348) Fixed Foot IK being applied in Editor when option is disabled. (1197426) Fixed issue where the Animation Track's inline curves were not properly aligned when panning the timeline. (1198364) [1.2.7] - 2019-11-15 Fixed Fixed inline curves to display PlayableBehaviour array properties. (1178251) Fixed clip selection from playhead. (1187495) Fixed recorded clips dirtying the scene on copy/paste. (1181492) [1.2.6] - 2019-10-25 Added Added Timeline manual. [1.2.5] - 2019-10-16 Changed Added tooltips that were missing for Timeline selector and settings buttons. (1152790) Removed Undo menu entry that was added when clicking on the Inline curves button. (1187402) Fixed Fixed issue where recording couldn't be turned off when an object is deactivated. (1187174) Timelines listed in the Timeline selector will now be sorted alphabetically. (1190514) Fixed Insert Frames options from Trackhead context menu not applying to markers. (1187895) Fixed incorrect display when a large number of nested group tracks was added to a Timeline. (1157367) [1.2.4] - 2019-10-03 Changed Properties in the Inline Curve editor will now be listed in the same order as the Animation window. (1184058) Updated the appearance of the Timeline window to conform to the editor's UX redesign Improved the appearance of clip blends. Fixed Adding a PlayableDirector with no Playable Asset will no longer trigger a repaint of the Timeline Window on each frame. (1172707) Fixed issue where a clip's blend selection border was not drawn correctly when there was a previous clip. (1178173) Fixed issue where Animation Events were fired twice when the Playable Director Wrap mode is set to Loop. (1173281) Fixed issue where double-clicking on a Timeline Asset would not open it in the Timeline window. (1182159) Fixed issue where the paste shortcut would not work when copying and pasting between two different timelines. (1184967) Fixed audio stutter when going into playmode. (1167289) Fixed PreviousFrame and NextFrame controls in subtimelines with large offsets. (1175320) Fixed issue where exceptions were thrown when resetting a Signal Receiver component. (1158227) Increased font size of clip labels (1179642) [1.2.3] - 2019-10-03 Fixed Removed unnecessary directories from the package. [1.2.2] - 2019-08-20 Fixed Fixed issue where fields for custom clips were not responding to Add Key commands. (1174416) Fixed issue where a different track's bound GameObject is highlighted when clicking a track's bound GameObject box. (1141836) Fixed issue where a clip locks to the playhead's position when moving it. (1157280) [1.2.1] - 2019-08-01 Fixed Fixed appearance of a selected clip's border. Fixed non-transform properties from AnimationClips not being correctly put into preview mode when the avatar root does not contain the animator component. (1162334) Fixed an issue where the context menu for inline curves keys would not open on MacOS. (1158584) Fixed recording state being incorrect after toggling preview mode (1146551) Fixed copying clips without ExposedReferences causing the scene to dirty (1144469) [1.2.0] - 2019-07-16 Compatible with Unity 2019.3 Added Added ILayerable interface. Implementing this interface on a custom track will enable support for multiple layers, similar to the AnimationTracks override tracks. Added \"Pan\" autoscrolling option in the Timeline window. Enabled rectangle tool for inline curves. Changed Scrolling horizontally with the mouse wheel or trackpad now pans the timeline view horizontally, instead of zooming. Scrolling vertically with the mouse wheel or trackpad on the track headers or on the vertical scroll bar now pans the timeline view vertically, instead of zooming. Fixed Fixed an issue causing info text to overlap when displaying multiple lines (1150863). Fixed duration mode not reverting from \"Fixed Length\" to \"Based On Clips\" properly. (1154034) Fixed playrange markers being drawn over horizontal scrollbar (1156023) Fixed an issue where a hotkey does not autofit all when Marker is present (1158704) Fixed an issue where an exception was thrown when overwriting a Signal Asset through the Signal Emitter inspector. (1152202) Fixed Control Tracks not updating instances when source prefab change. (case 1158592) An exception will be thrown when calling TrackAsset.CreateMarker() with a marker that implements INotification if the track does not support notifications. (1150248) Fixed preview mode being reenabled when warnings change on tracks. (case 1151381) Fixed minimum clip duration to be frame aligned. (case 1156602) Fixed playhead being moved when applying undo while recording.(case 1154802) Fixed warnings about localEulerAnglesRaw when using RectTransform. (case 1151100) Fixed precision error on the duration of infinite tracks. (case 1156723) Fixed issue where two GatherProperties call were made when switching between two PlayableDirectors. (1159036) Fixed issue where inspectors for clips, tracks and markers would get incorrectly displayed when no Timeline Window is opened. (1158242, 1158283) Fixed issue with clip connectors that were incorrectly drawn when the timeline was panned or zoomed. (1141960) Fixed issue where evaluating a Playable Graph inside a Notification Receiver would cause an infinite recursion. (1149930) Fixed Trim and Move operations to ensure playable duration is updated upon completion. (1151894) Fixed options menu icon that was blurry on high-dpi screens. (1154623) Track binding field is now larger. (1153446) Fixed issue where an empty Timeline window would create new objects on each repaint. (1142894) Fixed an issue causing info text to overlap when displaying multiple lines (when trimming + time scaling, for example). (1150863) Fixed duration mode not reverting from \"Fixed Length\" to \"Based On Clips\" properly. (1154034) Prevented the PlayableGraph from being created twice when playing a timeline in play mode with the Timeline window opened. (1147247) Fixed issue where an exception was thrown when clicking on a SignalEmitter with the Timeline window in asset mode. (1146261) A timeline will now be played correctly when building a player with Mono and Managed Stripping Level set higher than Low. (1133182) The Signal Asset creation dialog will no longer throw exceptions when canceled on macOS. (1141959) Fixed issue where the Emit Signal property on a Signal Emitter would not get saved correctly. (1148709) Fixed issue where a Signal Emitter placed at the start of a timeline would be fired twice. (1149653) Fixed record button state not updating when offset modes are changed. (1142747) Cleared invalid assets from the Timeline Clipboard when going into or out of PlayMode. (1144473) Copying a Control Clip during play mode no longer throws exceptions. (1141581) Going to Play Mode while inspecting a Track Asset will no longer throw exceptions. (1141958) Resizing Timeline's window no longer affects the zoom value. (1147150) Snap relaxing now responds to Command on Mac, instead of Control. (1149144) Clips will no longer randomly disappear when showing or hiding inline curves. (1141661) The global/local time referential button will no longer be shown for a top-level timeline. (1080872) Playhead will not be drawn above the bottom scrollbar anymore. (1134016) Fixed moving a marker on an Infinite Track will keep the track in infinite mode (1141190) Fixed zooming in/out will keep the padding at the beginning of the timeline (1030689) Fixed marker UI is the same color and size on infinite track (1139370) Fixed Disable the possibility to add Markers to tracks of a Timeline that is ReadOnly (1134463) Fixed wrong context menu being shown when right-clicking a marker (1133592) Fixed creation of override track to work with multiselection (1133592) [1.1.0] - 2019-02-14 Compatible with Unity 2019.2 Added ClipEditor, TrackEditor and MarkerEditor classes users can derive from to control visual appearance of custom timeline clips, tracks and markers using the CustomTimelineEditor attribute. ClipEditor.GetSubTimelines to allow user created clips that support sub-timelines in editor TimelineEditor.selectedClip and TimelineEditor.selectedClips to set and retrieve the currently selected timeline clips IPropertyCollector.AddFromName override that takes a component. Warning icons to SignalEmitters when they do not reference an asset Ability to mute/unmute a Group Track. Mute/Unmute only selected track command added for tracks with multiple layers. Animate-able Properties on Tracks and Clips can now be edited through inline curves. Added loop override on AnimationTrack clips (1140766) ReadOnly/Source Control Lock support for Timeline Scene Changed Control Track display to show a particle system icon when particle systems are being controlled Animate-able Properties for clips are no longer edited using by \"recording\"; they are edited through the inline curves just like tracks. AudioTrack properties can now be animated through inline curves. Changed Marker show/hide to be undoable. Hide will also unselect markers. (1124661) Changed SignalReceivers show their enabled state in the inspector. (1131163) Changed Track Context Menu to show \"Add Signal Emitter\" at the top of the list of Marker commands. (1131166) Moved \"Add Signal Emitter\" and \"Add Signal Emitter From Asset\" commands out of their sub-menu. (1131166) Fixed Fixed markers being drawn outside their pane. (1124381) Fixed non-public tracks not being recognized by the Timeline Editor. (1122803) Fixed keyboard shortcuts for Frame All (default: A) and Frame Selected (default: F) to also apply horizontally (1126623) Fixed recording getting disabled when selecting a different GameObject while the Timeline Window is not locked. (1123119) Fixed time sync between Animation and Timeline windows when clips have non-default timescale or clip-in values. (930909) Fixed animation window link not releasing when deleting the timeline asset. (1127425) Fixed an exception being raised when selecting both a Track marker and a Timeline marker at the same time. (1113006) Fixed the header marker area will so it no longer opens its context menu if it's hidden. (1124351) Fixed Signal emitters to show the Signals list when created on override tracks. (1102913) Fixed a crash on IL2CPP platforms when the VideoPlayer component is not used. (1129572) Fixed Timeline Duration changes in editor not being undoable. (1109279) Fixed Match Offsets commands causing improper animation defaults to be applied. (911678) Fixed Timeline Inspectors leaving EditorGUI.showMixedValue in the wrong state. (1123895) Fixed issue where performing undo after moving items on multiple tracks would not undo some items. (1131071) Fixed cog icon in the Signal Receiver inspector being blurry. (1130320) Fixed Timeline marker track hamburger icon not being centered vertically. (1131112) Fixed detection of signal receivers when track is in a group. (1131811) Fixed exception being thrown when deleting Signal entries. (1131065) Fixed Markers blocking against Clips when moving both Clips and Markers in Ripple mode. (1102594) Fixed NullReferenceException being thrown when muting an empty marker track. (1131106) Fixed SignalEmitter Inspector losing the Receiver UI when it is locked and another object is selected. (1116041) Fixed Marker and Clip appearing to be allowed to move to another track in Ripple mode. (1131123) Fixed issue where the Signal Emitter inspector did not show the Signal Receiver UI when placed on the timeline marker track. (1131811) Fixed Replace mode not drawing clips when moved together with a Marker. (1132605) Fixed inline curves to retain their state when performing undo/redo or keying from the inspector. (1125443) Fixed an issue preventing Timeline from entering preview mode when an Audio Track is present an a full assembly reload is performed. (1132243) Fixed an issue where the Marker context menu would show a superfluous line at the bottom. (1132662) Fixed an issue preventing Timeline asset to be removed from a locked Timeline Window when a new scene is loaded. (1135073) Fixed EaseIn/Out shortcut for clips [1.0.0] - 2019-01-28 Compatible with Unity 2019.1 Added This is the first release of Timeline, as a Package Added API calls to access all AnimationClips used by Timeline. Added support in the runtime API to Animate Properties used by template-style PlayableBehaviours used as Mixers. Added Markers. Markers are abstract types that represent a single point in time. Added Signal Emitters and Signal Assets. Signal Emitters are markers that send a notification, indicated by a SignalAsset, to a GameObject indicating an event has occurred during playback of the Timeline. Added Signal Receiver Components. Signal Receivers are MonoBehaviour that listen for Signals from Timeline and respond by invoking UnityEvents. Added Signal Tracks. Signal Tracks are Timeline Tracks that are used only for Signal Emitters. Fixed Signal Receiver will no longer throw exceptions when its inspector is locked (1114526) Context menu operations will now be applied on all selected tracks (1089820) Clip edit mode clutch keys will not get stuck when holding multiple keys at the same time (1097216) Marker inspector will be disabled when the marker is collapsed (1102860) Clip inspector will no longer throw exceptions when changing values when the inspector is locked (1115984) Fixed appearance of muted tracks (1018643) Fixed multiple issues where clips and markers were selectable when located under the time ruler and the marker header track (1117925, 1102598) A marker aligned with the edge of a clip is now easier to select (1102591) Changed behaviour of the Timeline Window to apply modifications immediately during Playmode (922846, 1111908) PlayableDirector.played event is now called after entering or exiting Playmode (1088918) Undoing a paste track operation in a group will no longer corrupt the timeline (1116052) The correct context menu will now be displayed on the marker header track (1120857) Fixed an issue where a circular reference warning appeared in the Control Clip inspector even if there was no circular reference (1116520) Fixed preview mode when animation clips with root curves are used (case 1116297, case 1116007) Added option to disable foot IK on animation playable assets (case 1115652) Fixed unevaluated animation tracks causing default pose (case 1109118) Fixed drawing of Group Tracks when header is off-screen (case 876340) Fixed drag and drop of objects inside a group being inserted outside (case 1011381, case 1014774)"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "About Timeline Timeline overview Using the Timeline window Creating a Timeline Asset and Timeline instance Recording basic animation with an Infinite clip Converting an Infinite clip to an Animation clip Animating a humanoid Using an Animation Override track and Avatar masking Nesting Timeline instances Timeline window Timeline Preview and Timeline Selector Timeline Playback Controls Track List and Track Headers Adding Tracks Selecting Tracks Duplicating Tracks Deleting Tracks Locking Tracks Muting Tracks Reordering Tracks and Rendering Priority Using Track Groups Collapsing and Expanding Track Groups Locking Track groups Clip Edit modes and the Clips view Panning and Zooming the Clips View Adding Clips Inserting Clips Selecting Clips Positioning Clips Tiling Clips Duplicating Clips Trimming Clips Splitting Clips Resetting Clips Changing Clip Play Speed Setting Gap Extrapolation Easing-in and Easing-out Clips Blending Clips Matching clip offsets Curves View Hiding and Showing Curves Navigating the Curves View Selecting Keys Adding Keys Editing Keys Changing Interpolation and Shape Deleting Keys Timeline Settings Timeline Inspector Setting Timeline Properties Setting Track Properties Activation Track Properties Animation Track Properties Setting Clip Properties Activation Clip Properties Animation Clip Common Properties Animation Clip Playable Asset Properties Audio Clip Properties Control Clip Common Properties Control Clip Playable Asset Properties Playable Director Component Samples Annotation marker Video track Time dilation track Tween track Text track Defining custom USS styles Timeline Glossary"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_about.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_about.html",
    "title": "Clip Edit modes and the Clips view | mmo-rpg-unity",
    "keywords": "Clip Edit modes and the Clips view Use the Clips view to add, position, and manipulate clips on each track in the Track list. The selected Clip Edit mode determines how clips interact when you add, move, or delete them. The Clip Edit modes (green) and the Clips view (red) Clips and the Clips view In the Clips view, each clip has a colored accent line that identifies the type of clip: Activation clips are green. Animation clips are blue. Audio clips are orange. Control clips are turquoise. Playable clips are white. A clip based on data, such as an Animation clip or an Audio clip, displays arrows that indicate when the clip has been trimmed to exclude part of its source animation, waveform, or other data. For example, if an Animation clip uses only part of its full key animation, white arrows indicate that key animation exists before the start or after the end of the clip. Small arrows (circled) indicate that data exists before the start or after the end of the area defined by the clip To resize a clip and view its hidden data, either right-click the clip and select Match Content from the context menu, or select the clip and modify its clip timing properties in the Inspector window. When you resize a clip, the selected Clip Edit mode determines how the surrounding clips are affected. Clip Edit modes Select a Clip Edit mode to choose how clips are added, positioned, and trimmed within the Clips view, or when modifying clip timing properties in the Inspector window. There are three Clip Edit modes that affect most clip editing features: Mix mode (default), Ripple mode, and Replace mode. Clip Edit modes are Mix (default and selected), Ripple, and Replace mode You can also temporarily switch between Clip Edit modes. This is useful if, for example, you want to temporarily use Ripple mode to offset the content of a track while you position clips. To temporarily switch between Clip Edit modes, hold down the following keyboard keys: Hold 1 to temporarily switch to Mix mode. Hold 2 to temporarily switch to Ripple mode. Hold 3 to temporarily switch to Replace mode. Mix mode Use Mix mode to add, position, and trim clips without moving or replacing adjacent clips. Mix mode creates blends between intersecting clips. Mix mode is the default Clip Edit mode. Timeline window with Mix mode as the selected Clip Edit mode. The position cursor (circled) indicates where you drag to position the clip. In Mix mode, when you hover over a selected clip in the Clips view, the cursor changes to indicate the action that you can perform. The action depends on the part of the clip that you hover over: When you hover over the start of a selected clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the start of the clip. When you hover over the middle of a selected clip, the cursor changes to a position cursor and indicates the area to drag to position the clip. When you hover over the end of a selected clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the end of the clip. In Mix mode, if you drag to trim or position a clip and it intersects another clip, the cursor changes to a white arrow that points towards the blend being created. There are three possible cursors depending on whether the blend is created at the beginning of the clip, at the end of the clip, or at both the beginning and end of the clip. The white arrow cursor indicates that dragging Clip 2A to the right creates a blend, at the end of the clip, between Clip 2A and Clip 2B. Ripple mode Use Ripple mode to add, position, and trim a clip while affecting the subsequent clips on the same track. Positioning or trimming clips in Ripple mode preserves the gaps between subsequent clips. Timeline window with Ripple mode as the selected Clip Edit mode. The position cursor (circled) indicates where you drag to position the clip. In Ripple mode, when you hover over a selected clip in the Clips view, the cursor changes to indicate the action that you can perform. The actions and areas are similar to Mix mode: When you hover over the start of a selected clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the clip relative to its start. When you hover over the middle of a clip, the cursor changes to a position cursor and indicates the area to drag to position the clip. When you hover over the end of a clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the clip relative to its end. In Ripple mode, when you click and drag to trim or position a clip, the cursor switches to a yellow arrow that points towards the affected clips and gaps. A yellow line indicates the ripple point. When you drag to trim a clip, dragging left and right changes the duration of the selected clip and repositions subsequent clips and gaps after the ripple point. For example, the yellow arrow cursor indicates that trimming the start of Clip 2A in Ripple mode changes the clip duration and affects the clips and gaps after the ripple point: Clip 2B and Clip 2C.] Replace mode Use Replace mode to add, position, and trim a clip while cutting or replacing intersecting clips. Timeline window with Replace mode as the selected Clip Edit mode. The position cursor (circled) indicates where you drag to position the clip. In Replace mode, when you hover over a selected clip in the Clips view, the cursor changes to indicate the action that you can perform. The actions and areas are similar to Mix mode: When you hover over the start of a selected clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the clip relative to its start. When you hover over the middle of a clip, the cursor changes to a position cursor and indicates the area to drag to position the clip. When you hover over the end of a clip, the cursor changes to a trim cursor. The trim cursor indicates the area to drag to trim the clip relative to its end. In Replace mode, when you drag to position a clip, the clip becomes translucent so that you can view overlapping clips. If the clip being positioned overlaps other clips, the cursor changes to a red arrow and red replacement lines indicate where each overlap occurs. Releasing the clip cuts the underlying clip at each red overlap. For example, the red arrow cursor indicates that dragging Clip 2A to the right overlaps Clip 2B. Releasing the clip cuts Clip 2B at the point where the overlap occurs. In Replace mode, trimming a clip is similar to positioning a clip. When you drag to trim a clip and it intersects another clip, the cursor changes to a red arrow and a red replacement line indicates where the overlap occurs. Releasing the trim cuts the intersecting clip at the red replacement line."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_add.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_add.html",
    "title": "Adding clips | mmo-rpg-unity",
    "keywords": "Adding clips The Timeline window supports different methods of adding clips to tracks, depending on the type of track, where you click, and whether a clip or track is already selected. The quickest method to add a clip is to right-click on an empty area within a track and select the appropriate Add option from the context menu. Depending on the track, the options for adding a clip change. Context menu for adding an Activation clip. There are other ways to add clips: Select a clip option from the Track menu in the Track Header to add a clip at the location of the Timeline Playhead. Drag an animation Source Asset from the Project window to an empty area in the Timeline window to automatically create an Animation track and add an Animation clip. Drag an animation Source Asset from the Project window to an existing track in the Timeline window to add an Animation clip to the same track. Drag an audio Source Asset from the Project window to an empty area in the Timeline window to automatically create an Audio track and add an Audio clip. Drag a GameObject with a PlayableDirector component to create a nested Timeline instance. This automatically creates a Control track and adds a Control clip for the nested Timeline instance. Drag a Prefab from the Project window to an empty area in the Timeline window to add a Prefab instance to your Timeline instance. This automatically creates a Control track and adds a Control clip for the Prefab instance. Drag a GameObject with a Particle component to add a particle effect to your Timeline instance. This automatically creates a Control track and adds a Control clip for the duration of the Particle effect. When you add a clip, the selected Clip Edit mode determines how the added clip interacts with surrounding clips. For example, if you add an Animation clip or an Audio clip in Mix mode and the added clip intersects a clip on the same track, Timeline creates a blend."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_blend.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_blend.html",
    "title": "Blending clips | mmo-rpg-unity",
    "keywords": "Blending clips Blend two clips on the same track to create a smooth transition between two Animation clips, two Audio clips, or two Playable clips. To blend two clips, select the Mix Clip Edit mode and position or trim one clip until it overlaps an adjacent clip. In a blend, the first clip is referred to as the outgoing clip and the second clip is referred to as the incoming clip. The area where the outgoing clip transitions to the incoming clip is referred to as the blend area. The blend area sets the duration of the transition. The blend area shows the transition between the outgoing clip and incoming clip Although the Clips view represents a blend area as a single linear curve, the transition between clips is actually comprised of two blend curves. The blend curve for the outgoing clip is referred to as the Blend Out curve. The blend curve for the incoming clip is referred to as the Blend In curve. By default, each blend curve is automatically set to an ease-in and ease-out curve. Use Blend Curves to customize the blend area Use the Blend Curves in the Inspector window to change the shape for either the Blend In or Blend Out curve of the selected clip. However, the Inspector window only allows you to edit the properties of one clip at a time. You cannot simultaneously customize both blend curves from the same blend area. To customize the Blend Curves for the transition between two clips: Select the outgoing clip to customize its Blend Out curve (labelled Out). Select the incoming clip to customize its Blend In curve (labelled In). To customize either the Blend Out curve or Blend In curve, use the drop-down menu to switch from Auto to Manual. With Manual selected, the Inspector window shows a preview of the blend curve. Click the curve preview to open the Curve Editor below the Inspector window. Select Manual and click the curve preview to open the Curve Editor Use the Curve Editor to customize the shape of the blend curve. By default, the blend curve includes a key at the beginning of the curve and a key at the end of the curve. The Curve Editor provides the following different methods of modifying the blend curve: Select the key at the start or end of the blend curve and use the tangent handles to adjust the interpolation between keys. Add additional keys to change the shape of the blend curve by adding more interpolation points. Adding keys in the Curve Editor is the same as adding keys in the Curves view. Right-click a key to delete or edit the key. Editing keys in the Curve Editor is the same as editing keys in the Curves view. Note that you cannot delete the first and last keys. Select a shape template from the bottom of the Curve Editor. The Curve Editor also includes shape templates based on whether you are modifying the Blend In curve or the Blend Out curve. Select a shape template to change the blend curve to the selected shape template."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_dup.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_dup.html",
    "title": "Duplicating clips | mmo-rpg-unity",
    "keywords": "Duplicating clips There are many ways to duplicate clips in the Clips view: Select a clip or multiple clips. Right-click in the Clips view and select Duplicate from the context menu. Select a clip or multiple clips. Hold Command/Control and press D. Right-click an unselected clip and choose Duplicate from the context menu. Duplicating clips copies each selected clip and places the duplicates after the last clip on the same track. If you duplicate clips used in a blend or clips separated by a gap, the blend or gap is also duplicated. If you duplicate an Animation clip that uses a recorded clip as its Source Asset, the recorded clip is also duplicated. The duplicate of the recorded clip only appears in your Project after you save the Scene or Project. For example, the following images demonstrates what happens if you duplicate an Animation clip named \"Clip 2B\" that uses the recorded clip named \"Recorded (3)\". Select the\"Clip 2B\", hold Command/Control and press D to duplicate A duplicate Animation clip is placed at the end of the same track. The recorded clip associated with \"Clip 2B\" is also duplicated. The new \"Recorded (6)\" recorded clip appears in the Project window after you save the Scene or Project"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_ease.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_ease.html",
    "title": "Easing-in and easing-out clips | mmo-rpg-unity",
    "keywords": "Easing-in and easing-out clips Ease-in and ease-out a clip to create a smooth transition between a clip and its surrounding gaps. To create an ease-in or ease-out transition, select a clip and, in the Inspector window, set either the Ease In Duration or the Ease Out Duration. Use Ease In Duration and Ease Out Duration to smoothly transition into and out of the selected clip. Ease-in and ease-out transitions create different effects, depending on the track: On an Animation track or an Animation Override track, ease-in to an Animation clip to create a smooth transition between the animation in the gap before the clip and the Animation clip. Ease-out of an Animation clip to create a smooth transition between the Animation clip and the animation in the gap after the clip. For information on the factors that determine what animation occurs in the gap before and after an Animation clip, see Setting gap extrapolation. On an Audio track, ease-in to an Audio clip to fade in the volume of the audio waveform. Ease-out of an Audio clip to fade out the volume of the audio waveform specified by the Audio clip. On a Playable track, ease-In to a Playable clip to fade in the effect or script in the Playable clip. Ease-out of a Playable clip to fade out the effect or script in the Playable clip. Ease-in and ease-out an Animation clip to transition between its animation and its gaps. Timeline represents ease-in and ease-out transitions as a linear curve. Although the Clips view represents an ease-in or ease-out transition as a single linear curve, every ease-in or ease-out transition is actually set to a gradually easing-in or easing-out curve by default. To change the shape of either the ease-in curve (labelled In) or the ease-out (labelled Out) curve, use the Blend Curves in the Inspector window. Use the Blend Curves to customize ease-in or ease-out transitions Note that the Blend Curves might affect the blend area used for blending between two clips. The Ease In Duration and Ease Out Duration properties indicate whether the Blend Curves affect an ease-in or ease-out transition, or a blend. For example, If the Ease Out Duration is editable, then the Blend Out curve (labelled Out) affects the curve used by an ease-out transition. If the Ease Out Duration is not editable, then the Blend Out curve (labelled Out) affects the outgoing clip in a blend between two clips. Ease Out Duration is not editable, therefore the Out curve affects the blend area between two clips To customize either the ease-in or ease-out transition, use the drop-down menu to switch from Auto to Manual. With Manual selected, the Inspector window shows a preview of the blend curve. Click the curve preview to open the Curve Editor below the Inspector window. Select Manual and click the preview to open the Curve Editor The Curve Editor is the same editor that is used to customize the shape of the blend curves when blending between clips. When creating an ease-in or an ease-out transition with Animation clips, the Animation clip blends between its gaps and the Animation clip. The following factors affect the values of animated properties in the gaps surrounding an Animation clip: The pre-extrapolate and post-extrapolate settings for the Animation clip and for other Animation clips on the same track. Animation clips on other Animation tracks that are bound to the same GameObject. The position or animation of the GameObject in the Scene, outside the Timeline Asset. Gap extrapolation and easing clips To successfully ease-in or ease-out an Animation clip, gap extrapolation must not be set based on the Animation clip being eased-in or eased-out. Gap extrapolation must either be set to None or set by another Animation clip. For example, the following ease-in transition has no effect because the Pre-Extrapolate for the Victory_Dance clip is set to Hold. This means that the ease-in creates a transition between the first frame of the Animation clip and the rest of the Animation clip. The gap is set to Hold from the Animation clip (circled). The ease-in transition has no effect. To ease-in from the Idle clip, set pre-extrapolate for the Victory_Dance clip to None. The ease-in gap uses the post-extrapolate mode from the Idle clip (circled). Overriding Animation tracks with ease-in and ease-out transitions Use two Animation tracks bound to the same GameObject to create a smooth transition between two Animation clips. For example, if two Animation tracks are bound to the same GameObject and a clip on the second track contains an ease-in transition, the ease-in transition creates a smooth transition between the animation on the previous track and the animation on the second track. Example of using two Animation tracks, bound to the same GameObject, to create smooth transitions between Animation clips. In this example, the Animation clip on the first track is a repeated idle cycle where the humanoid GameObject stands still. The Animation clip in the second track eases-in the Victory_Dance motion and eases-out to return back to the idle cycle To successfully override animation on a previous track, the gap extrapolation for the second track must be set to None so that the animation data in the gap is taken from the previous track bound to the same GameObject. The ease-in and ease-out transitions use this animation data."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_gap_extrap.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_gap_extrap.html",
    "title": "Setting gap extrapolation | mmo-rpg-unity",
    "keywords": "Setting gap extrapolation Gap extrapolation refers to how an Animation track approximates animation data in the gaps before and after an Animation clip. The main purpose for extrapolating animation data in the gaps between Animation clips is to avoid animation anomalies. Depending on the GameObject bound to the Animation track, these anomalies could be a GameObject jumping between two transformations, or a humanoid jumping between different poses. Each Animation clip has two gap extrapolation properties: Pre-Extrapolate, which controls how animation data is approximated in the gap before an Animation clip, and Post-Extrapolate, which controls how animation data extends in the gap after an Animation clip. By default, Timeline sets both extrapolation properties to Hold. This sets the gap before the Animation clip to the animation on the first frame, and the gap after the Animation clip to the animation on the last frame. Each gap \"holds\" the animation at a certain frame. Icons before and after an Animation clip indicate the selected extrapolation modes. Icons indicate the pre-extrapolate and post-extrapolate modes When an Animation track contains a gap between two Animation clips, the Post-Extrapolate property of the left clip sets the gap extrapolation. If the Post-Extrapolate property of the clip to the left of a gap is set to None, the Pre-Extrapolate property of the right clip sets the gap extrapolation. Icons before and after Animation clips indicate whether the extrapolation for a gap is taken from the Post-Extrapolate property of the clip to the left or from the Pre-Extrapolate property of the clip to the right. First track (red box): gap extrapolation from Post-Extrapolate of the left clip. Third track (blue box): gap extrapolation from Pre-Extrapolate of the right clip. To change the Pre-Extrapolate and Post-Extrapolate properties, select the Animation clip and use the Animation Extrapolation properties in the Inspector window. Use Pre-Extrapolate and Post-Extrapolate to set the extrapolation modes for the selected Animation clip The Pre-Extrapolate property is hidden when one of the following is true: The gap before the Animation clip is set by the Post-Extrapolation mode of the previous clip. There is no gap before the Animation clip. Use the Pre-Extrapolation property to set the gap extrapolation of the gap before the selected Animation clip to one of the following options: None: Turns off pre-extrapolation. In the gap before the selected Animation clip, the GameObject uses its transform, pose, or state from the Scene. Select None if, for example, you want to create an ease-in between the motion of a GameObject in the Scene and an Animation clip. See Easing-in and Easing-out Clips for details. Hold (default): In the gap before the selected Animation clip, the GameObject bound to the Animation track uses the values assigned at the start of the Animation clip. Loop: In the gap before the selected Animation clip, the GameObject bound to the Animation track repeats the entire animation as a forward loop: from start to end. To offset the start of the loop, use the Clip In property. Ping Pong: In the gap before the selected Animation clip, the GameObject bound to the Animation track repeats the entire animation forwards, then backwards. Use the Clip In property to offset the start of the loop. Changing the Clip In property affects the start of the loop when looping forward, and the end of the loop when looping backwards. Continue: In the gap before the selected Animation clip, the GameObject bound to the Animation track either holds or loops the animation based on the settings of the Source Asset. For example, if the selected Animation clip uses the motion file \"Recorded(2)\" as its Source Asset and \"Recorded(2)\" is set to Loop, then selecting Continue loops the animation according to the \"Recorded(2)\" Loop Time settings. Use the Post-Extrapolate property to set the gap extrapolation of the gap after the selected Animation clip to one of the following options: None: Turns off post-extrapolation. In the gap after the selected Animation clip, the GameObject uses its transform, pose, or state from the Scene. Selecting None is useful if, for example, you want to create an ease-out between an Animation clip and the motion of a GameObject in the Scene. See Easing-in and Easing-out Clips for details. Hold (default): In the gap after the selected Animation clip, the GameObject bound to the Animation track uses the values assigned at the end of the Animation clip. Loop: In the gap after the selected Animation clip, the GameObject bound to the Animation track repeats the entire animation as a forward loop: from start to end. To offset the start of the loop, use the Clip In property. Ping Pong: In the gap after the selected Animation clip, the GameObject bound to the Animation track repeats the entire animation forwards, then backwards. Use the Clip In property to offset the start of the loop. Changing the Clip In property affects the start of the loop when looping forward, and the end of the loop when looping backwards. Continue: In the gap after the selected Animation clip, the GameObject bound to the Animation track either holds or loops the animation based on the settings of the Source Asset. For example, if the selected Animation clip uses the motion file \"Recorded(2)\" as its Source Asset and \"Recorded(2)\" is set to Loop, then selecting Continue loops the animation according to the \"Recorded(2)\" Loop Time settings."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_insert.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_insert.html",
    "title": "Inserting clips | mmo-rpg-unity",
    "keywords": "Inserting clips The Timeline window supports different methods of inserting clips depending on the type of track, where you click, and whether a clip or track is already selected. In the Timeline window, inserting clips refers to adding and making space for a clip without blending or replacing intersecting clips. To accurately insert a clip, select Ripple mode as the Clip Edit mode, and position the Timeline Playhead to set the insertion point. Select Add From Animation Clip from the Track menu for the track where you want to insert the clip. Accurately insert a clip with the Ripple mode (red circle), the Timeline Playhead (green box), and the Add From Animation Clip in the Track menu In the above example, the Timeline Playhead is the insertion point. You can specify the insertion point using these other methods: Right-click within a gap and add a clip with the context menu. The insertion point is where you right-click. Drag a Source Asset (animation or audio) to a track in the Clips view. The insertion point is where you stop dragging. The location of the insertion point determines where the clip is inserted and how it affects the other clips and gaps on the same track: If the insertion point intersects a clip, the inserted clip is added at the insertion point. The intersected clip, and all subsequent clips and gaps, are rippled after the inserted clip. If the insertion point is within a gap and there is enough space between the insertion point and the next clip, then the inserted clip is added to the gap. The other clips on the track are not affected. If the insertion point is within a gap and the inserted clip overlaps the next clip, the inserted clips is added at the insertion point. The next clip, and all subsequent clips and gaps, are rippled to accommodate the inserted clip. For example, inserting a clip at the Timeline Playhead ripples Clip 1B to accommodate the 36 frame Run clip."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_match.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_match.html",
    "title": "Matching clip offsets | mmo-rpg-unity",
    "keywords": "Matching clip offsets Every Animation clip contains key animation, or motion, that animates the GameObject, or humanoid, bound to the Animation track. When you add an Animation clip to an Animation track, its key animation or motion does not automatically begin where the previous clip ends. The key animation or motion also does not end where the next clip begins. By default, each Animation clip begins at the position and rotation of the GameObject, or humanoid, at the beginning of the Timeline instance. An animation sequence of three Animation clips. For example, three Animation clips create an animation sequence that starts with a clip of a standing humanoid that starts to run, then turns left, and finally comes to a stand still. Each Animation clip begins at the position and rotation of the humanoid at the start of the Timeline instance, indicated by a red arrow in the Scene view below. The three Animation clips, Stand2Run, RunLeft, and Run2Stand, end at the green, blue, and yellow arrows, respectively. For an animation sequence to flow seamlessly between adjacent Animation clips, you must match each Animation clip with its previous clip or next clip. Matching clips adds a position and rotation offset for each Animation clip. The position and rotation offsets are named Clip Transform Offsets and they can be set manually or automatically. The following sections describe how to automatically match two or many Animation clips. Matching two clips To match the clip offsets between two clips, right-click the Animation clip that you want to match. From the context menu, select either Match Offsets to Previous Clip or Match Offsets to Next Clip. Matching an Animation clip with the next clip For example, right-click the middle Animation clip, named \"RunLeft\", and select Match Offsets To Next Clip to match its offsets to the next clip When you are matching offsets for a single Animation clip, you don’t need to select the Animation clip first, but you must right-click the Animation clip that you want to match. For example, if you right-click an Animation clip that is not selected, Timeline matches the clicked clip and ignores the selected Animation clips. The context menu only displays the match options available for the clicked Animation clip. For example, if there is a gap before the clicked Animation clip, only the Match Offsets to Next Clip menu item is available. Matching many clips To match the clip offsets of many clips, select the adjacent Animation clips that you want to match and right-click one of the selected clips. From the context menu, select either Match Offsets to Previous Clip or Match Offsets to Next Clip. Matching many clips with previous clips For example, select the \"RunLeft\" and \"Run2Stand\" clips. Right-click one of the selected clips, and select Match Offsets to Previous Clips, to match the \"RunLeft\" clip with the previous \"Stand2Run\" clip, and to match \"Run2Stand\" with the previous \"RunLeft\" clip."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_pan_zoom.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_pan_zoom.html",
    "title": "Panning and zooming the Clips view | mmo-rpg-unity",
    "keywords": "Panning and zooming the Clips view Use either the keyboard or the zoombar to pan and zoom the contents of the Clips view. There are many ways to pan, zoom, or frame clips in the Clips view with the keyboard: To pan, either middle-drag, or hold Alt and drag. To frame all selected clips, select clips then press F. To frame all clips, press A. To zoom horizontally, move the scroll-wheel. To zoom vertically, hold Command/Control and move the scroll-wheel. When you horizontally zoom the Clips view, the zoombar indicates the level of zoom. The zoombar is the horizontal bar at the bottom of the Clips view that zooms and pans the section of the Timeline instance or Timeline Asset that is shown in the Clips view. The zoombar (inside the red box) and the zoombar handles (shown by the green arrows). The zoombar thumb is the area between the two zoombar handles. There are many ways to pan and zoom with the zoombar: To pan, drag the zoombar thumb left or right. To jump to a section of the Timeline instance or Timeline Asset, click on an empty area of the scrollbar, on either side of the zoombar. To zoom in or zoom out, drag either zoombar handle. Dragging a zoombar handle also resizes the zoombar thumb. On the zoombar thumb, a white line indicates the location of the Timeline Playhead. Use this line to see where the Timeline Playhead is in relation to the zoom level and the part of the Timeline instance shown in the Clips view."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_position.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_position.html",
    "title": "Positioning clips | mmo-rpg-unity",
    "keywords": "Positioning clips To position a clip, select Mix mode as the Clip Edit mode. Select a clip and hover over the middle of the clip. When the cursor changes to a position cursor, click and drag the clip to its new position. While dragging, black lines indicate the selection of clips being positioned. The Timeline ruler shows the start time and end time of the selected clips being positioned. Select Mix mode (circled). Select and drag to position a clip. By default, when you drag to position clips, both Snap to Frame and Edge Snap are enabled in the Clips view. You can change these snap settings in the Timeline Settings menu. You can also move a clip to another track of the same type. Drag the clip off of its current track and a white ghost indicates where the clip will be moved. If you drag a clip to an area where the clip cannot be placed, the ghost changes to red indicating that you cannot release the clip in that area. For example, you cannot drag a clip where there is no track. The ghost of the selection being moved is drawn in red if you attempt to move a clip to an invalid area You can position a selection of clips on the same track, or on different tracks. You are not limited to positioning one clip at a time. The same edge snapping rules and invalid area restrictions apply when positioning a selection of clips on many tracks. Positioning clips with the Inspector window You can use the Inspector window to position clips. To position a clip with the Inspector window, select a clip and use the Clip Timing properties in the Inspector window to change its Start property. Clip Timing properties for an Animation clip The effect that changing the Start value has on adjacent clips depends on the selected Clip Edit mode. Positioning clips in different Clip Edit modes You are not restricted to positioning clips with Mix mode as the selected Clip Edit mode. You can also position clips in Ripple mode and in Replace mode. The difference is the effect each Clip Edit mode has on adjacent clips on the tracks where clips are being moved: Positioning clips in Mix mode creates blends between intersecting clips. Positioning clips in Ripple mode ripples subsequent clips, respecting the gaps between clips. Positioning clips in Replace mode cuts or replaces intersecting clips. Positioning clips with the Timeline Playhead You can position clips by inserting frames at the position of the Timeline Playhead. To do this, move the Timeline Playhead to where you want to insert frames. To insert frames starting at frame 40, move the Timeline Playhead to frame 40 Right-click the Timeline Playhead on the Timeline ruler above the Clips view, choose Insert > Frame, and a number of frames. To insert 25 frames, right-click the Timeline Playhead and select Insert > Frame, then 25 Frames This inserts frames in the Timeline Asset at the position of the Timeline Playhead. Inserting frames only repositions the clips that start after the position of the Timeline Playhead. Only the clips that start after the Timeline Playhead are moved. In this example, inserting 25 frames at frame 40 affects Clip 1B, Clip 2B, and Clip 2C."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_reset.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_reset.html",
    "title": "Resetting clips | mmo-rpg-unity",
    "keywords": "Resetting clips You can reset the duration and speed of a clip. Resetting a clip does not reset the following properties: Start Ease In Duration and Ease Out Duration Animation Extrapolation settings Blend Curves To reset a clip, right-click the clip and select Editing from the context menu. Then, select Reset Duration, Reset Speed, or Reset All. Depending on the reset option you select, resetting a clip does the following: Option: Description: Reset Duration Resets the Duration and the Clip In. Reset Speed Resets the Speed Multiplier. Reset All Resets the Duration, Clip In, and Speed Multiplier. If resetting a clip results in two clips overlapping each other, Timeline creates a blend for the overlap, regardless of the selected Clip Edit mode."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_select.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_select.html",
    "title": "Selecting clips | mmo-rpg-unity",
    "keywords": "Selecting clips Click to select a single clip. The Clips view displays the selected clip with a white border, including its blends. Selecting a clip deselects all other tracks or clips. Selecting a clip also shows its properties in the Inspector window. The clip properties change depending on the type of clip and whether multiple clips are selected. See Setting Clip properties for details. Hold Shift and click to select contiguous clips vertically on different tracks or horizontally on the same track. For example, to select three contiguous clips on the same track, select the first clip, then hold Shift and click the third clip. All three clips are selected. Click to select the first clip Shift-click the third clip to select contiguous clips on the same track Hold Command/Control and click to select discontiguous clips. Hold Command/Control and click a selected clip to deselect it. Click and drag on an empty area in the Clips view to draw a selection rectangle. This selects all clips inside the rectangle, including the clips that intersect the rectangle. Hold down Shift and draw a selection rectangle to add clips to the current selection. You can also press the Tab key to select clips. The behaviour of the Tab key changes depending on the current selection: If a track is selected, press Tab to select the first clip on the selected track. If many tracks are selected, press Tab to select the first clip on the first selected track. If a clip is selected, press Tab to select its track. If there are no clips or tracks selected, press Tab to select the first clip on the first track. Use the arrow keys to change the selected clips. The behaviour and results depend on the current selection and which modifier keys you press: If nothing is selected in the Timeline window, press the Tab, Up arrow, or Down arrow key to select the first clip on the first track. If a clip is selected, press the Left arrow key to select the previous clip. If the selected clip is the first clip on a track, the Left arrow key selects the track. If a clip is selected, press the Right arrow key to select the next clip. Press the Up arrow key to select the closest clip on a previous track. Press the Down arrow key to select the closest clip on a next track. Hold Shift and press either the Left arrow key or Right arrow key to add or remove clips from the selection of clips. Whether a clip is added to or removed from the selection of clips is relative to the first selected clip. If you zoom into the Clips view, it pans to show either the start or end of the most recently selected clip. For example, if a selected clip is framed in the Clips view and you press the Right arrow key to select the next clip which is outside the Clips view, the Clips view pans to show the start of the selected clip. You can also select clips with the Timeline Playhead. Right-click the Timeline Playhead and choose a selection option. This selects clips that either start after, start before, end after, end before, or intersect the Timeline Playhead. Clips are selected on all tracks. Right-click the Timeline Playhead and choose Select for more clip selection options"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_speed.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_speed.html",
    "title": "Changing clip play speed | mmo-rpg-unity",
    "keywords": "Changing clip play speed Change the clip play speed to accelerate or decelerate its audio, motion, animation, or particle effect. Changing the clip play speed affects the duration of the clip. You can only change the play speed for Animation clips, Audio clips, and Control clips. To change the clip play speed, first, select the Clip Edit mode to determine how other clips on the same track are affected: If the change in duration results in two clips that overlap each other: Select Mix mode to create a blend. Select Replace mode to cut or remove intersecting clips. Select Ripple mode to reposition the clips that come after the clip being sped up or slowed down. Ripple mode preserves the gaps between clips. Select the clip and set the Speed Multiplier property in the Inspector window. The Speed Multiplier property shows the play speed as a multiplier of the original clip speed, so 1 plays the clip at the same speed as the original clip. Speed Multiplier in the Inspector window For example, to double the play speed of an Animation clip, change the Speed Multiplier to 2. This changes the duration of an 80 frame Animation clip to 40 frames by doubling its play speed. There are other ways to change the play speed of a clip: Right-click the clip and select Editing > Double Speed to halve the clip duration. The clip plays at twice its current speed. A short-dashed line and a multiplication factor indicates an accelerated clip. Doubling the clip speed sets the Speed Multiplier property to double its current value. Right-click the clip and select Editing > Half Speed to double the clip duration. The clip plays at half its current speed. A long-dashed line and multiplication factor indicates a decelerated clip. Halving the clip speed sets the Speed Multiplier property to half its current value. Right-click the clip and select Editing > Reset Speed to reset the clip to its original speed. This is the original duration of the clip. Resetting the clip speed sets the Speed Multiplier property to 1. A short-dashed line and multiplication factor of 2.00x indicates a clip playing at double its original speed"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_split.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_split.html",
    "title": "Splitting clips | mmo-rpg-unity",
    "keywords": "Splitting clips You can split a clip into two identical clips that have different start points, end points, and durations. You can extend the start or end of the clip to include split animation or audio. You can also reset a clip to undo a split and other edits. To split a clip, select the clip, position the playhead where you want to split the clip, and either right-click the clip and select Editing > Split, or press S. Any selected clips that intersect the playhead are split into separate clips. You can position, trim, and edit split clips independently. Select the clips to be split, position the playhead where you want the split to occur, and press S Selected clips are split where each clip intersects the playhead If a split clip is part of a blend, or if the split is performed within a blend, Timeline copies the blend settings to the split clips."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_tile.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_tile.html",
    "title": "Tiling clips | mmo-rpg-unity",
    "keywords": "Tiling clips Tile clips to remove gaps and blends between clips on the same track. Tiling clips is useful if you want each clip to begin exactly where the previous clip ends. If you select multiple clips on multiple tracks, you must select at least two clips on the same track for tiling to have an affect. To tile clips, select at least two clips on the same track. Three clips with gaps and blends are selected Right-click on one of the selected clips and select Tile from the context menu. Timeline positions the selected clips based on the position of the first selected clip. The first selected clip does not move, and the duration of each clip remains the same. Tiling removes gaps and blends between the selected clips"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_trim.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/clp_trim.html",
    "title": "Trimming clips | mmo-rpg-unity",
    "keywords": "Trimming clips Trimming a clip cuts off a portion of the clip at its start or end. To trim a clip, select the Mix mode as the Clip Edit mode, then drag the start or end of the clip. Dragging the start or end of a clip automatically selects the clip, showing its properties in the Inspector window. Use the Clip Timing properties in the Inspector window to set the start, end, duration, and offset (Clip In) of a clip to exact values. Position and trim a clip by adjusting its Start, End, Duration, and Clip In properties in the Inspector window Trimming the start of a clip Trimming an Animation clip or Audio clip after the start of the Source Asset, selects the part of the Source Asset the clip uses. Trimming the start of an Animation clip trims its key animation, relative to the start of the Source Asset Trimming a clip is non-destructive. Trim the clip again to modify its start to include the animation, or the audio waveform, cut off during a previous trim. You can also reset a clip to undo trims or other edits. To trim the start of a clip to a precise time or frame, use the Clip In property in the Inspector window. Changing the Clip In property is similar to the same effect as trimming the start of a clip after the start of its Source Asset. Trimming the end of a clip As with the start of the clip, trimming an Animation clip or Audio clip before the end of the Source Asset, selects the part of the Source Asset the clip uses. Trimming the end of an Animation clip trims its key animation, relative to the end of the Source Asset If you trim the end of an Animation clip or Audio clip past the end of the Source Asset the clip is based on, the extra clip area either holds or loops, depending on the settings of the Source Asset. For example, an Animation clip named \"End Move\" uses the motion file \"Recorded(2)\" as its Source Asset. The motion file \"Recorded(2)\" is set to loop. Trimming the end of the Animation clip past the end of the \"Recorded(2)\" Source Asset fills the extra clip area by looping \"Recorded(2)\". A white animation curve shows the hold or loop. A white animation curve indicates whether the extra clip area holds or loops data, depending on the Source Asset To choose whether the extra clip area holds or loops, select the Source Asset to change its settings in the Inspector window. Depending on the type of Source Asset, different properties control whether the Source Asset holds or loops. If you are unsure which Source Asset is used by a clip, select the clip in the Clips view, right-click and select Find Source Asset from the context menu. This highlights the Source Asset in the Project window. Trimming the end of looping clips The Timeline window provides special trimming options for Animation clips or Audio clips with loops. These special trim options either remove the last partial loop or complete the last partial loop. For example, the Animation clip named run_away is over three times longer than the Source Asset on which it is based. Since the Source Asset is set to loop, the Animation clip loops the Source Asset until the Animation clip ends which results in a partial loop. L1, L2, and L3 signify complete loops. The clip ends partially through the fourth loop, L4. To extend the end of the clip and complete a partial loop, select the clip, right-click and select Editing > Complete Last Loop. To trim the clip at the last complete loop, select the clip, Right-clip and select Editing > Trim Last Loop. The result of select Editing > Complete Last Loop The result of select Editing > Trim Last Loop Trimming with the Timeline Playhead You can also trim a clip based on the location of the playhead. To trim using the playhead, position the playhead within the clip to be trimmed. Right-click the clip and select either Editing > Trim Start or Editing > Trim End. Trim Start trims the start of the clip to the playhead. Trim End trims the end of the clip to the playhead. _Move the Timeline Playhead within the _ Right-click and select Editing > Trim Start to trim the start of the clip to the playhead If you select clips on multiple tracks, Timeline only trims the selected clips that intersect the playhead."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_about.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_about.html",
    "title": "Curves view | mmo-rpg-unity",
    "keywords": "Curves view The Curves view shows the animation curves for Infinite clips, or for Animation clips that were converted from Infinite clips. Use the Curves view for basic animation editing such as adding keys, modifying keys, adjusting tangents, and changing the interpolation between keys. To view animation curves for an Infinite clip, click the Curves icon next to the Track name. To view animation curves for an Animation clip, select the Animation clip and click the Curves icon. The Curves view is similar to Curves mode in the Animation window. The Curves icon (circled) shows and hides the Curves view for the selected clip The Curves icon does not appear for Animation tracks with humanoid animation or imported animation. To view and edit key animation for humanoid or imported Animation clips, right-click an Animation clip and select Edit in Animation Window from the context menu. You can also double-click the Animation clip. The Animation window appears, linked to the Timeline window. When in linked mode, the Animation window shows a Linked icon and the name of the Animation clip being edited. Click the Linked icon to stop editing the Animation clip and to release the Animation window from linked mode. Animation window linked to the Timeline window, indicated by the Linked icon and Animation clip name"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_hide.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_hide.html",
    "title": "Hiding and showing curves | mmo-rpg-unity",
    "keywords": "Hiding and showing curves For the selected Animation clip, the Curves view includes a hierarchical list of the properties with animation curves. Expand, collapse, select, and deselect the properties in this list to filter which animation curves show in the Curves view. For example, to show only the X-axis animation curves for the position of a GameObject, expand Position, select the Position.x property, and then press F to frame the animation curve for the Position.x property. Curves view showing the animation curve for the Position.x property There are many ways to expand, collapse, select, and deselect animation curves: Click the Triangle icon of a parent property to expand and collapse its list of child properties. Hold Shift and click to select contiguous properties. Hold Command/Control and click to select discontiguous properties. Hold Command/Control and click a selected property to deselect it."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_add.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_add.html",
    "title": "Adding keys | mmo-rpg-unity",
    "keywords": "Adding keys The Curves view provides the following methods for adding keys: Right-click on an animation curve and select Add Key. This method adds a key at the location of the right-click. Double-click on an animation curve. This method adds a key at the location of the Double-click."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_del.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_del.html",
    "title": "Deleting keys | mmo-rpg-unity",
    "keywords": "Deleting keys The Curves view provides the following methods for deleting keys: Right-click a key and select Delete Key from the context menu. This method does not affect selected keys. Select a key and either press Delete or right-click and select Delete Key from the context menu."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_edit.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_edit.html",
    "title": "Editing keys | mmo-rpg-unity",
    "keywords": "Editing keys Edit a key to change its time, value, or both. The Curves view provides the following different methods for editing a key: Right-click a key and select Edit from the context menu to enter specific values for time and value. Select a key and press Enter to enter specific values. Select and drag a key to change its time and value. Drag a key vertically, then press Shift to snap the key on the vertical axis. This changes the value of the key, but not its time. Drag a key horizontally, then press Shift to snap the key on the horizontal axis. This changes the time of the key, but not its value."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_interp.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_interp.html",
    "title": "Changing interpolation and shape | mmo-rpg-unity",
    "keywords": "Changing interpolation and shape Every key has one or two tangents that control the interpolation of the animation curve. The term interpolation refers to the estimation of values that determine the shape of the animation curve between two keys. Whether a key has one of two tangents depends on the location of the key on the animation curve. The first key only has a right tangent that controls the interpolation of the animation curve after the key. The last key only has a left tangent that controls the interpolation of the animation curve before the last key. The first key (red) only has a right tangent, and the last key (blue) only has a left tangent All other keys have two tangents where the left tangent controls the interpolation before the key, and the right tangent controls the interpolation after the key. By default, tangents are joined. Dragging one tangent affects the position of both tangents, and the interpolation of the animation curve both before and after the key. Keys that are neither the first key nor last key have joined tangents by default. Dragging either tangent changes the interpolation of the animation curve both before and after the key. Dragging a tangent may also change the interpolation mode of the animation curve. For example, most keys are set to the Clamped Auto interpolation mode which automatically smooths animation curve as it passes through the key. If you drag a tangent of a key set to Clamped Auto, the interpolation mode changes to Free Smooth. The term interpolation mode refers to the interpolation algorithm that determines which shape to use when drawing the animation curve. To view the interpolation mode for a key, select the key and right-click. The context menu shows the interpolation mode. To change the interpolation mode for a key, select the key, right-click and select another interpolation mode. The context menu shows the interpolation mode for the selected key. Use the context menu to change the interpolation mode. Some interpolation modes break the left and right tangents so that you can position them separately. When tangents are broken, you can set a separate interpolation mode for the animation curve before the key and the animation curve after the key. For more details on the different interpolation modes, see Editing Curves. In the Animation window documentation, the interpolation mode is referred to as tangent type."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_sel.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_keys_sel.html",
    "title": "Selecting keys | mmo-rpg-unity",
    "keywords": "Selecting keys Click to select a single key. Selecting a key deselects all other selected keys. The Curves view displays the selected key with its tangents. Click to select a single key. A selected key shows its tangents. To select contiguous keys along the same animation curve, click the first key, then hold Shift and click the last key. Hold Shift and click a key to select contiguous keys There are many ways to select and deselect keys in the Curves view: Hold Command/Control and click to select discontiguous keys. Hold Command/Control and click a selected key to deselect it. Click and drag on an empty spot in the Curves view to draw a selection rectangle. This selects all keys within the rectangle. Hold down Shift while drawing the selection rectangle to add keys to the current selection. Double-click a selected key to select all keys on the same animation curve."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_nav.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/crv_nav.html",
    "title": "Navigating the Curves view | mmo-rpg-unity",
    "keywords": "Navigating the Curves view Use one of the following methods to pan, zoom, resize, or frame the animation curves and keys in the Curves view: To pan, middle-drag, or hold Alt and drag. To zoom vertically, move the scroll-wheel, or hold Alt and right-drag. To zoom horizontally, hold Command/Control and zoom vertically. To resize the Curves view, drag the double line separating the Curves view from the next track in the Track list. To frame only selected animation curves or selected keys, press F. To frame all animation curves or keys, press A. You can also use the Zoombar to pan, zoom, and resize the Clips view."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/grp_hide.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/grp_hide.html",
    "title": "Collapsing and expanding Track groups | mmo-rpg-unity",
    "keywords": "Collapsing and expanding Track groups To collapse the tracks in a Track group, either click the Triangle icon beside the name of the Track group or double-click the Track group. The tracks are collapsed from view in the Timeline window, not muted. To expand the tracks in a Track group, click the Triangle icon or double-click the Track group again. Triangle icon (circled) collapses the tracks in the Game Board Track group. A ghost track visually represents the tracks in the collapsed group. You can also press the Left Arrow key to collapse the tracks in a Track group while the Track group is selected. Press the Right Arrow key to expand the tracks in a Track group. If you press the Right Arrow key with a Track group already selected, the selection switches to the first track in the Track group."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/grp_lock.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/grp_lock.html",
    "title": "Locking Track groups | mmo-rpg-unity",
    "keywords": "Locking Track groups You can also lock a Track group to prevent editing its Track sub-groups, tracks, and clips. This is useful when you have finished animating the content within a Track group and you want to avoid inadvertently modifying its tracks or clips. You cannot edit the tracks or select the clips in a locked Track group. The Lock icon identifies a locked Track group. Selected and locked Track group with Lock icon (red circle) To lock a Track group, right-click on the Track group header and select Lock from the context menu. You can also select a Track group and press L. You can select and lock multiple Track groups. To unlock a Track group, click the Lock icon. You can also select a locked Track group and press L, or right-click and select Unlock from the context menu. Tracks in a Track group maintain their individual locked state when you lock a Track group. This means that if you lock a track and then lock its Track group, when you unlock the Track group, the track remains locked. For example, the MovingPieces Track group has its first track locked and its second track unlocked. If you lock the Track group, both the first and second track are locked. If you unlock the Track group, the first track remains locked and the second track is unlocked because the first track was already locked before the Track group was locked."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/grp_use.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/grp_use.html",
    "title": "Using Track groups | mmo-rpg-unity",
    "keywords": "Using Track groups Use Track groups to organize tracks when you are working with many tracks. For example, a Timeline Asset contains an Animation track and an Audio track that interacts with the same GameObject. To organize these tracks, move them into their own Track group. To add a Track group, click the Add button and select Track Group from the Add menu. You can also right-click an empty area of the Track list and select Track Group from the context menu. A new Track group appears at the bottom of the Track list. Timeline window with Track group added To rename a Track group, click its name and an I-beam cursor appears. Type the new name for the Track group and press Return. To move tracks into a Track group, select one or more tracks and drag over the Track group. The Track group is highlighted. When dragging a selection of tracks, the last selected track type displays beside the cursor. To drop the tracks before a specific track in the Track group, drag until a white insert line indicates the destination. Release the mouse button when the white insert line appears within the Track group Selected tracks are moved to the location of the insert line A Track group can also have any number of Track sub-groups. To add a Track sub-group, either select a Track group and click the Add button in the Track list, or click the Plus icon beside the Track group name, and select Track Sub-Group. You can also use this menu to add tracks directly to a Track group or a Track sub-group. Click the Plus icon to add Track Sub-Groups and tracks to Track groups"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/index.html",
    "title": "About Timeline | mmo-rpg-unity",
    "keywords": "About Timeline Unity's Timeline Use Unity's Timeline to create cinematic content, game-play sequences, audio sequences, and complex particle effects. Each cut-scene, cinematic, or game-play sequence that you create with Unity's Timeline consists of a Timeline Asset and a Timeline instance. The Timeline window creates and modifies Timeline Assets and Timeline instances simultaneously. The Timeline Overview section includes details on the relationship between the Timeline window, Timeline Assets, and Timeline instances. The Using Timeline section shows how to create Timeline Assets and Timeline instances, record basic animation, animate humanoids, and use other Timeline features. The Samples section includes a description of the samples offered by the Timeline package. Installing Timeline Timeline is a Package and is installed through the Packages window in Unity. Consult the Packages window documentation for more information. Technical details Requirements This version of Timeline is compatible with the following versions of the Unity Editor: 2019.1 and later (recommended) Package contents The following table indicates the folder structure of the Timeline package: Location Description <Runtime> Root folder containing the source for the Timeline Runtime. This is the source for what is available in the Player. <Editor> Root folder containing the source for the Timeline Editor used to edit Timeline files inside the Unity Editor. Document revision history Date Reason October 23, 2020 Added documentation for customization samples. October 22, 2020 Added samples section October 10, 2018 Document created. Matches package version 0.0.0"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_about.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_about.html",
    "title": "Timeline properties in the Inspector window | mmo-rpg-unity",
    "keywords": "Timeline properties in the Inspector window The Inspector window displays information about the selected GameObject including all attached components and their properties. This section documents the properties in the Inspector window that appear when you select one or many Timeline Assets, tracks, clips, or a combination. If you select a single Timeline Asset, track, or clip, the Inspector window displays the properties for the selected Asset, track, or clip. For example, if you select an Animation clip, the Inspector window shows the common properties and Playable Asset properties for the selected Animation clip. Inspector window when selecting an Animation clip in the Timeline window If you select multiple Timeline Assets, tracks, or clips, the Inspector window shows two sections: a section with properties that apply to the entire selection, and a section of common properties that apply to each selected object individually. For example, if you select an Audio clip on one track and two Animation clips on another track, the Inspector window includes Multiple Clip Timing properties and Clip Timing properties: Use the Multiple Clip Timing properties to change the Start or End of the selection as a group. For example, if you change the Start to frame 30, the selection of clips start at frame 30. This moves the start of the first clip to frame 30 and the remaining selected clips are placed relative to the first clip, respecting gaps between selected clips. Use the Clip Timing properties to change the common properties for each selected clip. If the selected clips have different values for the same property, the value is represented with a dash (\"-\"). If you change the dash to a value, it sets the value for all selected clips. For example, if you change the Ease In Duration from a dash to 10 frames, the ease in of each selected clip changes to 10 frames. Inspector window when selecting multiple clips, on multiple tracks, in the Timeline window If your selection does not have common properties, the Inspector window prompts you to narrow the selection. For example, if you select an Animation track and an Audio clip in the Timeline window, you are prompted to narrow the selection: The message in the Inspector window when the selection does not have common properties"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp.html",
    "title": "Setting clip properties | mmo-rpg-unity",
    "keywords": "Setting clip properties Use the Inspector window to change the name of a clip and other properties, such as its timing and blend properties. The available properties depend on the type of clip selected. For example, select an Activation clip to change its name and set its Clip Timing. Inspector window when selecting an Activation clip in the Timeline window Not all clips have properties. See the following sections for clips with properties: Activation clip properties Animation clip common properties Animation clip Playable Asset properties Audio clip properties Control clip common properties Control clip Playable Asset properties"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_act.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_act.html",
    "title": "Activation clip properties | mmo-rpg-unity",
    "keywords": "Activation clip properties Use the Inspector window to change the name of an Activation clip and its Clip Timing. Inspector window when selecting an Activation clip in the Timeline window Display Name The name of the Activation clip shown in the Timeline window. By default, each Activation clip is named \"Active\". Clip Timing properties Use the Clip Timing properties to change the position and duration of the Activation clip. Most timing properties are expressed in both seconds (s) and frames (f). When specifying seconds to modify a Clip Timing property, all decimal values are accepted. When specifying frames, only integer values are accepted. For example, if you attempt to enter 12.5 in a frames (f) field, it is set to 12 frames. Depending on the selected Clip Edit mode, changing the Start, End, or Duration may ripple or replace Activation clips on the same track. Property Description Start The frame or time (in seconds) when the clip starts. Changing the Start also affects the End. Changing the Start sets the End to the new Start value plus the Duration. End The frame or time (in seconds) when the clip ends. Changing the End also affects the Start. Changing the End sets the Start to the new End value minus the Duration. Duration The duration of the clip in frames or seconds. Changing the Duration also affects the End. Changing the Duration sets the End to the Start value plus the new Duration."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_anim_com.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_anim_com.html",
    "title": "Animation clip common properties | mmo-rpg-unity",
    "keywords": "Animation clip common properties Use the Inspector window to change the common properties of an Animation clip. The common properties of an Animation clip include its name, timing, play speed, blend properties, and extrapolation settings. Inspector window when selecting an Animation clip in the Timeline window Display Name The name of the Animation clip shown in the Timeline window. Clip Timing properties Use the Clip Timing properties to position, change the duration, change the ease-in and ease-out duration, choose the extrapolation mode, and adjust the play speed of the Animation clip. Most timing properties are expressed in both seconds (s) and frames (f). When specifying seconds, a Clip Timing property accepts decimal values. When specifying frames, a property only accepts integer values. For example, if you attempt to enter 12.5 in a frames (f) field, the Inspector window sets the value to 12 frames. Depending on the selected Clip Edit mode, changing the Start, End, or Duration may blend, ripple, or replace Animation clips on the same track. Property Description Start The frame or time (in seconds) when the clip starts. Changing the Start changes the position of the clip on its track in the Timeline Asset. Changing the Start also affects the End. Changing the Start sets the End to the new Start value plus the Duration. End The frame or time (in seconds) when the clip ends. Changing the End also affects the Start. Changing the End sets the Start to the new End value minus the Duration. Duration The duration of the clip in frames or seconds. Changing the Duration also affects the End. Changing the Duration sets the End to the Start value plus the new Duration. Ease In Duration Sets the number of seconds or frames that it takes for the clip to ease in. If the beginning of the clip overlaps and blends with another clip, the Ease In Duration cannot be edited and instead shows the duration of the blend between clips. See Blending clips. Ease Out Duration Sets the number of seconds or frames that it takes for the clip to ease out. If the end of the clip overlaps and blends with another clip, the Ease Out Duration cannot be edited and instead shows the duration of the blend between clips. In this case, trim or position the clip to change the duration of the blend between clips. See Blending clips. Clip In Sets the offset of when the source clip should start playing. For example, to play the last 10 seconds of a 30 second Animation clip, set Clip In to 20 seconds. Speed Multiplier A multiplier on the playback speed of the clip. This value must be greater than 0. Changing this value changes the duration of the clip. Animation Extrapolation Use the Animation Extrapolation properties to set the gap extrapolation before and after an Animation clip. The term gap extrapolation refers to how an Animation track approximates or extends animation data in the gaps before, between, and after the Animation clips on a track. There are two properties for setting the gap extrapolation between Animation clips. The Pre-Extrapolate property only appears for Animation clips. Property Description Pre-Extrapolate Controls how animation data is approximated in the gap before an Animation clip. The Pre-Extrapolate property affects the easing-in of an Animation clip. Post-Extrapolate Controls how animation data extends in the gap after an Animation clip. The Post-Extrapolate property affects the easing-out of an Animation clip. Blend Curves Use the Blend Curves to customize the transition between the outgoing and incoming Animation clips. See Blending clips for details on how to blend clips and customize blend curves. When easing-in or easing-out clips, use the Blend Curves to customize the curve that eases-in or eases-out an Animation clip. See Easing-in and Easing-out clips for details."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_anim_plyb.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_anim_plyb.html",
    "title": "Animation clip Playable Asset properties | mmo-rpg-unity",
    "keywords": "Animation clip Playable Asset properties Use the Inspector window to change the Playable Asset properties of an Animation clip. These properties include controls for manually applying position and rotation clip offsets, and options for overriding default clip matching. To view the Playable Asset properties for an Animation clip, select an Animation clip in the Timeline window and expand Animation Playable Asset in the Inspector window. Inspector window showing the Animation Playable Asset properties for the selected Animation clip Animation Clip Use the Animation Clip to change the source asset used by the clip on the Animation track. The source asset is either a recorded Infinite clip or an external motion clip. Clip Transform Offsets Use the Clip Transform Offsets area to manually apply position and rotation offsets to the selected Animation clip. The tools and properties underneath the Clip Transform Offsets provide two methods of manually applying offsets based on the selected source: Property: Description: Move tool Shows a Move Gizmo in the Scene view. Use the Move Gizmo to manually position the clip offset for the selected Animation clip. Using the Move Gizmo changes the Position coordinates. Rotate tool Shows a Rotate Gizmo in the Scene view. Use the Rotate Gizmo to manually rotate the clip offset for the selected Animation clip. Using the Rotate Gizmo changes the Rotation coordinates. Position Manually sets the clip offset in X, Y, and Z coordinates. By default, the Position coordinates are set to zero and are relative to the track offsets. Rotation Manually sets the clip rotation offset around the X, Y, and Z axes. By default, the Rotation axes are set to zero and are relative to the track offsets. You can also automatically match the clip offsets based on the end of the previous Animation clip, or the start of the next Animation clip. The transforms that are matched depends on the Offset Match Fields. Offsets Match Fields Use Offsets Match Fields to choose which transforms to match when matching clip offsets. By default, Use Defaults is enabled and uses the default matching options set for the Animation track. Disable Use Defaults to override the track matching options and choose which transformations to match when performing a Match Offsets to Previous Clip or Match Offsets to Next Clip for the selected Animation clip. When you disable Offsets Match Fields, a series of additional checkboxes appear. Use these additional checkboxes to enable or disable matching per coordinate, for both position and rotation. Remove Start Offset Enable Remove Start Offset to make the Animation clip begin at position zero and rotation zero. The rest of the position and rotation keys in the Animation clip follow from zero. Enabling Remove Start Offset makes it easier to match the Animation clip with the previous Animation clip. Disable Remove Start Offset to keep the starting position and rotation. The Animation clip starts from its original position and rotation. Foot IK Enable Foot IK if the Animation clip is animating a humanoid and you want to use inverse kinematics for foot solving. Inverse kinematics attempts to remedy foot sliding by solving and influencing foot placement from the foot to the hip of the humanoid. Disable Foot IK if the Animation clip is animating a non-humanoid object such as a moving platform or a quadruped character with a non-human bone structure."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_aud.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_aud.html",
    "title": "Audio clip properties | mmo-rpg-unity",
    "keywords": "Audio clip properties Use the Inspector window to change the properties of an Audio clip. These properties include the name, timing, play speed, blend properties, audio media, and loop option. Inspector window when selecting an Audio clip in the Timeline window Display Name The name of the Audio clip shown in the Timeline window. This is not the name of the audio file that Unity uses for the waveform. For information on audio file properties, see Audio Playable Asset below. Clip Timing properties Use the Clip Timing properties to position, change the duration, change the ease-in and ease-out duration, and adjust the play speed of the Audio clip. Most timing properties are expressed in both seconds (s) and frames (f). When specifying seconds, a Clip Timing property accepts decimal values. When specifying frames, a property only accepts integer values. For example, if you attempt to enter 12.5 in a frames (f) field, the Inspector window sets the value to 12 frames. Depending on the selected Clip Edit mode, changing the Start, End, or Duration may blend, ripple, or replace Audio clips on the same track. Property Description Start The frame or time (in seconds) when the clip starts. Changing the Start property changes the position of the clip on its track in the Timeline Asset. Changing the Start also affects the End. Changing the Start sets the End to the new Start value plus the Duration. End The frame or time (in seconds) when the clip ends. Changing the End also affects the Start. Changing the End sets the Start to the new End value minus the Duration. Duration The duration of the clip in frames or seconds. Changing the Duration also affects the End. Changing the Duration sets the End to the Start value plus the new Duration. Blend Curves Use the Blend Curves to customize the fade-in and fade-out between the outgoing and incoming Audio clips. See Blending clips for details on how to blend clips and customize blend curves. When easing-in or easing-out Audio clips, use the Blend Curves to customize the curve that fades-in or fades-out an Audio clip. See Easing-in and Easing-out clips for details. Audio Playable Asset Use the Audio Playable Asset properties to select the Audio file used by the Audio clip and to set whether the selected Audio clip loops (Loop enabled) or plays once (Loop disabled)."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_ctrl_com.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_ctrl_com.html",
    "title": "Control clip common properties | mmo-rpg-unity",
    "keywords": "Control clip common properties Use the Inspector window to change the common properties of a Control clip. You can only create a Control clip in a Control track. A Control clip is a special clip that controls a nested Timeline instance, Particle System, Prefab instance, or ITimeControl Script, depending on how you create the Control clip: If you create the Control clip from a GameObject with a Playable Director component associated with a Timeline Asset, then the Control clip controls a nested Timeline instance. If the GameObject parents other GameObjects associated with many Timeline Assets, then the Control clip controls multiple Timeline instances. If you create the Control clip from a GameObject with a Particle System component, then the Control clip controls a Particle System. If you create the Control clip from a GameObject linked to a Prefab, then the Control clip controls a Prefab instance. If you create the Control clip from a GameObject with a script that implements the ITimeControl interface, then the Control clip controls an ITimeControl Script. The common properties of a Control clip include its name and Clip Timing properties. Not all common properties apply to all types of Control clips. Inspector window when selecting a Control clip in the Timeline window Display Name The name of the Control clip shown in the Timeline window. Clip Timing properties Use the Clip Timing properties to position and change the duration of the Control clip. Most timing properties are expressed in both seconds (s) and frames (f). When specifying seconds, a Clip Timing property accepts decimal values. When specifying frames, a property only accepts integer values. For example, if you attempt to enter 12.5 in a frames (f) field, the Inspector window sets the value to 12 frames. Depending on the selected Clip Edit mode, changing the Start, End or Duration of a Control clip may create an insert or replace clips on the same track. You cannot create a blend between Control clips. Property: Description: Start The frame or time (in seconds) when the Control clip starts. Changing the Start changes the position of the Control clip on its track in the Timeline Asset. Changing the Start also affects the End. Changing the Start sets the End to the new Start value plus the Duration. End The frame or time (in seconds) when the Control clip ends. Changing the End also affects the Start. Changing the End sets the Start to the new End value minus the Duration. Duration The duration of the clip in frames or seconds. Changing the Duration also affects the End. Changing the Duration sets the End to the Start value plus the new Duration. Clip In Sets the offset of when the Control clip starts playing. The Clip In property only affects Particle Systems and nested Timeline instances. Speed Multiplier A speed multiplier that affects the playback speed of the Control clip. This value must be greater than 0. The Speed Multiplier property only affects Particle Systems and nested Timeline instances."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_ctrl_plyb.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_clp_ctrl_plyb.html",
    "title": "Control clip Playable Asset properties | mmo-rpg-unity",
    "keywords": "Control clip Playable Asset properties Use the Inspector window to change the playable asset properties of a Control clip. To view the playable asset properties for a Control clip, select a Control clip in the Timeline window and expand Control Playable Asset in the Inspector window. Inspector window showing the Control Playable Asset properties for the selected Control clip Source Game Object Use Source Game Object to select the GameObject with the Particle System, nested Timeline instance, or ITimeControl Script for the selected Control clip. Changing the Source Game Object changes what the Control clip controls. Prefab Use Prefab to select a Prefab to instantiate when the Timeline instance plays in Play Mode. When a Prefab is selected, the label of the Source Game Object property changes to Parent Object. When in Play Mode, the Prefab is instantiated as a child of the Parent Object. Although the Prefab is instantiated at the start of the Timeline instance, the Prefab is only activated during the Control clip. When the Control clip ends, the Prefab instance is deactivated. Control Activation Enable Control Activation to activate the Source Game Object while the Control clip plays. Disable this property to activate the Source Game Object during the entire Timeline instance. The Control Activation property only affects Control clips that control a nested Timeline instance or a Particle System. Post Playback When Control Activation is enabled, use the Post Playback property to set the activation state for the nested Timeline instance when the main Timeline stops playing. The Post Playback property only affects nested Timeline instances. Post-Playback State Description Active Activates the Source Game Object after the nested Timeline instance finishes playing. Inactive Deactivates the Source Game Object after the nested Timeline instance finishes playing. Revert Reverts the Source Game Object to its activation state before the nested Timeline instance began playing. Advanced properties Use the Advanced properties to select additional functionality based on whether the Control clip controls a Playable Director, Particle System, or ITimeControl Script. The Advanced properties do not apply to all Control clips. Property Description Control Playable Directors Enable this property if the Source Game Object is attached to a Playable Director and you want the Control clip to control the nested Timeline instance associated with this Playable Director. Control Particle Systems Enable this property when the Control clip includes a Particle System. Set the value of the Random Seed property to create a unique, repeatable effect. Control ITimeControl Enable this property to control ITimeControl scripts on the Source GameObject. To use this feature, the Source Game Object must have a script that implements the ITimeControl interface. Control Children Enable this property if the Source Game Object has a child GameObject with either a Playable Director, Particle System, or ITimeControl Script, and you want the Control clip to control this child component. For example, if the Source Game Object is a GameObject that parents another GameObject with a Particle System, enable this property to make the Control clip control the Particle system on the child GameObject."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_tl.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_tl.html",
    "title": "Setting Timeline Asset properties | mmo-rpg-unity",
    "keywords": "Setting Timeline Asset properties Use the Inspector window to set the frame rate, the duration mode, and a fixed length for the selected Timeline Asset. From the Project window, select a Timeline Asset to view its properties. Inspector window when selecting a Timeline Asset in the Project window Property Description Frame Rate Sets the reference frame rate for the Timeline Asset and its Timeline instances. Change the Frame Rate to align clips at precise frames but changing the Frame Rate is only visual and has no effect on play speed, keys, tracks, or clips. Timeline supports the following standard frame rates: 24 (PAL), 25 (NTSC), 30, 50, and 60. Timeline also supports custom frame rates from 1e-6 to 1000. To set a custom frame rate, enter a non-standard frame rate for the Frame Rate property. In the Timeline Settings menu, the Custom menu item is enabled and automatically selected for the Timeline instance. The Custom menu item shows the custom frame rate in parentheses. Duration Mode Choose whether the duration of the Timeline Asset extends to the end of the last clip or ends at a specific time or frame. Based On Clips Sets the length of the Timeline Asset based on the end of the last clip. Fixed Length Sets the length of the Timeline Asset to a specific number of seconds or frames. Duration Shows the length of the Timeline Asset in seconds and frames when the Duration Mode is set to Based on Clips. Sets the length of the Timeline Asset to a specific number of seconds or frames when the Duration Mode is set to Fixed Length."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_trk.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_trk.html",
    "title": "Setting track properties | mmo-rpg-unity",
    "keywords": "Setting track properties Use the Inspector window to change the name of a track and its properties. The available properties depend on the type of track selected. For example, select an Animation Track to set how track offsets are applied, to apply an avatar mask, and to select which transforms are modified when matching offsets between Animation clips. Inspector window when selecting an Animation track in the Timeline window Not all tracks have properties. See the following sections for tracks with properties: Activation Track properties Animation Track properties"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_trk_act.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_trk_act.html",
    "title": "Activation track properties | mmo-rpg-unity",
    "keywords": "Activation track properties Use the Inspector window to change the name of an Activation track and set the state of its bound GameObject when the Timeline Asset finishes playing. Inspector window when selecting an Activation track in the Timeline window Property Description Display Name The name of the Activation track shown in the Timeline window and Playable Director component. The Display Name applies to the Timeline Asset and all of its Timeline instances. Post-playback state Sets the activation state for the bound GameObject when the Timeline Asset stops playing. The Post-playback state applies to the Timeline Asset and all of its Timeline instances. Active Activates the bound GameObject when the Timeline Asset finishes playing. Inactive Deactivates the bound GameObject when the Timeline Asset finishes playing. Revert Reverts the bound GameObject to its activation state before the Timeline Asset began playing. For example, if the Timeline Asset finishes playing with the GameObject set to inactive, and the GameObject was active before the Timeline Asset began playing, then the GameObject reverts to active. Leave As Is Sets the activation state of the bound GameObject to the state the Timeline Asset is at when it finishes playing. For example, if the Timeline Asset finishes playing with the GameObject set to inactive, the GameObject remains inactive."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_trk_anim.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/insp_trk_anim.html",
    "title": "Animation track properties | mmo-rpg-unity",
    "keywords": "Animation track properties Use the Inspector window to change the name of an Animation track, set how track offsets are applied, apply an avatar mask, and set which transforms are modified by default when you match clip offsets. Inspector window when selecting an Animation track in the Timeline window Property Description Display Name The name of the Animation track shown in the Timeline window and in the Playable Director component. The Display Name applies to the Timeline Asset and all of its Timeline instances. Track Offsets Applies a position and rotation offset to the start of each Animation clip on the selected Animation track. The position and rotation offset starts from a specific position and rotation or from the position and rotation relative to a state machine or another Timeline instance. Apply Transform Offsets Starts the animation in each Animation clip from a specific position and rotation offset. Use the Move and Rotate tools, and the Position and Rotation fields, to set the starting position and rotation. Apply Scene Offsets Starts the animated GameObject from its current position and rotation in the Scene. Use this mode to build a Timeline instance that transitions to and from a state machine or to and from another Timeline instance. Auto (deprecated) If you load a Scene or Project that was built before 2018.3, Track Offsets is automatically set to Auto (deprecated). This is a special mode for backwards compatibility. After opening an old Project, choose another Track Offsets mode because the Auto (deprecated) offset disables key animation recording. Move tool Enable the Move tool to show the Move Gizmo in the Scene view. Use the Move Gizmo to visually position the transform offset. Positioning the Move Gizmo changes the Position properties. The Move tool only appears when Track Offsets is set to Apply Transform Offsets. Rotate tool Enable the Rotate tool to show the Rotate Gizmo in the Scene view. Use the Rotate Gizmo to visually rotate the track offset. Rotating the Rotate Gizmo changes the Rotation properties. The Rotate tool only appears when Track Offsets is set to Apply Transform Offsets. Position Sets the track position offset in X, Y, and Z coordinates. The Position fields only appears when Track Offsets is set to Apply Transform Offsets. Rotation Sets the track rotation offset in X, Y, and Z coordinates. The Rotation fields appear when Track Offsets is set to Apply Transform Offsets. Apply Avatar Mask Enables Avatar masking. When enabled, Timeline applies the animation of all Animation clips on the track based on the selected Avatar Mask. Avatar Mask Selects the Avatar Mask applied to all Animation clips on the Animation track. An Avatar Mask defines which humanoid body parts are animated by Animation clips on the selected Animation track. The body parts that are masked are animated by other Animation tracks in the Timeline Asset. For example, you can use an Avatar Mask to combine the lower-body animation on an Animation track with the upper body animation on an Override Animation track. Default Offset Match Fields Expand to display a series of checkboxes that choose which transforms are matched when matching clip offsets between Animation clips. The Default Offset Match Fields set the default matching options for all Animation clips on the same track. Use the Animation Playable Asset properties to override these defaults for each Animation clip."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/play_director.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/play_director.html",
    "title": "Playable Director component | mmo-rpg-unity",
    "keywords": "Playable Director component The Playable Director component stores the link between a Timeline instance and a Timeline Asset. The Playable Director component controls when the Timeline instance plays, how the Timeline instance updates its clock, and what happens when the Timeline instance finishes playing. Playable Director component added to the GameObject named Ground. The GameObject is associated with the GroundCTL Timeline Asset. The Playable Director component also shows the list of tracks from the associated Timeline Asset (Playable property) that animate GameObjects in the Scene. The link between Timeline Asset tracks and GameObjects in the Scene is referred to as binding or Track binding. For more on binding and the relationship between Timeline Assets and Timeline instances, see Timeline overview. Property Description Playable Associates a Timeline Asset with a GameObject in the Scene. When you make this association, you create a Timeline instance for the selected Timeline Asset. After you create a Timeline instance, you can use the other properties in the Playable Director component to control the instance and choose which GameObjects in the Scene are animated by the Timeline Asset. Update Method Sets the clock source that the Timeline instance uses to update its timing. DSP Select for sample accurate audio scheduling. When selected, the Timeline instance uses the same clock source that processes audio. DSP stands for digital signal processing. Game Time Select to use the same clock source as the game clock. This clock source is affected by time scaling. Unscaled Game Time Select to use the same clock source as the game clock, but without being affected by time scaling. Manual Select to not use a clock source and to manually set the clock time through scripting. Play on Awake Whether the Timeline instance is played when game play is initiated. By default, a Timeline instance is set to begin as soon as the Scene begins playback. To disable the default behaviour, disable the Play on Awake option in the Playable Director component. Wrap Mode The behaviour when the Timeline instance ends playback. Hold Plays the Timeline instance once and holds on the last frame until playback is interrupted. Loop Plays the Timeline instance repeatedly until playback is interrupted. None Plays the Timeline instance once. Initial Time The time (in seconds) at which the Timeline instance begins playing. The Initial Time adds a delay in seconds before the Timeline instance actually begins. For example, when Play On Awake is enabled and Initial Time is set to five seconds, if you click the Play button in the Unity Toolbar, Play Mode starts and the Timeline instance begins five seconds later. Current Time Views the progression of time according to the Timeline instance in the Timeline window. The Current Time field matches the Playhead Location field. Use the Current Time field when the Timeline window is hidden. The Current Time field appears in the Playable Director Component when in Timeline Playback mode or when Unity is in Game Mode. Bindings Shows the link between GameObjects in the Scene with tracks from the associated Timeline Asset (Playable property). The Bindings area is split into two columns: The first column lists the tracks from the Timeline Asset. Each track is identified by an icon and its track type. The second column lists the GameObject linked (or bound) to each track. The Bindings area does not list Track groups, Track sub-groups, or tracks that do not animate GameObjects. The Timeline window shows the same bindings in the Track list."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_about.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_about.html",
    "title": "Samples | mmo-rpg-unity",
    "keywords": "Samples Gameplay Sequence Demo This sample demonstrates how Timeline can be used to create a small in-game moment, using built-in tracks. Overview In this example, we have a Player character jogging and then colliding with another character. The Player character represents our gameplay character and is using a looping jog animation. The Timeline then takes control of the player character, collides with the other character, then returns to his original gameplay animation (jog) once the Timeline has finished. Note that the gameplay animation is driven by an Animator and will only play at runtime. The character will be in a T-Stance pose for the runtime portion when using the Timeline preview. Timeline Structure This sample uses the following tracks: Activation, Animation, Audio, Control and Marker track. The GameplaySequence timeline has been organized in the following groups: Building, Lights, Cameras, Characters, Audio and Props. Building group This group contains two Control tracks: Building Spawn which spawns the building prefab, and Building Particles that controls two particle systems in the scene (ElectricalSparks and SandSwirlsEffect). Lights group This group contains two Animation tracks; one for the Sun light, and the other for the flickering light. Both tracks where animated in Unity and the curves can be seen by enabling the curves icon or double clicking on the track to open the Animation window. Sun light is animated in Rotation (sunrise) and the Point light has a spiked Intensity curve. Cameras group This group contains two cameras: Main camera using an Animation track, and Follow camera using an Activation track. Main Camera has an animation curve for the continuous movement (which can be seen by enabling the curves icon) and two override tracks, one for each character. The clips on the override tracks have static values for a fixed camera shot. Follow camera is simply parented child of the Player character's root and activated for the follow-cam shots. Characters group The first track is an Animation track for the Playercharacter. Notice that clip pre and post extrapolations are set to None, meaning the character will not be influenced by the timeline during these gaps. At runtime, these gaps mean the Player character will be using his Animator state, jog. The second track is an Activation track for the second character, making his appear in the scene. The third and last track is an Animation track for the second character. On this track, the second character blends from one clip to another creating a cinematic sequence. Audio group This group contains four Audio tracks; Player, crickets, neon-light & character2. The Player track has a jog/breathing and bump clip. The crickets track has pan and volume animation curves (can be seen by enabling the curves icon). The neon-light sound is for the flickering Point light. The Character2 tracks contains all audio clips for this second character. Props group This group animates Table and Can. The first Activation track makes Table appear in the scene. The second Activation track makes a static version of Can appear in the scene. The third track is an Animation track that animates the table bump animation. The last track is a Control track with a sub-timeline for the can animation. The static version of the can is disabled and replaced with the animated version when the Control clip starts. Double-clicking the Control track clip will enter the Can sub-timeline. Can Sub-Timeline This sub-timeline contains an Animation track for the can rolling off the table and bouncing on the ground, an Audio track for the sounds effects and a Control track for the liquid particles splashing out of the can. Marker track In the Timeline window, under the time ruler, there is a Marker track with one Signal at frame 1200. This is the Signal marker that triggers the jog audio clip on Player once the timeline finishes the gameplay jog. Customization samples This sample includes tracks, clips, markers and actions that demonstrate how to extend and customize timeline in different ways. Annotation: provides a marker that can be used as a bookmark. Video track: provides a track capable of playing video clips. Time dilation track: provides a track that can be used to adjust Unity's global Time.timeScale. Tween track: provides a track that can be used for simple transform movements. Text track: provides a track that can be used to display different messages to the screen using a TextMeshPro Text component. Demo Included is a demo timeline that showcases all the of the above samples."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_annotation.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_annotation.html",
    "title": "Annotation marker sample | mmo-rpg-unity",
    "keywords": "Annotation marker sample The Annotation sample provides a marker that can be used as a bookmark for your timeline. Here are the options available on an annotation: Field | Description --- | --- Title | The annotation's title. This will be displayed as a tooltip, when hovering the mouse on the annotation. Color | The annotation's color in the Timeline window. Show line overlay | Use this option to show a vertical line that spans the full height of the Timeline window. Custom marker workflow example This example will demonstrate how to: create a custom marker; customize a marker with MarkerEditor; use a custom USS style to draw a marker; add additional commands with Actions; 1. Create an annotation marker A marker is an item that can be added to a Timeline Asset and is used to represent a point in time. Markers also have a specialization, just like clips (Activation clip, Audio clip, Animation clip, etc). In order to add a new type of marker, all we need to do is to create a class that inherits the Marker class: public class AnnotationMarker : UnityEngine.Timeline.Marker {} This custom marker can now be added to any track or on the timeline marker area: We can add a title, description and color to the annotation: public class AnnotationMarker : Marker { public string title; public Color color; public string description; public bool showLineOverlay; } The annotation marker itself is now complete. But the customization work is not done yet. Timeline offers many customization abilities. 2. Customize the marker's appearance A marker's appearance can be customized using a USS style or with MarkerEditor. Both paths have their advantages and drawbacks. Custom USS style A marker can use a USS style to specify its appearance. For more information on how to create custom USS styles, see how to define custom USS styles. The CustomStyle attribute can be used to specify a style for a given marker: [CustomStyle(\"AnnotationStyle\")] public class AnnotationMarker : Marker { //... } AnnotationStyle is defined in a USS stylesheet and will be used when a marker is displayed on screen: USS styles are useful if the desired appearance is simple (i.e. when only using a texture icon). For more complex stuff (i.e. dynamically changing a marker's color), a MarkerEditor will be needed. Custom editor MarkerEditor can be used to augment the capabilities of a marker in the editor. It works like a custom Inspector; the CustomTimelineEditor attribute is used to tell Timeline that a MarkerEditor class should be associated to a given marker. [CustomTimelineEditor(typeof(AnnotationMarker))] public class AnnotationMarkerEditor : MarkerEditor { //... } Marker information MarkerEditor lets us provide information about the marker by overriding the GetMarkerOptions method. public override MarkerDrawOptions GetMarkerOptions(IMarker marker) { var annotation = marker as AnnotationMarker; if (annotation != null) { return new MarkerDrawOptions { tooltip = annotation.title }; } return base.GetMarkerOptions(marker); } Here the tooltip of an Annotation has been set to use the annotation's title variable. MarkerDrawOptions can also set the error text on a marker, which can be useful if a variable has been incorrectly set and needs attention. Overlay An overlay can be drawn on top of a marker by overriding the DrawOverlay method: public override void DrawOverlay(IMarker marker, MarkerUIStates uiState, MarkerOverlayRegion region) { var annotation = marker as AnnotationMarker; if (annotation != null) { //Draw overlay code... } } An overlay is drawn on top of the marker; the USS style is drawn first and DrawOverlay is called afterwards. For an Annotation, we can use DrawOverlay to change the color of the marker and to draw a line that spans the full Timeline window's height. To do this, we can use the information given in region. Along with the visible time range, MarkerOverlayRegion provides two rectangles that can be used to know where to draw: markerRegion markerRegion is the rectangle that encompasses the marker. This is useful to draw something directly on the marker itself. For Annotation, this rectangle is used to draw the color overlay. timelineRegion timelineRegion is the rectangle that encompasses the clips and markers region of the timeline window. This is useful to draw something out of the marker's region, like the Annotation's line overlay. const float k_LineOverlayWidth = 6.0f; float markerRegionCenter = markerRegion.xMin + (markerRegion.width - k_LineOverlayWidth) / 2.0f; Rect lineRect = new Rect(markerRegionCenter, timelineRegion.y, k_LineOverlayWidth, timelineRegion.height); 3. Create custom Actions Timeline Action Actions can be used to add new menu entries in Timeline's context menus. For an Annotation, we want to add a menu item available in all context menus to create an Annotation with the clipboard's contents. To do this, a TimelineAction is needed, along with the MenuEntry attribute. [MenuEntry(\"Create Annotation from clipboard contents\")] public class CreateAnnotationFromClipboardContents : TimelineAction { //... } MenuEntry lets Timeline know that this action can be added in context menus. Classes inheriting from TimelineAction need to override two methods: Execute and Validate. Validate Validate is used to specify that the action's prerequisites are fulfilled. In the case of CreateAnnotationFromClipboardContents, the action is only valid if there actually is contents in the clipboard. ActionValidity is used to describe the validity state of an action: public override ActionValidity Validate(ActionContext context) { if (!markers.All(marker => marker is AnnotationMarker)) return ActionValidity.NotApplicable; string buffer = EditorGUIUtility.systemCopyBuffer; return buffer.Length == 0 ? ActionValidity.Invalid : ActionValidity.Valid; } ActionValidity.Valid : The action can be executed. ActionValidity.Invalid : The action cannot be executed given the current context and will appear grayed out in context menus. ActionValidity.NotApplicable : The action does not apply to the current context and will not show up in menus. Execute Execute should run the code necessary to execute the action's purpose. public override bool Execute(ActionContext context) { string buffer = EditorGUIUtility.systemCopyBuffer; TrackAsset track = context.tracks.FirstOrDefault(); if (buffer.Length != 0) { // Create the new annotation and add it to the track //... return true; } return false; } The return value should specify if the execution succeeded or not. Marker Action It is also possible to write custom actions that apply only to markers, instead of all Timeline items. This is the purpose of the MarkerEditor class. It works just like TimelineAction, except that action applies to a list of markers. A shortcut can also be assigned to an action. A static method with the TimelineShortcut attribute is needed. Invoker can be used to easily execute a given action: [TimelineShortcut(\"Replace annotation description with clipboard\", KeyCode.G)] public static void InvokeAction() { Invoker.InvokeWithSelectedMarkers<ReplaceAnnotationDescriptionAction>(); } Notes Runtime considerations AnnotationMarker is available at runtime; it can be queried using, for example, TrackAsset.GetMarkers(). However, AnnotationMarkerEditor and custom actions are not available at runtime, since it depends on classes that are not part of the runtime assembly."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_text.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_text.html",
    "title": "Text Track sample | mmo-rpg-unity",
    "keywords": "Text Track sample This track requires the TextMeshPro package to be installed in the project. This type of track can be used to display different messages to the screen using a TextMeshPro Text Component. It is ideal for things like subtitles. It demonstrates the following: Registering custom previewable properties in a custom track. Perform custom blending of clips using a mixer PlayableBehaviour. Provide custom clip data that can be animated using the inline curve editor using a PlayableBehaviour template. Using a ClipEditor to react to changes in a clip. Usage To use this custom track, drag a TextMeshPro Text Component into the hierarchy view of the Timeline. A TextTrack will be created, and use the track context menu to create clips. Clip properties such as Message, FontSize and Color can be modified in the inspector by selecting the clip. Clips can be overlapped to create transitions."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_time.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_time.html",
    "title": "Time Dilation Track sample | mmo-rpg-unity",
    "keywords": "Time Dilation Track sample This type of track can be used to adjust Unity's global Time.timeScale for the duration of the clip. The most common use would be to create bullet-time style effects. The sample demonstrates the following: Creating a custom TrackMixer PlayableBehaviour that performs custom blending of clip values. Setting and restoring Unity global values in a PlayableBehaviour. How to support blending and extrapolation on custom clips. Provide custom clip data that can be animated using the inline curve editor using a PlayableBehaviour template. Usage Create a TimeDilationTrack in timeline using the Add Track menu, found under the Timeline.Samples submenu. Add clips to the track, and use the inspector to set scale values for the clip, or use the inline curve editor to animate the scale values. Clips can also be overlapped to create transitions between clips."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_tween.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_tween.html",
    "title": "Transform Tween track sample | mmo-rpg-unity",
    "keywords": "Transform Tween track sample This track can be used for simple transform movements between two points. Usage This track can be used for simple transform movements. All translation happens in a straight line but the speed can be controlled with an animation curve. The Tween track binds to the scene Transform you wish to move. Field Description Start Location This is a reference to a Transform in the scene that marks the position and/or rotation of the moving Transform when the playable starts. If it is left null the position/rotation of the moving Transform when the playable starts will be used. End Location This is a reference to a Transform in the scene that marks the position and/or rotation of the moving Transform when the playable finishes. Tween Position Whether or not the position of the Transform should change. Tween Rotation Whether or not the rotation of the Transform should change. Custom clip workflow example This example will demonstrate how to: create a custom clip, track and mixer; use the PlayableGraph API to animate an object's transform; customize a clip with ClipEditor; 1. Custom clip when a Timeline begins playing, nodes called Playables are created. They are organized in a tree-like structure called the PlayableGraph. For each frame, Timeline samples this graph to read and mix multiple data sources (animation, audio and more). The first step to create a custom clip is to define a new PlayableBehaviour that will be added to a graph. It will need to store the data needed to implement the transform tween: public class TweenBehaviour : PlayableBehaviour { public Transform startLocation; public Transform endLocation; public bool shouldTweenPosition; public bool shouldTweenRotation; public AnimationCurve curve; } The PlayableBehaviour's data is not serialized and will be lost once its parent graph is destroyed. To save this data, the next step is to define a new PlayableAsset: [Serializable] public class TweenClip : PlayableAsset { public ExposedReference<Transform> startLocation; public ExposedReference<Transform> endLocation; public bool shouldTweenPosition = true; public bool shouldTweenRotation = true; public AnimationCurve curve; //... } Note: The clip needs to store a start and an end location. Since an asset cannot directly reference a scene object, it cannot store a transform object directly. This is why an ExposedReference<Transform> is used. A PlayableAsset's main purpose is to build a PlayableBehaviour. This is done with the CreatePlayable method: public class TweenClip : PlayableAsset { //... public override Playable CreatePlayable(PlayableGraph graph, GameObject owner) { // create a new TweenBehaviour ScriptPlayable<TweenBehaviour> playable = ScriptPlayable<TweenBehaviour>.Create(graph); TweenBehaviour tween = playable.GetBehaviour(); // set the behaviour's data tween.startLocation = startLocation.Resolve(graph.GetResolver()); tween.endLocation = endLocation.Resolve(graph.GetResolver()); tween.curve = curve; tween.shouldTweenPosition = shouldTweenPosition; tween.shouldTweenRotation = shouldTweenRotation; return playable; } } CreatePlayable will initialize a new TweenBehaviour using TweenClip's data. 2. Custom track A custom track is created by defining a TrackAsset subclass. The following attributes can be added to a TrackAsset: TrackBindingType: defines which type of object should be bound to a track; TrackClipType: defines which type of clip should be associated to a track. For this example, the track needs a Transform object binding and can only accepts clips of type TweenClip, which was previously defined in step 1: [TrackBindingType(typeof(Transform))] [TrackClipType(typeof(TweenClip))] public class TweenTrack : TrackAsset { // ... } The data setup is complete; TweenTrack and TweenClip can now be added to a timeline: However, no transform tween has been implemented yet. To do this, a track mixer is needed. 3. Define a track mixer To properly handle blending, or crossfading, between two clips, a track mixer is needed. A track mixer is a PlayableBehaviour that will have access to all clips data and will blend those together. Track mixer setup By default, when a track is added to a timeline, an empty playable is generated and is connected to each clip's playable. For example, this track: will generate the following playable graph: Timeline: this playable is the root playable; all playables related to tracks are connected to this node. Playable: this playable represents the track mixer. Since no track mixer is defined, an empty one is generated. TweenBehaviour: this playable represents a clip. One per clip is generated. All clip playables are connected to the track mixer. In order to define a custom track mixer, a new PlayableBehaviour needs to be defined: public class TweenMixerBehaviour : PlayableBehaviour {} then, in TrackAsset, the CreateTrackMixer method can be used to specify a custom track mixer: public class TweenTrack : TrackAsset { public override Playable CreateTrackMixer(PlayableGraph graph, GameObject go, int inputCount) { return ScriptPlayable<TweenMixerBehaviour>.Create(graph, inputCount); } } Now the playable graph looks like this: The empty playable that used to connect clip playables together is now replaced by TweenMixerBehaviour. Transform tween implementation The implementation of the transform tween resides in the ProcessFrame method from TweenMixerBehaviour. Here are the main steps of that implementation: Initialization: When the timeline is first played, the initial transform of the track binding is fetched. If the start or end transform is null, the initial transform will be used instead. Get clip behaviours & weights: to appropriately blend, the mixer needs to ask information for all of its inputs (clips): // Iterate on all the playable's (mixer) inputs (ie each clip on the track) int inputCount = playable.GetInputCount(); for (int i = 0; i < inputCount; i++) { // get the input connected to the mixer Playable input = playable.GetInput(i); // get the weight of the connection float inputWeight = playable.GetInputWeight(i); // get the clip's behaviour TweenBehaviour tweenInput = GetTweenBehaviour(input); } Calculate and blend: A linear interpolation is used to calculate a transform between two points. Apply result: Once the calculation is done, the transform is written in the track binding object: // Apply the final position and rotation values in the track binding trackBinding.position = accumPosition + m_InitialPosition * (1.0f - totalPositionWeight); trackBinding.rotation = accumRotation.Blend(m_InitialRotation, 1.0f - totalRotationWeight); 4. Customize a clip's appearance ClipEditor can be used to augment the capabilities of a clip in the editor. It works like a custom Inspector; the CustomTimelineEditor attribute is used to tell Timeline that a ClipEditor class should be associated to a given clip. [CustomTimelineEditor(typeof(TweenClip))] public class TweenClipEditor : ClipEditor { //... } It is possible to customize the appearance of a clip with the DrawBackground method: public override void DrawBackground(TimelineClip clip, ClipBackgroundRegion region) { TweenClip asset = clip.asset as TweenClip; if (asset == null) return; // Drawing code here... } Notes Only the portion between (0,1) of the curve will be used. When a clip ends, the object bound to the track will return to its original position."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_video.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/smpl_custom_video.html",
    "title": "VideoTrack sample | mmo-rpg-unity",
    "keywords": "VideoTrack sample The Video Track sample provides a track capable of playing video clips in Timeline. It demonstrates how to do the following: Using built-in blending, speed and clip-in capabilities in custom clips. Using ClipEditors to customize clip drawing. Using a mixer PlayableBehaviour to perform look-ahead operations. Managing UnityEngine.Object lifetime (VideoPlayer) with a PlayableBehaviour. Using ExposedReferences to reference components in the scene from a PlayableAsset. Usage Drag and drop an imported video from the project window onto a timeline. The video track and clip will be created. The video clip has several playback options, including the option to specify the camera to render to video to, and an audio source to redirect the audio. If no camera is specified, the main camera in the scene will be used. If no audio source is specified, the audio will play directly (i.e. no 3D audio). Known Issues The video track supports ease-in and ease-out of a video, but blending between videos will not give expected results. Editing a timeline containing video clips may cause the clip to flicker or change unexpectedly. Looping a timeline with video clips may cause the video to be de-synchronized."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_about.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_about.html",
    "title": "Timeline overview | mmo-rpg-unity",
    "keywords": "Timeline overview Use the Timeline window to create cut-scenes, cinematics, and game-play sequences by visually arranging tracks and clips linked to GameObjects in your Scene. A cinematic sequence in the Timeline window. For each cut-scene, cinematic, or game-play sequence, the Timeline window saves the following: Timeline Asset: Stores the tracks, clips, and recorded animations without links to the specific GameObjects being animated. The Timeline Asset is saved to the Project. Timeline instance: Stores links to the specific GameObjects being animated or affected by the Timeline Asset. These links, referred to as bindings, are saved to the Scene. Timeline Asset The Timeline window saves track and clip definitions as a Timeline Asset. If you record key animations while creating your cinematic, cut-scene, or game-play sequence, the Timeline window saves the recorded clips as children of the Timeline Asset. The Timeline Asset saves tracks and clips (red). Timeline saves recorded clips (blue) as children of the Timeline Asset. Timeline instance To animate a GameObject in your Scene with a Timeline Asset, you must create a Timeline instance. A Timeline instance associates a Timeline Asset with the GameObject in the Scene, through a Playable Director component. When you select a GameObject in a Scene that has a Playable Director component, the Timeline instance appears in the Timeline window. The bindings appear in the Timeline window and in the Playable Director component (Inspector window). The Playable Director component shows the Timeline Asset (blue) with its bound GameObjects (red). The Timeline window shows the same bindings (red) in the Track list. The Timeline window provides an automated method of creating a Timeline instance while creating a Timeline Asset. Reusing Timeline Assets Because Timeline Assets and Timeline instances are separate, you can reuse the same Timeline Asset with many Timeline instances. For example, you could create a Timeline Asset named VictoryTL with the animation, music, and particle effects that play when the main game character (Player) wins. To reuse the VictoryTL Timeline Asset to animate another game character (Enemy) in the same Scene, you can create another Timeline instance for the secondary game character. The Player GameObject (red) is attached to the VictoryTL Timeline Asset] The Enemy GameObject (blue) is also attached to the VictoryTL Timeline Asset] Because you are reusing the Timeline Asset, any modification to the Timeline Asset in the Timeline window results in changes to all Timeline instances. For example, in the previous example, if you delete the Audio track while modifying the Player Timeline instance, the Timeline window removes the track from the VictoryTL Timeline Asset. The Timeline window also removes the Audio track from all instances of the VictoryTL Timeline Asset, including the Enemy Timeline instance."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_gloss.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_gloss.html",
    "title": "Timeline glossary | mmo-rpg-unity",
    "keywords": "Timeline glossary This topic provides an alphabetical list of the terminology used throughout the Timeline documentation. animatable property: A property belonging to a GameObject, or belonging to a component added to a GameObject, that can have different values over time. animation: The result of adding two different keys, at two different times, for the same animatable property. animation curve: The curve drawn between keys set for the same animatable property, at different frames or seconds. The position of the tangents and the selected interpolation mode for each key determines the shape of the animation curve. binding or Track binding: Refers to the link between Timeline Asset tracks and the GameObjects in the scene. When you link a GameObject to a track, the track animates the GameObject. Bindings are stored as part of the Timeline instance. blend and blend area: The area where two Animation clips, Audio clips, or Control clips overlap. The overlap creates a transition that is referred to as a blend. The duration of the overlap is referred to as the blend area. The blend area sets the duration of the transition. Blend In curve: In a blend between two Animation clips, Audio clips, or Control clips, there are two blend curves. The blend curve for the incoming clip is referred to as the Blend In curve. Blend Out curve: In a blend between two Animation clips, Audio clips, or Control clips, there are two blend curves. The blend curve for the out-going clip is referred to as the Blend Out curve. clip: A generic term that refers to any clip within the Clips view of the Timeline window. Clips view: The area in the Timeline window where you add, position, and manipulate clips. Control/Command: This term is used when instructing the user to press or hold down the Control key on Windows, or the Command key on Mac. Curves view: The area in the Timeline window that shows the animation curves for Infinite clips or for Animation clips that have been converted from Infinite clips. The Curves view is similar to Curves mode in the Animation window. Gap extrapolation: How an Animation track approximates animation data in the gaps before and after an Animation clip. field: A generic term that describes an editable box that the user clicks and types-in a value. A field is also referred to as a property. incoming clip: The second clip in a blend between two clips. The first clip, the out-going clip, transitions to the second clip, the incoming clip. Infinite clip: A special animation clip that contains basic key animation recorded directly to an Animation track within the Timeline window. An Infinite clip cannot be positioned, trimmed, or split because it does not have a defined duration: it spans the entirety of an Animation track. interpolation: The estimation of values that determine the shape of an animation curve between two keys. interpolation mode: The interpolation algorithm that draws the animation curve between two keys. The interpolation mode also joins or breaks left and right tangents. key: The value of an animatable property, set at a specific point in time. Setting at least two keys for the same property creates an animation. out-going clip: The first clip in a blend between two clips. The first clip, the out-going clip, transitions to the second clip, the incoming clip. Playhead Location field: The field that expresses the location of the Timeline Playhead in either frames or seconds, depending on the Timeline Settings. property: A generic term for the editable fields, buttons, checkboxes, or menus that comprise a component. An editable field is also referred to as a field. tangent: One of two handles that controls the shape of the animation curve before and after a key. Tangents appear when a key is selected in the Curves view, or when a key is selected in the Curve Editor. tangent mode: The selected interpolation mode used by the left tangent, right tangent, or both tangents. Timeline or Unity's Timeline: Generic terms that refer to all features, windows, editors, and components related to creating, modifying, or reusing cut-scenes, cinematics, and game-play sequences. Timeline Asset: Refers to the tracks, clips, and recorded animation that comprise a cinematic, cut-scene, game-play sequence, or other effect created with the Timeline window. A Timeline Asset does not include bindings to the GameObjects animated by the Timeline Asset. The bindings to scene GameObjects are stored in the Timeline instance. The Timeline Asset is project-based. Timeline window: The official name of the window where you create, modify, and preview a Timeline instance. Modifications to a Timeline instance also affects the Timeline Asset. Timeline instance: Refers to the link between a Timeline Asset and the GameObjects that the Timeline Asset animates in the scene. You create a Timeline instance by associating a Timeline Asset to a GameObject through a Playable Director component. The Timeline instance is scene-based. Timeline Playback Controls: The row of buttons and fields in the Timeline window that controls playback of the Timeline instance. The Timeline Playback Controls affect the location of the Timeline Playhead. Timeline Playback mode: The mode that previews the Timeline instance in the Timeline window. Timeline Playback mode is a simulation of Play mode. Timeline Playback mode does not support audio playback. Timeline Playhead: The white marker and line that indicates the exact point in time being previewed in the Timeline window. Timeline Selector: The name of the menu in the Timeline window that selects the Timeline instance to be previewed or modified. track: A generic term that refers to any track within the Track list of the Timeline window. Track groups: The term for a series of tracks organized in an expandable and collapse collection of tracks. Track list: The area in the Timeline window where you add, group, and modify tracks."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_play_cntrls.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_play_cntrls.html",
    "title": "Timeline Playback Controls | mmo-rpg-unity",
    "keywords": "Timeline Playback Controls To play the Timeline instance and to control the location of the Timeline Playhead, use the Timeline Playback Controls. Timeline Playback Controls Timeline Start button To move the Timeline Playhead to the start of the Timeline instance, click the Timeline Start button, or hold Shift and press Comma (,). Previous Frame button To move the Timeline Playhead to the previous frame, click the Previous Frame button, or press Comma (,). Timeline Play button To preview the Timeline instance in Timeline Playback mode, click the Timeline Play button, or press the Spacebar. Timeline Playback mode does the following: Begins playback at the current location of the Timeline Playhead and continues to the end of the Timeline instance. If the Play Range button is enabled, playback is restricted to a specified time range. The Timeline Playhead position moves along the Timeline instance. The Playhead Location field shows the position of the Timeline Playhead in either frames, timecode or seconds, depending on the Timeline settings. To pause playback, click the Timeline Play button again, or press the Spacebar. When playback reaches the end of the Timeline instance, the Wrap Mode determines whether playback should hold, repeat, or do nothing. The Wrap Mode setting is a Playable Director component property. Timeline Playback mode provides a preview of the Timeline instance while in the Timeline window. Timeline Playback mode is only a simulation of Play Mode in the Game View. The Timeline Playback mode does not support audio playback. To preview a Timeline instance with audio, enable the Play on Awake option in the Playable Director component and preview game play in Play Mode. Next Frame button To move the Timeline Playhead to the next frame, click the Next Frame button, or press Period (.). Timeline End button To move the Timeline Playhead to the end of the Timeline instance, click the Timeline End button, or hold Shift and press Period (.). Play Range button Enable the Play Range button to restrict playback to a specific range of seconds or frames. You can only set a play range when previewing a Timeline instance within the Timeline window. Unity ignores the play range in Play Mode. The Timeline ruler highlights the play range and indicates its start and end with white markers. To modify the play range, drag either marker. Play Range (red circle) enabled with while markers and highlighted area defining range Timeline Playhead and Playhead Location field The Timeline Playhead indicates the exact point in time being previewed in the Timeline window. The Playhead Location field expresses the location of the Timeline Playhead in either frames or seconds. Playhead Location field and Timeline Playhead (red). The Timeline Playhead also appears on the Zoombar (red arrow). Use the Zoombar to navigate, scroll, and zoom the Clips view. A white line indicates the location of the Timeline Playhead in relation to the entire Timeline instance. To jump the Timeline Playhead to a specific time, click the Timeline ruler. You can also enter the time value in the Playhead Location field and press Enter. When entering a value, frames are converted to seconds or seconds are converted to frames, based on the Timeline settings. For example, if the Timeline ruler is expressed as seconds with a frame rate of 30 frames per second, entering 180 in the Playhead Location field converts 180 frames to seconds and moves the Timeline Playhead to 6:00. To set the time format that the Timeline window uses, configure the Timeline Settings. Switching between Local and Global Use the Local or Global button to change the Timeline ruler from local time to global time. Local time and global time are only relevant when editing a nested Timeline instance. To create a nested Timeline instance, drag a GameObject associated with a Timeline instance into another Timeline instance. The Timeline instance you are dragging into becomes the master Timeline instance. The Timeline instance associated with the GameObject becomes a nested Timeline instance. A nested Timeline instance appears as a Control clip on a Control track (red arrow) To edit a nested Timeline instance, double-click the Control clip that contains the nested Timeline instance. The Timeline window switches to the nested Timeline instance, indicated by the Timeline title which shows the name and GameObject of the master Timeline instance, followed by the name and GameObject of the nested Timeline instance. The Timeline title indicates that you are editing a nested Timeline instance (red outline). The Global button (red arrow) indicates that the nested Timeline instance is shown using global time. When editing a nested Timeline instance, click Global to switch the Timeline ruler to Local time. Local time is relative to the nested Timeline. This means that the Timeline ruler starts at zero. A nested Timeline instance in Local time. Click Local to view the Timeline ruler in relation to the placement of the nested Timeline in the master Timeline instance. This means that if, for example, if the Control clip is placed at frame 70 of the master Timeline then the Timeline ruler starts at 70 at the beginning of the nested Timeline instance. A nested Timeline instance in Global time."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_selector.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_selector.html",
    "title": "Timeline Preview and Timeline Selector | mmo-rpg-unity",
    "keywords": "Timeline Preview and Timeline Selector Use the Timeline Selector to select the Timeline instance to view, modify, or preview in the Timeline window. The Timeline Preview button enables or disables previewing the effect that the selected Timeline instance has on your Scene. Timeline Preview button with Timeline Selector and menu. Selecting a Timeline instance automatically enables the Timeline Preview button. To select a Timeline instance, click the Timeline Selector and choose from the list of Timeline instances in the current Scene. Each menu item displays the name of the Timeline Asset and its associated GameObject in the current Scene. For example, the Timeline Asset named GroundATL that is associated with the Ground GameObject, displays as \"GroundATL (Ground).\""
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_settings.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_settings.html",
    "title": "Timeline Settings | mmo-rpg-unity",
    "keywords": "Timeline Settings Use the Timeline Settings to choose the Timeline window and Timeline Asset settings such as the unit of measurement, the duration mode, audio waveform, and window snap settings. Click the Cog icon in the Timeline window to view the Timeline Settings menu Time Unit Select either Frames, Timecode or Seconds to set the Timeline window to display time in that format. Timecode will display the time in seconds with sub-second values displayed in frames. Duration Mode Use the Duration Mode to set whether the duration of the Timeline Asset extends to the end of the last clip (Based On Clips), or ends at a specific time or frame (Fixed Length). When the Duration Mode is set to Fixed Length, use one of the following methods to change the length of the Timeline Asset: Select the Timeline Asset in the Project window and use the Inspector window to set the Duration in seconds or frames. In the Timeline window, drag the blue marker on the timeline. The blue marker indicates the end of the Timeline Asset. A blue line indicates the duration of the Timeline Asset. Timeline Asset duration (red rectangle) and end marker (green circle) Frame Rate Select one of the options under Frame Rate to set the unit of measurement for the Timeline ruler. Change the Frame Rate to align clips at precise frames but changing the Frame Rate is only visual and has no effect on play speed, keys, tracks, or clips. The following standard frame rates are listed: Film (24 fps), PAL (25 fps), NTSC (29.97 fps), 30, 50, or 60. Timeline supports custom frame rates from 1e-6 to 1000. To set a custom frame rate, you must use the Frame Rate property in the Timeline Asset settings. When the Timeline Asset is set to a custom frame rate, the Custom menu item is enabled and is automatically selected for the Timeline instance. The Custom menu item shows the custom frame rate in parentheses. Show Audio Waveforms Enable Show Audio Waveforms to draw the waveforms for all audio clips on all audio tracks. For example, use an audio waveform as a guide when manually positioning an Audio clip of footsteps with the Animation clip of a humanoid walking. Disable Show Audio Waveform to hide audio waveforms. Show Audio Waveforms is enabled by default. Enable Audio Scrubbing Enable Audio Scrubbing to play audio while dragging the Timeline Playhead. Disable Enable Audio Scrubbing to stop playing audio while dragging the Timeline Playhead. When disabled, Timeline only plays audio when in Timeline Playback mode. Snap to Frame Enable Snap to Frame to manipulate clips, preview Timeline instances, drag the Timeline Playhead, and position the Timeline Playhead using frames. Disable Snap to Frame to use subframes. Snap to Frame is enabled by default. Disable Snap to Frame to position clips and drag the playhead between frames For example, when Snap to Frame is disabled and you drag the Timeline Playhead, it moves the playhead between frames. The format of Playhead Location displays differently depending on whether the Timeline window is set to Seconds, Timecode or Frames: When the Timeline window is set to Frames, the Playhead Location shows frames and subframes. For example, 8 frames and 34 subframes displays as 8.34. When the Timeline window is set to Timecode, the Playhead Location shows seconds, frames, and subframes. For example, 6 seconds, 17 frames, and 59 subframes displays as 6:17 [.59]. When the Timeline window is set to Seconds, the Playhead Location shows seconds. For example, 6.5 seconds displays as 6:50. Manipulating clips, previewing Timeline instances, and positioning the playhead at the subframes level is useful when attempting to synchronize animation and effects with audio. Many high-end audio processing software products create audio waveforms with subframe accuracy. Edge Snap Enable the Edge Snap option to snap clips when you position, trim, and create blends. When enabled, the Timeline window snaps the start or end of a clip when dragged within 10 pixels of the Timeline Playhead, the start or end of a clip on the same track, the start or end of a clip on another track, or the start or end of the entire Timeline instance. The start guide or end guide is redrawn in white to indicate that the clip has snapped to the edge of another clip or the Timeline Playhead. Disable Edge Snap to create more accurate blends, ease-ins, or ease-outs. Edge Snap is enabled by default."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_window.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/tl_window.html",
    "title": "Timeline window | mmo-rpg-unity",
    "keywords": "Timeline window To access the Timeline window, select Sequencing > Timeline from the Window menu. What the Timeline window shows depends on what you select in either the Project window or the Scene view. For example, if you select a GameObject that is associated with a Timeline Asset, the Timeline window shows the tracks and clips from the Timeline Asset and the GameObject bindings from the Timeline instance. Selecting a GameObject associated with a Timeline Asset displays its tracks and clips, and the bindings from the Timeline instance If you haven’t selected a GameObject, the Timeline window informs you that the first step for creating a Timeline Asset and a Timeline instance is to select a GameObject. With no GameObject selected, the Timeline window provides instructions If a GameObject is selected and it is not associated with a Timeline Asset, the Timeline window provides the option for creating a new Timeline Asset, adding the necessary components to the selected GameObject, and creating a Timeline instance. Select a GameObject that is not associated with a Timeline Asset to create a new Timeline Asset, add components, and create a Timeline instance To use the Timeline window to view a previously created Timeline Asset, select the Timeline Asset in the Project window and open the Timeline window. The Timeline window shows the tracks and clips associated with the Timeline Asset, but without the track bindings to GameObjects in the Scene. In addition, the Timeline Playback Controls are disabled and there is no Timeline Playhead. Timeline Asset selected in the Project window shows its tracks and clips, but with no track bindings. The Timeline Playback Controls are disabled. Timeline saves the track bindings to GameObjects in the Scene with the Timeline instance, not the Timeline Asset. For details on the relationship between the Project, Scene, Timeline Assets, and Timeline instances, see Timeline overview."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_add.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_add.html",
    "title": "Adding tracks | mmo-rpg-unity",
    "keywords": "Adding tracks The Timeline window supports many different methods of adding tracks to the Track list. Depending on the method you choose, the Timeline window may also add track bindings to the Track header, clips to tracks, and components to GameObjects. Add Track menu The simplest method to add a track is to click the Add button and select the type of track from the Add Track drop-down menu. You can also right-click an empty area of the Track list to make the Add Track menu appear. The Timeline window also supports dragging a GameObject into the Track list. Drag a GameObject into an empty area in the Track list and select the type of track to add from the context menu. Depending on the type of track selected, the Timeline window performs different actions: Select Animation Track and the Timeline window binds the GameObject to the Animation track. If the GameObject doesn't already have an Animator component, the Timeline window creates an Animator component for the GameObject. Select Activation Track and the Timeline window binds the GameObject to the Activation track. There are some limitations when creating an Activation track when dragging a GameObject. For example, the main GameObject with the Playable Directory component should not be bound to an Activation track. Because this is the same GameObject that links the Timeline Asset to the Scene, activating and disabling the GameObject affects the length of Timeline instance. Select Audio Track and the Timeline window adds an Audio Source component to the GameObject and binds this Audio Source component to the Audio track."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_delete.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_delete.html",
    "title": "Deleting tracks | mmo-rpg-unity",
    "keywords": "Deleting tracks Delete a track to remove the track, its clips, blends, and properties from the Timeline window. This is a destructive action that modifies a Timeline Asset and affects all Timeline instances based on the Timeline Asset. There are many ways to delete tracks: Select a track and press the Delete key (or hold Command and press Delete). Select a track. Right-click an empty area in the Track list and select Delete from the context menu. Right-click a track and select Delete from the context menu. Deleting an Animation track also deletes the recorded Infinite clips for Animation clips that were converted from Infinite clips. The Project window may still show recorded Infinite clips as children of a Timeline Asset because it is not updated until you save the Scene or Project. You cannot delete a locked track."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_dup.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_dup.html",
    "title": "Duplicating tracks | mmo-rpg-unity",
    "keywords": "Duplicating tracks Duplicating a track copies its clips, blends, and Inspector properties. If the duplicated track is bound to a GameObject, the binding is reset to None. Track binding for a duplicated track is reset to None There are many ways to duplicate tracks: Select a track. Right-click an empty area in the Track list and select Duplicate from the context menu. Select a track. Hold Command/Control and press D. Select a track. Hold Command/Control and press C, for copy, then press V, for paste. Right-click a track and either select Duplicate from the context menu or hold Command/Control and press D."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_list_about.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_list_about.html",
    "title": "Track list and Track headers | mmo-rpg-unity",
    "keywords": "Track list and Track headers Use the Track list to add, select, duplicate, delete, lock, mute, and reorder the tracks that comprise a Timeline Asset. You can also organize tracks into Track groups. Track list and Track headers for the Timeline instance named GroundETL Each track has two areas: Track list: Shows a Track header for each track. Clips view: Shows the clips for each track. The Track header contains the name of the track or its binding information. Track bindings are saved to the Playable Director component associated with the GameObject that is linked to the Timeline Asset. This association is referred to as a Timeline instance (see Timeline overview). Each Track header has a colored accent that identifies the track type and its clips: Activation tracks are green. Use Activation tracks to add Activation clips which set when the bound GameObject is active (shown). The GameObject is bound to the Activation track. Animation tracks are blue. Use Animation tracks to add Animation clips that animate the bound GameObject. Use an Animation track and its Animation clips to record basic animation or animate a humanoid. Audio tracks are orange. Use Audio tracks to add Audio clips for playing background music or sound effects. Each Audio clip is bound to an audio waveform. The audio source, that plays each waveform, is bound to the Audio track. Control tracks are turquoise. Use Control tracks to add Control clips which are special clips that control a nested Timeline instance, Particle System, Prefab instance, or ITimeControl Script. How the Control clip is created determines what it controls. Playable tracks are white. Use Playable tracks to add Playable clips. Each Playable clip is bound to a script that uses the Playables API to create custom animation tools, effects or gameplay mechanisms. Each Track header is also identified by an icon. If a track has a binding error or if the bound GameObject is disabled, the icon representing a track changes to an alert icon. For example, if an Animation track is bound to a GameObject that is disabled at the location of the Playhead, the icon switches to an alert icon. An alert icon indicates that the RedCube bound GameObject is disabled at the start of the Timeline instance"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_lock.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_lock.html",
    "title": "Locking tracks | mmo-rpg-unity",
    "keywords": "Locking tracks Lock a track to prevent editing of the track and any of the clips used by the track. Use lock when you have finished animating a track and you want to avoid inadvertently modifying the track. You cannot edit or delete a locked track, or select its clips. The Lock icon identifies a locked track. Selected and locked track with Lock icon (red circle) To lock a track, right-click on the track and select Lock from the context menu. You can also select a track and press L. You can select and lock multiple tracks at a time. A track can be both locked and muted. To unlock a track, click the Lock icon. You can also select a locked track and press L, or right-click and select Unlock."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_mute.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_mute.html",
    "title": "Muting tracks | mmo-rpg-unity",
    "keywords": "Muting tracks Mute a track to disable its clips and their effect on the Scene. You can also use mute when your Timeline instance includes many tracks with animations and you want to focus on the animation of one or a few tracks. The Mute icon identifies a muted track. Selected and muted track with Mute icon (red circle) To mute a track, right-click on the track and select Mute from the context menu. You can also select a track and press M. You can select and mute multiple tracks at a time. A track can be both muted and locked. To unmute a track, click the Mute icon. You can also select a muted track and press M, or right-click and select Unmute. Note: Muted tracks can be deleted."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_reorder.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_reorder.html",
    "title": "Reordering tracks and rendering priority | mmo-rpg-unity",
    "keywords": "Reordering tracks and rendering priority In the Timeline window, the rendering and animation priority is from the last track to the first track, where the last track takes priority. You can reorder tracks to change their rendering or animation priority. For example, a Timeline instance has four Animation tracks, where the second and fourth Animation tracks animate the same GameObject. The fourth track overrides the animation on any of the preceding tracks. This animation priority is the reason why Animation Override tracks are added as child tracks, under Animation tracks. The second track (red arrow) and fourth track (selected, green arrow) animate the same GameObject (GreenCube). The fourth track has priority and overrides the second track.) To reorder tracks, select one or more tracks and drag until a white insert line appears between tracks in the Track list. The white insert line indicates the destination of the tracks you are dragging. The last selected track type displays beside the cursor. Release the mouse button to reorder tracks. For example, the white insert line indicates that the Control track (Storm) will be placed between the first track (Ground) and second track (Audio Src) An Animation Override track is bound to the same GameObject as its parent Animation track. Reordering an Animation Override track converts it to an Animation track and resets its binding to none."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_select.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/trk_select.html",
    "title": "Selecting tracks | mmo-rpg-unity",
    "keywords": "Selecting tracks To select a single track, click its Track header in the Track list. You can also click an empty area in the Clips view. When you select a track, Timeline highlights its Track header and Clips view. Selecting a track deselects all other tracks or clips. Selecting a track shows its properties in the Inspector window. The track properties change depending on the type of track and how many tracks you select. See Timeline Inspector for details. To select contiguous tracks, select the first track and then hold Shift and click the last track in the series. For example, to select three contiguous tracks, click the first track, then hold Shift and click the third track. All three tracks are selected. Click to select the first track Hold Shift and click to select contiguous tracks Hold Command/Control and click to select discontiguous tracks. Hold Command/Control and click to deselect a selected track. There are many other ways to select tracks: Hold down Shift and press the Up arrow or Down arrow keys to add and remove tracks from the selection. To deselect all tracks or clips, click on an empty area in the Track list. When a clip is selected on a track, press Tab to select the track. Use the arrow keys to change the selected track. The Up and Down arrow keys select the previous or next track. The Right arrow key selects the first clip on the track. If a Track group is already selected, the Left arrow and Right arrow keys collapse and expand the Track group."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/uss_styles.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/uss_styles.html",
    "title": "Defining custom USS styles | mmo-rpg-unity",
    "keywords": "Defining custom USS styles The first step to define a USS style is to create a new stylesheet. Stylesheets can be used to extend the Editor’s visual appearance. This can be done by adding a file named common.uss in an Editor folder in a StyleSheets/Extensions folder hierarchy. For example, the following locations are valid: Assets/Editor/Stylesheets/Extensions/common.uss Assets/Editor/MyFolder/Stylesheets/Extensions/common.uss Assets/Editor/MyFolder1/MyFolder2/Stylesheets/Extensions/common.uss USS files (for Unity Style Sheet) use a CSS-like syntax to describe new styles. Here is an example: myStyle { width:18px; height:18px; background-image: resource(\"Assets/Editor/icon.png\"); } In this style, we specified that we wish to use a custom icon along with size properties. USS styles also support pseudo-states, which works like pseudo-classes in CSS. Timeline markers support the following pseudo-states: Collapsed: .myStyle Normal: .myStyle:checked Selected: .myStyle:hover:focus:checked USS stylesheets also support Unity's light and dark themes. Styles in files named dark.uss and light.uss will be used as an override of the style in common.uss. For example: common.uss myStyle { width:18px; height:18px; color: rgb(125, 125, 125); } dark.uss myStyle { color: rgb(0, 0, 0); background-image: resource(\"icon_dark.png\"); } light.uss myStyle { color: rgb(255, 255, 255); background-image: resource(\"icon_light.png\"); } In the dark theme, myStyle will be resolved to: myStyle { width:18px; height:18px; color: rgb(0, 0, 0); background-image: resource(\"icon_dark.png\"); } and in the light theme: myStyle { width:18px; height:18px; color: rgb(255, 255, 255); background-image: resource(\"icon_light.png\"); }"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_about.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_about.html",
    "title": "Using the Timeline window | mmo-rpg-unity",
    "keywords": "Using the Timeline window Use the Timeline window to create Timeline Assets and Timeline instances, record animation, schedule animation, and create cinematic content. This section shows you how to do the following tasks: Create a Timeline Asset and Timeline instance Record basic animation with an Infinite clip Convert an Infinite clip to an Animation clip Animate a humanoid Use Animation Override tracks and Avatar Masking Nest Timeline Instances"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_char_anim.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_char_anim.html",
    "title": "Animating a humanoid | mmo-rpg-unity",
    "keywords": "Animating a humanoid This task demonstrates how to use a Timeline instance to animate a humanoid with external motion clips. This workflow also demonstrates how to match clip offsets, manually adjust clip offsets, and create blends between clips to minimize jumping and sliding. Although this workflow uses a humanoid, you can use this animation method for any GameObject. This workflow assumes that you have already created a Timeline instance with an empty Animation track bound to a humanoid. For example, the DefaultMale humanoid is bound to an empty Animation track: DefaultMale humanoid bound to an empty Animation track. From your Project, drag a motion clip into the Animation track to create a new Animation clip. For example, drag an idle pose as the first clip to start the humanoid from an idle stance. To position, resize, or trim your Animation clip in the Clips view, select Mix mode as the Clip Edit mode. There are three different Clip Edit modes that change the editing behaviour of the Timeline window. When the Timeline window is in Mix mode, you can drag and trim clips to create blends. Animation track, bound to the DefaultMale humanoid, with an idle pose (Idle) as its Animation clip. The Mix mode (red circle) is the selected Clip Edit mode. Add a second Animation clip. This example adds a run and turn left clip (named Run_Left) to the Animation track, and then resizes the clip to include one loop, so the DefaultMale runs and turns 180 degrees. Animation track with an Idle clip and a Run_Left clip Play the Timeline instance. In this example, the DefaultMale humanoid jumps between each Animation clip because the position of the humanoid at the end of the first Animation clip (Idle) does not match the position of the humanoid at the start of the next Animation clip (RunLeft). The humanoid jumps between the first Animation clip, which ends at frame 29 (red arrow and box), and the second Animation clip, which starts at frame 30 (ghost with green arrow and box) Matching clips To fix the animation jump between clips, match the offset of each Animation clip. The Timeline window provides different methods for matching offsets. In this example, Timeline matches the second Animation clip with the previous clip. To do this, select the Run_Left clip, right-click and select Match Offsets to Previous Clip. Right-click and select Match Offsets to Previous Clip to match the offsets of the selected Animation clip with the preceding Animation clip After matching offsets, the position and rotation of the humanoid at the start of the second Animation clip (frame 30, ghost with green arrow) matches the position and rotation of the humanoid at the end of the first Animation clip (frame 29, red arrow) Play the Timeline instance again. Although the position and rotation of the humanoid matches, there is still a jump between the two Animation clips because the humanoid is in different poses. At the end of the first Animation clip, the humanoid is standing upright with its feet together. At the start of the second Animation clip, the humanoid is bent forward with its feet apart. Blending clips Create a blend to remove the jump and transition between the two poses. Adjust the size of the clips, the Blend Area, the Clip In, and the shape of each Blend Curve to create a transition between the two poses. For example, in the transition between the Idle clip and the Run_Left clip, the Idle clip was resized to 36 frames and the Run_Left clip was repositioned to start at frame 25. The rest of the clip properties are unchanged from their default values. With Mix mode selected, you can create a blend (red circle) between two clips to create a smooth transition between two animations. As the Idle clip transitions to the Run_Left clip, the blend removes the obvious jump between poses. The transition between most body parts appears natural, however in this example, the blend between the different positions of the foot results in an unnatural foot slide. Reducing foot slide To reduce foot sliding, manually adjust the offset of an Animation clip so that the position of the foot changes less drastically. To manually adjust the offset, select the Animation clip in the Timeline window. In the Inspector window, expand Animation Playable Asset. Select an Animation clip. In the Inspector window, expand Animation Playable Asset (red) to view the Clip Transform Offsets. The rotation and position Clip Transform Offsets are not zero because performing Match Offsets to Previous Clip already set these values to match the root (hips) of the humanoid at the end of the previous Animation clip. Under Clip Transform Offsets, enable the Move tool. The Move Gizmo appears in the Scene view, at the root of the Animation clip. Enable the Move tool (Inspector window, red arrow) to show the Move Gizmo (green arrow) in the Scene view Use one of the following methods to manually adjust the offset position of the Animation clip: In the Scene view, drag the Move Gizmo. In the Inspector window, under Clip Transform Offsets, change the value of the appropriate Position property."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_conv_infinite.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_conv_infinite.html",
    "title": "Converting an Infinite clip to an Animation clip | mmo-rpg-unity",
    "keywords": "Converting an Infinite clip to an Animation clip An Infinite clip appears as a dope sheet. An Infinite clip cannot be positioned, trimmed, or split because it does not have a defined duration. To position, trim, split, or perform other clip manipulations on an Infinite clip, you must first convert it to an Animation clip. You cannot convert an Animation clip back to an Infinite clip. To convert an Infinite clip to an Animation clip, click the Track menu icon and select Convert to Clip Track: The Track menu (circled) converts an Infinite clip to an Animation clip. You can also right-click the track and select Convert to Clip Track from the context menu. The Track menu and context menu are the same. An infinite clip after it has been converted to an Animation clip"
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_instance.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_instance.html",
    "title": "Creating a Timeline Asset and Timeline instance | mmo-rpg-unity",
    "keywords": "Creating a Timeline Asset and Timeline instance To use a Timeline Asset in your Scene, associate the Timeline Asset with a GameObject using a Playable Director component. Associating a Timeline Asset with a Playable Director component creates a Timeline instance and allows you to specify which objects in the Scene are animated by the Timeline Asset. To animate a GameObject, it must also have an Animator component. The Timeline window automatically creates a Timeline instance while creating a new Timeline Asset. The Timeline window also creates the necessary components. To create a new Timeline Asset and Timeline instance, follow these steps: In your Scene, select the GameObject that you want to use as the focus of your cinematic or other gameplay-based sequence. Open the Timeline window (menu: Window > Sequencing > Timeline). If the GameObject does not yet have a Playable Director component attached to a Timeline Asset, a message in the Timeline window prompts you to click the Create button. Click Create. A dialog box prompts you for the name and location of the Timeline Asset you are creating. You can also specify tags to identify the Timeline Asset. Click Save. The Timeline window does the following: Saves a new Timeline Asset to the Assets directory of your Project. If you did not change the name and location of the Timeline Asset you are creating, the Timeline window creates a name based on the selected GameObject with the \"Timeline\" suffix. For example, selecting the GameObject called \"Enemy\" names the Asset \"EnemyTimeline\". Adds an empty Animation track to the Timeline Asset. Adds a Playable Director component to the selected GameObject, and sets the Playable property to the Timeline Asset. This creates a Timeline instance. Sets the binding on the Animation track in the Playable Director component to the selected GameObject. The Animation track does not have any clips, so the selected GameObject is not animated. Adds an Animator component to the selected GameObject. The Animator component animates the GameObject through the Timeline instance. The GameObject cannot be animated without an Animator component."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_mask.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_mask.html",
    "title": "Using an Animation Override track and an Avatar Mask | mmo-rpg-unity",
    "keywords": "Using an Animation Override track and an Avatar Mask This task demonstrates how to use an Animation Override track and an Avatar Mask to replace the upper-body animation of an Animation track. Use this technique to animate a humanoid to, for example, run and carry an object. For information on creating an Avatar mask, see Avatar Mask window. This task assumes that you have already created a Timeline instance with a simple Animation clip on an Animation track bound to a humanoid: This example uses a humanoid bound to a simple run cycle animation (RunForward) that loops once Right-click the Animation track and select Add Override Track from the context menu. An Animation Override track, named Override 0, is linked to the selected Animation track. Notice that the Animation Override track is not bound to a GameObject. Because the Override track is linked to the Animation track above, the Override track is bound to the same GameObject, in this case, the DefaultMale humanoid. To add an Override track, right-click the Animation track and select Add Override Track from the context menu] From your Project, drag an Animation Clip with upper-body animation into the Override track. For example, drag an animation of a humanoid standing still and waving their arms. Position and resize the clip to match the Animation clip that you want to override. The Animation Override track contains an Animation clip of a humanoid standing still, waving their arms (WavingArms). This clip was resized to match the Animation clip (RunForward) of the parent Animation track. Play the Timeline instance. In this example, the WavingArms clip completely overrides the RunForward clip. To combine the lower-body animation from one Animation clip with upper-body animation from another Animation clip, specify an Avatar Mask for the Animation Override track. To specify an Avatar Mask, select the Override track to view its properties in the Inspector window From the Project, drag an Avatar Mask, that masks the lower body animation, into the Avatar Mask property in the Inspector window. Enable the Apply Avatar Mask checkbox. An Avatar Mask icon appears beside the track name. An Avatar Mask, that masks the lower body animation, is specified for the Animation Overview clip in the Inspector window. This allows the upper body animation to pass through. The Avatar Mask icon (red) indicates that the Animation Override track uses an Avatar Mask. Play the Timeline instance. In this example, the DefaultMale humanoid uses upper-body animation from the WavingArms clip and lower-body animation from the RunForward clip. To temporarily disable the Avatar Mask, click the Avatar Mask icon. The Avatar Mask icon (red) is gray when disabled. The WavingArms clip completely overrides the RunForward clip."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_nested.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_nested.html",
    "title": "Nesting Timeline instances | mmo-rpg-unity",
    "keywords": "Nesting Timeline instances Timeline supports nesting Timeline instances. A nested Timeline instance refers to a Timeline instance that is added within another Timeline instance. The master Timeline instance refers to the main or parent Timeline instance that includes other Timeline instances. Nesting Timeline instances is useful if you have a large team working on different aspects of a Project and you want them to collaborate on the same cinematic or cut-scene. For example, you are developing a puzzle game that starts with a cinematic of the character walking into frame while the pieces on the game board move into position. You could create a master Timeline instance for the character walking into frame. You could create another Timeline instance for the game board animation. You could then nest the game board animation into the master Timeline instance of the character walking into frame. The master NestTL Timeline instance has a character walking and theme music. A Control track nests the BoardTL Timeline instance for the game board animation. By creating a master Timeline instance with nested Timeline instances, different teams can work on different animations and then combine the animations into one master Timeline. In the puzzle game example, one team could work on the character Timeline instance, and another team could work on the game board animation. When you have two Timeline instances, and you want to nest one instance into the other, open the Timeline instance that you want to be the master Timeline instance. To ensure that the Timeline window does not switch while you select GameObjects, click the lock icon (red arrow): The master NestTL Timeline instance has a character walking and theme music. Find the GameObject in your Scene that is associated with the Timeline instance that you want to nest inside the master Timeline instance. Drag the GameObject into the Clips view of the Timeline window. The Board GameObject is associated with the BoardTL Timeline instance. Drag the Board GameObject into the NestTL master Timeline to nest the BoardTL Timeline instance in the NestTL Timeline instance. The Timeline window creates a Control track and places the Control clip where you drop the GameObject. The Control clip is set to the same size as the Timeline instance. When a Control clip contains a nested Timeline instance, a downward arrow appears beside its name. To edit a nested Timeline instance from the master timeline, double-click its Control clip. Double-click the Control clip to edit the nested BoardTL Timeline instance from within the master A warning icon appears beside the name of the nested Timeline instance because the Timeline Playhead is outside the range of the nested Timeline. Timeline also disables the Timeline Playhead controls. When you edit a nested Timeline instance, you cannot change the duration of the nested Timeline instance. You must return to the master Timeline instance and change the duration of the Control clip to change the duration of the nested Timeline instance. To return to the master, click the name of the master Timeline instance (red arrow): Warning icon (red circle) means the Timeline Playhead Controls are disabled. The Timeline window is in this state because, by default, the size of the Control clip in the master Timeline instance determines when the nested Timeline instance is active. Use one of the following methods to change this state and edit the nested Timeline instance: Click the Timeline ruler to move the Timeline Playhead into the nested Timeline. This enables editing and the Timeline Playback Controls. In the master Timeline instance, move the Timeline Playhead to within the Control clip before you double-click the Control clip. In the master Timeline instance, select the Control clip, and disable the Control Activation property in the Inspector window. Disable the Control Activation property (red outline) to have the nested Timeline instance active throughout the duration of the master Timeline instance."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_rec_anim.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/Documentation~/wf_rec_anim.html",
    "title": "Recording basic animation with an Infinite clip | mmo-rpg-unity",
    "keywords": "Recording basic animation with an Infinite clip You can record animation directly to an Animation track. When you record directly to an empty Animation track, you create an Infinite clip. An Infinite clip is a clip that contains basic key animation recorded through the Timeline window. An Infinite clip cannot be positioned, trimmed, or split because it does not have a defined size: it spans the entirety of an Animation track. Before creating an Infinite clip, you must add an empty Animation track for the GameObject that you want to animate. In the Track list, click the red circular Record button for the empty Animation track to enable Record mode. Click the Record button on an empty track to enable Record mode When a track is in Record mode, the clip area of the track is drawn in red with the \"Recording...\" message, and the Record button blinks on and off. Timeline window in Record mode When in Record mode, any modification to an animatable property of the GameObject sets a key at the location of the Timeline Playhead. To start creating an animation, move the Timeline Playhead to the location of the first key, and do one of the following: In the Inspector window, right-click the name of the property and choose Add Key. This adds an animation key for the property without changing its value. A diamond appears in the Infinite clip to show the position of the key. In the Inspector window, change the value of the animatable property of the GameObject. This adds an animation key for the property with its changed value. A diamond appears in the Infinite clip. In the Scene view, either move, rotate, or scale the GameObject. This automatically adds a key for the properties you change. A diamond appears in the Infinite clip. Red background indicates that you’ve added an animation curve for the property to the clip Setting a key adds a diamond to the Infinite clip Move the playhead to a different position on the Timeline and change the animatable properties of the GameObject. At each position, the Timeline window adds a diamond to the Infinite clip for any changed properties and adds a key to its associated animation curves. While in Record mode, you can right-click the name of an animatable property name to perform keying operations such as setting a key without changing its value, jumping to the next or previous keys, and removing keys. For example, to set a key for the position of a GameObject without changing its value, right-click Position and select Add Key from the context menu. Right-click the name of an animatable property to perform keying operations When you finish the animation, click the blinking Record button to disable Record mode. An Infinite clip appears as a dope sheet in the Timeline window, but you cannot edit the keys in this view. Use the Curves view to edit keys. You can also double-click the Infinite clip and edit the keys with the Animation window. An Infinite clip appears as a dope sheet Save the Scene or Project to save the Timeline Asset and the Infinite clip. The Timeline window saves the key animation from the Infinite clip as a source asset. The source asset is named \"Recorded\" and saved as a child of the Timeline Asset in the Project. Recorded clips are saved under the Timeline Asset in the Project For every additional recorded Infinite clip, the Timeline window numbers each clip sequentially, starting at \"(1)\". For example, a Timeline Asset with three recorded Infinite clips are named \"Recorded\", \"Recorded (1)\", and \"Recorded (2)\". If you delete a Timeline Asset, its recorded clips are also removed."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Timeline copyright © 2022 Unity Technologies Licensed under the Unity Companion License for Unity-dependent projects--see Unity Companion License. Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.timeline@1.7.6/README.html": {
    "href": "Library/PackageCache/com.unity.timeline@1.7.6/README.html",
    "title": "About Timeline | mmo-rpg-unity",
    "keywords": "About Timeline Use Unity’s Timeline to create cinematic content, game-play sequences, audio sequences, and complex particle effects. Installing Timeline To install this package, follow the instructions in the Package Manager documentation. Using Timeline The Timeline Manual can be found here Technical details Requirements This version of Timeline is compatible with the following versions of the Unity Editor: 2019.3 and later (recommended)"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog [1.0.0] - 2019-01-08 This is the first release of Unity UI as a built in package."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/EventSystem.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/EventSystem.html",
    "title": "Event System | mmo-rpg-unity",
    "keywords": "Event System The Event System is a way of sending events to objects in the application based on input, be it keyboard, mouse, touch, or custom input. The Event System consists of a few components that work together to send events. When you add an Event System component to a GameObject you will notice that it does not have much functionality exposed, this is because the Event System itself is designed as a manager and facilitator of communication between Event System modules. The primary roles of the Event System are as follows: Manage which GameObject is considered selected Manage which Input Module is in use Manage Raycasting (if required) Updating all Input Modules as required Input Modules An Input Module is where the main logic of how you want the Event System to behave lives, they are used for: Handling Input Managing event state Sending events to scene objects. Only one Input Module can be active in the Event System at a time, and they must be components on the same GameObject as the Event System component. If you want to write a custom Input Module, send events supported by existing UI components in Unity. To extend and write your own events, see the Messaging System documentation. Raycasters Raycasters are used for figuring out what the pointer is over. It is common for Input Modules to use the Raycasters configured in the Scene to calculate what the pointing device is over. There are 3 provided Raycasters that exist by default: Graphic Raycaster - Used for UI elements Physics 2D Raycaster - Used for 2D physics elements Physics Raycaster - Used for 3D physics elements If you have a 2d / 3d Raycaster configured in your Scene, it is easy to make non-UI elements receive messages from the Input Module. Simply attach a script that implements one of the event interfaces. For examples of this, see the IPointerEnterHandler and IPointerClickHandler Scripting Reference pages."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/EventSystemReference.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/EventSystemReference.html",
    "title": "Event System Reference | mmo-rpg-unity",
    "keywords": "Event System Reference This section provides details about the following parts of the event system: Event System Manager Graphic Raycaster Physics Raycaster Physics2D Raycaster Standalone Input Module Touch Input Module Event Trigger"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UICreateFromScripting.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UICreateFromScripting.html",
    "title": "Creating UI elements from scripting | mmo-rpg-unity",
    "keywords": "Creating UI elements from scripting If you are creating a dynamic UI where UI elements appear, disappear, or change based on user actions or other actions in the game, you may need to make a script that instantiates new UI elements based on custom logic. Creating a prefab of the UI element In order to be able to easily instantiate UI elements dynamically, the first step is to create a prefab for the type of UI element that you want to be able to instantiate. Set up the UI element the way you want it to look in the Scene, and then drag the element into the Project View to make it into a prefab. For example, a prefab for a button could be a Game Object with a Image component and a Button component, and a child Game Object with a Text component. Your setup might be different depending on your needs. You might wonder why we don't have a API methods to create the various types of controls, including visuals and everything. The reason is that there are an infinite number of way e.g. a button could be setup. Does it use an image, text, or both? Maybe even multiple images? What is the text font, color, font size, and alignment? What sprite or sprites should the image use? By letting you make a prefab and instantiate that, you can set it up exactly the way you want. And if you later want to change the look and feel of your UI you can just change the prefab and then it will be reflected in your UI, including the dynamically created UI. Instantiating the UI element Prefabs of UI elements are instantiated as normal using the Instantiate method. When setting the parent of the instantiated UI element, it's recommended to do it using the Transform.SetParent method with the worldPositionStays parameter set to false. Positioning the UI element A UI Element is normally positioned using its Rect Transform. If the UI Element is a child of a Layout Group it will be automatically positioned and the positioning step can be skipped. When positioning a Rect Transform it's useful to first determine it has or should have any stretching behavior or not. Stretching behavior happens when the anchorMin and anchorMax properties are not identical. For a non-stretching Rect Transform, the position is set most easily by setting the anchoredPosition and the sizeDelta properties. The anchoredPosition specifies the position of the pivot relative to the anchors. The sizeDelta is just the same as the size when there's no stretching. For a stretching Rect Transform, it can be simpler to set the position using the offsetMin and offsetMax properties. The offsetMin property specifies the corner of the lower left corner of the rect relative to the lower left anchor. The offsetMax property specifies the corner of the upper right corner of the rect relative to the upper right anchor. Customizing the UI Element If you are instantiating multiple UI elements dynamically, it's unlikely that you'll want them all to look the same and do the same. Whether it's buttons in a menu, items in an inventory, or something else, you'll likely want the individual items to have different text or images and to do different things when interacted with. This is done by getting the various components and changing their properties. See the scripting reference for the Image and Text components, and for how to work with UnityEvents from scripting."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UIFitContentSize.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UIFitContentSize.html",
    "title": "Making UI elements fit the size of their content | mmo-rpg-unity",
    "keywords": "Making UI elements fit the size of their content Normally when positioning a UI element with its Rect Transform, its position and size is specified manually (optionally including behavior to stretch with the parent Rect Transform). However, sometimes you may want the rectangle to be automatically sized to fit the content of the UI element. This can be done by adding a component called Content Size Fitter. Fit to size of Text In order to make a Rect Transform with a Text component on it fit the text content, add a Content Size Fitter component to the same Game Object which has the Text component. Then set both the Horizontal Fit and Vertical Fit dropdowns to the Preferred setting. How does it work? What happens here is that the Text component functions as a Layout Element that can provide information about how big its minimum and preferred size is. In a manual layout this information is not used. A Content Size Fitter is a type of Layout Controller, which listens to layout information provided by Layout Elements and control the size of the Rect Transform according to this. Remember the pivot When UI elements are automatically resized to fit their content, you should pay extra attention to the pivot of the Rect Transform. The pivot will stay in place when the element is resized, so by setting the pivot position you can control in which direction the element will expand or shrink. For example, if the pivot is in the center, then the element will expand equally in all directions, and if the pivot is in the upper left corner, then the element will expand to the right and down. Fit to size of UI element with child Text If you have a UI element, such as a Button, that has a background image and a child Game Object with a Text component on it, you probably want the whole UI element to fit the size of the text - maybe with some padding. In order to do this, first add a Horizontal Layout Group to the UI element, then add a Content Size Fitter too. Set the Horizontal Fit, the Vertical Fit, or both to the Preferred setting. You can add and tweak padding using the padding property in the Horizontal Layout Group. Why use a Horizontal Layout Group? Well, it could have been a Vertical Layout Group as well - as long as there is only a single child, they produce the same result. How does it work? The Horizontal (or Vertical) Layout Group functions both as a Layout Controller and as a Layout Element. First it listens to the layout information provided by the children in the group - in this case the child Text. Then it determines how large the group must be (at minimum, and preferably) in order to be able to contain all the children, and it functions as a Layout Element that provides this information about its minimum and preferred size. The Content Size Fitter listens to layout information provided by any Layout Element on the same Game Object - in this case provided by the Horizontal (or Vertical) Layout Group. Depending on its settings, it then controls the size of the Rect Transform based on this information. Once the size of the Rect Transform has been set, the Horizontal (or Vertical) Layout Group makes sure to position and size its children according to the available space. See the page about the Horizontal Layout Group for more information about how it controls the positions and sizes of its children. Make children of a Layout Group fit their respective sizes If you have a Layout Group (horizontal or vertical) and want each of the UI elements in the group to fit their respective content, what do you do? You can't put a Content Size Fitter on each child. The reason is that the Content Size Fitter wants control over its own Rect Transform, but the parent Layout Group also wants control over the child Rect Transform. This creates a conflict and the result is undefined behavior. However, it isn't necessary either. The parent Layout Group can already make each child fit the size of the content. What you need to do is to disable the Child Force Expand toggles on the Layout Group. If the children are themselves Layout Groups too, you may need to disable the Child Force Expand toggles on those too. Once the children no longer expand with flexible width, their alignment can be specified in the Layout Group using the Child Alignment setting. What if you want some of the children to expand to fill additional available space, but not the other children? You can easily control this by adding a Layout Element component to the children you want to expand and enabling the Flexible Width or Flexible Height properties on those Layout Elements. The parent Layout Group should still have the Child Force Expand toggles disabled, otherwise all the children will expand flexibly. How does it work? A Game Object can have multiple components that each provide layout information about minimum, preferred and flexible sizes. A priority system determines which values take effect over others. The Layout Element component has a higher priority than the Text, Image, and Layout Group components, so it can be used to override any layout information values they provide. When the Layout Group listens to the layout information provided by the children, it will take the overridden flexible sizes into account. Then, when controlling the sizes of the children, it will not make them any bigger than their preferred sizes. However, if the Layout Group has the Child Force Expand option enabled, it will always make the flexible sizes of all the children be at least 1. More information This page has explained solutions to a few common use cases. For a more in depth explanation of the auto layout system, see the UI Auto Layout page."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UIMultiResolution.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UIMultiResolution.html",
    "title": "Designing UI for Multiple Resolutions | mmo-rpg-unity",
    "keywords": "Designing UI for Multiple Resolutions Modern games and applications often need to support a wide variety of different screen resolutions and particularly UI layouts need to be able to adapt to that. The UI System in Unity includes a variety of tools for this purpose that can be combined in various ways. In this how-to we're going to use a simple case study and look at and compare the different tools in the context of that. In our case study we have three buttons in the corners of the screen as shown below, and the goal is to adapt this layout to various resolutions. For this how-to we're going to consider four screen resolutions: Phone HD in portrait (640 x 960) and landscape (960 x 640) and Phone SD in portrait (320 x 480) and landscape (480 x 320). The layout is initially setup in the Phone HD Portrait resolution. Using anchors to adapt to different aspect ratios UI elements are by default anchored to the center of the parent rectangle. This means that they keep a constant offset from the center. If the resolution is changed to a landscape aspect ratio with this setup, the buttons may not even be inside the rectangle of the screen anymore. One way to keep the buttons inside the screen is to change the layout such that the locations of the buttons are tied to their respective corners of the screen. The anchors of the top left button can be set to the upper left corner using the Anchors Preset drop down in the Inspector, or by dragging the triangular anchor handles in the Scene View. It's best to do this while the current screen resolution set in the Game View is the one the layout is initially designed for, where the button placement looks correct. (See the UI Basic Layout page for more information on anchors.) Similarly, the anchors for the lower left and lower right buttons can be set to the lower left corner and lower right corner, respectively. Once the buttons have been anchored to their respective corners, they stick to them when changing the resolution to a different aspect ratio. When the screen size is changed to a larger or smaller resolution, the buttons will also remain anchored to their respective corners. However, since they keep their original size as specified in pixels, they may take up a larger or smaller proportion of the screen. This may or may not be desirable, depending on how you would like your layout to behave on screens of different resolutions. In this how-to, we know that the smaller resolutions of Phone SD Portrait and Landscape don't correspond to screens that are physically smaller, but rather just screens with a lower pixel density. On these lower-density screens the buttons shouldn't appear larger than on the high-density screens - they should instead appear with the same size. This means that the buttons should become smaller by the same percentage as the screen is smaller. In other words, the scale of the buttons should follow the screen size. This is where the Canvas Scaler component can help. Scaling with Screen Size The Canvas Scaler component can be added to a root Canvas - a Game Object with a Canvas component on it, which all the UI elements are children of. It is also added by default when creating a new Canvas through the GameObject menu. In the Canvas Scaler component, you can set its UI Scale Mode to Scale With Screen Size. With this scale mode you can specify a resolution to use as reference. If the current screen resolution is smaller or larger than this reference resolution, the scale factor of the Canvas is set accordingly, so all the UI elements are scaled up or down together with the screen resolution. In our case, we set the Canvas Scaler to be the Phone HD portrait resolution of 640 x 960. Now, when setting the screen resolution to the Phone SD portrait resolution of 320 x 480, the entire layout is scaled down so it appears proportionally the same as in full resolution. Everything is scaled down: The button sizes, their distances to the edges of the screen, the button graphics, and the text elements. This means that the layout will appear the same in the Phone SD portrait resolution as in Phone HD portrait; only with a lower pixel density. One thing to be aware of: After adding a Canvas Scaler component, it's important to also check how the layout looks at other aspect ratios. By setting the resolution back to Phone HD landscape, we can see that the buttons now appear bigger than they should (and used to). The reason for the larger buttons in landscape aspect ratio comes down to how the Canvas Scaler setting works. By default it compares the width or the current resolution with the width of the Canvas Scaler and the result is used as the scale factor to scale everything with. Since the current landscape resolution of 960 x 640 has a 1.5 times larger width than the portrait Canvas Scaler of 640 x 960, the layout is scaled up by 1.5. The component has a property called Match which can be 0 (Width), 1 (Height) or a value in between. By default it's set to 0, which compares the current screen width with the Canvas Scaler width as described. If the Match property is set to 0.5 instead, it will compare both the current width to the reference width and the current height to the reference height, and choose a scale factor that's in between the two. Since in this case the landscape resolution is 1.5 times wider but also 1.5 times shorter, those two factor even out and produce a final scale factor of 1, which means the buttons keep their original size. At this point the layout supports all the four screen resolutions using a combination of appropriate anchoring and the Canvas Scaler component on the Canvas. See the Canvas Scaler reference page for more information on different ways to scale UI elements in relation to different screen sizes."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UIScreenTransition.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UIScreenTransition.html",
    "title": "Creating Screen Transitions | mmo-rpg-unity",
    "keywords": "Creating Screen Transitions The need to transition between multiple UI screens is fairly common. In this page we will explore a simple way to create and manage those transitions using animation and State Machines to drive and control each screen. Overview The high-level idea is that each of our screens will have an Animator Controller with two states (Open and Closed) and a boolean Parameter (Open). To transition between screens you will only need to close the currently open Screen and open the desired one. To make this process easier we will create a small Class ScreenManager that will keep track and take care of closing any already open Screen for us. The button that triggers the transition will only have to ask the ScreenManager to open the desired screen. Thinking about Navigation If you plan to support controller/keyboard navigation of UI elements, then it's important to have a few things in mind. It's important to avoid having Selectable elements outside the screen since that would enable players to select offscreen elements, we can do that by deactivating any off-screen hierarchy. We also need to make sure when a new screen is shown we set a element from it as selected, otherwise the player would not be able to navigate to the new screen. We will take care of all that in the ScreenManager class below. Setting up the Animator Controller Let's take a look at the most common and minimal setup for the Animation Controller to do a Screen transition. The controller will need a boolean parameter (Open) and two states (Open and Closed), each state should have an animation with only one keyframe, this way we let the State Machine do the transition blending for us. Now we need to create the transition between both states, let's start with the transition from Open to Closed and let's set the condition properly, we want to go from Open to Closed when the parameter Open is set to false. Now we create the transition from Closed to Open and set the condition to go from Closed to Open when the parameter Open is true. Managing the screens With all the above set up, the only thing missing is for us to set the parameter Open to true on the screens Animator we want to transition to and Open to false on the currently open screens Animator. To do that, we will create a small script: using UnityEngine; using UnityEngine.UI; using UnityEngine.EventSystems; using System.Collections; using System.Collections.Generic; public class ScreenManager : MonoBehaviour { //Screen to open automatically at the start of the Scene public Animator initiallyOpen; //Currently Open Screen private Animator m_Open; //Hash of the parameter we use to control the transitions. private int m_OpenParameterId; //The GameObject Selected before we opened the current Screen. //Used when closing a Screen, so we can go back to the button that opened it. private GameObject m_PreviouslySelected; //Animator State and Transition names we need to check against. const string k_OpenTransitionName = \"Open\"; const string k_ClosedStateName = \"Closed\"; public void OnEnable() { //We cache the Hash to the \"Open\" Parameter, so we can feed to Animator.SetBool. m_OpenParameterId = Animator.StringToHash (k_OpenTransitionName); //If set, open the initial Screen now. if (initiallyOpen == null) return; OpenPanel(initiallyOpen); } //Closes the currently open panel and opens the provided one. //It also takes care of handling the navigation, setting the new Selected element. public void OpenPanel (Animator anim) { if (m_Open == anim) return; //Activate the new Screen hierarchy so we can animate it. anim.gameObject.SetActive(true); //Save the currently selected button that was used to open this Screen. (CloseCurrent will modify it) var newPreviouslySelected = EventSystem.current.currentSelectedGameObject; //Move the Screen to front. anim.transform.SetAsLastSibling(); CloseCurrent(); m_PreviouslySelected = newPreviouslySelected; //Set the new Screen as then open one. m_Open = anim; //Start the open animation m_Open.SetBool(m_OpenParameterId, true); //Set an element in the new screen as the new Selected one. GameObject go = FindFirstEnabledSelectable(anim.gameObject); SetSelected(go); } //Finds the first Selectable element in the providade hierarchy. static GameObject FindFirstEnabledSelectable (GameObject gameObject) { GameObject go = null; var selectables = gameObject.GetComponentsInChildren<Selectable> (true); foreach (var selectable in selectables) { if (selectable.IsActive () && selectable.IsInteractable ()) { go = selectable.gameObject; break; } } return go; } //Closes the currently open Screen //It also takes care of navigation. //Reverting selection to the Selectable used before opening the current screen. public void CloseCurrent() { if (m_Open == null) return; //Start the close animation. m_Open.SetBool(m_OpenParameterId, false); //Reverting selection to the Selectable used before opening the current screen. SetSelected(m_PreviouslySelected); //Start Coroutine to disable the hierarchy when closing animation finishes. StartCoroutine(DisablePanelDeleyed(m_Open)); //No screen open. m_Open = null; } //Coroutine that will detect when the Closing animation is finished and it will deactivate the //hierarchy. IEnumerator DisablePanelDeleyed(Animator anim) { bool closedStateReached = false; bool wantToClose = true; while (!closedStateReached && wantToClose) { if (!anim.IsInTransition(0)) closedStateReached = anim.GetCurrentAnimatorStateInfo(0).IsName(k_ClosedStateName); wantToClose = !anim.GetBool(m_OpenParameterId); yield return new WaitForEndOfFrame(); } if (wantToClose) anim.gameObject.SetActive(false); } //Make the provided GameObject selected //When using the mouse/touch we actually want to set it as the previously selected and //set nothing as selected for now. private void SetSelected(GameObject go) { //Select the GameObject. EventSystem.current.SetSelectedGameObject(go); //If we are using the keyboard right now, that's all we need to do. var standaloneInputModule = EventSystem.current.currentInputModule as StandaloneInputModule; if (standaloneInputModule != null) return; //Since we are using a pointer device, we don't want anything selected. //But if the user switches to the keyboard, we want to start the navigation from the provided game object. //So here we set the current Selected to null, so the provided gameObject becomes the Last Selected in the EventSystem. EventSystem.current.SetSelectedGameObject(null); } } Let's hook up this script, we do this by creating a new GameObject, we can rename it \"ScreenManager\" for instance, and add the component above to it. You can assign an initial screen to it, this screen will be open at the start of your scene. Now for the final part, let's make the UI buttons work. Select the button that should trigger the screen transition and add a new action under the On Click () list in the Inspector. Drag the ScreenManager GameObject we just created to the ObjectField, on the dropdown select ScreenManager->OpenPanel (Animator) and drag and drop the panel you want to open when the user clicks the button to the las ObjectField. Notes This technique only requires each screen to have an AnimatorController with an Open parameter and a Closed state to work - it doesn't matter how your screen or State Machine are constructed. This technique also works well with nested screens, meaning you only need one ScreenManager for each nested level. The State Machine we set up above has the default state of Closed, so all of the screens that use this controller start as closed. The ScreenManager provides an initiallyOpen property so you can specify which screen is shown first."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UIWorldSpace.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/HOWTO-UIWorldSpace.html",
    "title": "Creating a World Space UI | mmo-rpg-unity",
    "keywords": "Creating a World Space UI The UI system makes it easy to create UI that is positioned in the world among other 2D or 3D objects in the Scene. Start by creating a UI element (such as an Image) if you don't already have one in your scene by using GameObject > UI > Image. This will also create a Canvas for you. Set the Canvas to World Space Select your Canvas and change the Render Mode to World Space. Now your Canvas is already positioned in the World and can be seen by all cameras if they are pointed at it, but it is probably huge compared to other objects in your Scene. We'll get back to that. Decide on a resolution First you need to decide what the resolution of the Canvas should be. If it was an image, what should the pixel resolution of the image be? Something like 800x600 might be a good starting point. You enter the resolution in the Width and Height values of the Rect Transform of the Canvas. It's probably a good idea to set the position to 0,0 at the same time. Specify the size of the Canvas in the world Now you should consider how big the Canvas should be in the world. You can use the Scale tool to simply scale it down until it has a size that looks good, or you can decide how big it should be in meters. If you want it to have a specific width in meters, you can can calculate the needed scale by using meter_size / canvas_width. For example, if you want it to be 2 meters wide and the Canvas width is 800, you would have 2 / 800 = 0.0025. You then set the Scale property of the Rect Transform on the Canvas to 0.0025 for both X, Y, and Z in order to ensure that it's uniformly scaled. Another way to think of it is that you are controlling the size of one pixel in the Canvas. If the Canvas is scaled by 0.0025, then that is also the size in the world of each pixel in the Canvas. Position the Canvas Unlike a Canvas set to Screen Space, a World Space Canvas can be freely positioned and rotated in the Scene. You can put a Canvas on any wall, floor, ceiling, or slanted surface (or hanging freely in the air of course). Just use the normal Translate and Rotate tools in the toolbar. Create the UI Now you can begin setting up your UI elements and layouts the same way you would with a Screen Space Canvas."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/InputModules.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/InputModules.html",
    "title": "Input Modules | mmo-rpg-unity",
    "keywords": "Input Modules An Input Module is where the main logic of an event system can be configured and customized. Out of the box there are two provided Input Modules, one designed for Standalone, and one designed for Touch input. Each module receives and dispatches events as you would expect on the given configuration. Input modules are where the 'business logic' of the Event System take place. When the Event System is enabled it looks at what Input Modules are attached and passes update handling to the specific module. Input modules are designed to be extended or modified based on the input systems that you wish to support. Their purpose is to map hardware specific input (such as touch, joystick, mouse, motion controller) into events that are sent via the messaging system. The built in Input Modules are designed to support common game configurations such as touch input, controller input, keyboard input, and mouse input. They send a variety of events to controls in the application, if you implement the specific interfaces on your MonoBehaviours. All of the UI components implement the interfaces that make sense for the given component."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/MessagingSystem.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/MessagingSystem.html",
    "title": "Messaging System | mmo-rpg-unity",
    "keywords": "Messaging System The new UI system uses a messaging system designed to replace SendMessage. The system is pure C# and aims to address some of the issues present with SendMessage. The system works using custom interfaces that can be implemented on a MonoBehaviour to indicate that the component is capable of receiving a callback from the messaging system. When the call is made a target GameObject is specified; the call will be issued on all components of the GameObject that implement the specified interface that the call is to be issued against. The messaging system allows for custom user data to be passed, as well as how far through the GameObject hierarchy the event should propagate; that is should it just execute for the specified GameObject, or should it also execute on children and parents. In addition to this the messaging framework provides helper functions to search for and find GameObjects that implement a given messaging interface. The messaging system is generic and designed for use not just by the UI system but also by general game code. It is relatively trivial to add custom messaging events and they will work using the same framework that the UI system uses for all event handling. Defining A Custom Message If you wish to define a custom message it is relatively simple. In the UnityEngine.EventSystems namespace there is a base interface called 'IEventSystemHandler'. Anything that extends from this can be considered as a target for receiving events via the messaging system. public interface ICustomMessageTarget : IEventSystemHandler { // functions that can be called via the messaging system void Message1(); void Message2(); } Once this interface is defined then it can be implemented by a MonoBehaviour. When implemented it defines the functions that will be executed if the given message is issued against this MonoBehaviours GameObject. public class CustomMessageTarget : MonoBehaviour, ICustomMessageTarget { public void Message1() { Debug.Log (\"Message 1 received\"); } public void Message2() { Debug.Log (\"Message 2 received\"); } } Now that a script exists that can receive the message we need to issue the message. Normally this would be in response to some loosely coupled event that occurs. For example, in the UI system we issue events for such things as PointerEnter and PointerExit, as well as a variety of other things that can happen in response to user input into the application. To send a message a static helper class exists to do this. As arguments it requires a target object for the message, some user specific data, and a functor that maps to the specific function in the message interface you wish to target. ExecuteEvents.Execute<ICustomMessageTarget>(target, null, (x,y)=>x.Message1()); This code will execute the function Message1 on any components on the GameObject target that implement the ICustomMessageTarget interface. The scripting documentation for the ExecuteEvents class covers other forms of the Execute functions, such as Executing in children or in parents."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/Raycasters.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/Raycasters.html",
    "title": "Raycasters | mmo-rpg-unity",
    "keywords": "Raycasters The Event System needs a method for detecting where current input events need to be sent to, and this is provided by the Raycasters. Given a screen space position they will collect all potential targets, figure out if they are under the given position, and then return the object that is closest to the screen. There are a few types of Raycasters that are provided: Graphic Raycaster - Used for UI elements, lives on a Canvas and searches within the canvas Physics 2D Raycaster - Used for 2D physics elements Physics Raycaster - Used for 3D physics elements When a Raycaster is present and enabled in the scene it will be used by the Event System whenever a query is issued from an Input Module. If multiple Raycasters are used then they will all have casting happen against them and the results will be sorted based on distance to the elements."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/StyledText.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/StyledText.html",
    "title": "Rich Text | mmo-rpg-unity",
    "keywords": "Rich Text The text for UI elements and text meshes can incorporate multiple font styles and sizes. Rich text is supported both for the UI System and the legacy GUI system. The Text, GUIStyle, GUIText and TextMesh classes have a Rich Text setting which instructs Unity to look for markup tags within the text. The Debug.Log function can also use these markup tags to enhance error reports from code. The tags are not displayed but indicate style changes to be applied to the text. Markup format The markup system is inspired by HTML but isn't intended to be strictly compatible with standard HTML. The basic idea is that a section of text can be enclosed inside a pair of matching tags:- We are <b>not</b> amused. As the example shows, the tags are just pieces of text inside the \"angle bracket\" characters, < and >. You place the opening tag at the beginning of the section. The text inside the tag denotes its name (which in this case is just b). You place another tag at the end of the section. This is the closing tag. It has the same name as the opening tag, but the name is prefixed with a slash / character. Every opening tag must have a corresponding closing tag. If you don't close an opening tag, it is rendered as regular text. The tags are not displayed to the user directly but are interpreted as instructions for styling the text they enclose. The b tag used in the example above applies boldface to the word \"not\", so the text appears ons creen as:- We are not amused A marked up section of text (including the tags that enclose it) is referred to as an element. Nested elements It is possible to apply more than one style to a section of text by \"nesting\" one element inside another We are <b><i>definitely not</i></b> amused The <i> tag applies italic style, so this would be presented onscreen as We are definitely not amused Note the ordering of the closing tags, which is in reverse to that of the opening tags. The reason for this is perhaps clearer when you consider that the inner tags need not span the whole text of the outermost element We are <b>absolutely <i>definitely</i> not</b> amused which gives We are absolutely definitely not amused Tag parameters Some tags have a simple all-or-nothing effect on the text but others might allow for variations. For example, the color tag needs to know which color to apply. Information like this is added to tags by the use of parameters:- We are <color=green>green</color> with envy Which produces this result: Note that the ending tag doesn't include the parameter value. Optionally, the value can be surrounded by quotation marks but this isn't required. Tag parameters cannot include blank spaces. For example: We are <color = green>green</color> with envy does not work because of the spaces to either side of the = character. Supported tags The following list describes all the styling tags supported by Unity. Tag Description Example Notes b Renders the text in boldface. We are <b>not</b> amused. i Renders the text in italics. We are <i>usually</i> not amused. size Sets the size of the text according to the parameter value, given in pixels. We are <size=50>largely</size> unaffected. Although this tag is available for Debug.Log, you will find that the line spacing in the window bar and Console looks strange if the size is set too large. color Sets the color of the text according to the parameter value. The color can be specified in the traditional HTML format. #rrggbbaa ...where the letters correspond to pairs of hexadecimal digits denoting the red, green, blue and alpha (transparency) values for the color. For example, cyan at full opacity would be specified by color=#00ffffff... You can specify hexadecimal values in uppercase or lowercase; #FF0000 is equivalent to #ff0000. We are <color=#ff0000ff>colorfully</color> amused Another option is to use the name of the color. This is easier to understand but naturally, the range of colors is limited and full opacity is always assumed. <color=cyan>some text</color> The available color names are given in the table below. material This is only useful for text meshes and renders a section of text with a material specified by the parameter. The value is an index into the text mesh's array of materials as shown by the inspector. We are <material=2>texturally</material> amused quad This is only useful for text meshes and renders an image inline with the text. It takes parameters that specify the material to use for the image, the image height in pixels, and a further four that denote a rectangular area of the image to display. Unlike the other tags, quad does not surround a piece of text and so there is no ending tag - the slash character is placed at the end of the initial tag to indicate that it is \"self-closing\". <quad material=1 size=20 x=0.1 y=0.1 width=0.5 height=0.5> This selects the material at position in the renderer's material array and sets the height of the image to 20 pixels. The rectangular area of image starts at given by the x, y, width and height values, which are all given as a fraction of the unscaled width and height of the texture. Supported colors The following table lists colors for which you can use a name instead of a hexadecimal tag in the <color> rich text tag. Color name Hex value Swatch aqua (same as cyan) #00ffffff black #000000ff blue #0000ffff brown #a52a2aff cyan (same as aqua) #00ffffff darkblue #0000a0ff fuchsia (same as magenta) #ff00ffff green #008000ff grey #808080ff lightblue #add8e6ff lime #00ff00ff magenta (same as fuchsia) #ff00ffff maroon #800000ff navy #000080ff olive #808000ff orange #ffa500ff purple #800080ff red #ff0000ff silver #c0c0c0ff teal #008080ff white #ffffffff yellow #ffff00ff Editor GUI Rich text is disabled by default in the editor GUI system but it can be enabled explicitly using a custom GUIStyle. The richText property should be set to true and the style passed to the GUI function in question: GUIStyle style = new GUIStyle (); style.richText = true; GUILayout.Label(\"<size=30>Some <color=yellow>RICH</color> text</size>\",style);"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/SupportedEvents.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/SupportedEvents.html",
    "title": "Supported Events | mmo-rpg-unity",
    "keywords": "Supported Events The Event System supports a number of events, and they can be customized further in user custom user written Input Modules. The events that are supported by the Standalone Input Module and Touch Input Module are provided by interface and can be implemented on a MonoBehaviour by implementing the interface. If you have a valid Event System configured the events will be called at the correct time. IPointerEnterHandler - OnPointerEnter - Called when a pointer enters the object IPointerExitHandler - OnPointerExit - Called when a pointer exits the object IPointerDownHandler - OnPointerDown - Called when a pointer is pressed on the object IPointerUpHandler- OnPointerUp - Called when a pointer is released (called on the GameObject that the pointer is clicking) IPointerClickHandler - OnPointerClick - Called when a pointer is pressed and released on the same object IInitializePotentialDragHandler - OnInitializePotentialDrag - Called when a drag target is found, can be used to initialize values IBeginDragHandler - OnBeginDrag - Called on the drag object when dragging is about to begin IDragHandler - OnDrag - Called on the drag object when a drag is happening IEndDragHandler - OnEndDrag - Called on the drag object when a drag finishes IDropHandler - OnDrop - Called on the object where a drag finishes IScrollHandler - OnScroll - Called when a mouse wheel scrolls IUpdateSelectedHandler - OnUpdateSelected - Called on the selected object each tick ISelectHandler - OnSelect - Called when the object becomes the selected object IDeselectHandler - OnDeselect - Called on the selected object becomes deselected IMoveHandler - OnMove - Called when a move event occurs (left, right, up, down) ISubmitHandler - OnSubmit - Called when the submit button is pressed ICancelHandler - OnCancel - Called when the cancel button is pressed"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Unity UI: Unity User Interface Canvas Basic Layout Visual Components Interaction Components Animation Integration Auto Layout Rich Text Events MessagingSystem InputModules SupportedEvents Raycasters Reference Rect Transform Canvas Components Canvas Canvas Scaler Canvas Group Canvas Renderer Visual UIInteractionComponents Text Image Raw Image Mask RectMask2D UI Effect Components Shadow Outline Position as UV1 Interaction Components Selectable Base Class Transition Options Navigation Options Button Toggle Toggle Group Slider Scrollbar Dropdown Input Field Scroll Rect Auto Layout Layout Element Content Size Fitter Aspect Ratio Fitter Horizontal Layout Group Vertical Layout Group Grid Layout Group Events script-EventSystem script-GraphicRaycaster script-PhysicsRaycaster script-Physics2DRaycaster script-StandaloneInputModule script-TouchInputModule script-EventTrigger UI How Tos Designing UI for Multiple Resolutions Making UI elements fit the size of their content Creating a World Space UI Creating UI elements from scripting Creating Screen Transitions"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIAnimationIntegration.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIAnimationIntegration.html",
    "title": "Animation Integration | mmo-rpg-unity",
    "keywords": "Animation Integration Animation allows for each transition between control states to be fully animated using Unity's animation system. This is the most powerful of the transition modes due to the number of properties that can be animated simultaneously. To use the Animation transition mode, an Animator Component needs to be attached to the controller element. This can be done automatically by clicking \"Auto Generate Animation\". This also generates an Animator Controller with states already set up, which will need to be saved. The new Animator controller is ready to use straight away. Unlike most Animator Controllers, this controller also stores the animations for the controller's transitions and these can be customised, if desired. For example, if a Button element with an Animator controller attached is selected, the animations for each of the button's states can be edited by opening the Animation window (Window>Animation). There is an Animation Clip pop-up menu to select the desired clip. Choose from \"Normal\", \"Highlighted\", \"Pressed\" and \"Disabled\". The Normal State is set by the values on button element itself and can be left empty. On all other states, the most common configuration is a single keyframe at the start of the timeline. The transition animation between states will be handled by the Animator. As an example, the width of the button in the Highlighted State could be changed by selecting the Highlighted state from the Animation Clip pop up menu and with the playhead at the start of the time line: Select the record Button Change the width of the Button in the inspector Exit the record mode. Change to play mode to see how the button grows when highlighted. Any number of properties can have their parameters set in this one keyframe. Several buttons can share the same behaviour by sharing Animator Controllers. The UI Animation transition mode is not compatible with Unity's legacy animation system. You should only use the Animator Component."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIAutoLayout.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIAutoLayout.html",
    "title": "Auto Layout | mmo-rpg-unity",
    "keywords": "Auto Layout The Rect Transform layout system is flexible enough to handle a lot of different types of layouts and it also allows placing elements in a complete freeform fashion. However, sometimes something a bit more structured can be needed. The auto layout system provides ways to place elements in nested layout groups such as horizontal groups, vertical groups, or grids. It also allows elements to automatically be sized according to the contained content. For example a button can be dynamically resized to exactly fit its text content plus some padding. The auto layout system is a system built on top of the basic Rect Transform layout system. It can optionally be used on some or all elements. Understanding Layout Elements The auto layout system is based on a concept of layout elements and layout controllers. A layout element is an Game Object with a Rect Transform and optionally other components as well. The layout element has certain knowledge about which size it should have. Layout elements don't directly set their own size, but other components that function as layout controllers can use the information they provide in order to calculate a size to use for them. A layout element has properties that defines its own: Minimum width Minimum height Preferred width Preferred height Flexible width Flexible height Examples of layout controller components that use the information provided by layout elements are Content Size Fitter and the various Layout Group components. The basic principles for how layout elements in a layout group are sized is as follows: First minimum sizes are allocated. If there is sufficient available space, preferred sizes are allocated. If there is additional available space, flexible size is allocated. Any Game Object with a Rect Transform on it can function as a layout element. They will by default have minimum, preferred, and flexible sizes of 0. Certain components will change these layout properties when added to the Game Object. The Image and Text components are two examples of components that provide layout element properties. They change the preferred width and height to match the sprite or text content. Layout Element Component If you want to override the minimum, preferred, or flexible size, you can do that by adding a Layout Element component to the Game Object. The Layout Element component lets you override the values for one or more of the layout properties. Enable the checkbox for a property you want to override and then specify the value you want to override with. See the reference page for Layout Element for more information. Understanding Layout Controllers Layout controllers are components that control the sizes and possibly positions of one or more layout elements, meaning Game Objects with Rect Transforms on. A layout controller may control its own layout element (the same Game Object it is on itself) or it may control child layout elements. A component that functions as a layout controller may also itself function as a layout element at the same time. Content Size Fitter The Content Size Fitter functions as a layout controller that controls the size of its own layout element. The simplest way to see the auto layout system in action is to add a Content Size Fitter component to a Game Object with a Text component. If you set either the Horizontal Fit or Vertical Fit to Preferred, the Rect Transform will adjust its width and/or height to fit the Text content. See the reference page for Content Size Fitter for more information. Aspect Ratio Fitter The Aspect Ratio Fitter functions as a layout controller that controls the size of its own layout element. It can adjust the height to fit the width or vice versa, or it can make the element fit inside its parent or envelope its parent. The Aspect Ratio Fitter does not take layout information into account such as minimum size and preferred size. See the reference page for Aspect Ratio Fitter for more information. Layout Groups A layout group functions as a layout controller that controls the sizes and positions of its child layout elements. For example, a Horizontal Layout Group places its children next to each other, and a Grid Layout Group places its children in a grid. A layout group doesn't control its own size. Instead it functions as a layout element itself which may be controlled by other layout controllers or be set manually. Whatever size a layout group is allocated, it will in most cases try to allocate an appropriate amount of space for each of its child layout elements based on the minimum, preferred, and flexible sizes they reported. Layout groups can also be nested arbitrarily this way. See the reference pages for Horizontal Layout Group, Vertical Layout Group and Grid Layout Group for more information. Driven Rect Transform properties Since a layout controller in the auto layout system can automatically control the sizes and placement of certain UI elements, those sizes and positions should not be manually edited at the same time through the Inspector or Scene View. Such changed values would just get reset by the layout controller on the next layout calculation anyway. The Rect Transform has a concept of driven properties to address this. For example, a Content Size Fitter which has the Horizontal Fit property set to Minimum or Preferred will drive the width of the Rect Transform on the same Game Object. The width will appear as read-only and a small info box at the top of the Rect Transform will inform that one or more properties are driven by Conten Size Fitter. The driven Rect Transforms properties have other reasons beside preventing manual editing. A layout can be changed just by changing the resolution or size of the Game View. This in turn can change the size or placement of layout elements, which changes the values of driven properties. But it wouldn't be desirable that the Scene is marked as having unsaved changes just because the Game View was resized. To prevent this, the values of driven properties are not saved as part of the Scene and changes to them do not mark the scene as changed. Technical Details The auto layout system comes with certain components built-in, but it is also possible to create new components that controls layouts in custom ways. This is done by having a component implement specific interfaces which are recognized by the auto layout system. Layout Interfaces A component is treated as a layout element by the auto layout system if it implements the interface ILayoutElement. A component is expected to drive the Rect Transforms of its children if it implements the interface ILayoutGroup. A component is expected to drive its own RectTransform if it implements the interface ILayoutSelfController. Layout Calculations The auto layout system evaluates and executes layouts in the following order: The minimum, preferred, and flexible widths of layout elements are calculated by calling CalculateLayoutInputHorizontal on ILayoutElement components. This is performed in bottom-up order, where children are calculated before their parents, such that the parents may take the information in their children into account in their own calculations. The effective widths of layout elements are calculated and set by calling SetLayoutHorizontal on ILayoutController components. This is performed in top-down order, where children are calculated after their parents, since allocation of child widths needs to be based on the full width available in the parent. After this step the Rect Transforms of the layout elements have their new widths. The minimum, preferred, and flexible heights of layout elements are calculated by calling CalculateLayoutInputVertical on ILayoutElement components. This is performed in bottom-up order, where children are calculated before their parents, such that the parents may take the information in their children into account in their own calculations. The effective heights of layout elements are calculated and set by calling SetLayoutVertical on ILayoutController components. This is performed in top-down order, where children are calculated after their parents, since allocation of child heights needs to be based on the full height available in the parent. After this step the Rect Transforms of the layout elements have their new heights. As can be seen from the above, the auto layout system evaluates widths first and then evaluates heights afterwards. Thus, calculated heights may depend on widths, but calculated widths can never depend on heights. Triggering Layout Rebuild When a property on a component changes which can cause the current layout to no longer be valid, a layout recalculation is needed. This can be triggered using the call: LayoutRebuilder.MarkLayoutForRebuild (transform as RectTransform); The rebuild will not happen immediately, but at the end of the current frame, just before rendering happens. The reason it is not immediate is that this would cause layouts to be potentially rebuild many times during the same frame, which would be bad for performance. Guidelines for when a rebuild should be triggered: In setters for properties that can change the layout. In these callbacks: OnEnable OnDisable OnRectTransformDimensionsChange OnValidate (only needed in the editor, not at runtime) OnDidApplyAnimationProperties"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIBasicLayout.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIBasicLayout.html",
    "title": "Basic Layout | mmo-rpg-unity",
    "keywords": "Basic Layout In this section we'll look at how you can position UI elements relative to the Canvas and each other. If you want to test yourself while reading, you can create an Image using the menu GameObject -> UI -> Image. The Rect Tool Every UI element is represented as a rectangle for layout purposes. This rectangle can be manipulated in the Scene View using the Rect Tool in the toolbar. The Rect Tool is used both for Unity's 2D features and for UI, and in fact can be used even for 3D objects as well. The Rect Tool can be used to move, resize and rotate UI elements. Once you have selected a UI element, you can move it by clicking anywhere inside the rectangle and dragging. You can resize it by clicking on the edges or corners and dragging. The element can be rotated by hovering the cursor slightly away from the corners until the mouse cursor looks like a rotation symbol. You can then click and drag in either direction to rotate. Just like the other tools, the Rect Tool uses the current pivot mode and space, set in the toolbar. When working with UI it's usually a good idea to keep those set to Pivot and Local. Rect Transform The Rect Transform is a new transform component that is used for all UI elements instead of the regular Transform component. Rect Transforms have position, rotation, and scale just like regular Transforms, but it also has a width and height, used to specify the dimensions of the rectangle. Resizing Versus Scaling When the Rect Tool is used to change the size of an object, normally for Sprites in the 2D system and for 3D objects it will change the local scale of the object. However, when it's used on an object with a Rect Transform on it, it will instead change the width and the height, keeping the local scale unchanged. This resizing will not affect font sizes, border on sliced images, and so on. Pivot Rotations, size, and scale modifications occur around the pivot so the position of the pivot affects the outcome of a rotation, resizing, or scaling. When the toolbar Pivot button is set to Pivot mode, the pivot of a Rect Transform can be moved in the Scene View. Anchors Rect Transforms include a layout concept called anchors. Anchors are shown as four small triangular handles in the Scene View and anchor information is also shown in the Inspector. If the parent of a Rect Transform is also a Rect Transform, the child Rect Transform can be anchored to the parent Rect Transform in various ways. For example, the child can be anchored to the center of the parent, or to one of the corners. The anchoring also allows the child to stretch together with the width or height of the parent. Each corner of the rectangle has a fixed offset to its corresponding anchor, i.e. the top left corner of the rectangle has a fixed offset to the top left anchor, etc. This way the different corners of the rectangle can be anchored to different points in the parent rectangle. The positions of the anchors are defined in fractions (or percentages) of the parent rectangle width and height. 0.0 (0%) corresponds to the left or bottom side, 0.5 (50%) to the middle, and 1.0 (100%) to the right or top side. But anchors are not limited to the sides and middle; they can be anchored to any point within the parent rectangle. You can drag each of the anchors individually, or if they are together, you can drag them together by clicking in the middle in between them and dragging. If you hold down Shift key while dragging an anchor, the corresponding corner of the rectangle will move together with the anchor. A useful feature of the anchor handles is that they automatically snap to the anchors of sibling rectangles to allow for precise positioning. Anchor presets In the Inspector, the Anchor Preset button can be found in the upper left corner of the Rect Transform component. Clicking the button brings up the Anchor Presets dropdown. From here you can quickly select from some of the most common anchoring options. You can anchor the UI element to the sides or middle of the parent, or stretch together with the parent size. The horizontal and vertical anchoring is independent. The Anchor Presets buttons displays the currently selected preset option if there is one. If the anchors on either the horizontal or vertical axis are set to different positions than any of the presets, the custom options is shown. Anchor and position fields in the Inspector You can click the Anchors expansion arrow to reveal the anchor number fields if they are not already visible. Anchor Min corresponds to the lower left anchor handle in the Scene View, and Anchor Max corresponds to the upper right handle. The position fields of rectangle are shown differently depending on whether the anchors are together (which produces a fixed width and height) or separated (which causes the rectangle to stretch together with the parent rectangle). When all the anchor handles are together the fields displayed are Pos X, Pos Y, Width and Height. The Pos X and Pos Y values indicate the position of the pivot relative to the anchors. When the anchors are separated the fields can change partially or completely to Left, Right, Top and Bottom. These fields define the padding inside the rectangle defined by the anchors. The Left and Right fields are used if the anchors are separated horizontally and the Top and Bottom fields are used if they are separated vertically. Note that changing the values in the anchor or pivot fields will normally counter-adjust the positioning values in order to make the rectangle stay in place. In cases where this is not desired, enable Raw edit mode by clicking the R button in the Inspector. This causes the anchor and pivot value to be able to be changed without any other values changing as a result. This will likely cause the rectangle to be visually moved or resized, since its position and size is dependent on the anchor and pivot values."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UICanvas.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UICanvas.html",
    "title": "Canvas | mmo-rpg-unity",
    "keywords": "Canvas The Canvas is the area that all UI elements should be inside. The Canvas is a Game Object with a Canvas component on it, and all UI elements must be children of such a Canvas. Creating a new UI element, such as an Image using the menu GameObject > UI > Image, automatically creates a Canvas, if there isn't already a Canvas in the scene. The UI element is created as a child to this Canvas. The Canvas area is shown as a rectangle in the Scene View. This makes it easy to position UI elements without needing to have the Game View visible at all times. Canvas uses the EventSystem object to help the Messaging System. Draw order of elements UI elements in the Canvas are drawn in the same order they appear in the Hierarchy. The first child is drawn first, the second child next, and so on. If two UI elements overlap, the later one will appear on top of the earlier one. To change which element appear on top of other elements, simply reorder the elements in the Hierarchy by dragging them. The order can also be controlled from scripting by using these methods on the Transform component: SetAsFirstSibling, SetAsLastSibling, and SetSiblingIndex. Render Modes The Canvas has a Render Mode setting which can be used to make it render in screen space or world space. Screen Space - Overlay This render mode places UI elements on the screen rendered on top of the scene. If the screen is resized or changes resolution, the Canvas will automatically change size to match this. Screen Space - Camera This is similar to Screen Space - Overlay, but in this render mode the Canvas is placed a given distance in front of a specified Camera. The UI elements are rendered by this camera, which means that the Camera settings affect the appearance of the UI. If the Camera is set to Perspective, the UI elements will be rendered with perspective, and the amount of perspective distortion can be controlled by the Camera Field of View. If the screen is resized, changes resolution, or the camera frustum changes, the Canvas will automatically change size to match as well. World Space In this render mode, the Canvas will behave as any other object in the scene. The size of the Canvas can be set manually using its Rect Transform, and UI elements will render in front of or behind other objects in the scene based on 3D placement. This is useful for UIs that are meant to be a part of the world. This is also known as a \"diegetic interface\"."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIHowTos.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIHowTos.html",
    "title": "UI How Tos | mmo-rpg-unity",
    "keywords": "UI How Tos In this section you can learn about solutions to common UI tasks."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIInteractionComponents.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIInteractionComponents.html",
    "title": "Interaction Components | mmo-rpg-unity",
    "keywords": "Interaction Components This section covers components in the UI system that handles interaction, such as mouse or touch events and interaction using a keyboard or controller. The interaction components are not visible on their own, and must be combined with one or more visual components in order to work correctly. Common Functionality Most of the interaction components have some things in common. They are selectables, which means they have shared built-in functionality for visualising transitions between states (normal, highlighted, pressed, disabled), and for navigation to other selectables using keyboard or controller. This shared functionality is described on the Selectable page. The interaction components have at least one UnityEvent that is invoked when user interacts with the component in specific way. The UI system catches and logs any exceptions that propagate out of code attached to UnityEvent. Button A Button has an OnClick UnityEvent to define what it will do when clicked. See the Button page for details on using the Button component. Toggle A Toggle has an Is On checkbox that determines whether the Toggle is currently on or off. This value is flipped when the user clicks the Toggle, and a visual checkmark can be turned on or off accordingly. It also has an OnValueChanged UnityEvent to define what it will do when the value is changed. See the Toggle page for details on using the Toggle component. Toggle Group A Toggle Group can be used to group a set of Toggles that are mutually exclusive. Toggles that belong to the same group are constrained so that only one of them can be selected at a time - selecting one of them automatically deselects all the others. See the Toggle Group page for details on using the Toggle Group component. Slider A Slider has a decimal number Value that the user can drag between a minimum and maximum value. It can be either horizontal or vertical. It also has a OnValueChanged UnityEvent to define what it will do when the value is changed. See the Slider page for details on using the Slider component. Scrollbar A Scrollbar has a decimal number Value between 0 and 1. When the user drags the scrollbar, the value changes accordingly. Scrollbars are often used together with a Scroll Rect and a Mask to create a scroll view. The Scrollbar has a Size value between 0 and 1 that determines how big the handle is as a fraction of the entire scrollbar length. This is often controlled from another component to indicate how big a proportion of the content in a scroll view is visible. The Scroll Rect component can automatically do this. The Scrollbar can be either horizontal or vertical. It also has a OnValueChanged UnityEvent to define what it will do when the value is changed. See the Scrollbar page for details on using the Scrollbar component. Dropdown A Dropdown has a list of options to choose from. A text string and optionally an image can be specified for each option, and can be set either in the Inspector or dynamically from code. It has a OnValueChanged UnityEvent to define what it will do when the currently chosen option is changed. See the Dropdown page for details on using the Dropdown component. Input Field An Input Field is used to make the text of a Text Element editable by the user. It has a UnityEvent to define what it will do when the text content is changed, and an another to define what it will do when the user has finished editing it. See the Input Field page for details on using the Input Field component. Scroll Rect (Scroll View) A Scroll Rect can be used when content that takes up a lot of space needs to be displayed in a small area. The Scroll Rect provides functionality to scroll over this content. Usually a Scroll Rect is combined with a Mask in order to create a scroll view, where only the scrollable content inside the Scroll Rect is visible. It can also additionally be combined with one or two Scrollbars that can be dragged to scroll horizontally or vertically. See the Scroll Rect page for details on using the Scroll Rect component."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIReference.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIReference.html",
    "title": "UI Reference | mmo-rpg-unity",
    "keywords": "UI Reference This section goes into more depth about Unity’s UI features."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIVisualComponents.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/UIVisualComponents.html",
    "title": "Visual Components | mmo-rpg-unity",
    "keywords": "Visual Components With the introduction of the UI system, new Components have been added that will help you create GUI specific functionality. This section will cover the basics of the new Components that can be created. Text The Text component, which is also known as a Label, has a Text area for entering the text that will be displayed. It is possible to set the font, font style, font size and whether or not the text has rich text capability. There are options to set the alignment of the text, settings for horizontal and vertical overflow which control what happens if the text is larger than the width or height of the rectangle, and a Best Fit option that makes the text resize to fit the available space. Image An Image has a Rect Transform component and an Image component. A sprite can be applied to the Image component under the Target Graphic field, and its colour can be set in the Color field. A material can also be applied to the Image component. The Image Type field defines how the applied sprite will appear, the options are: Simple - Scales the whole sprite equally. Sliced - Utilises the 3x3 sprite division so that resizing does not distort corners and only the center part is stretched. Tiled - Similar to Sliced, but tiles (repeats) the center part rather than stretching it. For sprites with no borders at all, the entire sprite is tiled. Filled - Shows the sprite in the same way as Simple does except that it fills in the sprite from an origin in a defined direction, method and amount. The option to Set Native Size, which is shown when Simple or Filled is selected, resets the image to the original sprite size. Images can be imported as UI sprites by selecting Sprite( 2D / UI) from the 'Texture Type' settings. Sprites have extra import settings compared to the old GUI sprites, the biggest difference is the addition of the sprite editor. The sprite editor provides the option of 9-slicing the image, this splits the image into 9 areas so that if the sprite is resized the corners are not stretched or distorted. Raw Image The Image component takes a sprite but Raw Image takes a texture (no borders etc). Raw Image should only be used if necessary otherwise Image will be suitable in the majority of cases. Mask A Mask is not a visible UI control but rather a way to modify the appearance of a control’s child elements. The mask restricts (ie, “masks”) the child elements to the shape of the parent. So, if the child is larger than the parent then only the part of the child that fits within the parent will be visible. Effects Visual components can also have various simple effects applied, such as a simple drop shadow or outline. See the UI Effects reference page for more information."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/class-Canvas.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/class-Canvas.html",
    "title": "Canvas | mmo-rpg-unity",
    "keywords": "Canvas The Canvas component represents the abstract space in which the UI is laid out and rendered. All UI elements must be children of a GameObject that has a Canvas component attached. When you create a UI element object from the menu (GameObject > Create UI), a Canvas object will be created automatically if there isn't one in the scene already. Properties Property: Function: Render Mode The way the UI is rendered to the screen or as an object in 3D space (see below). The options are Screen Space - Overlay, Screen Space - Camera and World Space. Pixel Perfect (Screen Space modes only) Should the UI be rendered without antialiasing for precision? Render Camera (Screen Space - Camera mode only) The camera to which the UI should be rendered (see below). Plane Distance (Screen Space - Camera mode only) The distance at which the UI plane should be placed in front of the camera. Event Camera (World Space mode only) The camera that will be used to process UI events. Receives Events Are UI events processed by this Canvas? Details A single Canvas for all UI elements is sufficient but multiple Canvases in the scene is possible. It is also possible use nested Canvases, where one Canvas is placed as a child of another for optimization purposes. A nested Canvas uses the same Render Mode as its parent. Traditionally, UIs are rendered as if they were simple graphic designs drawn directly on the screen. That is to say, they have no concept of a 3D space being viewed by a camera. Unity supports this kind of screen space rendering but also allows UIs to rendered as objects in the scene, depending on the value of the Render Mode property. The modes available are Screen Space - Overlay, Screen Space - Camera and World Space. Screen Space - Overlay In this mode, the Canvas is scaled to fit the screen and then rendered directly without reference to the scene or a camera (the UI will be rendered even if there is no camera in the scene at all). If the screen's size or resolution are changed then the UI will automatically rescale to fit. The UI will be drawn over any other graphics such as the camera view. Note: The Screen Space - Overlay canvas needs to be stored at the top level of the hierarchy. If this is not used then the UI may disappear from the view. This is a built-in limitation. Keep the Screen Space - Overlay canvas at the top level of the hierarchy to get expected results. Screen Space - Camera In this mode, the Canvas is rendered as if it were drawn on a plane object some distance in front of a given camera. The onscreen size of the UI does not vary with the distance since it is always rescaled to fit exactly within the camera frustum. If the screen's size or resolution or the camera frustum are changed then the UI will automatically rescale to fit. Any 3D objects in the scene that are closer to the camera than the UI plane will be rendered in front of the UI, while objects behind the plane will be obscured. World Space This mode renders the UI as if it were a plane object in the scene. Unlike Screen Space - Camera mode, however, the plane need not face the camera and can be oriented however you like. The size of the Canvas can be set using its Rect Transform but its onscreen size will depend on the viewing angle and distance of the camera. Other scene objects can pass behind, through or in front of the Canvas. Hints Read more about setting up a World Space Canvas on the Creating a World Space UI page. For information about making your Canvas and UI scale to different resolutions or aspect ratios, see the Designing UI for Multiple Resolutions page as well as the Canvas Scaler page."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/class-CanvasGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/class-CanvasGroup.html",
    "title": "Canvas Group | mmo-rpg-unity",
    "keywords": "Canvas Group The Canvas Group can be used to control certain aspects of a whole group of UI elements from one place without needing to handle them each individually. The properties of the Canvas Group affect the GameObject it is on as well as all children. Properties Property: Function: Alpha The opacity of the UI elements in this group. The value is between 0 and 1 where 0 is fully transparent and 1 is fully opaque. Note that elements retain their own transparency as well, so the Canvas Group alpha and the alpha values of the individual UI elements are multiplied with each other. Interactable Determines if this component will accept input. When it is set to false interaction is disabled. Block Raycasts Will this component act as a collider for Raycasts? You will need to call the RayCast function on the graphic raycaster attached to the Canvas. This does not apply to Physics.Raycast. Ignore Parent Groups Will this group also be affected by the settings in Canvas Group components further up in the Game Object hierarchy, or will it ignore those and hence override them? Details Typical uses of Canvas Group are: Fading in or out a whole window by adding a Canvas Group on the GameObject of the Window and control its Alpha property. Making a whole set of controls non-interactable (\"grayed out\") by adding a Canvas Group to a parent GameObject and setting its Interactable property to false. Making one or more UI elements not block mouse events by placing a Canvas Group component on the element or one of its parents and setting its Block Raycasts property to false."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/class-CanvasRenderer.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/class-CanvasRenderer.html",
    "title": "Canvas Renderer | mmo-rpg-unity",
    "keywords": "Canvas Renderer The Canvas Renderer component renders a graphical UI object contained within a Canvas. Properties The Canvas Renderer has no properties exposed in the inspector. Details The standard UI objects available from the menu (GameObject > Create UI) all have Canvas Renderers attached wherever they are required but you may need to add this component manually for custom UI objects. Although there are no properties exposed in the inspector, a few properties and function can be accessed from scripts - see the CanvasRenderer page in the Script Reference for full details."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/class-RectTransform.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/class-RectTransform.html",
    "title": "Rect Transform | mmo-rpg-unity",
    "keywords": "Rect Transform The Rect Transform component is the 2D layout counterpart of the Transform component. Where Transform represents a single point, Rect Transform represent a rectangle that a UI element can be placed inside. If the parent of a Rect Transform is also a Rect Transform, the child Rect Transform can also specify how it should be positioned and sized relative to the parent rectangle. Properties Property: Function: Pos (X, Y, Z) Position of the rectangle's pivot point relative to the anchors. The pivot point is the location around which the rectangle rotates. Width/Height Width and height of the rectangle. Left, Top, Right, Bottom Positions of the rectangle's edges relative to their anchors. This can be thought of as padding inside the rectangle defined by the anchors. Shown in place of Pos and Width/Height when the anchors are separated (see below). To access these options click the square Anchor Presets box at the top left of the RectTransform component. Anchors The anchor points for the lower left corner and the upper right corner of the rectangle. Min The anchor point for the lower left corner of the rectangle defined as a fraction of the size of the parent rectangle. 0,0 corresponds to anchoring to the lower left corner of the parent, while 1,1 corresponds to anchoring to the upper right corner of the parent. Max The anchor point for the upper right corner of the rectangle defined as a fraction of the size of the parent rectangle. 0,0 corresponds to anchoring to the lower left corner of the parent, while 1,1 corresponds to anchoring to the upper right corner of the parent. Pivot Location of the pivot point around which the rectangle rotates, defined as a fraction of the size of the rectangle itself. 0,0 corresponds to the lower left corner while 1,1 corresponds to the upper right corner. Rotation Angle of rotation (in degrees) of the object around its pivot point along the X, Y and Z axis. Scale Scale factor applied to the object in the X, Y and Z dimensions. Blueprint Mode Edit RectTransforms as if they were not rotated and scaled. This enabled snapping too. Raw Edit Mode When enabled, editing pivot and anchor values will not counter adjust the position and size of the rectangle in order to make it stay in one place. Details Note that some RectTransform calculations are performed at the end of a frame, just before calculating UI vertices, in order to ensure that they are up to date with all the latest changes performed throughout the frame. This means that they haven't yet been calculated for the first time in the Start callback and first Update callback. You can work around this by creating a Start() callback and adding Canvas.ForceUpdateCanvases() method to it. This will force Canvas to be updated not at the end of the frame, but when that method is called. See the Basic Layout page for a full introduction and overview of how to use the Rect Transform."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-CanvasComponents.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-CanvasComponents.html",
    "title": "Canvas Components | mmo-rpg-unity",
    "keywords": "Canvas Components All UI Components are placed within a Canvas. Canvas Canvas Scaler Canvas Group Canvas Renderer"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-UIAutoLayout.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-UIAutoLayout.html",
    "title": "Auto Layout | mmo-rpg-unity",
    "keywords": "Auto Layout The auto layout system provides ways to place elements in nested layout groups such as horizontal groups, vertical groups, or grids. It also allows elements to automatically be sized according to the contained content. Content Size Fitter Layout Element Horizontal Layout Group Vertical Layout Group Grid Layout Group"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-UIEffects.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-UIEffects.html",
    "title": "UI Effect Components | mmo-rpg-unity",
    "keywords": "UI Effect Components The effects components allow adding simple effects to Text and Image graphics, such as shadow and outline. Shadow Outline Position as UV1"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-UIInteraction.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-UIInteraction.html",
    "title": "Interaction Components | mmo-rpg-unity",
    "keywords": "Interaction Components The interaction components in the UI system handle interaction, such as mouse or touch events and interaction using a keyboard or controller. Selectable Base Class Button Toggle Toggle Group Slider Scrollbar Scroll Rect InputField"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-UIVisual.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/comp-UIVisual.html",
    "title": "Visual Components | mmo-rpg-unity",
    "keywords": "Visual Components The visual components allow for ease of creation and GUI specific functionality. Text Image Raw Image Mask"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/index.html",
    "title": "Unity UI: Unity User Interface | mmo-rpg-unity",
    "keywords": "Unity UI: Unity User Interface Unity UI is a UI toolkit for developing user interfaces for games and applications. It is a GameObject-based UI system that uses Components and the Game View to arrange, position, and style user interfaces. ​ You cannot use Unity UI to create or change user interfaces in the Unity Editor. This documentation describes Unity UI features such as creating a Canvas, positioning and animating elements, defining user interactions, and sizing layouts automatically."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-AspectRatioFitter.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-AspectRatioFitter.html",
    "title": "Aspect Ratio Fitter | mmo-rpg-unity",
    "keywords": "Aspect Ratio Fitter Properties Property: Function: Aspect Mode How the rectangle is resized to enforce the aspect ratio. None Do not make the rect fit the aspect ratio. Width Controls Height The height is automatically adjusted based on the width. Height Controls Width The width is automatically adjusted based on the height. Fit In Parent The width, height, position, and anchors are automatically adjusted to make the rect fit inside the rect of the parent while keeping the aspect ratio. The may be some space inside the parent rect which is not covered by this rect. Envelope Parent The width, height, position, and anchors are automatically adjusted to make the rect cover the entire area of the parent while keeping the aspect ratio. This rect may extend further out than the parent rect. Aspect Ratio The aspect ratio to enforce. This is the width divided by the height. Description The Aspect Ratio Fitter functions as a layout controller that controls the size of its own layout element. It can adjust the height to fit the width or vice versa, or it can make the element fit inside its parent or envelope its parent. The Aspect Ratio Fitter does not take layout information into account such as minimum size and preferred size. It's worth keeping in mind that when a Rect Transform is resized - whether by an Aspect Ratio Fitter or something else - the resizing is around the pivot. This means that the pivot can be used to control the alignment of the rectangle. For example, a pivot placed at the top center will make the rectangle grow evenly to both sides, and only grow downwards while the top edge remain at its position."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Button.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Button.html",
    "title": "Button | mmo-rpg-unity",
    "keywords": "Button The Button control responds to a click from the user and is used to initiate or confirm an action. Familiar examples include the Submit and Cancel buttons used on web forms. Properties Property: Function: Interactable Enable Interactable if you want this button to accept input. See API documentation on Interactable for more details. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Events Property: Function: On Click A UnityEvent that Unity invokes when a user clicks the button and releases it. Details The button is designed to initiate an action when the user clicks and releases it. If the mouse is moved off the button control before the click is released, the action does not take place. The button has a single event called On Click that responds when the user completes a click. Typical use cases include: Confirming a decision (eg, starting gameplay or saving a game) Moving to a sub-menu in a GUI Cancelling an action in progress (eg, downloading a new scene)"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-CanvasScaler.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-CanvasScaler.html",
    "title": "Canvas Scaler | mmo-rpg-unity",
    "keywords": "Canvas Scaler The Canvas Scaler component is used for controlling the overall scale and pixel density of UI elements in the Canvas. This scaling affects everything under the Canvas, including font sizes and image borders. Properties Property: Function: UI Scale Mode Determines how UI elements in the Canvas are scaled. Constant Pixel Size Makes UI elements retain the same size in pixels regardless of screen size. Scale With Screen Size Makes UI elements bigger the bigger the screen is. Constant Physical Size Makes UI elements retain the same physical size regardless of screen size and resolution. Settings for Constant Pixel Size: Property: Function: Scale Factor Scales all UI elements in the Canvas by this factor. Reference Pixels Per Unit If a sprite has this 'Pixels Per Unit' setting, then one pixel in the sprite will cover one unit in the UI. Settings for Scale With Screen Size: Property: Function: Reference Resolution The resolution the UI layout is designed for. If the screen resolution is larger, the UI will be scaled up, and if it's smaller, the UI will be scaled down. Screen Match Mode A mode used to scale the canvas area if the aspect ratio of the current resolution doesn't fit the reference resolution. Match Width or Height Scale the canvas area with the width as reference, the height as reference, or something in between. Expand Expand the canvas area either horizontally or vertically, so the size of the canvas will never be smaller than the reference. Shrink Crop the canvas area either horizontally or vertically, so the size of the canvas will never be larger than the reference. Match Determines if the scaling is using the width or height as reference, or a mix in between. Reference Pixels Per Unit If a sprite has this 'Pixels Per Unit' setting, then one pixel in the sprite will cover one unit in the UI. Settings for Constant Physical Size: Property: Function: Physical Unit The physical unit to specify positions and sizes in. Fallback Screen DPI The DPI to assume if the screen DPI is not known. Default Sprite DPI The pixels per inch to use for sprites that have a 'Pixels Per Unit' setting that matches the 'Reference Pixels Per Unit' setting. Reference Pixels Per Unit If a sprite has this 'Pixels Per Unit' setting, then its DPI will match the 'Default Sprite DPI' setting. Settings for World Space Canvas (shown when Canvas component is set to World Space): Property: Function: Dynamic Pixels Per Unit The amount of pixels per unit to use for dynamically created bitmaps in the UI, such as Text. Reference Pixels Per Unit If a sprite has this 'Pixels Per Unit' setting, then one pixel in the sprite will cover one unit in the world. If the 'Reference Pixels Per Unit' is set to 1, then the 'Pixels Per Unit' setting in the sprite will be used as-is. Details For a Canvas set to 'Screen Space - Overlay' or 'Screen Space - Camera', the Canvas Scaler UI Scale Mode can be set to Constant Pixel Size, Scale With Screen Size, or Constant Physical Size. Constant Pixel Size Using the Constant Pixel Size mode, positions and sizes of UI elements are specified in pixels on the screen. This is also the default functionality of the Canvas when no Canvas Scaler is attached. However, With the Scale Factor setting in the Canvas Scaler, a constant scaling can be applied to all UI elements in the Canvas. Scale With Screen Size Using the Scale With Screen Size mode, positions and sizes can be specified according to the pixels of a specified reference resolution. If the current screen resolution is larger than the reference resolution, the Canvas will keep having only the resolution of the reference resolution, but will scale up in order to fit the screen. If the current screen resolution is smaller than the reference resolution, the Canvas will similarly be scaled down to fit. If the current screen resolution has a different aspect ratio than the reference resolution, scaling each axis individually to fit the screen would result in non-uniform scaling, which is generally undesirable. Instead of this, the ReferenceResolution component will make the Canvas resolution deviate from the reference resolution in order to respect the aspect ratio of the screen. It is possible to control how this deviation should behave using the Screen Match Mode setting. Constant Physical Size Using the Constant Physical Size mode, positions and sizes of UI elements are specified in physical units, such as millimeters, points, or picas. This mode relies on the device reporting its screen DPI correctly. You can specify a fallback DPI to use for devices that do not report a DPI. World Space For a Canvas set to 'World Space' the Canvas Scaler can be used to control the pixel density of UI elements in the Canvas. Hints See the page Designing UI for Multiple Resolutions for a step by step explanation of how Rect Transform anchoring and Canvas Scaler can be used in conjunction to make UI layouts that adapt to different resolutions and aspect ratios."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-ContentSizeFitter.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-ContentSizeFitter.html",
    "title": "Content Size Fitter | mmo-rpg-unity",
    "keywords": "Content Size Fitter Properties Property: Function: Horizontal Fit How the width is controlled. Unconstrained Do not drive the width based on the layout element. Min Size Drive the width based on the minimum width of the layout element. Preferred Size Drive the width based on the preferred width of the layout element. Vertical Fit How the height is controlled. Unconstrained Do not drive the height based on the layout element. Min Size Drive the height based on the minimum height of the layout element. Preferred Size Drive the height based on the preferred height of the layout element. Description The Content Size Fitter functions as a layout controller that controls the size of its own layout element. The size is determined by the minimum or preferred sizes provided by layout element components on the Game Object. Such layout elements can be Image or Text components, layout groups, or a Layout Element component. It's worth keeping in mind that when a Rect Transform is resized - whether by a Content Size Fitter or something else - the resizing is around the pivot. This means that the direction of the resizing can be controlled using the pivot. For example, when the pivot is in the center, the Content Size Fitter will expand the Rect Transform out equally in all directions. And when the pivot is in the upper left corner, the Content Size Fitter will expand the Rect Transform down and to the right."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Dropdown.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Dropdown.html",
    "title": "Dropdown | mmo-rpg-unity",
    "keywords": "Dropdown The Dropdown can be used to let the user choose a single option from a list of options. The control shows the currently chosen option. Once clicked, it opens up the list of options so a new option can be chosen. Upon choosing a new option, the list of closed again, and the control shows the new selected option. The list is also closed if the user clicks on the control itself, or anywhere else inside the Canvas. Properties Property: Function: Interactable Will this component will accept input? See Interactable. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Template The Rect Transform of the template for the dropdown list. See instructions below. Caption Text The Text component to hold the text of the currently selected option. (Optional) Caption Image The Image component to hold the image of the currently selected option. (Optional) Item Text The Text component to hold the text of the item. (Optional) Item Image The Image component to hold the image of the item. (Optional) Value The index of the currently selected option. 0 is the first option, 1 is the second, and so on. Options The list of possible options. A text string and an image can be specified for each option. Events Property: Function: On Value Changed A UnityEvent that is invoked when a user has clicked one of the options in the dropdown list. Details The list of options is specified in the Inspector or can be assigned from code. For each option a text string can be specified, and optionally an image as well, if the Dropdown is setup to support it. The button has a single event called On Value Changed that responds when the user completes a click on one of the options in the list. It supports sending an integer number value that is the index of the selected option. 0 is the first option, 1 is the second, and so on. The template system The Dropdown control is designed to have a child GameObject which serves as a template for the dropdown list that is shown when clicking the dropdown control. The template GameObject is inactive by default, but can be made active while editing the template to better see what's going on. A reference to the template object must be specified in the Template property of the Dropdown component. The template must have a single item in it with a Toggle component on. When the actual dropdown list is created upon clicking the dropdown control, this item is duplicated multiple times, with one copy used for each option in the list. The parent of the item is automatically resized so it can fit all the items inside. The template can be setup in many different ways. The setup used by the GameObject > UI > Dropdown menu item includes a scroll view, such that if there are too many options to show at once, a scrollbar will appear and the user can scroll through the options. This is however not a mandatory part of the template setup. (See the ScrollRect page for more information about setup of Scroll Views.) Setup of text and image support The dropdown supports one text content and one image content for each option. Both text and image is optional. They can only be used if the Dropdown is setup to support it. The dropdown supports text for each option when the Caption Text and Item Text properties are both setup. These are setup by default when using the GameObject > UI > Dropdown menu item. The Caption Text is the Text component to hold the text for the currently selected option. It is typically a child to the Dropdown GameObject. The Item Text is the Text component to hold the text for each option. It is typically a child to the Item GameObject. The dropdown supports an image for each option when the Caption Image and Item Image properties are both setup. These are not setup by default. The Caption Image is the Image component to hold the image for the currently selected option. It is typically a child to the Dropdown GameObject. The Item Image is the Image component to hold the image for each option. It is typically a child to the Item GameObject. The actual text and images used for the dropdowns are specified in the Options property of the Dropdown component, or can be set from code. Placement of the dropdown list The placement of the dropdown list in relation to the dropdown control is determined by the anchoring and pivot of the Rect Transform of the Template. By default, the list will appear below the control. This is achieved by anchoring the template to the bottom of the control. The pivot of the template also needs to be at the top, so that as the template is expanded to accommodate a variable number of option items, it only expands downwards. The Dropdown control has simple logic to prevent that the dropdown is displayed outside the bounds of the Canvas, since this would make it impossible to select certain options. If the dropdown at its default position is not fully within the Canvas rectangle, its position in relation to the control is reversed. For example, a list that is shown below the control by default will be shown above it instead. This logic is quite simple and has certain limitations. The dropdown template needs to be no larger than half the Canvas size minus the size of the dropdown control, otherwise there may not be room for the list at either position if the dropdown control is placed in the middle of the Canvas."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-EventSystem.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-EventSystem.html",
    "title": "Event System Manager | mmo-rpg-unity",
    "keywords": "Event System Manager This subsystem is responsible for controlling all the other elements that make up eventing. It coordinates which Input Module is currently active, which GameObject is currently considered 'selected', and a host of other high level Event System concepts. Each 'Update' the Event System receives the call, looks through its Input Modules and figures out which is the Input Module that should be used for this tick. It then delegates the processing to the modules. Properties Property: Function: First Selected The GameObject that was selected first. Send Navigation Events Should the EventSystem allow navigation events (move / submit / cancel). Drag Threshold The soft area for dragging in pixels. Beneath the Properties table is the \"Add Default Input Modules\" button."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-EventTrigger.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-EventTrigger.html",
    "title": "Event Trigger | mmo-rpg-unity",
    "keywords": "Event Trigger The Event Trigger receives events from the Event System and calls registered functions for each event. The Event Trigger can be used to specify functions you wish to be called for each Event System event. You can assign multiple functions to a single event and whenever the Event Trigger receives that event it will call those functions. Note that attaching an Event Trigger component to a GameObject will make that object intercept all events, and no event bubbling will occur from this object! Events Each of the Supported Events can optionally be included in the Event Trigger by clicking the Add New Event Type button."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-GraphicRaycaster.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-GraphicRaycaster.html",
    "title": "Graphic Raycaster | mmo-rpg-unity",
    "keywords": "Graphic Raycaster The Graphic Raycaster is used to raycast against a Canvas. The Raycaster looks at all Graphics on the canvas and determines if any of them have been hit. The Graphic Raycaster can be configured to ignore backfacing Graphics as well as be blocked by 2D or 3D objects that exist in front of it. A manual priority can also be applied if you want processing of this element to be forced to the front or back of the Raycasting. Properties Property: Function: Ignore Reversed Graphics Should graphics facing away from the raycaster be considered? Blocked Objects Type of objects that will block graphic raycasts. Blocking Mask Type of objects that will block graphic raycasts."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-GridLayoutGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-GridLayoutGroup.html",
    "title": "Grid Layout Group | mmo-rpg-unity",
    "keywords": "Grid Layout Group The Grid Layout Group component places its child layout elements in a grid. Properties Property: Function: Padding The padding inside the edges of the layout group. Cell Size The size to use for each layout element in the group. Spacing The spacing between the layout elements. Start Corner The corner where the first element is located. Start Axis Which primary axis to place elements along. Horizontal will fill an entire row before a new row is started. Vertical will fill an entire column before a new column is started. Child Alignment The alignment to use for the layout elements if they don't fill out all the available space. Constraint Constraint the grid to a fixed number of rows or columns to aid the auto layout system. Description Unlike other layout groups, the Grid Layout Group ignores the minimum, preferred, and flexible size properties of its contained layout elements and instead assigns a fixed size to all of them which is defined with the Cell Size property of the Grid Layout Group itself. Grid Layout Group and auto layout There are special considerations to be aware of when using the Grid Layout Group as part of an auto layout setup, such as using it with a Content Size Fitter. The auto layout system calculates the horizontal and vertical sizes independently. This can be at odds with the Grid Layout Group, where the number of rows depends on the number of columns and vice versa. For any given number of cells, there are different combinations of row count and column count that can make the grid fit its content. In order to aid the layout system, you can specify that you intent the table to have a fixed number of columns or rows by using the Constraint property. Here are suggested ways of using the Layout System with a Content Size Fitter: Flexible width and fixed height To setup a grid with a flexible width and fixed height, where the grid expands horizontally as more elements are added, you can set these properties as follows: Grid Layout Group Constraint: Fixed Row Count Content Size Fitter Horizontal Fit: Preferred Size Content Size Fitter Vertical Fit: Preferred Size or Unconstrained If unconstrained Vertical Fit is used, it's up to you to give the grid a height that is big enough to fit the specified row count of cells. Fixed width and flexible height To setup a grid with a fixed width and flexible height, where the grid expands vertically as more elements are added, you can set these properties as follows: Grid Layout Group Constraint: Fixed Column Count Content Size Fitter Horizontal Fit: Preferred Size or Unconstrained Content Size Fitter Vertical Fit: Preferred Size If unconstrained Horizontal Fit is used, it's up to you to give the grid a width that is big enough to fit the specified column count of cells. Both flexible width and height If you want a grid with both a flexible width and height you can do that, but you will have no control over the specific number of rows and columns. The grid will attempt to make the row and column count approximately the same. You can set these properties as follows: Grid Layout Group Constraint: Flexible Content Size Fitter Horizontal Fit: Preferred Size Content Size Fitter Vertical Fit: Preferred Size"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-HorizontalLayoutGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-HorizontalLayoutGroup.html",
    "title": "Horizontal Layout Group | mmo-rpg-unity",
    "keywords": "Horizontal Layout Group The Horizontal Layout Group component places its child layout elements next to each other, side by side. Their widths are determined by their respective minimum, preferred, and flexible widths according to the following model: The minimum widths of all the child layout elements are added together and the spacing between them is added as well. The result is the mimimum width of the Horizontal Layout Group. The preferred widths of all the child layout elements are added together and the spacing between them is added as well. The result is the preferred width of the Horizontal Layout Group. If the Horizontal Layout Group is at its minimum width or smaller, all the child layout elements will also have their minimum width. The closer the Horizontal Layout group is to its preferred width, the closer each child layout element will also get to their preferred width. If the Horizontal Layout Group is wider than its preferred width, it will distribute the extra available space proportionally to the child layout elements according to their respective flexible widths. For more information about minimum, preferred, and flexible width, see the documentation on Auto Layout. Properties Property: Function: Padding The padding inside the edges of the layout group. Spacing The spacing between the layout elements. Child Alignment The alignment to use for the child layout elements if they don't fill out all the available space. Control Child Size Whether the Layout Group controls the width and height of its child layout elements. Use Child Scale Whether the Layout Group considers the scale of its child layout elements when sizing and laying out elements. Width and Height correspond to the Scale > X and Scale > Y values in each child layout element's Rect Transform component. You cannot animate the Scale values using the Animator Controller Child Force Expand Whether to force the child layout elements to expand to fill additional available space."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Image.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Image.html",
    "title": "Image | mmo-rpg-unity",
    "keywords": "Image The Image control displays a non-interactive image to the user. You can use this for purposes such as decorations or icons, and you can change the image from a script to reflect changes in other controls. The control is similar to the Raw Image control, but offers more options for animating the image and accurately filling the control rectangle. However, the Image control requires its Texture to be a Sprite, while the Raw Image can accept any Texture. Properties Property: Function: Source Image The Texture that represents the image to display (which must be imported as a Sprite). Color The color to apply to the image. Material The Material to use for rendering the image. Raycast Target Enable Raycast Target if you want Unity to consider the image a target for raycasting. Preserve Aspect Ensure the image retains its existing dimension. Set Native Size Set the dimensions of the image box to the original pixel size of the Texture. You must import the image to display as a Sprite to work with the Image control."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-InputField.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-InputField.html",
    "title": "Input Field | mmo-rpg-unity",
    "keywords": "Input Field An Input Field is a way to make the text of a Text Control editable. Like the other interaction controls, it's not a visible UI element in itself and must be combined with one or more visual UI elements in order to be visible. Properties Property: Function: Interactable A boolean that determines if the Input Field can be interacted with or not. |Transition ||Transitions are used to set how the input field transitions when Normal, Highlighted, Pressed or Disabled. | |Navigation || Properties that determine the sequence of controls. See Navigation Options.| |TextComponent ||A reference to the Text element used as the contents of the Input Field| |Text ||Starting Value. The initial text placed in the field before editing begins. | |Character Limit ||The value of the maximum number of characters that can be entered into the input field.| |Content Type ||Define the type(s) of characters that your input field accepts| | |Standard |Any character can be entered.| | |Autocorrected |The autocorrection determines whether the input tracks unknown words and suggests a more suitable replacement candidate to the user, replacing the typed text automatically unless the user explicitly overrides the action.| | |Integer Number |Allow only whole numbers to be entered.| | |Decimal Number |Allow only numbers and a single decimal point to be entered.| | |Alphanumeric |Allow both letters and numbers. Symbols cannot be entered.| | |Name |Automatically capitalizes the first letter of each word. Note that the user can circumvent the capitalization rules using the Delete key.| | |Email Address |Allows you to enter an Alphanumeric string consisting of a maximum of one @ sign. periods/baseline dots cannot be entered next to each other. | | |Password* |Conceals the characters inputed with an asterisk. Allows symbols.| | |Pin |Conceals the characters inputed with an asterisk. Only allows only whole numbers to be entered.| | |Custom |Allows you to customise the Line Type, Input Type, Keyboard Type and Character Validation.| |Line Type ||Defines how text is formatted inside the text field.| | |Single Line |Only allows text to be on a single line.| | |Multi Line Submit |Allows text to use multiple lines. Only uses a new line when needed.| | |Multi Line Newline |Allows text to use multiple lines. User can use a newline by pressing the return key.| |Placeholder ||This is an optional ‘empty’ Graphic to show that the Input Field is empty of text. Note that this ‘empty' graphic still displays even when the Input Field is selected (that is; when there is focus on it). eg; \"Enter text...\".| |Caret Blink Rate ||Defines the blink rate for the mark placed on the line to indicate a proposed insertion of text.| |Selection Color ||The background color of the selected portion of text.| Hide Mobile Input Hides the native input field attached to the onscreen keyboard on mobile devices. Note that this only works on iOS and Android devices. Events Property: Function: On Value Change A UnityEvent that is invoked when the text content of the Input Field changes. The event can send the current text content as a string type dynamic argument. End Edit A UnityEvent that is invoked when the user finishes editing the text content either by submitting or by clicking somewhere that removes the focus from the Input Field. The event can send the current text content as a string type dynamic argument. Details The Input Field script can be added to any existing Text control object from the menu (Component > UI > Input Field). Having done this, you should also drag the object to the Input Field's Text property to enable editing. The Text property of the Text control itself will change as the user types and the value can be retrieved from a script after editing. Note that Rich Text is intentionally not supported for editable Text controls; the field will apply any Rich Text markup instantly when typed but the markup essentially \"disappears\" and there is no subsequent way to change or remove the styling. Hints To obtain the text of the Input Field, use the text property on the InputField component itself, not the text property of the Text component that displays the text. The text property of the Text component may be cropped or may consist of asterisks for passwords. Limitations On iOS when an external keyboard is connected, the onscreen keyboard will be hidden by the OS but the caret will not appear in the InputField. This is due to a lack of external keyboard support on iOS 13 and older."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-LayoutElement.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-LayoutElement.html",
    "title": "Layout Element | mmo-rpg-unity",
    "keywords": "Layout Element If you want to override the minimum, preferred, or flexible size of a layout element, you can do that by adding a Layout Element component to the GameObject. A layout controller allocates width or height to a layout element in the following order: First, the layout controller allocates the minimum size properties (Min Width, Min Height). If there is sufficient available space, the layout controller allocates the preferred size properties (Preferred Width, Preferred Height). If there is additional available space, the layout controller allocates the flexible size properties (Flexible Width, Flexible Height). For more information about minimum, preferred, and flexible size, see documentation on Auto Layout. Properties When you enable a width or height property, a value field appears next to it. Use this value field to enter the exact value for the width or height. Min and Preferred sizes are in regular units, while the Flexible sizes are in relative units. Property: Function: Ignore Layout When enabled, the layout system ignores this layout element. Min Width The minimum width this layout element should have. Min Height The minimum height this layout element should have. Preferred Width The preferred width this layout element should have before additional available width is allocated. Preferred Height The preferred height this layout element should have before additional available height is allocated. Flexible Width The relative amount of additional available width this layout element should fill out relative to its siblings. Flexible Height The relative amount of additional available height this layout element should fill out relative to its siblings. Layout Priority The layout priority for this component. If a GameObject has more than one component with layout properties (for example, an Image component and a LayoutElement component), the layout system uses the property values from the component with the highest Layout Priority. If the components have the same Layout Priority, the layout system uses the highest value for each property, regardless of which component it comes from. Description The Layout Element component lets you override the values for one or more of the layout properties. Enable the checkbox for a property you want to override and then specify the value you want to override with. Minimum and preferred sizes are defined in regular units, while the flexible sizes are defined in relative units. If any layout element has flexible size greater than zero, it means that all the available space will be filled out. The relative flexible size values of the siblings determines how big a proportion of the available space each sibling fills out. Most commonly, flexible width and height is set to just 0 or 1. Specifying both a preferred size and a flexible size can make sense in certain cases. Flexible sizes are only allocated after all preferred sizes have been fully allocated. Thus, a layout element which has a flexible size specified but no preferred size will keep its minimum size until other layout elements have grown to their full preferred size, and only then begin to grow based on additional available space. By also specifying a flexible size, this can be avoided and the element can grow to its preferred size in tandem with the other layout elements that have preferred sizes, and then grow further once all flexible sizes have been allocated."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Mask.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Mask.html",
    "title": "Mask | mmo-rpg-unity",
    "keywords": "Mask A Mask is not a visible UI control but rather a way to modify the appearance of a control's child elements. The mask restricts (ie, \"masks\") the child elements to the shape of the parent. So, if the child is larger than the parent then only the part of the child that fits within the parent will be visible. Properties Property: Function: Show Graphic Should the graphic of the masking (parent) object be drawn with alpha over the child object? Description A common use of a Mask is to show a small section of a large Image, using say a Panel object (menu: GameObject > Create UI > Panel) as a \"frame\". You can achieve this by firstly making the Image a child of the Panel object. You should position the Image so that the area that should be visible is directly behind the Panel area. Then, add a Mask component to the Panel. The areas of the child Image outside the panel will become invisible since they are masked by the shape of the Panel. If the image is then moved around then only the part revealed by the Panel will be visible. The movement could be controlled by Scrollbars to create a scrollable viewer for a map, say. Implementation Masking is implemented using the stencil buffer of the GPU. *The first Mask element writes a 1 to the stencil buffer *All elements below the mask check when rendering, and only render to areas where there is a 1 in the stencil buffer *Nested Masks will write incremental bit masks into the buffer, this means that renderable children need to have the logical & of the stencil values to be rendered."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Outline.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Outline.html",
    "title": "Outline | mmo-rpg-unity",
    "keywords": "Outline The Outline component adds a simple outline effect to graphic components such as Text or Image. It must be on the same GameObject as the graphic component. Properties Property: Function: Effect Color The color of the outline. Effect Distance The distance of the outline effect horizontally and vertically. Use Graphic Alpha Multiplies the color of the graphic onto the color of the effect."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Physics2DRaycaster.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Physics2DRaycaster.html",
    "title": "Physics 2D Raycaster | mmo-rpg-unity",
    "keywords": "Physics 2D Raycaster The 2D Raycaster raycasts against 2D objects in the scene. This allows messages to be sent to 2D physics objects that implement event interfaces. The Camera GameObject needs to be used and will be added to the GameObject if the Physics 3D Raycaster is not added to the Camera GameObject. For more Raycaster information see Raycasters. Properties Property: Function: Event Camera The camera that will generate rays for this raycaster. Priority Priority of the caster relative to other casters. Sort Order Priority Priority of the raycaster based upon sort order. Render Order Priority Priority of the raycaster based upon render order."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-PhysicsRaycaster.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-PhysicsRaycaster.html",
    "title": "Physics Raycaster | mmo-rpg-unity",
    "keywords": "Physics Raycaster The Raycaster raycasts against 3D objects in the scene. This allows messages to be sent to 3D physics objects that implement event interfaces. Properties Property: Function: Depth Get the depth of the configured camera. Event Camera Get the camera that is used for this module. Event Mask Logical and of Camera mask and eventMask. Final Event Mask Logical and of Camera mask and eventMask."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-PositionAsUV1.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-PositionAsUV1.html",
    "title": "Position as UV1 | mmo-rpg-unity",
    "keywords": "Position as UV1 This adds a simple Position as UV1 effect to text and image graphics. Properties Property: Function: Script"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-RawImage.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-RawImage.html",
    "title": "Raw Image | mmo-rpg-unity",
    "keywords": "Raw Image The Raw Image control displays a non-interactive image to the user. You can use this for purposes such as decorations or icons, and you can change the image from a script to reflect changes in other controls. The control is similar to the Image control, but offers more options for animating the image and accurately filling the control rectangle. However, the Image control requires its Texture to be a Sprite, while the Raw Image can accept any Texture. Properties Property: Function: Texture The texture that represents the image to display. Color The color to apply to the image. Material The Material to use for rendering the image. Raycast Target Enable Raycast Target if you want Unity to consider the image a target for raycasting. UV Rectangle The image's offset and size within the control rectangle, given in normalized coordinates (range 0.0 to 1.0). The edges of the image are stretched to fill the space around the UV rectangle. Details Since the Raw Image does not require a sprite texture, you can use it to display any texture available to the Unity player. For example, you might show an image downloaded from a URL using the WWW class or a texture from an object in a game. The UV Rectangle properties allow you to display a small section of a larger image. The X and Y coordinates specify which part of the image is aligned with the bottom left corner of the control. For example, an X coordinate of 0.25 will cut off the leftmost quarter of the image. The W and H (ie, width and height) properties indicate the width and height of the section of image that will be scaled to fit the control rectangle. For example, a width and height of 0.5 will scale a quarter of the image area up to the control rectangle. By changing these properties, you can zoom and scale the image as desired (see also the Scrollbar control)."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-RectMask2D.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-RectMask2D.html",
    "title": "RectMask2D | mmo-rpg-unity",
    "keywords": "RectMask2D A RectMask2D is a masking control similar to the Mask control. The mask restricts the child elements to the rectangle of the parent element. Unlike the standard Mask control it has some limitations, but it also has a number of performance benefits. Description A common use of a RectMask2D is to show small sections of a larger area. Using the RectMask2D to frame this area. The limitations of RectMask2D control are: It only works in 2D space It will not properly mask elements that are not coplanar The advantages of RectMask2D are: It does not use the stencil buffer No extra draw calls No material changes Fast performance"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-ScrollRect.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-ScrollRect.html",
    "title": "Scroll Rect | mmo-rpg-unity",
    "keywords": "Scroll Rect A Scroll Rect can be used when content that takes up a lot of space needs to be displayed in a small area. The Scroll Rect provides functionality to scroll over this content. Usually a Scroll Rect is combined with a Mask in order to create a scroll view, where only the scrollable content inside the Scroll Rect is visible. It can also additionally be combined with one or two Scrollbars that can be dragged to scroll horizontally or vertically. Properties Property: Function: Content This is a reference to the Rect Transform of the UI element to be scrolled, for example a large image. Horizontal Enables horizontal scrolling Vertical Enables vertical scrolling Movement Type Unrestricted, Elastic or Clamped. Use Elastic or Clamped to force the content to remain within the bounds of the Scroll Rect. Elastic mode bounces the content when it reaches the edge of the Scroll Rect Elasticity This is the amount of bounce used in the elasticity mode. Inertia When Inertia is set the content will continue to move when the pointer is released after a drag. When Inertia is not set the content will only move when dragged. Deceleration Rate When Inertia is set the deceleration rate determines how quickly the contents stop moving. A rate of 0 will stop the movement immediately. A value of 1 means the movement will never slow down. Scroll Sensitivity The sensitivity to scroll wheel and track pad scroll events. Viewport Reference to the viewport Rect Transform that is the parent of the content Rect Transform. Horizontal Scrollbar Optional reference to a horizontal scrollbar element. Visibility Whether the scrollbar should automatically be hidden when it isn't needed, and optionally expand the viewport as well. Spacing The space between the scrollbar and the viewport. Vertical Scrollbar Optional reference to a vertical scrollbar element. Visibility Whether the scrollbar should automatically be hidden when it isn't needed, and optionally expand the viewport as well. Spacing The space between the scrollbar and the viewport. Events Property: Function: On Value Changed A UnityEvent that is invoked when the scroll position of the Scroll Rect changes. The event can send the current scroll position as a Vector2 type dynamic argument. Details The important elements in a scroll view are the viewport, the scrolling content, and optionally one or two scrollbars. The root GameObject has the Scroll Rect component. The viewport has a Mask component. The viewport can either be the root GameObject, or a separate GameObject that's a child to the root. If auto-hiding scrollbars are used, it must be a child. The viewport Rect Transform needs to be referenced in the Viewport property of the Scroll Rect. All the scrolling content must be children of a single content GameObject that is a child to the viewport. The content Rect Transform needs to be referenced in the Content property of the Scroll Rect. The scrollbars - if used - are children to the root GameObject. See the Scrollbar page for more details on the setup of a scrollbar and see the section Scrollbar setup below for information about setup of scrollbars with a scroll view. This image shows a setup where the viewport is a child to the scroll view root. This is the default used when using the GameObject > UI > Scroll View menu option. To scroll content, the input must be received from inside the bounds of the ScrollRect, not on the content itself. Take care when using Unrestricted scrolling movement as it is possible to lose control of the content in an irretrievable way. When using Elastic or Constrained movement it is best to position the content so that it starts within the bounds of the ScrollRect, or undesirable behaviour may occur as the RectTransform tries to bring the content back within its bounds. Scrollbar setup Optionally, the Scroll Rect can be linked to a horizontal and/or a vertical Scrollbar. These are typically placed in the hierarchy as siblings to the viewport, and when present, should be dragged into the Horizontal Scrollbar and Vertical Scrollbar properties of the Scroll Rect, respectively. Note that the Direction property on such a horizontal Scrollbar should be set to Left To Right, and on the vertical Scrollbar to Bottom To Top. The scrollbars can optionally have auto-hiding behaviour that hides the scrollbars if the content doesn't need to scroll because it isn't larger than the viewport. Note that the auto-hiding only ever happens in Play Mode. In Edit Mode the scrollbars are always shown. This prevents marking the scene as dirty when it shouldn't be, and also help authoring content with proportions that there's room for even when the scrollbars are shown. If one or both scrollbars have their visibility behaviour set to Auto Hide And Expand View, the viewport is automatically expanded when the scrollbars are hidden in order to take up the extra room where the scrollbars would otherwise have been. With this setup, the position and size of the view is driven by the Scroll Rect, and the width of the horizontal scrollbar as well as the height of the vertical scrollbar is driven as well. With this setup the viewport as well as the scrollbars must be children to the Scroll Rect root GameObject. Hints The pivot and anchors of the content RectTransform can be used to determine how the content is aligned inside the scroll view if the content grows or shrinks. If the content should stay aligned with the top, set the anchors to the top of the parent, and set the pivot to the top position. See the page Making UI elements fit the size of their content for information about how to make the content Rect Transform automatically resize to fit the content."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Scrollbar.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Scrollbar.html",
    "title": "Scrollbar | mmo-rpg-unity",
    "keywords": "Scrollbar The Scrollbar control allows the user to scroll an image or other view that is too large to see completely. Note that the similar Slider control is used for selecting numeric values rather than scrolling. Familiar examples include the vertical Scrollbar at the side of a text editor and the vertical and horizontal pair of bars for viewing a section of a large image or map. Properties Property: Function: Interactable Will this component accept input? See Interactable. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Fill Rect The graphic used for the background area of the control. Handle Rect The graphic used for the sliding \"handle\" part of the control Direction The direction in which the Scrollbar's value will increase when the handle is dragged. The options are Left To Right, Right To Left, Bottom To Top and Top To Bottom. Value Initial position value of the Scrollbar, in the range 0.0 to 1.0. Size Fractional size of the handle within the Scrollbar, in the range 0.0 to 1.0. Number Of Steps The number of distinct scroll positions allowed by the Scrollbar. Events Property: Function: On Value Changed A UnityEvent that is invoked when the current value of the Scrollbar changes. The event can send the value as a float type dynamic argument. Details The value of a Scrollbar is determined by the position of the handle along its length with the value being reported as a fraction between the extreme ends. For example, the default left-to-right bar has a value of 0.0 at the left end, 1.0 at the right end and 0.5 indicates the halfway point. A scrollbar can be oriented vertically by choosing Top To Bottom or Bottom To Top for the Direction property. A significant difference between the Scrollbar and the similar Slider control is that the Scrollbar's handle can change in size to represent the distance of scrolling available; when the view can scroll only a short way, the handle will fill up most of the bar and only allow a slight shift either direction. The Scrollbar has a single event called On Value Changed that responds as the user drags the handle. The current value is passed to the even function as a float parameter. Typical use cases for a scrollbar include: Scrolling a piece of text vertically. Scrolling a timeline horizontally. Used as a pair, scrolling a large image both horizontally and vertically to view a zoomed section. The size of the handle changes to indicate the degree of zooming and therefore the available distance for scrolling."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Selectable.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Selectable.html",
    "title": "Selectable Base Class | mmo-rpg-unity",
    "keywords": "Selectable Base Class The Selectable Class is the base class for all the interaction components and it handles the items that are in common. Property: Function: Interactable This determines if this component will accept input. When it is set to false interaction is disabled and the transition state will be set to the disabled state. Transition Within a selectable component there are several Transition Options depending on what state the selectable is currently in. The different states are: normal, highlighted, pressed and disabled. Navigation There are also a number of Navigation Options to control how keyboard navigation of the controls is implemented."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-SelectableNavigation.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-SelectableNavigation.html",
    "title": "Navigation Options | mmo-rpg-unity",
    "keywords": "Navigation Options Property: Function: Navigation The Navigation options refers to how the navigation of UI elements in play mode will be controlled. None No keyboard navigation. Also ensures that it does not receive focus from clicking/tapping on it. Horizontal Navigates Horizontally. Vertical Navigates Vertically. Automatic Automatic Navigation. Explicit In this mode you can explicitly specify where the control navigates to for different arrow keys. Visualize Selecting Visualize gives you a visual representation of the navigation you have set up in the scene window. See below. In the above visualization mode, the arrows indicate how the change of focus is set up for the collection of controls as a group. That means - for each individual UI control - you can see which UI control will get focus next, if the user presses an arrow key when the given control has focus. So in the example shown above, If the \"button\" has focus and the user presses the right arrow key, the first (left-hand) vertical slider will then become focused. Note that the vertical sliders can't be focused-away-from using up or down keys, because they control the value of the slider. The same is true of the horizontal sliders and the left/right arrow keys."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-SelectableTransition.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-SelectableTransition.html",
    "title": "Transition Options | mmo-rpg-unity",
    "keywords": "Transition Options Within a selectable component there are several transition options depending on what state the selectable is currently in. The different states are: normal, highlighted, pressed and disabled. Transition Options: Function: None This option is for the button to have no state effects at all. Color Tint Changes the colour of the button depending on what state it is in. It is possible to select the colour for each individual state. It is also possible to set the Fade Duration between the different states. The higher the number is, the slower the fade between colors will be. Sprite Swap Allows different sprites to display depending on what state the button is currently in, the sprites can be customised. Animation Allows animations to occur depending on the state of the button, an animator component must exist in order to use animation transition. It’s important to make sure root motion is disabled. To create an animation controller click on generate animation (or create your own) and make sure that an animation controller has been added to the animator component of the button. Each Transition option (except None) provides additional options for controlling the transitions. We'll go into details with those in each of the sections below. Color Tint Property: Function: Target Graphic The graphic used for the interaction component. Normal Color The normal color of the control Highlighted Color The color of the control when it is highlighted Pressed Color The color of the control when it is pressed Disabled Color The color of the control when it is disabled Color Multiplier This multiplies the tint color for each transition by its value. With this you can create colors greater than 1 to brighten the colors (or alpha channel) on graphic elements whose base color is less than white (or less then full alpha). Fade Duration The time taken, in seconds, to fade from one state to another Sprite Swap Property: Function: Target Graphic The normal sprite to use Highlighted Sprite Sprite to use when the control is highlighted Pressed Sprite Sprite to use when the control is pressed Disabled Sprite Sprite to use when the control is disabled Animation Property: Function: Normal Trigger The normal animation trigger to use Highlighted Trigger Trigger to use when the control is highlighted Pressed Trigger Trigger to use when the control is pressed Disabled Trigger Trigger to use when the control is disabled"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Shadow.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Shadow.html",
    "title": "Shadow | mmo-rpg-unity",
    "keywords": "Shadow The Shadow component adds a simple outline effect to graphic components such as Text or Image. It must be on the same GameObject as the graphic component. Properties Property: Function: Effect Color The color of the shadow. Effect Distance The offset of the shadow expressed as a vector. Use Graphic Alpha Multiplies the color of the graphic onto the color of the effect."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Slider.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Slider.html",
    "title": "Slider | mmo-rpg-unity",
    "keywords": "Slider The Slider control allows the user to select a numeric value from a predetermined range by dragging the mouse. Note that the similar ScrollBar control is used for scrolling rather than selecting numeric values. Familiar examples include difficulty settings in games and brightness settings in image editors. Properties Property: Function: Interactable Will this component accept input? See Interactable. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Fill Rect The graphic used for the fill area of the control. Handle Rect The graphic used for the sliding \"handle\" part of the control Direction The direction in which the slider's value will increase when the handle is dragged. The options are Left To Right, Right To Left, Bottom To Top and Top To Bottom. Min Value The value of the slider when the handle is at its extreme lower end (determined by the Direction property). Max Value The value of the slider when the handle is at its extreme upper end (determined by the Direction property). Whole Numbers Should the slider be constrained to integer values? Value Current numeric value of the slider. If the value is set in the inspector it will be used as the initial value, but this will change at runtime when the value changes. Events Property: Function: On Value Changed A UnityEvent that is invoked when the current value of the Slider has changed. The event can send the current value as a float type dynamic argument. The value is passed as a float type regardless of whether the Whole Numbers property is enabled. Details The value of a Slider is determined by the position of the handle along its length. The value increases from the Min Value up to the Max Value in proportion to the distance the handle is dragged. The default behaviour is for the slider to increase from left to right but it is also possible to reverse this behavior using the Direction property. You can also set the slider to increase vertically by selecting Bottom To Top or Top To Bottom for the Direction property. The slider has a single event called On Value Changed that responds as the user drags the handle. The current numeric value of the slider is passed to the function as a float parameter. Typical use cases include: Choosing a level of difficulty in a game, brightness of a light, etc. Setting a distance, size, time or angle."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-StandaloneInputModule.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-StandaloneInputModule.html",
    "title": "Standalone Input Module | mmo-rpg-unity",
    "keywords": "Standalone Input Module The module is designed to work as you would expect a controller / mouse input to work. Events for button presses, dragging, and similar are sent in response to input. The module sends pointer events to components as a mouse / input device is moved around, and uses the Graphics Raycaster and Physics Raycaster to calculate which element is currently pointed at by a given pointer device. You can configure these raycasters to detect or ignore parts of your Scene, to suit your requirements. The module sends move events and submit / cancel events in response to Input tracked via the Input window. This works for both keyboard and controller input. The tracked axis and keys can be configured in the module's inspector. Properties Property: Function: Horizontal Axis Type the desired manager name for the horizontal axis button. Vertical Axis Type the desired manager name for the vertical axis. Submit Button Type the desired manager name for the Submit button. Cancel Button Type the desired manager name for the Cancel button. Input Actions Per Second Number of keyboard/controller inputs allowed per second. Repeat Delay Delay in seconds before the input actions per second repeat rate takes effect. Force Module Active Enable this property to force this Standalone Input Module to be active. Details The module uses: Vertical / Horizontal axis for keyboard and controller navigation Submit / Cancel button for sending submit and cancel events Has a timeout between events to only allow a maximum number of events a second. The flow for the module is as follows Send a Move event to the selected object if a valid axis from the Input window is entered Send a submit or cancel event to the selected object if a submit or cancel button is pressed Process Mouse input If it is a new press Send PointerEnter event (sent to every object up the hierarchy that can handle it) Send PointerPress event Cache the drag handler (first element in the hierarchy that can handle it) Send BeginDrag event to the drag handler Set the 'Pressed' object as Selected in the event system If this is a continuing press Process movment Send DragEvent to the cached drag handler Handle PointerEnter and PointerExit events if touch moves between objects If this is a release Send PointerUp event to the object that received the PointerPress If the current hover object is the same as the PointerPress object send a PointerClick event Send a Drop event if there was a drag handler cached Send a EndDrag event to the cached drag handler Process scroll wheel events"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Text.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Text.html",
    "title": "Text | mmo-rpg-unity",
    "keywords": "Text The Text control displays a non-interactive piece of text to the user. This can be used to provide captions or labels for other GUI controls or to display instructions or other text. Properties Property: Function: Text The text displayed by the control. Character Font The Font used to display the text. Font Style The style applied to the text. The options are Normal, Bold, Italic and Bold And Italic. Font Size The size of the displayed text. Line Spacing The vertical separation between lines of text. Rich Text Should markup elements in the text be interpreted as Rich Text styling? Paragraph Alignment The horizontal and vertical alignment of the text. Align by Geometry Use the extents of glyph geometry to perform horizontal alignment rather than glyph metrics. Horizontal Overflow The method used to handle the situation where the text is too wide to fit in the rectangle. The options are Wrap and Overflow. Vertical Overflow The method used to handle the situation where wrapped text is too tall to fit in the rectangle. The options are Truncate and Overflow. Best Fit Should Unity ignore the size properties and simply try to fit the text to the control's rectangle? Color The color used to render the text. Material The Material used to render the text. A default text element looks like this: Details Some controls (such as Buttons and Toggles) have textual descriptions built-in. For controls that have no implicit text (such as Sliders), you can indicate the purpose using a label created with a Text control. Text is also useful for lists of instructions, story text, conversations and legal disclaimers. The Text control offers the usual parameters for font size, style, etc, and text alignment. When the Rich Text option is enabled, markup elements within the text will be treated as styling information, so you can have just a single word or short section in boldface or in a different color, say (see the page about Rich Text for details of the markup scheme). Hints See the Effects page for how to apply a simple shadow or outline effect to the text."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Toggle.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-Toggle.html",
    "title": "Toggle | mmo-rpg-unity",
    "keywords": "Toggle The Toggle control is a checkbox that allows the user to switch an option on or off. Properties Property: Function: Interactable Will this component will accept input? See Interactable. Transition Properties that determine the way the control responds visually to user actions. See Transition Options. Navigation Properties that determine the sequence of controls. See Navigation Options. Is On Is the toggle switched on from the beginning? Toggle Transition The way the toggle reacts graphically when its value is changed. The options are None (ie, the checkmark simply appears or disappears) and Fade (ie, the checkmark fades in or out). Graphic The image used for the checkmark. Group The Toggle Group (if any) that this Toggle belongs to. Events Property: Function: On Value Changed A UnityEvent that is invoked when the Toggle is clicked. The event can send the current state as a bool type dynamic argument. Details The Toggle control allows the user to switch an option on or off. You can also combine several toggles into a Toggle Group in cases where only one of a set of options should be on at once. The Toggle has a single event called On Value Changed that responds when the user changes the current value. The new value is passed to the event function as a boolean parameter. Typical use cases for Toggles include: Switching an option on or off (eg, playing music during a game). Letting the user confirm they have read a legal disclaimer. Choosing one of a set of options (eg, a day of the week) when used in a Toggle Group. Note that the Toggle is a parent that provides a clickable area to children. If the Toggle has no children (or they are disabled) then it is not clickable."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-ToggleGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-ToggleGroup.html",
    "title": "Toggle Group | mmo-rpg-unity",
    "keywords": "Toggle Group A Toggle Group is not a visible UI control but rather a way to modify the behavior of a set of Toggles. Toggles that belong to the same group are constrained so that only one of them can switched on at a time - pressing one of them to switch it on automatically switches the others off. Properties Property: Function: Allow Switch Off Is it allowed that no toggle is switched on? If this setting is enabled, pressing the toggle that is currently switched on will switch it off, so that no toggle is switched on. If this setting is disabled, pressing the toggle that is currently switched on will not change its state. Description The Toggle Group is setup by dragging the Toggle Group object to the Group property of each of the Toggles in the group. Toggle Groups are useful anywhere the user must make a choice from a mutually exclusive set of options. Common examples include selecting player character types, speed settings (slow, medium, fast, etc), preset colors and days of the week. You can have more than one Toggle Group object in the scene at a time, so you can create several separate groups if necessary. Unlike other UI elements, an object with a Toggle Group component does not need to be a child of a Canvas object, although the Toggles themselves still do. Note that the Toggle Group will not enforce its constraint right away if multiple toggles in the group are switched on when the scene is loaded or when the group is instantiated. Only when a new toggle is swicthed on are the others switched off. This means it's up to you to ensure that only one toggle is switched on from the beginning."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-TouchInputModule.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-TouchInputModule.html",
    "title": "Touch Input Module | mmo-rpg-unity",
    "keywords": "Touch Input Module Note: TouchInputModule is obsolete. Touch input is now handled in StandaloneInputModule. This module is designed to work with touch devices. It sends pointer events for touching and dragging in response to user input. The module supports multitouch. The module uses the scene configured Raycasters to calculate what element is currently being touched over. A raycast is issued for each current touch. Properties Property: Function: Force Module Active Forces this module to be active. Details The flow for the module is as follows: For each touch event If it is a new press Send PointerEnter event (sent to every object up the hierarchy that can handle it) Send PointerPress event Cache the drag handler (first element in the hierarchy that can handle it) Send BeginDrag event to the drag handler Set the 'Pressed' object as Selected in the event system If this is a continuing press Process movement Send DragEvent to the cached drag handler Handle PointerEnter and PointerExit events if touch moves between objects If this is a release Send PointerUp event to the object that received the PointerPress If the current hover object is the same as the PointerPress object send a PointerClick event Send a Drop event if there was a drag handler cached Send a EndDrag event to the cached drag handler"
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-VerticalLayoutGroup.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/script-VerticalLayoutGroup.html",
    "title": "Vertical Layout Group | mmo-rpg-unity",
    "keywords": "Vertical Layout Group The Vertical Layout Group component places its child layout elements on top of each other. Their heights are determined by their respective minimum, preferred, and flexible heights according to the following model: The minimum heights of all the child layout elements are added together and the spacing between them is added as well. The result is the mimimum height of the Vertical Layout Group. The preferred heights of all the child layout elements are added together and the spacing between them is added as well. The result is the preferred height of the Vertical Layout Group. If the Vertical Layout Group is at its minimum height or smaller, all the child layout elements will also have their minimum height. The closer the Vertical Layout group is to its preferred height, the closer each child layout element will also get to their preferred height. If the Vertical Layout Group is taller than its preferred height, it will distribute the extra available space proportionally to the child layout elements according to their respective flexible heights. For more information about minimum, preferred, and flexible height, see the documentation on Auto Layout. Properties Property: Function: Padding The padding inside the edges of the layout group. Spacing The spacing between the layout elements. Child Alignment The alignment to use for the child layout elements if they don't fill out all the available space. Control Child Size Whether the Layout Group controls the width and height of its child layout elements. Use Child Scale Whether the Layout Group considers the scale of its child layout elements when sizing and laying out elements. Width and Height correspond to the Scale > X and Scale > Y values in each child layout element's Rect Transform component. You cannot animate the Scale values using the Animator Controller Child Force Expand Whether to force the child layout elements to expand to fill additional available space."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/ugui.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/Documentation~/ugui.html",
    "title": "About Unity UI | mmo-rpg-unity",
    "keywords": "About Unity UI Unity UI is a UI toolkit for developing user interfaces for games and applications. It is a GameObject-based UI system that uses Components and the Game View to arrange, position, and style user interfaces. You cannot use Unity UI to create or change user interfaces within the Unity Editor. Installing Unity UI Unity UI is a core package. A version of it is included in each Unity release. To remove this package, or reinstall it after removal, follow the instructions in the Package Manager documentation. Getting documentation User documentation The Unity UI user documentation is in the Unity Manual. It provides a basic overview of the available components, and a few how-tos. API documentation You can find Class descriptions and API compatibility information in the Scripting API section of this documentation. Getting support For questions and assistance, visit the Unity UI section of the Unity Forum."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "Unity UI Copyright © 2015-2020 Unity Technologies ApS (\"Unity\") Licensed under the Unity Companion License for Unity-dependent projects (see https://unity3d.com/legal/licenses/unity_companion_license). _Unless expressly provided otherwise, the Software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.ugui@1.0.0/README.html": {
    "href": "Library/PackageCache/com.unity.ugui@1.0.0/README.html",
    "title": "Unity UI | mmo-rpg-unity",
    "keywords": "Unity UI The Unity UI package allows you to create in-game user interfaces fast and intuitively. Prerequisites Unity 2019.2 This package is in development, and requires Unity 2019.2. Getting Started The Unity UI user manual can be found here."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/CHANGELOG.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/CHANGELOG.html",
    "title": "Changelog | mmo-rpg-unity",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog [1.9.4] - 2024-04-08 Fixed Fixed sqlite dll changes not being recognized correctly by the 2022.3 Unity Editor [1.9.3] - 2024-03-19 Fixed Fixed errors related to the sqlite dll when using the Windows ARM64 Editor Favorites are now kept when entering play mode UVSB-2519 Fixed continuous input when using an OnInputSystemEventVector2 node with OnHold UVSB-2518 [1.9.2] - 2023-10-30 Fixed Fixed a bug where the second player input device controlled all objects when using InputSystem event nodes UVSB-2499 Documentation links have been fixed for Visual Scripting MonoBehaviours UVSB-2475 UVSB-2496 Changed AnimationEvent and NamedAnimationEvent Nodes icon changed in favor of the AnimationClip icon instead of the Animation Component icon. [1.9.1] - 2023-08-15 Fixed Reverted a breaking change where LudiqScriptableObject._data was marked as private Reverted a breaking change related to IGraphEventListener [1.9.0] - 2023-08-01 Fixed Fixed code for custom nodes being stripped in AOT builds when Managed Stripping Level is set to High UVSB-2439 Fixed OnInputSystemEvent doesn't trigger until Input Vector variates from 0.5 UVSB-2435 Fixed assembly disappearing from Node Library after domain reload. UVSB-2459 Fixed custom inspectors not being generated UVSB-2466 Fixed error when trying to load exceptions for TryCatch node dropdown UVSB-2463 Fixed infinite amount of GameObjects created in Prefab mode when performing a null check of a scene variable in editor with an OnDrawGizmos event UVSB-2453 Removed corrupt mdb which caused the ScriptUpdater to fail UVSB-2360 Fixed Gradient graph variables resetting when entering PlayMode UVSB-2334 Fixed Memory leak after destroying object UVSB-2427 Fixed migration deserialization bug introduced in 1.8.0 UVSB-2492 Added Added a warning icon next to assemblies in Project Settings that reference Editor assemblies UVSB-2382 Changed Script Graph Asset string data is unloaded after deserialization UVSB-2366 AOT Prebuild should take less memory and be faster (Added an optimization to AssetUtility.GetAllAssetsOfType<T>) UVSB-2417 [1.8.0] - 2022-11-03 Fixed Fixed graphs being corrupted on deserialization if containing a node whose type cannot be found. UVSB-2332 For nodes that support a default parameter for each of their inputs, detect and fix parameter renames UVSB-1885 Fixed the problem that was preventing link.xml creation when building for Mono backend UVSB-2348 Moved Events/MessageListeners files to a Listeners folder to avoid to exceed some OS path limit Fixed Grandient.mode serialization. Fix available for Unity 2021.3.9f1 or newer UVSB-2356 Fixed Visual Scripting settings now only save to disk when modified Fixed sub graphs being shown with broken connections on first load as of Unity 2021.2 UVSB-2345 Fixed documentation links for Script Graph and State Graphs assets UVSB-2422 Added Added confirmation popup when resetting project settings and editor preferences. UVSB-2353 Added confirmation popup when resetting assemblies/types in project settings. Added Sticky Note for ScriptGraph and StateGraph. Nodes may now have a button which triggers a custom action in their inspector description. Nodes whose type cannot be found are now temporarily converted to dummy nodes until either their original type is defined again or the user replaces them. Support for parameter renaming in code used by API nodes Changed AOTStubs are now generated for all nodes regardless of whether they represent a runtime or editor member UVS-2381 Increased zoom out distance in graphs. [1.7.8] - 2022-02-22 Fixed Handle ReflectionTypeLoadException for TypeUtility to remove warning BOLT-1900 Fixed drag inconsistency in Graph Variables BOLT-2113 Fixed exception after creating a graph from the Welcome Window on Linux BOLT-1828 Fixed the Cooldown node not becoming \"Ready\" when the \"Reset\" port is triggered Fixed exception thrown after changing Hierarchy selection after removing Saved variable BOLT-1919 Fixed old Bolt saved variables not loading when using a build created using a newer version of Visual Scripting BOLT-2052 Fixed a performance issue when using lots of Get/Set Scene variable nodes in an open graph Fixed zooming out in the Graph to be relative to the mouse cursor BOLT-1667 Fixed a compilation error when migrating from Visual Scripting 1.7.6 to 1.7.7 with InputSystem-1.1.1 or below installed. Fixed a performance issue when using lots of Get/Set Scene variable nodes in an open graph Fixed default inspectors for nodes not appearing in the correct position after a connected node is deleted BOLT-1457 Fixed Scene variables drag and drop in graph having wrong scope BOLT-2247 OnDestroy events are now properly triggered in script graphs BOLT-1783 Changed Small optimization of load times involving generic types. Renamed ContinuousNumberDrawer.cs.cs to ContinuousNumberDrawer.cs BOLT-2288 Added TextMeshPro assembly is now added by default in Project Settings/Visual Scripting/Node Library Added highlight to new VS graph drop down items BOLT-2205 Added margins to the UI for project settings and editor preferences [1.7.7] - 2021-11-23 Fixed Fix an NullException error that occurs when creating a Variable right after project initialization. Fix Visual scripting naming in Project Settings and listener. Scene is marked as dirty when a graph is created on a new or exiting GameObject BOLT-1860 Fix Flow Variables missing icon Improved node regeneration speed Fix null texture error when switching platform after a build failure Fix null texture error when entering play mode Fix Linux build failing when run from command line Fix Editor Assemblies not detected correctly at Codebase initialization Fix Wait nodes naming inconsistency BOLT-1886 Fix constant being stripped in IL2CPP builds BOLT-1638 TryConvert now returns true when the conversion was successful BOLT-2105 Fix Input system by using correct Input API BOLT-2078 [1.7.6] - 2021-11-05 Fixed Fixed a regression where AOT Stubs were not being generated correctly, causing AOT builds to fail when run. [1.7.5] - 2021-08-30 Changed Removed unused Preferences Renamed preference \"Update Units Automatically\" to \"Update Nodes Automatically\" Reduced domain reload performance cost of visual scripting to 1ms or less when not actively used by a project Fixed Fixed an issue where uncaught exceptions were thrown in Debug builds of the Windows editor Fixed the missing arrow when the \"Transition End Arrow\" is on. BOLT-1535 Fixed wrong graph is showed after creating script graph form selected object in \"Welcome Screen\" Fixed duplicate variable error. BOLT-1569 Fixed 'ReadOnlySpan<>' does not exist in the namespace 'System'\" error with AOT build. BOLT-1648 Fixed jitter when the fuzzy window is on the bottom of the screen and the user scrolls BOLT-1530 Fixed missing AOT prebuild step when building an IL2CPP project in batchmode BOLT-1649 Restored a public icon set API in UnitPortDescription.cs that was by mistake Fixed il2cpp crash caused by a recursion of the machine states in itself when AOTstubs is generating.BOLT-1656 [1.7.3] - 2021-06-30 Changed Removed unused Preferences Renamed preference \"Update Units Automatically\" to \"Update Nodes Automatically\" Fixed Fixed an issue where uncaught exceptions were thrown in Debug builds of the Windows editor Fixed custom units not appearing in the finder [1.7.2] - 2021-05-17 Changed NotEquals node in non-scalar mode is now consistent with Equals Fixed Fixed long values not preserved in literal nodes. Fixed root icons in breadcrumbs in the graph editor window. BOLT-1290 Fixed graph nodes icons Fixed project settings will not show when looking for graphs Fixed exception when user double clicks on a graph Raise warnings at edit time when a MouseEvent node is used when targeting handheld devices instead of build time. [1.7.1] - 2021-05-07 Removed For performance reasons, the BackgroundWorker attribute is now obsolete and won't have any effect. Use BackgroundWorker.Schedule() directly Changed Renamed the VSSettingsProvider assembly to Unity.VisualScripting.SettingsProvider.Editor Variables Saver GameObject no longer appears until a variable is created or changed. BOLT-1343 Renamed Singleton GameObjects created by Visual Scripting to use \"VisualScripting ---\" names. All internal plugin and product versions have been normalized to use the package version. NotEquals node in non-scalar mode is now consistent with Equals SuperUnits have been renamed into Subgraphs No longer have a hard dependency on any of the following built-in modules: ai, animation, particlesystem, physics, physics2d ScriptMachine is now displayed as \"Script Machine\" instead of \"Flow Machine\" in the Gizmo window. Update, Start, Fixed Update and Late Update nodes have been renamed into On Update, On Start, On Fixed Update and On Late Update. Moved project settings from Assets directory to the ProjectSettings directory in Unity projects Renamed control schemes to Default/Alternate The UI references to 'Unit' were changed to 'Node' without any change to the underlying types Nodes from Timeline, Cinemachine and InputSystem packages are now automatically included, with their assemblies part of the default assemblyOptions. Progress bar titles for initial node generation have been tweaked to better indicate that it is a one-time process Various optimizations to reduce the duration of domain reloads Added Added workflows to create new graphs directly from the Graph Window SetScriptGraph node SetStateGraph node Support for RenamedFrom attribute on enum members GetStateGraphs node GetScriptGraphs node GetScriptGraph node GetStateGraph node HasStateGraph node HasScriptGraph node Fixed Fixed the problem were on Linux the fuzzy window would remains above all others. BOLT-1197 There is no more crash when the user navigates quickly between fuzzy finder levels on Linux BOLT-1197 Fixed variable type turns to null when clicked outside of the graph Fixed rearranging variables, if type is not set, it sets to the type that is bellow it Lots of miscellaneous migration fixes and quality of life changes Fixed unexpected error when exceptions are thrown by flow graph units and caught by the TryCatch unit BOLT-1392 [1.6.1] - 2021-03-30 Fixed Fixed bug caused by Editor API transitioning from private to public [1.6.0] - 2021-03-23 Changed Updated graph migration process [1.5.2] - 2021-03-05 Changed User interface updated Names in different UI elements made to be more consistent with new naming schemes [1.5.1] - 2021-02-23 Added Warn the user when an Input System Package event is referencing an action of the wrong type for that event A warning is raised when adding more than one Input unit in a SuperUnit \"Open\" inspector button and double clicking a graph in the project browser now opens the visual scripting editor A warning is raised when the step's default value of the For unit is set to 0. Fixed Fixed \"Restore to Defaults\" buttons in the Project Settings window Fixed ThreadAbortException when entering Play Mode while searching in the Fuzzy Finder Fixed Visual Scripting Preferences being searchable BOLT-1218 Fixed ScalarAdd unit migration from 1.4.13 to 1.4.14 and above Fixed Open the graph window no longer causes Unity UI to stop processing mouse clicks\" BOLT-1159, Fixed Fuzzy finder no longer blinks when trying to add a node BOLT-1157, Fixed Fuzzy search no longer drops keyboard inputs and respond slowly BOLT-1214, Fixed Fuzzy finder search window no longer remains above all other windows BOLT-1197\" Fixed Dropdown icon is not clipped with TextField under \"Get Variable\" Fixed Scale groups when zoom is not at 1x Fixed graph getting corrupted when adding \"Get Action Map\" unit Fixed node description being sometimes clipped Fixed warnings overflow in the console when deleting and adding a boolean variable in the blackboard Fixed warnings when entering play mode when the \"Script Changes While Playing\" is set to Recompile And Continue Playing Fixed resize cursor rect on group when graph window is zoomed Fixed VisualScripting.Generated folder is removed when removing the VisualScripting package. Fixed error when executing \"Fix Missing Scripts\" in a HDRP project Visual Scripting Preferences spacing has been adjusted to avoid overlaps Fixed rendering of inactive ObjectFields Fixed sidebar (graph inspector/blackboard) resize when a vertical scrollbar is needed Fixed variable type reset to Enum when changing from Enum to GameObject when both Blackbaord and Variables inspector are displayed Help button in the visual scripting Assets and Behaviours inspector now link to the package documentation. FlowMachine type is now back in usable types. Fixed GraphPointerException occurs when nesting graph within itself BOLT-1257 Fixed RenamedFrom attribute does not function correctly on array references to a renamed type BOLT-1149 Fixed error message when custom inspectors are generated Fixed missing succession for Cooldown. Output of Cooldown completed is treated as unentered. BOLT-725 Fixed infinite loop when setting the For unit's step's default value to 0. Instead, the unit won't be executed and the exit output will be triggered directly. Fixed Object Variables tabs not updated when creating a Prefab Fixed console errors when deleting a Prefab with a Visual Script Fixed console errors when editing nested graphs during Play Mode Fixed console errors when opening the standalone profiler window [1.5.1-pre.5] - 2021-01-20 Changed Removed code referring to an unused SceneManagement.PrefabStage API [1.5.1-pre.3] - 2020-12-07 Added Added Visual Scripting as built-in package as of Unity 2021.1 Added New Input System Support. You can import the Input System package, activate the back-end and regenerate units to use. Added AOT Pre-Compile to automatically run when building AOT platforms Improved UI for deprecated built-in nodes Added automatic unit generation the first time the graph window is opened Changed Switched to delivering source instead of pre-built .NET 3/4 assemblies Updated Documentation Renamed assemblies to match Unity.VisualScripting naming scheme (Ex: Bolt.Core -> Unity.VisualScripting.Core) Merged Ludiq.Core and Ludiq.Graphs into Unity.VisualScripting.Core Moved Setup Wizard contents from pop-up on Editor startup to Player Settings. You can change the default settings from \"Player Settings > Visual Scripting\" Renamed \"Assembly Options\" to \"Node Library\" Renamed \"Flow Graph\" to \"Script Graph\" Renamed \"Flow Machine\" to \"Script Machine\" Renamed \"Macro\" graphs to \"Graph\" in machine source configuration and \"GraphAsset\" in Assets Renamed \"Control Input/Output\" to \"Trigger Input/Output\" Renamed \"Value Input/Output\" to \"Data Input/Output\" Updated built-in nodes. The Fuzzy Finder still accepts earlier version names of nodes. Renamed \"Branch\" node to \"If\" Renamed \"Self\" node to \"This\" Deprecated the previous Add unit. The Sum unit has been renamed to Add. Updated Window Naming Changed \"Variables\" window to \"Blackboard\" Changed \"Graph\" window to \"Script Graph\" and \"State Graph\" Updated Bolt Preferences Renamed Bolt Preferences to \"Visual Scripting\" Removed BoltEx Moved settings previously accessed from \"Window > Bolt\" to preferences Renamed Control Schemes from \"Unity/Unreal\" to \"Default/Alternate\" (Neither control scheme currently matches their respective editors' controls and will be updated in a future release) Consolidated Graph editor, Blackboard and Graph Inspector into a single window Updated Third-Party Notices Plugin version information has been removed from the Visual Scripting settings window. This information can be retrieved from the Package Manager. Fixed Corrected UGUI event management to trickle down correctly when the hierarchy contains a Unity Message Listener BOLT-2 Fixed backup failures with large projects BOLT-10 Fixed \"Null Reference\" when opening the Graph Window for the first time BOLT-996 Fixed IL2CPP build crash on startup BOLT-1036 Fixed IL2CPP issue around converting certain managed types BOLT-8 Fixed deserialization issues when undoing graphs with Wait nodes BOLT-679 Fixed \"SelectOnEnum\" node behavior enums containing non-unique values e.g. \"RuntimePlatform\" BOLT-688"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/TableOfContents.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/TableOfContents.html",
    "title": "| mmo-rpg-unity",
    "keywords": "About Visual Scripting *Configure project settings *[Add or remove available nodes](vs-add-remove-node-library.md) *[Add or remove types](vs-add-remove-type-options.md) *[Create or restore a backup](vs-create-restore-backups.md) *Choose a control scheme *Configure your preferences *Update Visual Scripting *Version control systems *Use Visual Scripting with Unity Cloud Build Basic concepts in Visual Scripting *The interface *Nodes *Graphs *[Subgraphs and State Units](vs-nesting-subgraphs-state-units.md) *[Transitions](vs-transitions.md) *Script Machines and State Machines *Object types *[Custom types](vs-custom-types.md) *Variables Develop application logic with Script Graphs *Create a new graph file *[Create a new blank graph with the Project window](vs-create-graph-project-window.md) *[Create a new unassigned graph with the empty graph creation flow](vs-create-graph-unassigned-flow.md) *[Create and assign a graph to an existing GameObject](vs-create-graph-assign-existing-gameobject.md) *[Create and assign a graph to a new GameObject](vs-create-graph-assign-new-gameobject.md) *[Create a graph on a Script Machine or State Machine](vs-create-graph-on-machine.md) *Attach a graph file to a Script Machine or State Machine *Open a graph file *[Add a node to a Script Graph](vs-add-node-to-graph.md) *[Connect nodes in a Script Graph](vs-creating-connections.md) *[Create and add a variable to a Script Graph](vs-add-variable-graph.md) *[Create node groups](vs-groups.md) *[Add comments to a graph](vs-sticky-notes.md) *Add a Subgraph to a Script Graph *[Add a Trigger or Data port to a Script Graph](vs-nesting-add-triggers-data-graph.md) *Add a State Unit to a Script Graph *Custom Events *[Add a Custom Event node](vs-add-custom-event-node.md) *[Add a Trigger Custom Event node](vs-add-custom-event-node-trigger.md) *Capture user input in an application *[Capture input using the Input Manager](vs-capturing-player-inputs-old.md) *[Add and configure a Player Input component](vs-capture-player-input-add-component.md) *[Capture input using the Input System package](vs-capturing-player-inputs-new.md) *Use relations to debug *[Predictive and live debugging](vs-debugging.md) *[Working with debug messages](vs-debug-messages.md) *Live edit *[Live edit during runtime](vs-live-edit-runtime.md) Develop logic transitions with state graphs *Create a new state *Create a transition between states Advanced customization and development *Refactor a C# script with Visual Scripting *[Add the RenamedFrom attribute to a C# script](vs-refactor-add-attribute.md) *Custom C# nodes *[Create a new simple Custom C# node](vs-create-custom-node-empty.md) *[Add ports to your Custom C# node](vs-create-custom-node-add-ports.md) *[Add logic to your Custom C# node](vs-create-custom-node-add-logic.md) *[Add relations to your Custom C# node](vs-create-custom-node-add-relations.md) *[Add documentation to your Custom C# node](vs-create-custom-node-add-docs.md) *[Custom C# node attributes reference](vs-create-custom-node-attributes-reference.md) *Create a Custom Scripting Event node *[Create a Custom Scripting Event Sender node](vs-create-own-custom-event-send-node.md) *[Trigger a Custom Scripting Event from a C# script](vs-create-own-custom-event-node-trigger-code.md) *[Listen to a Custom Scripting Event from a C# script](vs-create-own-custom-event-listen-code.md) *Use a custom type *[Add the Inspectable attribute to a custom type](vs-add-inspectable-attribute-custom-types.md) *[Create a custom PropertyDrawer for a custom type](vs-create-custom-drawer.md) Node reference *This node *Control node *Time node *Events *[Event nodes](vs-events-reference.md) *[Input Event nodes](vs-input-nodes.md) *[On Input System Event Button](vs-nodes-events-input-system-button.md) *[On Input System Event Float](vs-nodes-events-input-system-float.md) *[On Input System Event Vector 2](vs-nodes-events-input-system-vector2.md) *[On Button Input](vs-nodes-events-on-button-input.md) *[On Keyboard Input](vs-nodes-events-on-keyboard-input.md) *[On Mouse Down](vs-nodes-events-on-mouse-down.md) *[On Mouse Drag](vs-nodes-events-on-mouse-drag.md) *[On Mouse Enter](vs-nodes-events-on-mouse-enter.md) *[On Mouse Exit](vs-nodes-events-on-mouse-exit.md) *[On Mouse Input](vs-nodes-events-on-mouse-input.md) *[On Mouse Over](vs-nodes-events-on-mouse-over.md) *[On Mouse Up As Button](vs-nodes-events-on-mouse-up-button.md) *[On Mouse Up](vs-nodes-events-on-mouse-up.md) *Variable node *Nulls node *Formula node *Nesting *[Input node](vs-nesting-input-node.md) *[Output node](vs-nesting-output-node.md) *[State Unit node](vs-nesting-state-unit-node.md) *[Subgraph node](vs-nesting-subgraph-node.md) *Script graph nodes *State graph nodes Developer's guide Known Issues"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/index.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/index.html",
    "title": "About Visual Scripting | mmo-rpg-unity",
    "keywords": "About Visual Scripting Use Visual Scripting to create logic for games or applications without hand-coded C# scripts. Visual Scripting uses visual, node-based graphs, which both programmers and non-programmers use to design final logic or create prototypes. Visual Scripting also has an API that programmers can use for more advanced tasks, or to create custom nodes for other team members. Visual Scripting nodes can represent functions, operators, and variables. Connect these nodes from their ports with edges to design your logic visually. Installation From Unity Editor version 2021.1 onward, Visual Scripting is installed by default as a package. For more information on packages, see the Packages section in the Unity User Manual. For earlier versions of Unity, including 2019 LTS and 2020 LTS, you must install the Visual Scripting package from the Unity Asset Store. Configure Visual Scripting Note To use Visual Scripting in a project for the first time, you must initialize it from the Editor's Project Settings window. To get started with Visual Scripting, configure your project settings and configure your preferences. Choose a control scheme Learn the common keyboard shortcuts and choose a control scheme that suits your needs. Update Visual Scripting Learn how to update Visual Scripting and create and restore backups. System requirements Visual Scripting has no external dependencies."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-c-nodes/vs-ff-add-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-c-nodes/vs-ff-add-node.html",
    "title": "ff-add-node | mmo-rpg-unity",
    "keywords": "Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-c-nodes/vs-open-graph-w-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-c-nodes/vs-open-graph-w-node.html",
    "title": "open-graph-w-node | mmo-rpg-unity",
    "keywords": "Open a Script Graph where you've already added your node."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-c-nodes/vs-tasks-note-end.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-c-nodes/vs-tasks-note-end.html",
    "title": "vs-tasks-note-end | mmo-rpg-unity",
    "keywords": "The examples below are based on the previous examples for a Custom C# node. For more information, see Create a new simple Custom C# node."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-events/vs-right-click-project.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-events/vs-right-click-project.html",
    "title": "right-click-project | mmo-rpg-unity",
    "keywords": "Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-events/vs-tasks-note-end.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/custom-events/vs-tasks-note-end.html",
    "title": "tasks-note-end | mmo-rpg-unity",
    "keywords": "The examples below are based on the previous example to create a Custom Scripting Event node. For more information, see Create a Custom Scripting Event node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-manager/nodes-desc-end.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-manager/nodes-desc-end.html",
    "title": "nodes-desc-end | mmo-rpg-unity",
    "keywords": "It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-manager/nodes-input-output-trigger.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-manager/nodes-input-output-trigger.html",
    "title": "nodes-input-output-trigger | mmo-rpg-unity",
    "keywords": "Trigger Output Trigger The control output port. Make a connection to specify what Visual Scripting should do after the configured Input event occurs in your application."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-manager/nodes-note-manual.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-manager/nodes-note-manual.html",
    "title": "nodes-note-manual | mmo-rpg-unity",
    "keywords": "node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-system/nodes-input-action-change.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-system/nodes-input-action-change.html",
    "title": "nodes-input-action-change | mmo-rpg-unity",
    "keywords": "Name Type Description Input Action Change Type Input Action Change Option Set an Input Action Change Type to choose the interaction type that triggers the node. On Pressed The node triggers when a user presses the button from the selected Input Action input asset. On Hold The node triggers when a user holds the button from the selected Input Action input asset. On Released The node triggers when a user releases the button from the selected Input Action input asset."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-system/nodes-input-system-output-trigger-port.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-system/nodes-input-system-output-trigger-port.html",
    "title": "nodes-input-system-output-trigger-port | mmo-rpg-unity",
    "keywords": "Trigger Output Trigger The control output port. Make a connection to specify what Visual Scripting does after the configured Player Input event, such as a button press, occurs in the application."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-system/nodes-input-system-ports.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-system/nodes-input-system-ports.html",
    "title": "nodes-input-system-ports | mmo-rpg-unity",
    "keywords": "Name Type Description Target Player Input The Player Input component that Visual Scripting uses to display a list of input actions. The default is This, which is the Player Input component attached to the GameObject where Visual Scripting runs the Script Graph. You can also connect a node that outputs a Player Input component. Input Action Input Action An input action. Use the dropdown to select an input action from the Player Input component specified in Player Input, or connect a node that outputs an input action."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-system/nodes-note-package.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/input-system/nodes-note-package.html",
    "title": "nodes-note-package | mmo-rpg-unity",
    "keywords": "is an Input System package node. For more information about how to use the Input System package in Visual Scripting, see Capture user input in an application."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-additional-settings.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-additional-settings.html",
    "title": "nodes-additional-settings | mmo-rpg-unity",
    "keywords": "node has additional settings. Access these settings from the Graph Inspector:"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-controls.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-controls.html",
    "title": "nodes-controls | mmo-rpg-unity",
    "keywords": "node has the following controls:"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-coroutine.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-coroutine.html",
    "title": "nodes-coroutine | mmo-rpg-unity",
    "keywords": "Coroutine Toggle Enable Coroutine if you want Visual Scripting to run this node and any of its connected nodes as a coroutine. Coroutine nodes don't execute all their code in a single frame, so they can spread an effect over several frames. Coroutines can also help optimize your code. For more information on coroutines, see the Unity User Manual section on Coroutines."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-inputs.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-inputs.html",
    "title": "nodes-inputs | mmo-rpg-unity",
    "keywords": "node has the following input ports:"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-outputs.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-outputs.html",
    "title": "nodes-outputs | mmo-rpg-unity",
    "keywords": "node has the following output ports:"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-related.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-related.html",
    "title": "nodes-related | mmo-rpg-unity",
    "keywords": "The following nodes are related or similar to the"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-single-control.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-single-control.html",
    "title": "nodes-single-control | mmo-rpg-unity",
    "keywords": "node has one control:"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-single-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-single-input.html",
    "title": "nodes-single-input | mmo-rpg-unity",
    "keywords": "node has one input port:"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-single-output.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/nodes-single-output.html",
    "title": "nodes-single-output | mmo-rpg-unity",
    "keywords": "node has one output port:"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-blackboard-tip.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-blackboard-tip.html",
    "title": "blackboard-tip | mmo-rpg-unity",
    "keywords": "Tip If the Blackboard isn't visible in the Graph window, select Blackboard () from the toolbar."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-create-c-script-project.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-create-c-script-project.html",
    "title": "create-c-script | mmo-rpg-unity",
    "keywords": "Go to Create > C# Script."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-graph-inspector-tip-html.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-graph-inspector-tip-html.html",
    "title": "graph-inspector-tip-html | mmo-rpg-unity",
    "keywords": "TIP If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-graph-inspector-tip.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-graph-inspector-tip.html",
    "title": "graph-inspector-tip | mmo-rpg-unity",
    "keywords": "Tip If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-existing-external-code.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-existing-external-code.html",
    "title": "open-existing-external-code | mmo-rpg-unity",
    "keywords": "Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-fuzzy-finder.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-fuzzy-finder.html",
    "title": "open-fuzzy-finder | mmo-rpg-unity",
    "keywords": "Right-click anywhere in the Graph Editor to open the fuzzy finder."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-graph-inspector.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-graph-inspector.html",
    "title": "open-graph-inspector | mmo-rpg-unity",
    "keywords": "Select Graph Inspector () from the toolbar."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-graph.html",
    "title": "open-graph | mmo-rpg-unity",
    "keywords": "Open a graph file in the Graph window."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-hierarchy-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-hierarchy-window.html",
    "title": "open-hierarchy-window | mmo-rpg-unity",
    "keywords": "Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-inspector-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-inspector-window.html",
    "title": "open-inspector-window | mmo-rpg-unity",
    "keywords": "With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-new-external-code.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-new-external-code.html",
    "title": "open-new-external-code | mmo-rpg-unity",
    "keywords": "Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-project-settings.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-project-settings.html",
    "title": "open-project-settings | mmo-rpg-unity",
    "keywords": "Go to Edit > Project Settings."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-project-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-project-window.html",
    "title": "open-project-window | mmo-rpg-unity",
    "keywords": "Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-state-menu.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-open-state-menu.html",
    "title": "open-state-menu | mmo-rpg-unity",
    "keywords": "With a State Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the context menu."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-regen-node-library.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-regen-node-library.html",
    "title": "regen-node-library | mmo-rpg-unity",
    "keywords": "Follow the process described in Configure project settings to regenerate your Node Library."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-return-unity.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-return-unity.html",
    "title": "return-unity | mmo-rpg-unity",
    "keywords": "Return to the Unity Editor."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-save-script.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-save-script.html",
    "title": "save-script | mmo-rpg-unity",
    "keywords": "Save your script file."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-visual-scripting-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-visual-scripting-window.html",
    "title": "visual-scripting-window | mmo-rpg-unity",
    "keywords": "Go to Window > Visual Scripting > Visual Scripting Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-with-graph-open-ff.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/snippets/vs-with-graph-open-ff.html",
    "title": "with-graph-open-ff | mmo-rpg-unity",
    "keywords": "With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-custom-event-node-trigger.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-custom-event-node-trigger.html",
    "title": "Add a Custom Event Trigger node | mmo-rpg-unity",
    "keywords": "Add a Custom Event Trigger node You can use a Custom Event Trigger node to trigger a matching Custom Event node in your application. For more information on custom Events, see Custom Events. Note Before you add a Custom Event Trigger node, you must add and configure a Custom Event node in a Script Graph. For more information, see Add a Custom Event node. To add a Custom Event Trigger node to a Script Graph: Open the Script Graph where you want to add a Custom Event Trigger node. This can be the same graph or a different graph from where you added a Custom Event node. Right-click anywhere in the Graph Editor to open the fuzzy finder.. Go to Events. Select the Custom Event Trigger node to add it to the graph. In the Name input port's field, enter the name of the Custom Event node you want to trigger, exactly as it appears on the Custom Event node, through one of the following methods: Enter the name in the field next to the Name input port. Attach a node that outputs the name as a string value to the Name input port. In the GameObject field, indicated by the GameObject icon on the node, specify the GameObject that you want to trigger your Event. This doesn't have to be the same GameObject as the Custom Event node. Do one of the following: Select the object picker (circle icon) and select the GameObject. Attach a node to the field's data input port that outputs the GameObject. Leave the field as the default value of This to use the GameObject from your currently open Script Graph's Script Machine. In the Arguments field, enter the number from your Custom Event node's Arguments field. Note All arguments on a Custom Event Trigger node must receive input values, even if the Custom Event node doesn't use those arguments. Otherwise, Visual Scripting displays an error in the Graph Inspector for the Custom Event Trigger node. Next steps You can add more nodes and connect them to create the trigger logic for your Custom Event node in the graph. You can also create a Custom Scripting Event node."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-custom-event-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-custom-event-node.html",
    "title": "Add a Custom Event node | mmo-rpg-unity",
    "keywords": "Add a Custom Event node You can add a Custom Event node to a Script Graph to trigger specific logic after an Event occurs. For more information about custom Events, see Custom Events. Note To use a Custom Event node, you must configure the node with the following instructions, then add a Custom Event Trigger node to your graph. For more information on how to add a Custom Event Trigger node, see Add a Custom Event Trigger node To add a Custom Event node to a Script Graph: Open the Script Graph where you want to add a Custom Event node. Right-click anywhere in the Graph Editor to open the fuzzy finder.. Go to Events. Select the Custom Event node to add it to your graph. In the GameObject field, indicated by the GameObject icon on the node, choose the GameObject where you want to create the Event. Do one of the following: Select the object picker (circle icon), and select a GameObject. Attach a node to the field's data input port that outputs a GameObject. Leave the field as the default value of This to use the GameObject where you attached your Script Graph to a Script Machine. In the Arguments field, enter the number of arguments you want the custom Event to receive and pass to other nodes in your graph. The default value is 0. If you enter a number greater than 0, Visual Scripting adds the corresponding number of Output ports to the Custom Event node. Note Visual Scripting labels your first argument as Arg. 0. Enter a unique name for the custom Event through one of the following methods: Enter a name in the field next to the Name input port. Attach a node that outputs a string value to the Name input port. In the following example, a custom Event called On Damage returns a single argument when it's triggered in a Script Graph. Next steps After you add a Custom Event node to your graph, add more nodes to your graph or connect nodes to specify what happens after your Event triggers. Then, add a Custom Event Trigger node to specify when to trigger the custom Event in your graph. To create more complex logic for your custom Event, you can also create a Custom Scripting Event node."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-inspectable-attribute-custom-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-inspectable-attribute-custom-types.html",
    "title": "Add the Inspectable attribute to a custom type | mmo-rpg-unity",
    "keywords": "Add the Inspectable attribute to a custom type If you have access to the source code for a custom type, add the [Inspectable] attribute to its fields and classes. The [Inspectable] attribute makes these fields and classes accessible to the Inspector window in the Unity Editor. You don't need to create a custom PropertyDrawer as Unity generates a basic UI for the custom type. For more information about how to use custom types in Visual Scripting, see Use a custom type or Custom types To add the [Inspectable] attribute to the source code for a custom type: Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, on a line above your public class definition, add the [Inspectable] attribute. On a line above the properties you want to have available in the Unity Inspector, add the [Inspectable] attribute. Follow the process described in Configure project settings to regenerate your Node Library. The following is an example of a public class, with fields name and amount that are accessible and can be modified through Unity's Inspector window. ```csharp using System; using UnityEngine; using Unity.VisualScripting; [Inspectable] public class MyClass { [Inspectable] public string name; [Inspectable] public int amount; public string dontShowThis; } ```"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-node-to-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-node-to-graph.html",
    "title": "Add a node to a Script Graph | mmo-rpg-unity",
    "keywords": "Add a node to a Script Graph All logic in a Script Graph starts with a node. Tip Depending on the method you used to create your Script Graph, you might already have two Event nodes in your graph: Start and Update. For more information on these nodes, see Events node. To add a node to a Script Graph: With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder. In the fuzzy finder, enter a search term into the Search bar or select a category from the list to find related nodes. Categories have an arrow (>) at the end of their entry in the fuzzy finder. Select an entry in the fuzzy finder to add that node to your Script Graph. Visual Scripting adds the node to your Script Graph at the location where you opened the fuzzy finder. Next steps After you've added a node to a graph, you can add additional nodes and connect nodes in a Script Graph to create logic for your application. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-remove-node-library.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-remove-node-library.html",
    "title": "Add or remove available nodes | mmo-rpg-unity",
    "keywords": "Add or remove available nodes Visual Scripting has a set of default assemblies and generated nodes for Unity features. Add more assemblies through the Visual Scripting Node Library in your Project Settings. Assemblies are special files that contain the code for the feature you want to use. Visual Scripting can generate nodes from assemblies in packages and third-party assets. To use a new package or third-party asset in Visual Scripting, you must import it into Unity. For more information on how to add packages to Unity, see Adding and removing in the Unity User Manual. For more information on how to add third-party assets to Unity, see Importing assets in the User Manual. Add assemblies and nodes to the Node Library To add a new assembly and its nodes to the Node Library: Go to Edit > Project Settings. Select Visual Scripting. Expand Node Library. At the end of the assemblies list, select Add (+). In the new assembly entry, select (No Assembly) to open the Assembly menu. Select an available assembly from the Assembly menu. Visual Scripting adds the assembly and its nodes to the Node Library. To use the nodes in your project, add their types to your Type Options and regenerate the Node Library. Remove assemblies and nodes from the Node Library To remove an assembly and its nodes from your Node Library: Go to Edit > Project Settings. Select Visual Scripting. Expand Node Library. In the assemblies list, locate the entry for the assembly you want to remove. Select Remove (-). Visual Scripting removes the assembly and its nodes from the Node Library. To remove the nodes from the fuzzy finder and your project, regenerate the Node Library. You might also want to remove their types from your Type Options."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-remove-type-options.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-remove-type-options.html",
    "title": "Add or remove types | mmo-rpg-unity",
    "keywords": "Add or remove types Type Options specify which node inputs and outputs Visual Scripting supports. After you add a new assembly, you must add types specific to those nodes to your Type Options. Add types to make the nodes and their types accessible in the fuzzy finder and the Blackboard. You can't use a node that has an input or output type that isn't listed in your Type Options. Add a type to your Type Options To add a new type to your Type Options list: Go to Edit > Project Settings. Select Visual Scripting. Expand Type Options. At the end of the types list, select Add (+). In the new type entry, select (No Type) to open the Type menu. Select an available type from the Type menu. Visual Scripting adds the new type to your Type Options. To use nodes with the type in your project, regenerate your Node Library. Remove a type from your Type Options To remove a type from your Type Options list: Go to Edit > Project Settings. Select Visual Scripting. Expand Type Options. In the types list, locate the entry for the type you want to remove. Select Remove (-). Visual Scripting removes the type from your Type Options. To make sure that your change appears in your project, regenerate your Node Library."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-subgraph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-subgraph.html",
    "title": "Add a Subgraph to a Script Graph | mmo-rpg-unity",
    "keywords": "Add a Subgraph to a Script Graph A Subgraph is a Script Graph nested inside of another Script Graph. A Subgraph appears as a single node inside the parent Script Graph. You can add a Subgraph to a Script Graph in two ways: create an entirely new Script Graph, or add an existing Script Graph file. Add a new Subgraph to a Script Graph To add a new blank Subgraph to an existing Script Graph: With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder.. Go to Nesting and select Subgraph. In the Graph Inspector, choose the Source for your Subgraph: Embed: The Subgraph only exists on the Subgraph node. You can only modify the Subgraph from the node in its parent graph. Graph: The Subgraph exists in a separate file. You can modify the Subgraph outside of its parent graph and reuse the graph in other areas of your application. Tip If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar. If you chose Graph, select New, enter a name for your graph file, and choose where you want to save it. Select Save. Add an existing Script Graph as a Subgraph To add an existing graph file as a Subgraph in a Script Graph: Note You can't nest a Script Graph as a Subgraph in its own graph file. With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder.. Go to Nesting and select Subgraph. In the Graph Inspector, set your Source to Graph. Tip If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar. In the Graph field, select the object picker (circle icon) and choose a compatible Script Graph from your project. You can also click and drag a Script Graph file from your Project window and drop it into the Graph field. Tip For a faster way to add a Script Graph as a Subgraph, click and drag the Script Graph from your Project window into the Graph Editor to automatically create a Subgraph node. Next steps To open your new Subgraph for editing, select Edit Graph. Once you've added a Subgraph to your Script Graph, define its Input and Output Triggers and Input and Output Data. For more information, see Add a Trigger or Data port to a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-triggers-data-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-triggers-data-graph.html",
    "title": "Add a Trigger or Data port to a Script Graph | mmo-rpg-unity",
    "keywords": "Add a Trigger or Data port to a Script Graph When you use a Script Graph as a Subgraph, you can pass data and logic to it from its parent graph. Add and define ports on your graph to determine which logic and data you can pass to it. To add a Trigger Input, Trigger Output, Data Input, or Data Output port to a Script Graph: If you haven't already, open the Script Graph you want to edit in the Graph window. With no nodes selected, in the Graph Inspector, select Add (+) under the port type you want to add to your Script Graph: Trigger Inputs, Trigger Outputs, Data Inputs, or Data Outputs. Tip If the Graph Inspector isn't visible in the Graph window, select Graph Inspector () from the toolbar. In the Key field, enter a unique key name for your port. This name can't be the same as any existing ports on your currently selected Script Graph. (Optional) In the Label field, enter any text you want to appear as a label for the port on a Subgraph, Input, or Output node for your current Script Graph. Otherwise, Visual Scripting uses the value in the Key field as a label. (Optional) In the Summary field, enter any text that you want to appear as a brief summary of the port in the Graph Inspector when you select a Subgraph, Input, or Output node for your current Script Graph. (Optional) Select Hide Label to hide the label for the port on any Subgraph, Input, or Output node for your current Script Graph. (Data Inputs and Data Outputs Only) Select the Type list to open the Type menu and select a type for the data your port should accept. (Data Inputs Only) Select Has Default Value to enable the Default Value field and specify a default value for your Script Graph's Data Input, if your graph doesn't receive another input while it runs. Next steps You can now specify triggers and data for your Script Graph when you use it as a Subgraph in another Script Graph. For more information on each port type, see Subgraph inputs and outputs. For more information on adding a Script Graph as a Subgraph, see Add a Subgraph to a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-variable-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-add-variable-graph.html",
    "title": "Create and add a variable to a Script Graph | mmo-rpg-unity",
    "keywords": "Create and add a variable to a Script Graph You can create and add a variable to a Script Graph in one of two ways: use the Graph window's Blackboard, or add a node to a graph. Note You can't add a Flow variable to a graph from the Blackboard. For more information on Flow variables, see Variables. Create and add a new variable through the Blackboard To create a new variable in the Blackboard and add it to a graph: With a graph open in the Graph window, open the Blackboard. In the Blackboard, select the scope for the variable you want to add: Graph, Object, Scene, App, or Saved. For more information on variable scopes and when you can use each scope in your graph, see Variables. In the (New Variable Name) field, enter a name for the new variable. Do one of the following: Press Enter. Select the Add Variable (+) button. In the Type list, select the data type for your variable. For more information on types, see Object types. In the Value field, enter or modify the default value for your variable. To add the node to your graph, click and drag from the Handle (=) on the variable's definition in the Blackboard into the Graph Editor. Visual Scripting adds a new Get Variable node for your variable to your graph. Create and add a new variable through the Graph Editor To create a Flow variable or another new variable directly in a graph: With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder. Select the Variables category. Select the scope for the variable you want to add: Flow, Graph, Object, Scene, Application, or Saved. For more information on variable scopes and when you can use each scope in a graph, see Variables. Select the Set <Scope> Variable node, where <Scope> is the scope you selected in the previous step. Visual Scripting adds a new Set Variable node to the graph. In the Name field, enter a name for the new variable. (Object variables only) In the GameObject field, indicated by a GameObject icon on the node, specify the GameObject where you want to create the variable. Do one of the following: Select the object picker (circle icon) and select a GameObject. Attach a node to the field's data input port that outputs a GameObject. Leave the field as the default value of This to use the GameObject where you attached the Script Graph to a Script Machine. To set a default value for your variable, connect another node that outputs the value you want to the Set Variable node's data input port. Next steps After you've added a variable to your graph, you can add nodes, create node groups, or add a Subgraph. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-advanced-topics-intro.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-advanced-topics-intro.html",
    "title": "Advanced customization and development | mmo-rpg-unity",
    "keywords": "Advanced customization and development Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. You can customize and extend the basic functionality of Visual Scripting using C# code. Create a Script Graph node With a C# script, you can create your own Custom C# node and add more functionality to your Visual Scripting graphs. Create a custom event node You can trigger logic in your application with a custom event node. Add custom types to Visual Scripting Add your own custom classes and types in Visual Scripting to store information more efficiently."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-aot.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-aot.html",
    "title": "Use Visual Scripting with Unity Cloud Build | mmo-rpg-unity",
    "keywords": "Use Visual Scripting with Unity Cloud Build At build time, Unity removes any code that isn't used by a project to reduce build size. This can cause problems with Visual Scripting because Unity can remove code that's necessary for Script Graphs to run in a project. For versions 1.7.x, Visual Scripting generates an AotStubs.cs file, which stores the Unity APIs that graphs use. With the AotStubs.cs file, Unity doesn't remove any Unity APIs used in a graph from a build. You can generate this file when you create a build of a project. Builds through Unity Cloud Build can fail because Cloud Build prevents domain reload between the prebuild and build phases of the project. Without a domain reload, the build doesn't include the generated AotStubs.cs file. For more information about domain reload, see Domain Reloading in the Unity User Manual. To build a Visual Scripting project with Cloud Build, do the following: Build the project locally for your desired platform. For more information on how to build a project, see the relevant section for each platform in Platform development in the User Manual. After the build, do one of the following: Open the project files in the system file explorer. Open the Project window in the Unity Editor. In the project files, go to Assets > Unity.VisualScripting.Generated > VisualScripting.Core. Locate the AotStubs.cs file. Add the AotStubs.cs file to your source control system. Your Cloud Build settings might automatically trigger a new build of the project after you commit the AotStubs.cs file. For more information about version control systems and Cloud Build, see Unity Cloud Build in the User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-attach-graph-machine.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-attach-graph-machine.html",
    "title": "Attach a graph file to a Script Machine or State Machine | mmo-rpg-unity",
    "keywords": "Attach a graph file to a Script Machine or State Machine To use a Script Graph or State Graph file in your project, you must attach it to a Script Machine or State Machine. A Script Machine or State Machine is a component. Components attach to GameObjects, and help define their behavior. For more information on components and GameObjects, see Using components or GameObjects in the Unity User Manual. Add a Script Machine or State Machine component to a GameObject Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select a GameObject where you'd like to add a Script Machine or State Machine. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. In the GameObject's Inspector window, select Add Component. The Components menu opens. Do one of the following: To add a Script Machine or State Machine, in the Components menu, go to Visual Scripting and select Script Machine or State Machine. Use the search bar to find the Script Machine or State Machine component. The new Script Machine or State Machine component appears in the Inspector window for the GameObject: Attach a graph file to the Script Machine or State Machine In the Inspector window, locate your Script Machine or State Machine component. Set the Source to Graph. Do one of the following: In the Graph field, select the object picker (circle icon) and choose a compatible graph file from your project. Click and drag a file from your Project window and drop it into the Graph field. For more information on how to create Script or State Graphs, see Create a new graph file. Next steps After you attach a graph to a Script Machine or State Machine, you can open the graph and edit. For more information, see Open a graph file."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-basic-concepts.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-basic-concepts.html",
    "title": "Basic concepts in Visual Scripting | mmo-rpg-unity",
    "keywords": "Basic concepts in Visual Scripting Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. In this section, you can find information about basic concepts in Visual Scripting. These concepts will help you create logic for your application. The interface The Visual Scripting interface starts with the Graph window. For more information, see The interface. Nodes Nodes are the most basic part of creating scripts in Visual Scripting. For more information, see Nodes. Graphs and Machines Graphs contain the visual representations of logic in your application. To use a graph, you attach it to a Script Machine or State Machine on a GameObject. For more information about graphs, see Graphs. For more information about Script Machines and State Machines, see Script Machines and State Machines. Variables Variables act as a container for a piece of information that might change as your application runs. For more information, see Variables. Object types Variables, data, and objects in Visual Scripting all have a specific type. For more information, see Object types."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-capture-player-input-add-component.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-capture-player-input-add-component.html",
    "title": "Add and configure a Player Input component | mmo-rpg-unity",
    "keywords": "Add and configure a Player Input component To use the Input System package with Visual Scripting, add a Player Input component to the same GameObject as the Script Graph and create an Input Actions asset. You must add the Player Input component and create the Input Actions asset before you create the Script Graph. Note If the Input System package isn't installed in your project, follow the Input System documentation's Installation guide to install the package. Go to Window > Package Manager to check your installed packages. To add a Player Input component to a GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject that you want to move with the Script Graph. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. Select Add Component. The Components menu opens. In the Components menu, do one of the following: Go to Input. In the Search bar, enter Player Input. Select the Player Input component to add it to the GameObject. Add an Input Actions asset to the Player Input component. Do one of the following: Create a new Input Actions asset. Use an existing Input Actions asset. Create a new Input Actions asset Select Create Actions. Choose a location in your project to save the Input Actions asset. Select Save. Use an existing Input Actions asset Do one of the following: Click the Actions field's object picker (circle icon) and in the SelectInputActionAsset window, select the asset. Click and drag a file from your Project window and drop it into the Actions field. Next steps To configure the available options on a Player Input component, see GameObject components for input in the Input System package documentation. To configure an Input Actions asset, see Input Action Assets in the Input System package documentation. To create a simple Script Graph to capture input with Visual Scripting, see Capture input with the Input System package. Additional resources Capture user input in an application Capture input with the Input System package Input event nodes"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-capture-player-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-capture-player-input.html",
    "title": "Capture user input in an application | mmo-rpg-unity",
    "keywords": "Capture user input in an application You can capture input from a user's input device to make your application interactive. Visual Scripting can use either the Input Manager or the Input System package to capture input data in a Script Graph. Use the Input System package The Input System package captures input in Unity applications. It uses any input device and replaces Unity's Input Manager. To install the Input System package, see the Installation guide in the Input System package documentation. To check if the Input System package is installed, go to Window > Package Manager. For more information on the Package Manager and managing packages in projects, see the Packages section in the Unity User Manual. Input System package prerequisites To use the Input System package in a project, do the following: Install the package. For more information, see the Packages section in the User Manual. Regenerate your Node Library to include the Input System package nodes. For more information, Configure project settings. In your Player Project Settings, set Active Input Handling to Input System Package (New) or Both. For more information on this setting, see Standalone Player settings in the User Manual. Create an Input System settings asset. Go to Edit > Project Settings and select Input System Package, then select Create Settings Asset. For more information on the available input settings, see Input Settings in the Input System package documentation. Create a GameObject with a PlayerInput component and an Input Actions asset. For more information, see Add and configure a PlayerInput component. After you've configured your project, create a graph to Capture input with the Input System package. Use the Input Manager The Input Manager is Unity's built-in system for input. Change the Input Manager's settings to change how a project receives input. Go to Edit > Project Settings and select Input Manager. For more information on the available settings, see the Input Manager documentation in the User Manual. Input Manager prerequisites To use the Input Manager in a project, in your Player Project Settings, set Active Input Handling to Input Manager (Old) or Both. For more information on this setting, see Standalone Player settings in the User Manual. After you’ve configured your Player Project Settings, create a graph to Capture input with the Input Manager. Additional resources Add and configure a Player Input component Capture input with the Input System package Capture input with the Input Manager Input event nodes"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-capturing-player-inputs-new.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-capturing-player-inputs-new.html",
    "title": "Capture input with the Input System package | mmo-rpg-unity",
    "keywords": "Capture input with the Input System package Important If you don't complete the prerequisite configuration for your project, you can't use the Input System package with Visual Scripting. For more information, see Input System package prerequisites. To use the Input System package with Visual Scripting to capture input in your project: Open or create a Script Graph attached to the GameObject that you want your users to move. Right-click anywhere in the Graph Editor to open the fuzzy finder. Go to Events > Input or search for On Input System Event. Select an Input System Event node. In this example, select the On Input System Event Vector 2 node to add it to the graph. Set the On Input System Event Vector 2 node's Input Action Change Type control to On Hold: In the Input Action list on the On Input System Event Vector 2 node, select an Input Action to trigger the node. In this example, select Move. Note By default, Visual Scripting displays all Input Actions from the Input Action asset attached to your current GameObject's Player Input component. Right-click anywhere in the Graph Editor to open the fuzzy finder. Tip If a context menu appears when you right-click, select Add Node to open the fuzzy finder. Go to Codebase > Unity Engine > Vector 3 or search for Vector 3 Get X. Select Get X to add the Vector 3 Get X node to the graph. Right-click anywhere in the Graph Editor to open the fuzzy finder. Go to Codebase > Unity Engine > Vector 3 or search for Vector 3 Get Z. Select Get Z to add the Vector 3 Get Z node to the graph. Select the Vector 2 Value output port on the On Input System Event Vector 2 node. Make a connection to the Target input port on the Vector 3 Get X node: Select the Vector 2 Value output port. Make a connection to the Target port on the Vector 3 Get Z node. Right-click anywhere in the Graph Editor to open the fuzzy finder. Go to Codebase > Unity Engine > Transform or search for Translate. Select Transform: Translate (X, Y, Z) to add the Translate node to the graph. Select the Value: Float output port on the Vector 3 Get X node. Make a connection to the X float input port on the Translate node. Select the Value: Float output port on the Vector 3 Get X node. Make a connection to the Z float input port on the Translate node. The finished graph looks similar to the following image: To enter Play mode, select Play from the Unity Editor's Toolbar. While in the Game view, press a key defined under the Input Actions asset for Move in the Player Action Map. The GameObject moves along the X or Z axis in the Game view, based on the key pressed and the Input Actions asset. For more information on how to define Input Actions, see Input Action Assets in the Input System package documentation. Additional resources Capture user input in an application Add and configure a Player Input component On Input System Event Button node On Input System Event Float node On Input System Event Vector 2 node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-capturing-player-inputs-old.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-capturing-player-inputs-old.html",
    "title": "Capture input with the Input Manager | mmo-rpg-unity",
    "keywords": "Capture input with the Input Manager Note You must configure your Project Settings to use the Input Manager with Visual Scripting. For more information, see Input Manager prerequisites. To create a basic Script Graph that uses the Input Manager to capture input: Open or create a Script Graph attached to the GameObject that you want your users to move. If there isn't an On Update or similar Event node in your graph: [!include[open-fuzzy-finder](./snippets/vs-open-fuzzy-finder.md)] Go to Events > Lifecycle, or enter On Update in the search field. Select the On Update Event node to add it to the graph. [!include[open-fuzzy-finder](./snippets/vs-open-fuzzy-finder.md)] TIP If you right-click and the context menu appears, select Add Node to open the fuzzy finder. Go to Codebase > Unity Engine > Input, or enter Get Axis in the search field. Select Get Axis (Axis Name) to add the Get Axis node to the graph. Repeat Steps 3 through 5 to create a second Get Axis (Axis Name) node. On the first Get Axis node, in the Axis Name input field, enter Horizontal. On the second Get Axis node, in the Axis Name input field, enter Vertical. NOTE If an Axis Name doesn't match the name in the Input Manager's Project Settings, Visual Scripting displays an error in the Graph Inspector. When you enter Play mode, the Unity Editor also displays an error in the Console window. [!include[open-fuzzy-finder](./snippets/vs-open-fuzzy-finder.md)] Go to Codebase > Unity Engine > Transform or search for Translate. Select Translate (X, Y, Z) to add a Translate node to the graph. Select the Result float output port on the Horizontal Get Axis node. Make a connection to the X input port on the Translate node. Select the Result float output port on the Vertical Get Axis node. Make a connection to the Z input port on the Translate node. The finished graph looks similar to the following image: To enter Play mode, select Play from the Unity Editor's Toolbar. While in the Game view, press a key mapped as a Negative Button or Positive Button from the Input Manager's virtual axes. The GameObject moves along the X or Z axis in the Game view, based on the key pressed and the Input Manager Project Settings. Additional resources Capture user input in an application Capture input with the Input System package On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up As Button node On Mouse Up node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-configuration.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-configuration.html",
    "title": "Configure project settings | mmo-rpg-unity",
    "keywords": "Configure project settings Note To use Visual Scripting in a project for the first time, you must initialize it from the Editor's Project Settings window. Use the Project Settings window with Visual Scripting to manage backups, node assemblies, type options, and regenerate your Node Library. To open your Project Settings: Go to Edit > Project Settings. Select Visual Scripting. You can find the following configuration options in your Visual Scripting Project Settings. To use Visual Scripting in a project for the first time, you must regenerate your Node Library, as described in the table below. Option Description Initialize Visual Scripting You must select Initialize Visual Scripting the first time you use Visual Scripting in a project. Initialize Visual Scripting to parse all assemblies and types for the Visual Scripting Node Library. After you initialize Visual Scripting, regenerate your Node Library. See Regenerate Nodes, below. Type Options Use the Type Options list to add or remove types for your node inputs and outputs. After you add or remove a type, you must regenerate your Node Library. See Regenerate Nodes, below. For more information on how to add or remove types, see Add or remove types. Node Library Use the Node Library list to add or remove nodes and their assemblies in Visual Scripting. You must add any new types to your Type Options after you add new nodes to Visual Scripting. You must also regenerate your Node Library after you add or remove nodes. See Regenerate Nodes, below. For more information on how to add or remove nodes from your Node Library, see Add or remove available nodes. Regenerate Nodes Regenerate your Node Library to make all nodes available for use in a project. To use Visual Scripting for the first time in a project, you must Initialize Visual Scripting and regenerate your Node Library. To regenerate your Node Library: Select Regenerate Nodes. Select OK. NOTE You must regenerate your Node Library in the following circumstances: Before you use Visual Scripting in your project for the first time. After you add or remove nodes from your Node Library. After you add or remove types from your Type Options. After you change the inputs or outputs for a Custom C# node. Generate To generate required property provider scripts for custom drawers, select Generate. These scripts are necessary for Unity to use custom drawers for custom classes and script variables inside Visual Scripting. To assign a default value to a custom variable type through the Unity Editor’s Inspector, you must either have access to the source code for the class, or provide a custom PropertyDrawer. For more information, see Custom types. Create Backup To create a new backup of your Visual Scripting graphs and settings, select Create Backup. For more information about backups, see Create or restore a backup. Restore Backup To open the folder where Visual Scripting stores your backups, select Restore Backup. For more information about backups, see Create or restore a backup. Fix Missing Scripts To correct any issues that might occur after migration from the Unity Asset Store version of Visual Scripting to the package version, select Fix Missing Scripts. This resolves any missing references to Visual Scripting Script Graphs and State Graphs in Script Machine or State Machine components. Note If your settings don't apply after you make a change, report a bug through the Unity Editor."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-control-schemes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-control-schemes.html",
    "title": "Choose a control scheme | mmo-rpg-unity",
    "keywords": "Choose a control scheme You can choose from two different control schemes in Visual Scripting. Each control scheme changes how you can interact with your graphs in the Graph Editor: Action Default Control Scheme Alternate Control Scheme Pan Middle-click and drag Middle-click and drag Pan Vertically Scroll N/A Zoom In/Zoom Out Ctrl+Scroll (macOS: Cmd+Scroll) Scroll Frame Selected Home Home Frame All Home Home Create Selection Click and drag Click and drag Select All Ctrl+A (macOS: Cmd+A) Ctrl+A (macOS: Cmd+A) Open Context Menu Right-click Ctrl+click (macOS) Ctrl+E (macOS: Cmd+E) Right-click Ctrl + click (MacOS) Ctrl+E (macOS: Cmd+E) Create Node Group Ctrl+click and drag (macOS: Cmd+click and drag) Ctrl+click and drag (macOS: Cmd+click and drag) Copy Selected Ctrl+C (macOS: Cmd+C) Ctrl+C (macOS: Cmd+C) Paste Selection Ctrl+V (macOS: Cmd+V) Ctrl+V (macOS: Cmd+V) Cut Selected Ctrl+X (macOS: Cmd+X) Ctrl+X (macOS: Cmd+X) Duplicate Selected Ctrl+D (macOS: Cmd+D) Ctrl+D (macOS: Cmd+D) Delete Selected Del Del Maximize Graph Window Shift+Space Double-click Shift+Space Double-click Move Group Without Child Nodes Alt+click and drag the group's Title bar Ctrl+click and drag the group's Title bar (macOS: Cmd+click and drag) Move Node on One Axis Shift+click and drag vertically or horizontally Shift+click and drag vertically or horizontally Pan Pan to move the viewable area in the Graph Editor to any part of your graph. Pan Vertically With the Default control scheme, pan the view in the Graph Editor vertically with the scroll wheel on your mouse. Zoom In/Zoom Out Change the zoom level in the Graph window to control how much of your graph is visible in the Graph Editor. You can also set your zoom level with the toolbar in the Graph window. For more information, see The interface. Frame Selected After you select a node or another item in your graph, press Home to center your selected item in the Graph Editor. Frame All With no nodes or items selected, press Home to center your entire graph in the Graph Editor. Your zoom level automatically adjusts to accommodate the size of your graph. Create Selection Click and drag to create a selection box around any nodes or items in your graph that you want to select. When you have multiple items selected, click and drag a single item to move the entire selection. Select All Press Ctrl+A (macOS: Cmd+A) to select all items in your current graph. Open Context Menu You can open the context menu to perform certain actions on State Graphs or manipulate a selection in a Script Graph. You can create new states and add transitions. Create Node Group Create a group of nodes to keep related sections of your graph together, or move multiple nodes at a time. For more information on node groups, see Create node groups. Copy Selected Copy your current selection to move it to another graph, or another location on your current graph. Paste Selection Paste the contents of a copied or cut selection into your graph. Cut Selected Cut your current selection to move it to another graph, or another location on your current graph. Duplicate Selected Duplicate a selection to instantly create a copy of your current selection to use elsewhere in your current graph. Delete Selected Delete your current selection to remove it from your graph. Maximize Graph Window After you dock the Graph window in the Unity Editor, press Shift+Space or double-click maximize your Graph window and take up the entire Editor window. Move Group Without Child Nodes You can move a group in your graph without any of the nodes contained inside that group. Move Node on One Axis Shift+click to move a node in only one direction at a time in the Graph Editor. The node can move either vertically or horizontally."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-control.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-control.html",
    "title": "Control nodes | mmo-rpg-unity",
    "keywords": "Control nodes Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Control nodes branch, loop and merge the flow. Branching Branching nodes split the control flow based on a value. If The common if node uses a boolean condition. Consider them as an \"if the condition is true, do something, otherwise, do something else.\" Switch Branch on the value of an enum, a string, or an integer. These nodes are called Switch nodes. To switch on an enum, decide on the type of the enum. The branch output ports appears. To switch on a string or number, create each branch option in the graph inspector. The node is updated with each output port. For strings, optionally choose to ignore the case of the selector. Note A Default port is always added. It is the path that the control flow should take if the input selector does not correspond to any other option. Select Select nodes are the opposite of switch nodes. You can select a single value from a set of options based on a selector. For example, a Select On Integer node that chooses a color based on a player number. Note In the above example predictive debugging warns of a crash if playerNo is not within 1, 2, 3, or 4, because the Default port is not connected. Looping Loops repeats logic for a certain number of iterations before moving on. The logic to be repeated is called the body of the loop. After the loop is over, the exit port is called. Note The body of every loop is called synchronously, not over the course of multiple frames. Co-routine-like behaviours are achieved by listening to the update event manually. While Loop The while loop is the simplest form of loop. It repeats its body while its condition remains true. Only when the condition becomes false does the loop terminate. For example, the following graph generates a new random name until the result isn't contained in the names application variable. Warning Do not create an infinite loop. If the condition is always true, the editor hangs. As loop bodies are synchronous, not parallel, there are few uses for while loops in visual scripting. For Each Loop For Each iterates over every element of a collection. It outputs the current index and item that is being looped over. For example, the following graph outputs four messages to the console: I love my cat I love my dog I love my bird I love my fish To access the key and value from dictionaries in the loop, check the Dictionary box. For Loop For is a numeric loop and requires three integers: a start index, an end index, and a step. The loop starts at the first index, then increments towards the last index via increments of the step. It outputs the current index. For example, this graph counts to ten by skipping odd numbers because of its step. In other words, its output is 0, 2, 4, 6, then 8. The For loop can also be very useful when combined with the Get List Item and Count Items nodes. For example, the following graph is very similar to the last graph as the output to the console is \"I like {animal}s\". Instead of using the For Each node that outputs each item, the graph outputs each item manually by its index in the list. This graph outputs the following messages: I like cats I like dogs I like birds I like horses Break Loop A loop can finish early by using the Break Loop node. As soon as this node is entered, the exit port of the loop is called, no matter how many more iterations remain. For example, even though this for loop is supposed to count to 10, it stops at 5 because of the break. Its output is 0, 1, 2, 3, then 4. Exception Handling Try Catch The Try Catch node handles Exceptions that occur. It prevents your game from crashing in case you suspect some code might fail. Anything that gets executed in the Try branch is considered \"safe\": the script continues from the Catch branch instead if it fails. The Exception port captures information about the failure when that happens. A common way of handling this is to log a warning with the exception message. Note By default, this node catches all exceptions. Be specific in your handling by changing the exception type in the dropdown. The Finally branch is optional. It is always called after Try or Catch, regardless of whether the operation succeeded or not. It is usually used to dispose or destroy any resources that must be freed. This port can be disconnected if there is no need to destroy any resources. Throw The Throw node allows you to raise your own exceptions that stop the flow. These are caught with Try Catch. It is good practice to \"fail early\" by throwing as soon as something unexpected happens. It helps catch bugs early in the chain, instead of letting them trickle down and have unexpected side effects that are hard to debug. For example, to ensure damage is positive before applying it: If the Custom checkbox is selected, you can pass a custom Exception object that contains more data than a simple message. Most often, this is not required. By default, the thrown exception is of type System.Exception. Toggles Toggle nodes are similar in principle to light-switches: they can be turned on and off to impact either the script or values. Think of them as \"gates\" that can be opened and closed. Toggle Flow The Toggle Flow node gates the flow of control. When on, the flow passes through; when off, the flow does not. There are many inputs and outputs that allow fine grained control over the logic. In the previous example, Toggle is used to show how the same event (a keypress) turns the toggle on and off. Instead you can use On and Off with two different events to get the same results. On the output side, the Is On boolean port indicates the toggle status, that is turned on or off. The control outputs are triggered according to the table below: Port Triggered When On Flow enters the toggle via the unmarked input while it is on. Off Flow enters the toggle via the unmarked input while it is off. Turned On The toggle gets turned on, either via the On or Toggle inputs. Turned Off The toggle gets turned off, either via the Off or Toggle inputs. Toggle Value The Toggle Value node selects between two different input values depending on whether it is on or off. Its ports work exactly like the Toggle Flow node. Another way of implementing the same logic as the previous example: clicking Space toggles the object to move up. This time a value of 1 or 0 is provided as the vertical velocity. Note Turn on relations in the toolbar as a means to visualize the flow between the toggle ports. Once The Once node executes different logic the first time it is traversed from any subsequent times. It can be reset by entering the Reset port. Cache The Cache node saves the result of an expensive operating and reuses it instead of fetching it again each time you need it. For example, using this graph, the formula is calculated twice: By using the Cache node, the result is saved and calculated only once, optimizing performance. Note It is important to note that caching only lasts within the scope of the current flow. The value of the cache is not shared or available from another event."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-drawer.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-drawer.html",
    "title": "Create a custom PropertyDrawer for a custom type | mmo-rpg-unity",
    "keywords": "Create a custom PropertyDrawer for a custom type If you want to use a custom type from a custom class in Visual Scripting, and you don't have access to its source code, you must create a custom PropertyDrawer. You can't assign a value to a custom type inside the Editor or initialize the value for a variable with a custom type if it doesn't have a PropertyDrawer. Note The class for your custom type must have the [Serializable] tag in its source code to create a custom PropertyDrawer. To create a custom PropertyDrawer: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Go to Create > C# Script. Enter a name, such as CounterDrawer, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. Remove the Start and Update functions and their comments from the script file. Above the line that defines your new public class, add a [CustomPropertyDrawer] attribute. In the parameters for the [CustomPropertyDrawer] attribute, specify a type of parameter with the name of the type you want to assign to this PropertyDrawer, exactly as it appears in Unity. Change the MonoBehaviour class at the end of your public class definition to PropertyDrawer. Note After you create a custom PropertyDrawer, you must generate the required property provider scripts from your Visual Scripting Project Settings. For more information, see Configure project settings. The following is an example of a finished PropertyDrawer script: using UnityEditor; using UnityEngine; [CustomPropertyDrawer(type of(<Counter>))] public class CounterDrawer : PropertyDrawer { // Draw the property inside the given rect public override void OnGUI(Rect position, SerializedProperty property, GUIContent label) { // Using BeginProperty / EndProperty on the parent property means that // prefab override logic works on the entire property. EditorGUI.BeginProperty(position, label, property); // Draw label position = EditorGUI.PrefixLabel(position, GUIUtility.GetControlID(FocusType.Passive), label); // Don't indent child fields var indent = EditorGUI.indentLevel; EditorGUI.indentLevel = 0; // Calculate rects var amountRect = new Rect(position.x, position.y, 30, position.height); var unitRect = new Rect(position.x + 35, position.y, 50, position.height); var nameRect = new Rect(position.x + 90, position.y, position.width - 90, position.height); // Draw fields - passs GUIContent.none to each so they are drawn without labels EditorGUI.PropertyField(amountRect, property.FindPropertyRelative(\"amount\"), GUIContent.none); EditorGUI.PropertyField(unitRect, property.FindPropertyRelative(\"unit\"), GUIContent.none); EditorGUI.PropertyField(nameRect, property.FindPropertyRelative(\"name\"), GUIContent.none); // Set indent back to what it was EditorGUI.indentLevel = indent; EditorGUI.EndProperty(); } } To create the rest of your custom PropertyDrawer, you must decide what fields you must display, and how you want them to display in the Editor's interface. For example, you might want to use the UIElements module to create your PropertyDrawer, or decide to use Unity's IMGUI module. For more information on how to create and design a custom PropertyDrawer, see the PropertyDrawer class in the main Unity Scripting API and its related methods."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-add-docs.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-add-docs.html",
    "title": "Add documentation to a Custom C# node | mmo-rpg-unity",
    "keywords": "Add documentation to a Custom C# node You can also add Graph Inspector documentation to a Custom C# node. Visual Scripting displays the documentation in the Graph Inspector when you select a node in a Script Graph. The documentation isn't required to use the node, but can help your users understand the purpose and usage of a node. To add documentation to a node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Note If you already have an Editor folder in your project, you can skip Steps 2-3. Right-click your Assets folder or select Add (+), then select Folder. Name the folder Editor. Do one of the following: Right-click your Editor folder in the Project window's folder list. Right-click anywhere in the Project window's preview pane with your Editor folder selected. Go to Create > C# Script. Enter a name, such as MyNodeDescriptor for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into the C# script: using System; using Unity.VisualScripting; using UnityEngine; [Descriptor(typeof(MyNode))] public class MyNodeDescriptor : UnitDescriptor<MyNode> { public MyNodeDescriptor(MyNode unit) : base(unit) {} protected override void DefinedPort(IUnitPort port, UnitPortDescription description) { base.DefinedPort(port, description); switch (port.key) { case \"inputTrigger\": description.summary = \"Trigger the concatenation of two strings, myValueA and myValueB, and return the result string on the Result port.\"; break; case \"myValueA\": description.summary = \"First string value.\"; break; case \"myValueB\": description.summary = \"Second string value.\"; break; case \"outputTrigger\": description.summary = \"Execute the next action in the Script Graph after concatenating myValueA and myValueB.\"; break; case \"result\": description.summary = \"The result string obtained from concatenating myValueA and myValueB.\"; break; } } } You can modify the script to suit the specifics of your own node. Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. Select the node and open the Graph Inspector to view your documentation. Next steps After you add documentation to a node, you can choose to further customize the node with node class and port attributes."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-add-logic.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-add-logic.html",
    "title": "Add logic to a Custom C# node | mmo-rpg-unity",
    "keywords": "Add logic to a Custom C# node Note To add logic to a node, you must create a Custom C# node and add ports. The examples below are based on the previous examples for a Custom C# node. For more information, see Create a new simple Custom C# node. After you create a Custom C# node and add ports, you can add logic to a node. Add logic to tell Visual Scripting what the node does with any data it receives from its ports. To add logic to a node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, add any logic for the node within the lambda expression that handles the assignment of the inputTrigger. For example, you can take the values of the two string input ports added in the previous example and concatenate them, as shown in the following code: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { [DoNotSerialize] public ControlInput inputTrigger; [DoNotSerialize] public ControlOutput outputTrigger; [DoNotSerialize] public ValueInput myValueA; [DoNotSerialize] public ValueInput myValueB; [DoNotSerialize] public ValueOutput result; private string resultValue; protected override void Definition() { //The lambda to execute our node action when the inputTrigger port is triggered. inputTrigger = ControlInput(\"inputTrigger\", (flow) => { //Making the resultValue equal to the input value from myValueA concatenating it with myValueB. resultValue = flow.GetValue<string>(myValueA) + flow.GetValue<string>(myValueB) + \"!!!\"; return outputTrigger; }); outputTrigger = ControlOutput(\"outputTrigger\"); myValueA = ValueInput<string>(\"myValueA\", \"Hello \"); myValueB = ValueInput<string>(\"myValueB\", String.Empty); result = ValueOutput<string>(\"result\", (flow) => resultValue); } } Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. Next steps After you add logic to a node, add relations to ensure that the node displays correctly in Visual Scripting."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-add-ports.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-add-ports.html",
    "title": "Add ports to a Custom C# node | mmo-rpg-unity",
    "keywords": "Add ports to a Custom C# node Note To add ports to your node, you must create the C# file for the node. The examples below are based on the previous examples for a Custom C# node. For more information, see Create a new simple Custom C# node. After you create a Custom C# node, add ports to allow the node to send and receive data or trigger other nodes in a Script Graph. To add ports to a node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. Add control ports In your external editor, under the class definition for the node, add two public variables: one with a ControlInput type and one with a ControlOutput type. In the Definition method for the node, use the variables to define the control ports, as shown below: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { [DoNotSerialize] // No need to serialize ports. public ControlInput inputTrigger; //Adding the ControlInput port variable [DoNotSerialize] // No need to serialize ports. public ControlOutput outputTrigger;//Adding the ControlOutput port variable. protected override void Definition() { //Making the ControlInput port visible, setting its key and running the anonymous action method to pass the flow to the outputTrigger port. inputTrigger = ControlInput(\"inputTrigger\", (flow) => { return outputTrigger; }); //Making the ControlOutput port visible and setting its key. outputTrigger = ControlOutput(\"outputTrigger\"); } } Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. If you used the previous code sample, Visual Scripting adds input and output control ports to the node. Add value ports In your external editor, under the class definition for the node, add any number of variables with either a Generic or specific type value: Generic: The port can receive or output any data type. Corresponds to Unity's Object type. Specific Type Value: The port can only receive or output a specific data type. For example, string, float, or integer. For more information on types in Visual Scripting, see Object types. In the Definition method for the node, use the variables to define the value ports. In the example below, there are two input ports with a type value of string, and one string output port: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { [DoNotSerialize] public ControlInput inputTrigger; [DoNotSerialize] public ControlOutput outputTrigger; [DoNotSerialize] // No need to serialize ports public ValueInput myValueA; // Adding the ValueInput variable for myValueA [DoNotSerialize] // No need to serialize ports public ValueInput myValueB; // Adding the ValueInput variable for myValueB [DoNotSerialize] // No need to serialize ports public ValueOutput result; // Adding the ValueOutput variable for result private string resultValue; // Adding the string variable for the processed result value protected override void Definition() { inputTrigger = ControlInput(\"inputTrigger\", (flow) => { return outputTrigger; }); outputTrigger = ControlOutput(\"outputTrigger\"); //Making the myValueA input value port visible, setting the port label name to myValueA and setting its default value to Hello. myValueA = ValueInput<string>(\"myValueA\", \"Hello \"); //Making the myValueB input value port visible, setting the port label name to myValueB and setting its default value to an empty string. myValueB = ValueInput<string>(\"myValueB\", string.Empty); //Making the result output value port visible, setting the port label name to result and setting its default value to the resultValue variable. result = ValueOutput<string>(\"result\", (flow) => { return resultValue; }); } } Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. If you used the previous code sample, Visual Scripting adds two input ports, My Value A and My Value B, and one output port, Result to the node. Next steps After you add ports to a node, add logic to tell the node what to do with the data it receives."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-add-relations.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-add-relations.html",
    "title": "Add relations to a Custom C# node | mmo-rpg-unity",
    "keywords": "Add relations to a Custom C# node Note To add logic to a node, you must create a Custom C# node and add ports. The examples below are based on the previous examples for a Custom C# node. For more information, see Create a new simple Custom C# node. After you add ports and add logic to a node, relations help Visual Scripting correctly display a Custom C# node in a Script Graph. To add relations to a node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Double-click the C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, add relations in the format $RelationType$($Port1$, $Port2$), where $RelationType$ is the relation type you want to assign between the ports you specify as $Port1$ or $Port2$. For example, to assign relations to the previous example node: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { [DoNotSerialize] public ControlInput inputTrigger; [DoNotSerialize] public ControlOutput outputTrigger; [DoNotSerialize] public ValueInput myValueA; [DoNotSerialize] public ValueInput myValueB; [DoNotSerialize] public ValueOutput result; private string resultValue; protected override void Definition() { inputTrigger = ControlInput(\"inputTrigger\", (flow) => { resultValue = flow.GetValue<string>(myValueA) + flow.GetValue<string>(myValueB) + \"!!!\"; return outputTrigger; }); outputTrigger = ControlOutput(\"outputTrigger\"); myValueA = ValueInput<string>(\"myValueA\", \"Hello \"); myValueB = ValueInput<string>(\"myValueB\", String.Empty); result = ValueOutput<string>(\"result\", (flow) => resultValue); Requirement(myValueA, inputTrigger); //Specifies that we need the myValueA value to be set before the node can run. Requirement(myValueB, inputTrigger); //Specifies that we need the myValueB value to be set before the node can run. Succession(inputTrigger, outputTrigger); //Specifies that the input trigger port's input exits at the output trigger port. Not setting your succession also dims connected nodes, but the execution still completes. Assignment(inputTrigger,result);//Specifies that data is written to the result string output when the inputTrigger is triggered. } } For more information on relation types, see Custom C# nodes. Save your script file. Return to the Unity Editor. Do one of the following: Open a Script Graph where you've already added your node.. Right-click anywhere in the Graph Editor to open the fuzzy finder. Then, select your node in the fuzzy finder to add it to your graph. In the Graph toolbar, enable Relations. Visual Scripting displays the relations you assigned to the Custom C# node. If you used the previous code sample, the node's relations might look like the following image: Next steps After you add relations to a node, you can choose to add documentation or customize the node with attributes."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-attributes-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-attributes-reference.html",
    "title": "Custom C# node attributes reference | mmo-rpg-unity",
    "keywords": "Custom C# node attributes reference You can add attributes to a node class and port variable definitions to customize the look of a Custom C# node. Node class attributes You can customize the titles that appear on a node, where it appears in the fuzzy finder, and its icon. Node class attributes must be placed above the node class definition in a node's C# script. Visual Scripting has 5 node class attributes: UnitTitle UnitShortTitle UnitSubtitle UnitCategory TypeIcon Usually, Visual Scripting automatically applies any changes you make to a node's class attributes after you save the C# file. UnitTitle You can specify a [UnitTitle] to display a different title than the node's class name on the node when it appears in a Script Graph, and when you view details about the node in the Graph Inspector: using System; using Unity.VisualScripting; using UnityEngine; [UnitTitle(\"My New Title\")] public class MyNodeAfter : Unit { ... } } The [UnitTitle] attribute overrides the node's class name. UnitShortTitle You can specify a [UnitShortTitle] to display a different title on the node when it appears in a Script Graph: using System; using Unity.VisualScripting; using UnityEngine; [UnitShortTitle(\"Short Title\")] [UnitTitle(\"My New Title\")] public class MyNodeAfter : Unit { ... } } The [UnitShortTitle] only appears on the node in a Script Graph. The [UnitTitle] or node class name still displays in the Graph Inspector. UnitSubtitle You can add a [UnitSubtitle] to add a line of text below the [UnitTitle], [UnitShortTitle], or node class name when a node appears in a Script Graph: using System; using Unity.VisualScripting; using UnityEngine; [UnitSubtitle(\"It's a subtitle!\")] [UnitShortTitle(\"Short Title\")] [UnitTitle(\"My New Title\")] public class MyNodeAfter : Unit { ... } } The [UnitSubtitle] doesn't appear in the Graph Inspector. UnitCategory You can specify a [UnitCategory] to tell Visual Scripting where to place the node in the fuzzy finder: using System; using Unity.VisualScripting; using UnityEngine; [UnitCategory(\"FirstLevel/SecondLevel\")] public class MyNodeAfter : Unit { ... } } Replace FirstLevel with the name of the top-level category in the fuzzy finder where you want Visual Scripting to place the node. Replace SecondLevel with the name of a subcategory. Visual Scripting creates the categories if they don't already exist in the fuzzy finder. Note You must regenerate your Node Library for changes made to a node's [UnitCategory] to take effect. TypeIcon You can use the [TypeIcon] attribute to change the icon that appears on a node when it appears in a Script Graph: using System; using Unity.VisualScripting; using UnityEngine; [TypeIcon(typeof(ToggleValue))] public class MyNodeAfter : Unit { ... } } The icon for the node changes in the Graph Inspector, too. Note You can't point to your own custom icons from this attribute. You must use an icon from the Visual Scripting icons library, which includes all Unity types. Port attributes Custom nodes have one mandatory port attribute and one optional port attribute: DoNotSerialize and PortLabelHidden, respectively. Port attributes must be placed above your variable declarations for each port variable in the node. Visual Scripting automatically applies any changes you make to a node's port attributes after you save the script file. DoNotSerialize [DoNotSerialize] is a mandatory attribute for all ports on custom nodes. Add this attribute to avoid serialization of data that shouldn't be serialized: using System; using Unity.VisualScripting; using UnityEngine; [UnitShortTitle(\"Short Title\")] [UnitTitle(\"My New Title\")] [UnitCategory(\"My Nodes\")] [UnitSubtitle(\"It's a subtitle!\")] [TypeIcon(typeof(Color))] public class MyNodeAfter : Unit { [DoNotSerialize] public ControlInput inputTrigger; [DoNotSerialize] public ControlOutput outputTrigger; [DoNotSerialize] public ValueInput myValueA; [DoNotSerialize] public ValueInput myValueB; [DoNotSerialize] public ValueOutput result; private string resultValue; protected override void Definition() { ... } } PortLabelHidden You can add the [PortLabelHidden] attribute to hide the name label for any port on a node when it appears in a Script Graph: using System; using Unity.VisualScripting; using UnityEngine; [UnitShortTitle(\"Short Title\")] [UnitTitle(\"My New Title\")] [UnitCategory(\"My Nodes\")] [UnitSubtitle(\"It's a subtitle!\")] [TypeIcon(typeof(Color))] public class MyNodeAfter : Unit { [DoNotSerialize] [PortLabelHidden] public ControlInput inputTrigger; [DoNotSerialize] [PortLabelHidden] public ControlOutput outputTrigger; [DoNotSerialize] public ValueInput myValueA; [DoNotSerialize] public ValueInput myValueB; [DoNotSerialize] public ValueOutput result; private string resultValue; protected override void Definition() { ... } } The port's label is still visible in the Graph Inspector. Use the same name in a port's variable definition and the port's key in the Definition method for the node's class, as shown: using System; using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { ... [DoNotSerialize, PortLabelHidden] public ValueInput myValueA; [DoNotSerialize, PortLabelHidden] public ValueInput myValueB; ... protected override void Definition() { ... myValueA = ValueInput<string>(\"myValueA\", \"Hello \"); myValueB = ValueInput<string>(\"myValueB\", String.Empty); ... } }"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-empty.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node-empty.html",
    "title": "Create a new simple Custom C# node | mmo-rpg-unity",
    "keywords": "Create a new simple Custom C# node You can create a Custom C# node to run your own custom logic in a Script Graph. For more information on Custom C# nodes, see Custom C# nodes. To create a new simple Custom C# node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list, or anywhere in the Project window's preview pane, and go to Create > C# Script. Enter a name, such as MyNode, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into your C# script: using Unity.VisualScripting; using UnityEngine; public class MyNode : Unit { protected override void Definition() //The method to set what our node will be doing. { } } Save your script file. Return to the Unity Editor. Follow the process described in Configure project settings to regenerate your Node Library. Note If you don't regenerate your Node Library, the node won't appear in Visual Scripting's fuzzy finder. Open a Script Graph where you want to add your new node. Right-click anywhere in the Graph Editor to open the fuzzy finder. The node appears as My Node at the end of the fuzzy finder list. Select the node to add it to your graph. Next steps After you create the basic start to a node and add it to Visual Scripting's fuzzy finder, add ports so your node can send and receive data."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-custom-node.html",
    "title": "Custom C# nodes | mmo-rpg-unity",
    "keywords": "Custom C# nodes You can create your own Custom C# node with a C# script. Use your node in Script Graphs to run your own custom logic, and provide the script file to other users to let them use it in their own Visual Scripting projects. You can create nodes that change the flow of logic in your graph, nodes that manipulate data, or both. You can also create nodes for custom events. To create a Custom C# node, you must: Create a C# script. Add ports. Add logic. Add relations. Create the initial C# script All custom nodes start with a C# file. After you create a C# file, you must regenerate your Node Library through your project settings. This allows Visual Scripting to recognize your Custom C# node and add it to the fuzzy finder for use in your project's graphs. After you regenerate your Node Library the first time, you only need to regenerate your Node Library again if you change the location of a node in the fuzzy finder. You can change the location through the [UnitCategory] attribute. For more information on how to create your initial C# script, see Create a new simple Custom C# node. Add ports Add ports to a node to specify what triggers Visual Scripting to run logic in a node, and decide what data it sends or receives. For more information on ports and nodes, see Nodes. Port types Visual Scripting has four different port types that you can add to a node: ControlInput: Provides a connection to a previous node, which tells Visual Scripting when to start the logic in a node. ControlOutput: Provides a connection to another node, which tells Visual Scripting when to run the logic for the next connected node in a Script Graph. ValueInput: Provides a connection that allows you to pass data into a node for use in its logic. ValueOutput: Provides a connection that allows you to pass data out of a node for use in other nodes. You can add any number of ports to a node. You can also choose what data type the ValueInput or ValueOutput ports send and receive: Generic: The port can receive or output any data type. Corresponds to Unity's Object type. Type Value: The port can only receive or output a specific data type. For example, string, float, or integer. For more information on types in Visual Scripting, see Object types. For more information on how to add ports to your node, see Add ports to your Custom C# node. Add logic Add logic to a node to specify what it does when it runs in a Script Graph. If there isn't any internal logic written for a node, the node can't trigger another node, or modify any of the data it receives from other nodes in a Script Graph. For more information on how to add logic to a node, see Add logic to a Custom C# node. Add relations Relations help define how a node and its Play mode animations appear in Visual Scripting. Without relations, Visual Scripting doesn't know how to animate or display a node in the Graph Editor. Relation types You can add three types of relations to a node to help correctly display its internal flow of logic: Assignment: Assignment relations are usually between a control input port and a data output port. Set an Assignment relation to tell Visual Scripting that a specific port needs to run before the node sends data to a data output port. Succession: Succession relations are usually between a control input port and a control output port. Set a Succession relation to tell Visual Scripting that a control input port exits at a control output port. Requirement: Requirement relations are usually between a control input port and a data port or ports. Set a Requirement relation to let Visual Scripting know that a specific data port or ports must have a value before the node can run any logic. Note If you don't set any Succession relations in a node, and Dim is enabled in the Graph toolbar, Visual Scripting dims your Custom C# node and any of its connected nodes in the Graph Editor during Play mode. For more information on how to add relations to a node, see Add relations to a node. Optional steps and customization After you've added relations, you can choose to add documentation for a node. Visual Scripting displays documentation in the Graph Inspector when a user selects a node in a Script Graph. Add documentation to help other users understand the purpose of each part of a node. You can also choose to customize a node with node attributes. You can add specific node class attributes to customize the entire node, or add port attributes to only customize specific ports. The attribute type determines the location where you must place the attribute in the node's C# file. Node class attributes must be placed above a node class definition, while port attributes must be placed above the variable definition for each port."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-assign-existing-gameobject.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-assign-existing-gameobject.html",
    "title": "Create and assign a graph to an existing GameObject | mmo-rpg-unity",
    "keywords": "Create and assign a graph to an existing GameObject You can use the empty graph creation flow to create a new graph file and assign it to an existing GameObject in your project. For more information on other ways to create a graph file, see Create a new graph file. Create a Script Graph To create a new Script Graph and assign it to an existing GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject where you want to assign the new graph. Go to Window > Visual Scripting > Visual Scripting Graph. Expand Create new Script Graph. Select on selected game object. Choose a location to save the new graph file. Enter a name for the graph. Select Save. The new graph file automatically opens in a new window. Create a State Graph To create a new State Graph and assign it to an existing GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject where you want to assign the new graph. Go to Window > Visual Scripting > Visual Scripting Graph. Expand Create new State Graph. Select on selected game object. Choose a location to save the new graph file. Enter a name for the graph. Select Save. The new graph file automatically opens in a new window. Next steps After you create a new graph, attach it to a Script Machine or State Machine to use it in your application. For more information, see Attach a graph file to a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-assign-new-gameobject.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-assign-new-gameobject.html",
    "title": "Create and assign a graph to a new GameObject | mmo-rpg-unity",
    "keywords": "Create and assign a graph to a new GameObject You can use the empty graph creation flow to create a new graph file and assign it to a new GameObject. Visual Scripting automatically creates a new GameObject with the required components for the new graph file. For more information on other ways to create a graph file, see Create a new graph file. To create a new graph and assign it to a new GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject where you want to assign the new graph. Go to Window > Visual Scripting > Visual Scripting Graph. Expand Create new Script Graph. Select on new game object. Choose a location to save the new graph file. Enter a name for the graph. Select Save. Note The GameObject you create with this method has the same name as the graph file. After you have named and saved the graph file, the GameObject appears in the Hierarchy. The new graph file automatically opens in a new window. Create a State Graph To create a new State Graph and assign it to a new GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject where you want to assign the new graph. Go to Window > Visual Scripting > Visual Scripting Graph. Expand Create new State Graph. Select on new game object. Choose a location to save the new graph file. Enter a name for the graph. Select Save. Note The GameObject you create with this method has the same name as the graph file. After you have named and saved the graph file, the GameObject appears in the Hierarchy. The new graph file automatically opens in a new window. Next steps After you create your new graph, attach it to a Script Machine or State Machine to use it in your application. For more information, see Attach a graph file to a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-on-machine.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-on-machine.html",
    "title": "Create a graph on a Script Machine or State Machine | mmo-rpg-unity",
    "keywords": "Create a graph on a Script Machine or State Machine You can create a new graph file directly from a Script Machine or State Machine component on a GameObject. For more information on how to create a Script Machine or State Machine, see Attach a graph file to a Script Machine or State Machine. Create a new graph file from a Script Machine or State Machine To create a new graph file from an existing Script Machine or State Machine: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select a GameObject that has a Script Machine or State Machine. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. In the Inspector window, on your Script Machine or State Machine component, set the Source set to Graph. Select New. Enter a name for your new graph file. Choose a location for the file in your project. Select Save. Create a new embedded graph on a Script Machine or State Machine You can create an embedded graph on a Script Machine or State Machine component instead of an external graph file: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select a GameObject that has a Script Machine or State Machine. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. In the Inspector window, on your Script Machine or State Machine component, set the Source to Embed. (Optional) In the (Title) field, enter a descriptive title for the embedded graph. (Optional) In the (Summary) field, enter a brief summary of what the embedded graph does. (Optional) To open the new embedded graph and edit, select Edit Graph. Note Unity recommends you create a graph file rather than an embedded graph. In some situations, an embedded graph works best. For more information on how to choose the correct graph type, see Source types for Script Machines and State Machines. Next steps After you attach a graph to a Script Machine or State Machine, you can open the graph and edit. For more information, see Open a graph file."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-project-window.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-project-window.html",
    "title": "Create a new blank graph with the Project window | mmo-rpg-unity",
    "keywords": "Create a new blank graph with the Project window You can create a new blank graph through the Project window in the Unity Editor. Your graph contains no starter nodes, and isn't connected to any existing components in your project. For more information on other ways to create a new graph file, see Create a new graph file. To create a new blank graph: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list, or anywhere in the Project window's preview pane, and go to Create > Visual Scripting. Do one of the following: To create a new Script Graph, select Script Graph. To create a new State Graph, select State Graph. Enter a name for the new graph. Press Enter. When you open the new graph file, the graph might look similar to the following example. Next steps After you create a new graph, attach it to a Script Machine or State Machine to use it in your application. For more information, see Attach a graph file to a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-unassigned-flow.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph-unassigned-flow.html",
    "title": "Create a new unassigned graph with the empty graph creation flow | mmo-rpg-unity",
    "keywords": "Create a new unassigned graph with the empty graph creation flow You can use the empty graph creation flow to create a new unassigned graph for use in your project. Note To use the graph file, you must attach it to a Script Machine or State Machine. For more information on other ways to create a graph file, see Create a new graph file. To create a new unassigned graph: Go to Window > Visual Scripting > Visual Scripting Graph. In the new Visual Scripting window, select one of the following options: To create a new Script Graph, select Create new Script Graph. To create a new State Graph, select Create new State Graph. Choose a location to save the new graph file. Enter a name for the graph. Select Save. The new graph file automatically opens in a new window. The new graph file should look similar to the following image: Next steps After you create a new graph, attach it to a Script Machine or State Machine to use it in your application. For more information, see Attach a graph file to a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-graph.html",
    "title": "Create a new graph file | mmo-rpg-unity",
    "keywords": "Create a new graph file To create a new Visual Scripting graph file, you can use the Unity Editor's Project window, Visual Scripting's empty graph creation flow, or create a graph from a Script Machine or State Machine component. Use the Project window If you create a graph with the Project window, the graph is blank. It contains no starter nodes, and isn't attached to any existing components in your project. For more information on the Unity Editor's Project window, see The Project window in the Unity User Manual. Use the empty graph creation flow If you use the empty graph creation flow, you have a few options for how to create your graph: You can choose to create an unassigned graph. The graph isn't assigned to a GameObject. You can choose to create a graph and assign it to an existing GameObject. Visual Scripting creates the required components on the GameObject for you to use your graph in your project. You can choose to create a graph and assign it to a new GameObject. Visual Scripting creates a new GameObject with the required components for you to use your graph in your project. For more information about GameObjects, see GameObjects in the User Manual. Any graph you create with the empty graph creation flow contains one or two initial nodes to help you get started with your graph. Tip To keep your project organized, place your Visual Scripting graphs in a Graphs folder inside your project's Assets folder. Use a Script Machine or State Machine You can also create a blank graph file directly on the Script Machine or State Machine component where you want to use it. For more information, see Create a graph on a Script Machine or State Machine."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-own-custom-event-listen-code.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-own-custom-event-listen-code.html",
    "title": "Listen to a Custom Scripting Event from a C# script | mmo-rpg-unity",
    "keywords": "Listen to a Custom Scripting Event from a C# script You can use a C# script to listen for or receive a Custom Scripting Event from a Script Graph. You can use an Event receiver script to execute additional logic in your application. Note Before you can create a listener for a Custom Scripting Event node, you must create a Custom Scripting Event node and its trigger. The examples below are based on the previous example to create a Custom Scripting Event node. For more information, see Create a Custom Scripting Event node and Create a Custom Scripting Event Sender node. To receive a Custom Scripting Event from a Script Graph: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane. Go to Create > C# Script. Enter a name, such as EventReceiver, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into your C# script: using Unity.VisualScripting; using UnityEngine; public class EventReceiver : MonoBehaviour { void Start() { EventBus.Register<int>(EventNames.MyCustomEvent, i => { Debug.Log(\"RECEIVED \" + i); }); } } Save your script file. Return to the Unity Editor. Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. Do one of the following in the Hierarchy window: Select an existing GameObject where you want to attach the new script. Select Add New (+) and in the menu, select a new GameObject to add to your scene from any of the available options. You can also right-click anywhere in the Hierarchy window and select the same options in the context menu. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. Select Add Component. In the Component menu, enter the name of the script file. Select it to add it to the GameObject. Select Play from the Unity Editor's Toolbar to enter Play mode. If you have a Custom Scripting Event Sender node or a C# script to trigger your Event, you can trigger your Custom Scripting Event. The EventReceiver script logs the following message to the console every time the Event is triggered, as shown in the following image."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-own-custom-event-node-trigger-code.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-own-custom-event-node-trigger-code.html",
    "title": "Trigger a Custom Scripting Event from a C# script | mmo-rpg-unity",
    "keywords": "Trigger a Custom Scripting Event from a C# script You can send or trigger a Custom Scripting Event node in a Script Graph with a C# script instead of a Custom Scripting Event Sender node. For more information on how to create a Custom Scripting Event Sender node, see Create a Custom Scripting Event Sender node. Note Before you can trigger a Custom Scripting Event node, you must create your Custom Scripting Event node. The examples below are based on the previous example to create a Custom Scripting Event node. For more information, see Create a Custom Scripting Event node. To trigger an Event from a C# script: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane. Go to Create > C# Script. Enter a name, such as CodeTriggerCustomEvent, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into your C# script: using Unity.VisualScripting; using UnityEngine; public class CodeTriggerCustomEvent : MonoBehaviour { void Update() { if (Input.anyKeyDown) { //Trigger the previously created Custom Scripting Event MyCustomEvent with the integer value 2. EventBus.Trigger(EventNames.MyCustomEvent, 2); } } } Save your script file. Return to the Unity Editor. Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. Do one of the following in the Hierarchy window: Select an existing GameObject where you want to attach the new script. Select Add New (+) and in the menu, select a new GameObject to add to your scene from any of the available options. You can also right-click anywhere in the Hierarchy window and select the same options in the context menu. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. Select Add Component. In the Component menu, enter the name of the script file. Select it to add it to the GameObject. Select Play from the Unity Editor's Toolbar to enter Play mode. Press any key on keyboard in the Game view. Visual Scripting triggers your Event in any Script Graph in the current scene that contains the Custom Scripting Event node. Next steps After you create the script, you can create a script to listen to your Event. You can also create an Event Sender node to trigger the Event from another Script Graph or location in the same Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-own-custom-event-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-own-custom-event-node.html",
    "title": "Create a Custom Scripting Event node | mmo-rpg-unity",
    "keywords": "Create a Custom Scripting Event node You can create a Custom Scripting Event node with a C# script. With C#, you can customize all aspects of your Custom Scripting Event, unlike a Visual Scripting custom Event. For more information on the different types of custom Events, see Custom Events. To create a Custom Scripting Event node: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane. Go to Create > C# Script. Enter a name, such as MyEventNode, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into the C# script: using Unity.VisualScripting; using UnityEngine; //Register a string name for your Custom Scripting Event to hook it to an Event. You can save this class in a separate file and add multiple Events to it as public static strings. public static class EventNames { public static string MyCustomEvent = \"MyCustomEvent\"; } [UnitTitle(\"On my Custom Event\")]//The Custom Scripting Event node to receive the Event. Add \"On\" to the node title as an Event naming convention. [UnitCategory(\"Events\\\\MyEvents\")]//Set the path to find the node in the fuzzy finder as Events > My Events. public class MyCustomEvent : EventUnit<int> { [DoNotSerialize]// No need to serialize ports. public ValueOutput result { get; private set; }// The Event output data to return when the Event is triggered. protected override bool register => true; // Add an EventHook with the name of the Event to the list of Visual Scripting Events. public override EventHook GetHook(GraphReference reference) { return new EventHook(EventNames.MyCustomEvent); } protected override void Definition() { base.Definition(); // Setting the value on our port. result = ValueOutput<int>(nameof(result)); } // Setting the value on our port. protected override void AssignArguments(Flow flow, int data) { flow.SetValue(result, data); } } Save your script file. Return to the Unity Editor. Follow the process described in Configure project settings to regenerate your Node Library. Open a Script Graph where you want to add your new node. Right-click anywhere in the Graph Editor to open the fuzzy finder.. Go to Events > My Events. Select your On My Custom Event node to add it to the graph. Note If you change the UnitTitle or UnitCategory attributes for the node in your code, the node appears in the location in the fuzzy finder with the name that you specify. After you regenerate your Node Library, the Custom Scripting Event node appears in the fuzzy finder. If you didn't change the [UnitCategory] or [UnitTitle] from the sample code, then the fuzzy finder displays the node under Events > MyEvents, as the On my Custom Event node. For more information on the fuzzy finder, see The interface. Next steps After you create your Custom Scripting Event node, you can create a Custom Scripting Event Sender node to trigger your Event from another Script Graph or location in the same Script Graph. You can also create a script to trigger your Event from code or create a script to listen to your Event."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-own-custom-event-send-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-own-custom-event-send-node.html",
    "title": "Create a Custom Scripting Event Sender node | mmo-rpg-unity",
    "keywords": "Create a Custom Scripting Event Sender node Note Before you create a Custom Scripting Event Sender node, you must create a Custom Scripting Event node. The examples below are based on the previous example to create a Custom Scripting Event node. For more information, see Create a Custom Scripting Event node. After you create a Custom Scripting Event node, you can create a Custom Scripting Event Sender node to trigger the Event from any other Script Graph in the same scene, or the same Script Graph. You can also choose to create a separate script to trigger the Event from code. For more information, see Trigger a Custom Scripting Event from a C# script. Create a node and add it to the fuzzy finder To create a Custom Scripting Event Sender node and add it to the fuzzy finder: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Right-click a folder in the Project window's folder list or anywhere in the Project window's preview pane. Go to Create > C# Script. Enter a name, such as SendMyEventNode, for the new script file. Press Enter. Double-click the new C# file. Unity opens the file in the program you specified in your preferences, under External Script Editor. Note For more information on script editors in Unity, see the Integrated development environment (IDE) support in the Unity User Manual. In your external editor, copy and paste the following code into the C# script: using Unity.VisualScripting; using UnityEngine; //Custom node to send the Event [UnitTitle(\"Send My Custom Event\")] [UnitCategory(\"Events\\\\MyEvents\")]//Setting the path to find the node in the fuzzy finder as Events > My Events. public class SendMyEvent : Unit { [DoNotSerialize]// Mandatory attribute, to make sure we don’t serialize data that should never be serialized. [PortLabelHidden]// Hide the port label, as we normally hide the label for default Input and Output triggers. public ControlInput inputTrigger { get; private set; } [DoNotSerialize] public ValueInput myValue; [DoNotSerialize] [PortLabelHidden]// Hide the port label, as we normally hide the label for default Input and Output triggers. public ControlOutput outputTrigger { get; private set; } protected override void Definition() { inputTrigger = ControlInput(nameof(inputTrigger), Trigger); myValue = ValueInput<int>(nameof(myValue),1); outputTrigger = ControlOutput(nameof(outputTrigger)); Succession(inputTrigger, outputTrigger); } //Send the Event MyCustomEvent with the integer value from the ValueInput port myValueA. private ControlOutput Trigger(Flow flow) { EventBus.Trigger(EventNames.MyCustomEvent, flow.GetValue<int>(myValue)); return outputTrigger; } } Save your script file. Return to the Unity Editor. Follow the process described in Configure project settings to regenerate your Node Library. After you regenerate your Node Library, the Custom Scripting Event Sender node appears in the fuzzy finder. If you didn't change the [UnitCategory] or [UnitTitle] from the sample code, then the fuzzy finder displays the node under Events > MyEvents, as the Send My Custom Event node. For more information on the fuzzy finder, see The interface. Trigger your Custom Scripting Event node You might use your Send My Custom Event node to trigger your Event based on keyboard input: Open a Script Graph where you want to add the new node. This can be the same or a different Script Graph from the one that contains your Custom Scripting Event node. Right-click anywhere in the Graph Editor to open the fuzzy finder.. Go to Events > Input. Select the On Keyboard Input node to add it to the graph. Right-click again in the Graph Editor to open the fuzzy finder. Go to Events > My Events. Select your Send My Custom Event node to add it to the graph. Connect the On Keyboard Input node's Trigger output port to the Send My Custom Event node's Input Trigger input port, as shown in the following image. Select Play from the Unity Editor's Toolbar to enter Play mode. Press and release the Spacebar in the Game view. The Custom Scripting Event Sender node triggers the Custom Scripting Event in your graph and sends the Event the value from My Value A. Next steps After you create a Custom Scripting Event Sender node, you can create a script to trigger your Event from code or create a script to listen to your Event."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-restore-backups.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-restore-backups.html",
    "title": "Create or restore a backup | mmo-rpg-unity",
    "keywords": "Create or restore a backup If you don't use a version control system, such as Unity Collaborate, Git, or Subversion, it's a good practice to create backups of your Visual Scripting assets and settings. Create a backup at any time from your Project Settings. Back up your data before you update Visual Scripting to a new version. For more information on the update process, see Update Visual Scripting. Create a new backup To create a new backup of your Visual Scripting assets and settings: Go to Edit > Project Settings. Select Visual Scripting. Select Create Backup, then select OK. Visual Scripting creates a .zip file, with a name in the format Assets_YYYY_MM_DD_HH_MM_SS, in a Backups folder inside the Unity Project. Restore an existing backup To restore an existing backup of your Visual Scripting assets and settings: Go to Edit > Project Settings. Select Visual Scripting. Select Restore Backup. Visual Scripting opens your Backups folder in your system's file explorer. You can extract a .zip back-up file and import graphs and settings back into Unity. For more information on how to import assets into Unity, see Importing assets in the Unity User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-state.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-create-state.html",
    "title": "Create a new state | mmo-rpg-unity",
    "keywords": "Create a new state You can create three types of State nodes in a State Graph: Script States, Any States, and Super States. For more information on the types of State nodes, see State Graphs in Graphs. You can also add a Sticky Note to add comments to a graph. Create a Script State To create a new blank Script State: [!include[open-state-menu](./snippets/vs-open-state-menu.md)] Select Create Script State. Visual Scripting creates a new Script State node. Open the Graph Inspector. In the Graph Inspector, choose a source for the Script State node: Embed: The graph only exists on the Script State node. You can only modify the graph from the node in its parent State Graph. Graph: The graph exists in a separate file. You can modify the graph outside of its parent State Graph and reuse the graph in other areas of your application. If you chose Graph: Select New. Enter a name for the graph file. Choose where you want to save the new graph. Select Save. To create a Script State from an existing Script Graph: [!include[open-state-menu](./snippets/vs-open-state-menu.md)] Select Create Script State. Visual Scripting creates a new Script State node. Open the Graph Inspector. In the Graph Inspector, set the source for the Script State node to Graph. Do one of the following: Select the object picker (circle icon) and choose a compatible Script Graph from your project. Click and drag a Script Graph file from your Project window and release on the Graph field. Tip Click and drag the Script Graph from your Project window into the Graph Editor to automatically create a Script State node. Create an Any State To create a new Any State node: With a State Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the context menu. Select Create Any State. Create a Super State To create a new blank Super State: [!include[open-state-menu](./snippets/vs-open-state-menu.md)] Select Create Super State. Visual Scripting creates a new Super State node. Open the Graph Inspector. In the Graph Inspector, choose a source for the Super State node: Embed: The graph only exists on the Super State node. You can only modify the graph from the node in its parent State Graph. Graph: The graph exists in a separate file. You can modify the graph outside of its parent State Graph and reuse the graph in other areas of your application. If you chose Graph: Select New. Enter a name for the graph file. Choose where you want to save the new graph. Select Save. To create a Super State from an existing State Graph: [!include[open-state-menu](./snippets/vs-open-state-menu.md)] Select Create Super State. Visual Scripting creates a new Super State node. Open the Graph Inspector. In the Graph Inspector, set the source for the Super State node to Graph. Do one of the following: Select the object picker (circle icon) and choose a compatible State Graph from your project. Click and drag a State Graph file from your Project window and release on the Graph field. Tip Click and drag the State Graph from your Project window into the Graph Editor to automatically create a Super State node."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-creating-connections.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-creating-connections.html",
    "title": "Connect nodes in a Script Graph | mmo-rpg-unity",
    "keywords": "Connect nodes in a Script Graph Connections control the flow of logic and data in a Script Graph's nodes. To connect nodes in a Script Graph: With a Script Graph open in the Graph window, either find an existing node where you want to make a connection, or add a new node to your Script Graph. Do one of the following: Connect to a new node. Connect to an existing node. Connect to a new node Select a port and point to a blank area in your graph to start the connection. Select again to open the fuzzy finder. Select an entry to automatically add that node at the end of your connection. Connect to an existing node Select a port and point to an existing port on another node. Select the port to make the connection. Delete a connection To delete a connection between two nodes: With a Script Graph open in the Graph window, right-click the port at either end of a connection. Visual Scripting deletes the connection. Next steps After you've connected nodes together, you can continue to add nodes to your Script Graph. You can also create and add variables, create node groups, or add a Subgraph. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-creating-transition.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-creating-transition.html",
    "title": "Create a transition between states | mmo-rpg-unity",
    "keywords": "Create a transition between states To switch between states in a State Graph, you must use a Script Graph called a transition. For more information on State Graphs, see State Graphs. Create a transition with an embedded Script Graph To create a new transition to another state with an embedded graph in a State Graph: With a State Graph open in the Graph window, do one of the following: Right-click on the state where you want to make a transition, then in the context menu, select Make Transition. Select the state where you want to make a transition, then press Ctrl+click and drag away from your selected state. Do one of the following: Select or release while on an existing state in your State Graph to connect the states with a transition. Select or release while on an empty space in the Graph Editor to automatically create a new blank Script State at the end of your transition. Select your transition node. Open the Graph Inspector. In the Graph Inspector, set the Source to Embed. In the (Title) field, enter a title for your transition's Script Graph. In the (Summary) field, enter a brief descriptive summary of your transition's Script Graph. Note If you choose to use an embedded transition Script Graph, Visual Scripting automatically provides the Trigger Transition node you need for the graph. Create a transition with an external Script Graph file To create a new transition with a graph asset file in a State Graph: With a State Graph open in the Graph window, do one of the following: Right-click on the state where you want to make a transition, then in the context menu, select Make Transition. Select the state where you want to make a transition, then press Ctrl+click and drag away from your selected state. Do one of the following: Select or release while on an existing state in your State Graph to connect the states with a transition. Select or release while on an empty space in the Graph Editor to automatically create a new blank Script State at the end of your transition. Select your transition node. Open the Graph Inspector. In the Graph Inspector, set the Source to Graph. Do one of the following: Select the object picker (circle icon). Select a Script Graph from your project. Click and drag a Script Graph file from your Project window and release on the Graph field. Select New and create a new Script Graph. Double-click the new transition node to open the transition Script Graph. Create a self transition with an embedded Script Graph To create a new self transition for a state in a State Graph: With a State Graph open in the Graph window, right-click on the state where you want to make the transition. In the context menu, select Make Self Transition. Visual Scripting attaches a new Self Transition node to the state in the State Graph automatically. Select your transition node. Open the Graph Inspector. In the Graph Inspector, set the Source to Embed. In the (Title) field, enter a title for your transition's Script Graph. In the (Summary) field, enter a brief descriptive summary of your transition's Script Graph. Double-click the new self transition to open the transition Script Graph. Note If you choose to use an embedded transition Script Graph, Visual Scripting automatically provides the Trigger Transition node you need for your graph. Create a transition with an external Script Graph file To create a new transition with a graph asset file in a State Graph: With a State Graph open in the Graph window, right-click on the state where you want to make the transition. In the context menu, select Make Self Transition. Visual Scripting attaches a new Self Transition node to the state in the State Graph automatically. Open the Graph Inspector. In the Graph Inspector, set the Source to Graph. Do one of the following: Select the object picker (circle icon). Select a Script Graph from your project. Click and drag a Script Graph file from your Project window and release on the Graph field. Select New and create a new Script Graph. Double-click the new transition node to open the transition Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-custom-events.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-custom-events.html",
    "title": "Custom Events | mmo-rpg-unity",
    "keywords": "Custom Events Events trigger, or start, a chain of logic in a Script Graph based on a specific occurrence in your application. Some Event types, such as On Start or On Update, exist by default in Visual Scripting. These Event nodes tell Visual Scripting to run the nodes they're connected to after the Script Graph starts, or on every frame while the Script Graph is active. You can also create your own custom Scripting Events to specify conditions for when a Script Graph's logic runs. Visual Scripting has two types of custom Events: Custom Event nodes: Use Custom Event nodes and Custom Event Trigger nodes to raise simple custom Events that don't require complex logic. Custom Scripting Events: Create your own Custom Scripting Event nodes to raise more complex Event logic. Custom Event nodes Custom Event nodes are always accessible from the fuzzy finder. You don't need to write your own code to use these custom Events in a Script Graph. They don't require an event listener. You can use the Custom Event node to create multiple custom Events, as long as you give each Event a unique name. You can also customize the number of arguments that the Custom Event node can send. To configure a Custom Event node, you need to provide: A unique name. A GameObject. The number of arguments the Custom Event receives. For more information on how to configure and use a Custom Event node, see Add a Custom Event node. To trigger a Custom Event, use a Custom Event Trigger node and provide the unique name of the Event. For more information, see Add a Custom Event Trigger node. Visual Scripting displays errors in the Graph Inspector if the Custom Event node and a Custom Event Trigger node have different values for: The name of the Event. The provided GameObject for the Event. The number of arguments for the Event. All arguments on a Custom Event Trigger node must have values, even if the Custom Event node doesn't give those values to another node. In the following example, Visual Scripting displays an error for both Arg. 0 and Arg. 1, even though Arg. 1 isn't used. Custom Scripting Events You can create a Custom Scripting Event node with a C# script. With C#, you can customize all aspects of your Custom Scripting Event, such as which category or categories to use for your node in the fuzzy finder. For more information, see Create a Custom Scripting Event node. To use and trigger the Event, code a Custom Scripting Event Sender node or another C# script: For more information on how to send or trigger an Event with a node in a Script Graph, see Create a Custom Scripting Event Sender node. For more information on how to send or trigger an Event with code, see Trigger a Custom Scripting Event from a C# script. You can also use a C# script to listen to or receive your Event after you trigger it in a Script Graph. You can use your receiver script to trigger more logic in your application. For more information, see Listen to a Custom Scripting Event from a C# script."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-custom-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-custom-types.html",
    "title": "Custom types | mmo-rpg-unity",
    "keywords": "Custom types Use a C# script file to create your own object types in Unity. These types are called classes. Classes are a blueprint for objects in your code. They decide what kind of data an object holds and what your code can do with that object. A class can hold multiple variables with different data types in a single object. Create a custom class to use it as a type for variables and other objects in a Visual Scripting Script graph. For more information on how to add and use your own custom types in Visual Scripting, see Use a custom type. The code you include in a C# script can also create new nodes to manipulate the data in your class. For example, you might write code to keep track of the characteristics of different player characters in your application. You can create a class, Player, and have different variables in that class for name, character type, favorite color, or player level: using System; using UnityEngine; using Unity.VisualScripting; [Serializable, Inspectable] public class PlayerCharacter { [Inspectable] public string name; [Inspectable] public string type; [Inspectable] public string color; [Inspectable] public int level; } Tip The variables in the example script above use the [Inspectable] attribute so they can display in Unity's Inspector window and the Visual Scripting Graph Inspector. Without the attribute, you can't assign a value to any variables that use the PlayerCharacter class in a Script Graph. For more information about the [Inspectable] attribute, see Use a custom type. These values can be different across different instances of Player objects in your code. Player1 can be Erin, a bard, who loves green and is level 5, and Player2 can be Sam, a mage, who loves black and is level 15. If you tried to represent the same data with basic variables, you must create a lot of nodes, as in the following example. With a custom class, you can create a single node to represent a player character's information, instead of four separate nodes."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-debug-messages.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-debug-messages.html",
    "title": "Working with debug messages | mmo-rpg-unity",
    "keywords": "Working with debug messages You can use debug nodes to see the result of a code segment inside the Unity console. For example, attaching a Debug node to a Variable node outputs the value of the variable. Tip Debugs are a useful tool when prototyping. To create a debug message Important Remove or disconnect the debugs from the graphs before producing the final executable. Add a Script Machine component to the GameObject. Select Edit Graph. Do one of the following: Use the starting events that are created with the script machine. Add an event node to the graph. Drag and release from the node port. The fuzzy finder appears. In the finder field, enter “Log”. A list of Debug nodes appears. Select the relevant debug message type you want to use (for example Log(Message), Log Error(Message) or Log Warning(Message)). The select Debug node is placed in the graph and linked to the event. Drag and release from the Debug green (output) port. The fuzzy finder appears. In the list, select the String node. A String node appears on the graph, connected to the Debug node.v Enter the debug message in the string node**.** Tip You can link variables or GameObjects other than a string to the port to see the value in the console. Whenever the graph is run and the Event is fired, the debug node executes and the text in the String appears in the console. Note The debug bar indicates the number of messages of each debug type (in the following order Message, Error, Warning)."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-debugging.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-debugging.html",
    "title": "Predictive and Live Debugging | mmo-rpg-unity",
    "keywords": "Predictive and Live Debugging Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Visual scripting can predict and indicate nodes in the script that can cause an error before entering play mode. It also analyzes your graphs to anticipate missing components or null references. If an error occurs at runtime, visual scripting pin-points the source of the error by highlighting it in the graph. Predictive Debugging When a node is not properly configured or may cause an error, it is colored yellow. When a node is certain to cause an error, it is colored orange. In both cases you should examine the node and make the required changes until it turns back to its normal color. Example: The Log node is colored orange because it's missing the Message that it should output to the console. If you connect the result of A + B to Message, the Log node goes back to normal. However, the Add node turns orange, because it's missing its first operand, A. If values are provided for both operands, all colors return to normal. The B input port does not need to be connected as it has a default inline value. Null References Null reference exceptions are very common. They happen when a parameter expects a value, but it receives \"nothing\", or in scripting lingo, \"null\". Visual scripting attempts to predict null references if the Predict Potential Null References option is checked in Unity > Preferences > Visual Scripting > Flow Graph. Example: Even though the Destroy node has an inline value, as it is set to \"None\" (null), it is colored orange. There are some rarer nodes that allow for null parameters. Unfortunately, because there is no way to know that from codebase analysis, visual scripting colors them orange as a false positive. If this is a recurring issue, turn off Predict Potential Null References. Missing Components When nodes are used that require components and pass a game object or a component that does not have the specified component, the node is colored yellow as a warning. For example, even though there are default values for each value input of the Add Force node, visual scripting detects that the owner game object does not have a rigidbody and provides a warning. Visual scripting does not color the node orange because it is possible to add components to game objects at runtime, so the node is not guaranteed to cause a crash if you add the required component before calling it. If this use case happens often in the project, you can disable Predict Potential Missing Components debugging from Unity > Preferences > Visual Scripting > Flow Graphs. Live Debugging When in play mode, the currently active nodes are highlighted in blue. If an error occurs, the node that caused it is highlighted in red. Example: The following is an example of a faulty graph. The result logs \"my 3rd third favorite fruit\" to the console when you press space. Here's what happens when play is selected and the object is clicked. All nodes are highlighted in blue as soon as you click because they were activated. However, there was an error in the console. Visual scripting highlights the faulty node in red. A common mistake is to assume array indices start at 1, whereas they actually start at 0. In scripting, indices are always zero-based; the first item is at index 0, the second at index 1, the third at index 2, etc. To get third item, write 2 in the field."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-developers-guide.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-developers-guide.html",
    "title": "Developer's guide | mmo-rpg-unity",
    "keywords": "Developer's guide _Misc Node Description Formula Outputs the result of the formula entered, which has a user specified number of input ports. Can create vector 2,3,4 and access all variables by name (object, graph, scene, application, saved). GetApplicationVariable Gets an application variable by name. GetGraphVariable Gets a graph variable by name. GetMember Invokes a getter via reflection (field or property, static or instance). GetObjectVariable Gets an object variable by name. GetSavedVariable Gets a saved variable by name. GetSceneVariable Gets a scene variable by name. GetVariable Gets a graph variable by name. InvokeMember Invokes a method via reflection (static or instance). IsApplicationVariableDefined Returns true if the variable is defined. IsGraphVariableDefined Returns true if the variable is defined. IsObjectVariableDefined Returns true if the variable is defined. IsSavedVariableDefined Returns true if the variable is defined. IsSceneVariableDefined Returns true if the variable is defined. IsVariableDefined Returns true if the variable is defined. This (formerly Self) Provides a reference to the GameObject that has the Machine Component running the graph. SetApplicationVariable Sets an application variable by name. SetGraphVariable Sets a graph variable by name. SetMember Invokes a setter via reflection (field or property, static or instance). SetObjectVariable Sets an object variable by name. SetSavedVariable Sets a saved variable by name. SetSceneVariable Sets a scene variable by name. SetVariable Sets a variable by name. Collections Node Description CountItems Provides a count of the number of items in the collection. FirstItem Gets a reference to the first item in the collections. LastItem Gets a reference to the last item in the collection. Collections, Dictionaries Node Description AddDictionaryItem Adds Key/Value pair into dictionary. ClearDictionary Removes all elements from the dictionary. CreateDictionary Creates a local dictionary. DictionaryContainsKey Returns true if the dictionary contains an entry with a matching key. GetDictionaryItem Return value for a dictionary entry with the provided keys. MergeDictionaries Combines the contents of two dictionaries into a single dictionary. RemoveDictionaryItem Removes an entry from the dictionary with the provided key. SetDictionaryItem Replaces the value of an existing entry with the provided key. Collections, Lists Node Description AddListItem Adds an item to the list. ClearList Removes all elements from the list. CreateList Creates a local list. GetListItem Gets the item in a list at the specified position provided by the index. InsertListItem Inserts an item into a list at the specified position provided by the index. ListContainsItem Returns true if the item is contained in the list. MergeLists Combines the contents of two lists into a single list. RemoveListItem Removes the item from the list (if it is present). RemoveListItemAt Removes the item from the list that is at the specified position provided by the index. SetListItem Replaces the item in the list with a new item at the specified position provided by the index. Control Node Description If (Formerly Branch) Executes the True branch if the provided input is true, otherwise executes the False branch. Break Immediately exits the current loop. Cache Flow node reads its input value whenever a value from any source is entered and outputs it when its output port is pulled. For A loop control. The Body branch is executed, providing an Index equal to First. If execution isn't interrupted (for example, by Break), the Index is incremented by Step. If the Index is less than Last, the Body branch is executed again. This process repeats until the Index is greater than Last, at which point the Exit branch is executed and the loop terminates. ForEach A loop control that executes Body once for every item (provided as Item) contained in the provided collection. Once completed, the Exit branch is executed. Once Flow node with an internal state that triggers its output only the first time it is entered. Entering a second time does not trigger the output flow. After a reset, the next time you enter, will trigger the output flow. SelectOnEnum Provides the object associated to the enum value provided as an input. SelectOnFlow Provides the object associated to the incoming flow branch that triggered the node. SelectOnInteger Data branching based on an input integer. SelectOnString Data branching based on an input string. SelectUnit Data branching based on an input enum. Sequence Executes a series of branches in order. To determine the order, specify the number of steps in the sequence, labelled with their order (e.g. 0, 1, 2, 3). SwitchOnEnum Executes the branch associated to the provided enum value. SwitchOnInteger Flow branching based on an input integer. SwitchOnString Flow branching based on an input string. Throw Causes an exception with the provided message. ToggleFlow Flow branching based on whether the node is On or Off, with inputs to set or toggle its On/Off state. ToggleValue Flow branching based on whether a value got set to its associated On/Off value. TryCatch Executes the Try branch. If an exception occurs in that branch, execute the Catch branch. Once the Try branch completes without exceptions or the Catch branch completes, the Finally branch is executed. While Executes the Body branch. Repeat this step as long as the provide condition is true. When that condition is no longer true, execute the Exit branch. Events Node Description TriggerCustomEvent Triggers a custom event by name. Logic Node Description And Logical AND (equivalent to &&) returns true if both operands are true and returns false otherwise. Comparison All comparisons in one node: inputs A/B, outputs < <= > >= == !=, and so on. Equal Logical AND (equivalent to &&) returns true if both operands are true and returns false otherwise. ExclusiveOr Exclusive OR (equivalent to ^) compares the first operand to the second operand and returns true only when inputs differ (one is true, the other is false). Greater Greater than (equivalent to >) returns false if the relationship in the expression is false; otherwise, returns true. GreaterOrEqual Greater than or equal to (equivalent to >=) returns false if the relationship in the expression is false; otherwise, returns true. Less Less than (equivalent to <) returns false if the relationship in the expression is false; otherwise, returns true. LessOrEqual Less than or equal to (equivalent to <=) returns false if the relationship in the expression is false; otherwise, returns true. Negate Negation (equivalent to !) reverses the meaning of its operand. NotEqual The not equal to operator (equivalent to. !=) returns true if the operands don't have the same value; otherwise, it returns false. Or Logical OR (equivalent to ||) returns true if either or both operands is true and returns false otherwise. Math, Generic Node Description Add Calls the + operator on inputs. Divide Calls the / operator on inputs. Modulo Calls the % operator on inputs. Multiply Call the * operator on inputs. Subtract Calls the - operator on inputs. Math, Scalar Node Description Absolute Absolute returns the absolute value of an integer. Add Sum of two floats. Average Average of all float inputs. Divide Divides the first float by the second float and returns the result. Exponentiate Raises the base to an exponent. Lerp Interpolates within a range based on a parameter. Maximum Computes the maximum values passed in its argument. Minimum Computes the minimum values passed in its argument. Modulo Returns the remainder of a float divided by another float. MoveTowards Returns the result of moving Current towards Target by up to Max Delta. Multiply Multiplies two floats. Normalize Equivalent to MathF.Sign. PerSecond Multiplies the value by the duration of the frame (for example, to move smoothly from frame to frame with a fixed speed). Root Calculates x to the root of n. Round Rounds a float - ceil, floor or closest integer. Subtract Subtracts the first float from the second float and returns the result. Sum Sum of multiple floats. Math, Vector2 Node Description Absolute Gives both the x and y values of a Vector2 a positive sign. Add Sum of two vectors. Angle Angle between two directional vectors. Average Average of a series of Vector2 value. Distance Distance between two Vector2 points. Divide Divide the components of one Vector2 by the corresponding components of a second Vector2. DotProduct Dot Product between two Vector2 values. Lerp Interpolates within a range based on a parameter. Maximum Computes the maximum values passed in its argument. Minimum Computes the minimum values passed in its argument. Modulo Returns a Vector2 where the components of the first vector are moduled by the corresponding components of the second vector. MoveTowards Returns the result of moving Current towards Target by up to Max Delta. Multiply Multiplies the corresponding components of two Vector2 values. Normalize Returns a Vector2 with a magnitude of 1 that retains the same direction. PerSecond Multiplies the value by the duration of the frame (for example, to move smoothly from frame to frame with a fixed speed). Project Projects one vector onto another vector. Round Rounds the components of a Vector2 to closest integer value. Subtract Subtracts one Vector2 value from another Vector2 value. Sum Adds two Vector2 values. Math, Vector3 Node Description Absolute Gives both the x and y values of a Vector3 a positive sign. Add Sum of two vectors. Angle Angle between two directional vectors. Average Average of a series of Vector3 value. Distance Distance between two Vector3 points. Divide Divide the components of one Vector3 by the corresponding components of a second Vector3. DotProduct Dot Product between two Vector3 values. Lerp Interpolates within a range based on a parameter. Maximum Computes the maximum values passed in its argument. Minimum Computes the minimum values passed in its argument. Modulo Returns a Vector3 where the components of the first vector are moduled by the corresponding components of the second vector. MoveTowards Returns the result of moving Current towards Target by up to Max Delta. Multiply Multiplies the corresponding components of two Vector3 values. Normalize Returns a Vector3 with a magnitude of 1 that retains the same direction. PerSecond Multiplies the value by the duration of the frame (for example, to move smoothly from frame to frame with a fixed speed). Project Projects one vector onto another vector. Round Rounds the components of a Vector3 to closest integer value. Subtract Subtracts one Vector3 value from another Vector3 value. Sum Adds two Vector3 values. Math, Vector4 Node Description Absolute Gives both the x and y values of a Vector4 a positive sign. Add Sum of two vectors. Angle Angle between two directional vectors. Average Average of a series of Vector4 value. Distance Distance between two Vector4 points. Divide Divide the components of one Vector4 by the corresponding components of a second Vector4. DotProduct Dot Product between two Vector4 values. Lerp Interpolates within a range based on a parameter. Maximum Computes the maximum values passed in its argument. Minimum Computes the minimum values passed in its argument. Modulo Returns a Vector4 where the components of the first vector are moduled by the corresponding components of the second vector. MoveTowards Returns the result of moving Current towards Target by up to Max Delta. Multiply Multiplies the corresponding components of two Vector4 values. Normalize Returns a Vector4 with a magnitude of 1 that retains the same direction. PerSecond Multiplies the value by the duration of the frame (for example, to move smoothly from frame to frame with a fixed speed). Project Projects one vector onto another vector. Round Rounds the components of a Vector4 to closest integer value. Subtract Subtracts one Vector4 value from another Vector4 value. Sum Adds two Vector4 values. Nesting Node Description GraphInput Gets the value of a graph input when the graph is used as a Subgraph. GraphOutput Gets the value of a graph output when the graph is used as a Subgraph. StateUnit References another state machine graph as a state in the current graph. Subgraph References another flow graph as a Subgraph in the current graph. TriggerStateTransition In a transition graph, triggers the transition to the target graph in the parent state machine graph. Nulls Node Description Null Null literal. NullCheck Branching based on the input value being null. NullCoalesce Returns the input value or a default value if the input value is null. Time Node Description Cooldown Coroutine node that can re-trigger its output only after a certain cooldown time interval. Timer Coroutine node that triggers its output after a time interval. WaitForEndOfFrameUnit Coroutine node that yields return new WaitForEndOfFrame(). WaitForFlow Coroutine node that waits until the input flow port is triggered. WaitForNextFrameUnit Coroutine node that returns null. WaitForSecondsUnit Coroutine node that returns new WaitForSeconds(). WaitUntilUnit Coroutine node that returns new WaitUntill(() => value). WaitWhileUnit Coroutine node that returns new WaitUntill(() => !value). Variables Node Description SaveVariables Forces saved variables to be saved to the PlayerPrefs (this is useful on platforms that do not support automatic save on quit). Events Node Description UnityEvent Called when a UnityEvent is pointed to TriggerUnityEvent. CustomEvent Bolt's custom events, defined by name. Events, Animation Node Description Animation Event Called when an animation event points to TriggerAnimationEvent. This version allows you to use the string parameter as the event name Named Animation Event Called when an animation event points to TriggerAnimationEvent. This version allows you to use the string parameter as the event name. OnAnimatorIK https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnAnimatorIK.html OnAnimatorMove https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnAnimatorMove.html Events, Application Node Description OnApplicationFocus https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnApplicationFocus.html OnApplicationLostFocus Implements https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnApplicationFocus.html OnApplicationPause https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnApplicationPause.html OnpplicationQuit https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnApplicationQuit.html OnApplicationResume Implements https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnApplicationPause.html Events, Editor Node Description OnDrawGizmos https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnDrawGizmos.html OnDrawGizmosSelected https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnDrawGizmosSelected.html Events, GUI Node Description OnBeginDrag Implements IBeginDragHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IBeginDragHandler.html OnButtonClick Registers to a Button's onClick event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Button.html OnCancel Implements ICancelHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.ICancelHandler.html OnDeselect Implements IDeselectHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IDeselectHandler.html OnDrag Implements IDragHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IDragHandler.html OnDrop Implements IDropHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IDragHandler.html OnDropdownValueChanged Registers to a Dropdown's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Dropdown.html OnEndDrag Implements IEndDragHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IEndDragHandler.html OnGUI Triggers on MonoBehaviour.OnGUI https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ MonoBehaviour.OnGUI.html OnInputFieldEndEdit Registers to an InputField's onEndEdit event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.InputField.html OnInputFieldValueChanged Registers to an InputField's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.InputField.html OnMove Implements IMoveHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IMoveHandler.html OnPointerClick Implements IPointerClickHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerClickHandler.html OnPointerDown Implements IPointerDownHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerDownHandler.html OnPointerEnter Implements IPointerEnterHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerEnterHandler.html OnPointerExit Implements IPointerExitHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerExitHandler.html OnPointerUp Implements IPointerUpHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerUpHandler.html OnScroll Implements IPointerScrollHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.IPointerScrollHandler.html OnScrollbarValueChanged Registers to a Scrollbar's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Scrollbar.html OnScrollRectValueChanged Registers to a ScrollRect's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.ScrollRect.html OnSelect Implements ISelectHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.ISelectHandler.html OnSliderValueChanged Registers to a Sliders's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Slider.html OnSubmit Implements ISubmitHandler https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ EventSystems.ISubmitHandler.html OnToggleValueChanged Registers to a Toggle's onValueChanged event https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ UI.Toggle.html Events, Hierarchy Node Description OnTransformChildrenChanged https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTransformChildrenChanged.html OnTransformParentChanged https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTransformParentChanged.html Events, Input Node Description OnButtonInput On Update, checks Input.GetButtonDown/GetButtonUp/GetButton based on the specified Action type https://docs.unity3d.com/2019.1/Documentation/ScriptReference/Input.html. OnKeyboardInput On Update, check Input.GetKeyDown/GetKeyUp/GetKey based on the specified action type https://docs.unity3d.com/2019.1/Documentation/ScriptReference/Input.html OnMouseDown https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseDown.html OnMouseDrag https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseDrag.html OnMouseEnter https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseEnter.html OnMouseExit https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseExit.html OnMouseInput https://docs.unity3d.com/ScriptReference/ Input.GetMouseButton.html OnMouseOver https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseOver.html OnMouseUp https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseUp.html OnMouseUpAsButton https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnMouseUpAsButton.html Events, Lifecycle Node Description FixedUpdate https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.FixedUpdate.html LateUpdate https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.LateUpdate.html OnDestroy https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnDestroy.html OnDisable https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnDisable.html OnEnable https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnEnable.html Start https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.Start.html Update https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.Update.html Events, Navigation Node Description OnDestinationReached Trigger if a NavMeshAgent's remaining distance to its target is less than the provided threshold and either has a current NavMeshPathStatus of PathComplete or requireSuccess is false. https://docs.unity3d.com/2019.1/Documentation/ScriptReference/ AI.NavMeshAgent.html. Events, Physics Node Description OnCollisionEnter https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionEnter.html OnCollisionExit https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionExit.html OnCollisionStay https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionStay.html OnControllerColliderHit https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnControllerColliderHit.html OnJointBreak https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnJointBreak.html OnParticleCollision https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnParticleCollision.html OnTriggerEnter https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerEnter.html OnTriggerExit https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerExit.html OnTriggerStay https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerStay.html Events, Physics 2D Node Description OnCollisionEnter2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionEnter2D.html OnCollisionExit2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionExit2D.html OnCollisionStay2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnCollisionStay2D.html OnControllerColliderHit2D https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnControllerColliderHit.html OnJointBreak2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnJointBreak2D.html OnParticleCollision2D https://docs.unity3d.com/ScriptReference/ MonoBehaviour.OnParticleCollision.html OnTriggerEnter2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerEnter2D.html OnTriggerExit2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerExit2D.html OnTriggerStay2D https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnTriggerStay2D.html Events, Rendering Node Description OnBecameInvisible https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnBecameInvisible.html OnBecameVisible https://docs.unity3d.com/2021.1/Documentation/ScriptReference/ MonoBehaviour.OnBecameVisible.html Events, State Node Description OnEnterState When a state is entered. OnExitState When a state is exited."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-editor-script-issues.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-editor-script-issues.html",
    "title": "Known Issues: Unity Editor script functions | mmo-rpg-unity",
    "keywords": "Known Issues: Unity Editor script functions If you use nodes that use Unity Editor script functions in any of the Visual Scripting graphs in your project, it causes errors when you try to build your project. Cause of the build errors Unity Visual Scripting (UVS) doesn't support preprocessor directives, so the use of Unity Editor script functions within graphs isn't possible. However, these functions can appear as node options within UVS because UVS uses C# reflection to generate nodes for your project based on your included assemblies. If you add one of these Unity Editor script nodes to a graph that's used in a build of your project, Unity generates an error when it attempts to build the project. An error message of the following format is displayed in the Unity Console: /<ProjectPath>/<CSharpFile>.cs: error CS0103: The name '<MissingApiName>' does not exist in the current context. The following code sample is an example of preprocessor directives for Unity Editor scripts : #if UNITY_EDITOR public static List<Type> GetAllVolumeComponents() { // TypeCache is only accessible in UnityEditor. // If you instantiate a GetAllVolumeComponents node in a graph // it prevents the project from being built. return TypeCache.GetTypesDerivedFrom<VolumeComponent>().ToList(); } #endif Find flagged packages Packages that contain editor scripts are flagged with a warning icon in the Node Library section of the Visual Scripting tab in the Project Settings window. To find the affected packages, do the following: Go to Edit > Project Settings. In the Project Settings window, select the Visual Scripting tab. On the Visual Scripting tab expand the Node Library section. A yellow warning flag is displayed next to any affected packages as shown in the following screenshot. Resolution To resolve this issue, go through your graphs and replace nodes that correspond to the API mentioned in the error message until you find the error no longer occurs."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-events-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-events-reference.html",
    "title": "Events node | mmo-rpg-unity",
    "keywords": "Events node Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Scripting nodes listen for events. They are the starting point for all scripts and appear as special green nodes in graphs. There are many kinds of events, grouped in sub-categories under the root Events category (fuzzy finder > Events). Two simple common events are Start and Update, both located under Lifecycle. Start is called once when the graph or event handler is first created. Update is called at every frame while the graph or event handler is active. New script machines start with both these events by default. Inputs & Outputs All events have a single Trigger control output that starts the script when they are triggered. Value inputs are options that influence when the event is triggered. For example, some events have a Target setting that determines which object is listening to the event. Most often, you'll leave this setting at its default value of Self. The value outputs on events are arguments that are passed from the event, giving you more information about what actually happened. For example, on the On Trigger Enter event, the other collider that is involved in the collision is an output. Custom Events There is a special type of event, the Custom Event that triggers custom events across graphs, along with their custom arguments. For example, to create a custom event called On Damage that gets called so the character loses health, the event should have one integer argument that indicates the amount of damage to inflict. Listen to the event by creating a Custom Event node (under Events). Set the name to On Damage. The set the argument count, below the name, to 1. Note Indices are zero-based, so the first argument is labeled Arg. 0. To trigger the event from elsewhere, use the Trigger Custom Event node, located right under the Custom Event node in the fuzzy finder. Enter the name of the event exactly as it is sensitive to case and whitespace. For example, to create a script machine on a boulder that could hit the player, use the force of the impact as the damage. The collider that hit with the boulder is the target of our trigger; the On Damage event is triggered on all machines attached to that collider. Use the damage value to subtract health from the receiver object. Custom events do not require a receiver and do not cause an error if there isn't a listener to handle them. Animation Events Use animation events to trigger Bolt graphs when you reach a certain point in your animation. Select an object with a machine and an animator. Then, from the animation window, add an animation event. With the event selected, choose TriggerAnimationEvent as the function from the inspector. Use any parameter from the inspector. In your script graph, add an Animation Event node (under Events >Animation). There are two types of events: a global animation event, and a named animation event. The difference is that the first type listens to all animation events on the object and return the string parameter. The second type's trigger is the string parameter that is equal to the specified name input. Unity Events Use Unity Events to trigger events that have been setup from the inspector. These are commonly found in GUI components like buttons, but they can also be created in your custom scripts. Configure them by selecting an object with a machine and select the Trigger Unity Event method. In the string field, type the event name to listen to in the graph and in the graph, add a UnityEvent node with a matching name. Additional arguments are not supported on Unity events. Events API Visual scripting provides a simple API to trigger custom events from C# script. Add the following usings to your C# script to access the API. using Unity.VisualScripting Triggering API A single method call is needed to trigger a custom event. Pass as many arguments as required. CustomEvent.Trigger(targetGameObject, argument1, argument2, ...) For example, this custom event node: Can be triggered with this line of code. CustomEvent.Trigger(enemy, \"Damage\", 30);"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-events.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-events.html",
    "title": "Events API | mmo-rpg-unity",
    "keywords": "Events API Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Visual scripting provides a simple API to trigger custom events from C# script. Usings Add the following usings to your C# script to access the API. using Unity.VisualScripting; Triggering A single method call is needed to trigger a custom event. Pass as many arguments as required. CustomEvent.Trigger(targetGameObject, argument1, argument2, ...) For example, this custom event node: Can be triggered with this line of code. CustomEvent.Trigger(enemy, \"On Damage\", 30);"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-formula.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-formula.html",
    "title": "Formula node | mmo-rpg-unity",
    "keywords": "Formula node Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Formula is a powerful node that evaluates logical and mathematical expressions directly via a textual Formula and a list of Arguments. Important Due to the binary tree traversal overhead (despite caching attempts), performance in using the formula node is significantly slower than using the operator nodes individually. It is preferable to avoid using this node at every frame. Although a formula can return either a boolean for logic, or a number for math, formulas can return any type of value. The first text field in the header is the formula itself. The second text field is the number of arguments. It's set to 2 by default, giving us A and B as inputs. Formulas can have up to 10 arguments, which are always ordered alphabetically. If more are required, they are called B, C, D, E, and so forth. For example, this formula returns a boolean indicating: whether, at a minimum, 10 seconds have elapsed since the start of the game and the current object's name is Player. Arguments Variable Names Variable names can be directly used in the formula. For example, a graph variable named health can return a boolean just by typing the formula health > 50. The argument names are evaluated in the following order of priority: Alphabetical argument names (a - z) Graph variable names Object variable names Scene variable names Application variable names Saved variable names Properties and Methods Retrieve the value of a property on an argument or variable by using the [arg.prop] notation. For example, if position is a Vector 3 object variable, check if it is equal to zero with: [position.x] = 0. Get the return value of parameterless methods with the [arg.Method()] notation. Note: Accessing properties and methods is not guaranteed to be compatible with AOT platforms, because the AOT pre-build cannot generate stubs for members that are only accessed by name. Literals Use the following literals for assigning fixed values. Literal Description Example Number An integer or float. 3.5 String A piece of text between apostrophes. \"Hello World!\" Boolean A boolean value. true, false Null The null constant. a != null Delta Time The Unity frame delta time. 30 * dt Invert Delta Time The inverse of the delta time. 30 / second Operators Every common logical and mathematical operator can be used in formulas, as well as the ones defined through custom operator overloading in script. Operator Operation Rank Result Example not, ! Logical Negation Unary The opposite of the operand. not true - Numerical Negation Unary The negative of the operand. -5 and, && Logical And Binary True if both operands are true. (a < 5) and (b > 3) or, || Logical Or Binary True if either operand is true (a < 5) or (b > 3) =, == Equality Binary True if the two operands are equal. a = b !=, <> Inequality Binary True if the two operands are not equal. a != b <, <=, >, >= Numeric Comparison Binary The result of a numeric comparison a >= 10 + Addition Binary The sum of the two operands. a + 5 - Subtraction Binary The difference between the two operands. b - 3 * Multiplication Binary The product of the two operands. 12 * a / Division Binary The quotient of the two operands. b / 2 % Modulo Binary The remainder of the division of the two operands. a % 2 ?: If Ternary The left operand if the condition is true, otherwise the right operand. (health > 0) ? \"Alive\" : \"Dead\" All common bitwise operators like ~ and >> are also supported. Functions You can also use any function from the following table. Name Result Example abs The absolute value of a specified number. abs(-1) acos The angle whose cosine is the specified number. acos(1) asin The angle whose sine is the specified number. asin(0) atan The angle whose tangent is the specified number. atan(0) ceiling The smallest integer greater than or equal to the specified number. ceiling(1.5) cos The cosine of the specified angle. cos(0) exp e raised to the specified power. exp(0) floor The largest integer less than or equal to the specified number. floor(1.5) log The logarithm of a specified number. log(1, 10) log10 The base 10 logarithm of a specified number. log10(1) max The larger of two specified numbers. max(1, 2) min The smaller of two numbers. min(1, 2) pow A specified number raised to the specified power. pow(3, 2) round Rounds a value to the nearest integer or specified number of decimal places. round(3.222, 2) sign 1 if the number is positive, -1 is if it negative. sign(-10) sin The sine of the specified angle. sin(0) sqrt The square root of a specified number. sqrt(4) tan The tangent of the specified angle. tan(0) truncate The integral part of a number. truncate(1.7) v2 Creates a 2D vector. v2(0, 0) v3 Creates a 3D vector. v3(0, 0, 0) v4 Creates a 4D vector. v4(0, 0, 0, 0)"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-graph-machine-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-graph-machine-types.html",
    "title": "Script Machines and State Machines | mmo-rpg-unity",
    "keywords": "Script Machines and State Machines A Script Machine is a GameObject component that lets you use a Script Graph in an application. You can't use a Script Graph unless it's attached to a Script Machine. For more information on components, see Introduction to components in the Unity User Manual. Script Machines can either link to a graph asset, or they can contain an embedded Script Graph asset. A State Machine is the same as a Script Machine, except it contains a State Graph. For more information on the difference between a Script Graph and a State Graph, see Graphs. Add a Script Machine or State Machine component to a GameObject and Visual Scripting automatically adds a Variables component. The Variables component holds any Object variables that you define in a Script Graph or State Graph attached to the GameObject. For more information on variables, see Variables. For more information on how to add a Script Machine or State Machine to a GameObject and attach a graph file, see Attach a graph file to a Script Machine or State Machine Source types Script Machines and State Machines have two options for their Source: a graph file (Graph), or an embedded asset (Embed). Set the Source for a Script Machine or State Machine at any time. If you switch the Source from Graph to Embed, the graph file still exists as a separate file from the State Machine or Script Machine inside of your project. Caution If you switch your Source from Embed to Graph, you will lose the embedded graph asset. You can copy the nodes from an embedded graph to a graph asset to avoid data loss. Other features of Visual Scripting, such as transitions, Super States, and Subgraphs, also have these source type options. The Graph source type Use the Graph source type to make your graphs faster to load and easier to maintain. Any changes made to a graph file apply to every Script Machine or State Machine that links to that graph file, even if those GameObjects don't use the same Prefab. To use the same graph across multiple GameObjects, use a Graph source type. You might encounter some situations where an embedded graph works best. The Embed source type An Embed graph exists only in the scene where it's created, if it isn't attached to a Prefab. This can cause problems with source control systems. If you delete a GameObject with an Embed graph asset, you will lose your graph. Changes made to an embedded graph aren't saved while the Editor is in Play mode. Use the Embed source type if: You need references to GameObjects from the current scene in the graph and the graph isn't on a Prefab. The graph is on a Prefab that you plan to instantiate in the application during runtime. You only need to use the logic in the graph once in the application. You can't reuse an embedded graph across multiple GameObjects unless the graph is on a Prefab. An embed graph only exists on the Script Machine or State Machine where you created it. This means you can share the graph across instances of a Prefab, but not on more than one GameObject. For more information about Prefabs, see Prefabs in the User Manual."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-graph-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-graph-types.html",
    "title": "Graphs | mmo-rpg-unity",
    "keywords": "Graphs A graph is a Visual Scripting asset that contains a visual representation of logic in an application. Visual Scripting has two different types of graphs: Script Graphs and State Graphs. You can use either graph type in specific situations to define and change how GameObjects in an application behave. Script Graphs and State Graphs must be attached to a Script Machine or State Machine to be used in a project. For more information on Script Machines and State Machines, see Script Machines and State Machines. Script Graphs Script Graphs control and connect specific actions and values. The actions in a Script Graph happen in a specific order. Actions can happen every frame, or when a specific event occurs. Visual Scripting represents the actions in a Script Graph through nodes. Connect nodes together with edges to tell your application what to do, and in what order. Script Graphs can access a large collection of nodes, which correspond to different features and functionality in the Unity Editor. Access these nodes through the fuzzy finder. Script Graphs define the specifics of what a GameObject does while your application runs. State Graphs A State Graph has states and gives the logic for when your application moves between states, through connections called transitions. Use State Graphs to design AI behavior or define scene and level structures. A state is any set of behaviors that you want a GameObject to perform, represented as a Script Graph. Visual Scripting represents states in State Graphs through State nodes. A State node can link to a Script Graph with logic for your application to follow, or give another State Graph with additional transitions and State nodes. States and transitions in a State Graph tell your application when to change its behavior, based on an event or after it fulfills a condition. For example, you might have an enemy character with Patrol and Chase states. The enemy character's actions can change from the actions in the Script Graph for the Patrol state to the actions for the Chase state after it detects the player character. The detection event for the enemy character triggers the transition between the two states. State Graphs don't use the fuzzy finder. They use a specific set of State nodes, which are in the Visual Scripting context menu: Script States contain a Script Graph. When an application triggers a Script State, Visual Scripting runs the logic in a Script State's attached Script Graph. Script States use On Enter State Event, On Update Event, and On Exit State Event nodes to control logic based on the current state. Super States contain another, nested State Graph. A Super State can help you better organize a State Graph, and reuse states and transitions across multiple graphs. Any States serve as a placeholder for any other state in a State Graph. You can use an Any State node and create a single transition to a new state, rather than create multiple transitions from other states. Transitions connect Script States, Any States, and Super States. Transitions contain Script Graphs that tell your application when to switch from one state to the next. For more information, see Transitions. You can set any Script State node or Super State node as a Start State. Any state marked as a Start State is automatically active when Visual Scripting runs a State Graph. You can also have multiple Start States in a single graph. The Super State, Start, and Script State nodes in the following example are all Start States."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-groups.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-groups.html",
    "title": "Create node groups | mmo-rpg-unity",
    "keywords": "Create node groups You can organize the nodes in your Script Graphs and State Graphs with node groups. Create a new group To create a new group: Open the graph where you want to create a new group. In an empty area of the Graph Editor, Ctrl+click (macOS: Cmd+click) and drag to create a selection. Release the mouse to create the group. After you create a group, you can: Change the group name Add a comment to the group Change the color of the group Resize the group Move the group Change a group name To change the name of the group in your graph: In the group header, click Group. Enter a new name for the group. Press Enter to save your changes. Add a comment to a group To add a comment to a group in a graph: Select the group where you want to add a comment. Open the Graph Inspector. In the (Comment) field in the Graph Inspector, enter comments or information about the group. Note Group comments are only visible in the Graph Inspector. To add comments to a graph that are always visible, use a Sticky Note. Change the color of a group To change the color of a group in a graph: Select the group you want to edit. Open the Graph Inspector. In the Graph Inspector, select the Color field. Select a new color for your group through one of the following methods: Use the color picker. Use the sliders or RGBA value fields. Enter a hexadecimal color value. Select the eyedropper icon and select a color from anywhere on your screen. Resize a group To resize a group in a graph: Click and drag from any edge or corner on the group. Move a group To move a group and its nodes: Click and drag the group's header to a new location in the Graph Editor. Note You can also move a group without moving any of the nodes inside, but the required input changes based on your chosen control scheme. For more information, see Choose a control scheme Next steps After you've created a node group, you can add nodes to your Script Graph, create and add variables, or add a Subgraph. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-input-nodes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-input-nodes.html",
    "title": "Input Event nodes | mmo-rpg-unity",
    "keywords": "Input Event nodes Input nodes are an Event node type that can read input from Unity's Input Manager or Input System package for use in a Script Graph. For more information about how to read and capture input in Visual Scripting, see Capture user input in an application. Input System package nodes The following nodes read and interact with Events from the Input System package: Node Description On Input System Event Button The On Input System Event Button node listens for a specific Input Action from a Player Input component. It doesn't send or read any other data. On Input System Event Float The On Input System Event Float node listens for a specific Input Action from a Player Input component. The node can output a single float value. On Input System Event Vector 2 The On Input System Event Vector 2 node listens for a specific Input Action from a Player Input component. The node can output two values as a Vector 2. Input Manager nodes The following nodes read and interact with Events from Unity's Input Manager: Node Description On Button Input The On Button Input node listens for a specified action on a virtual button from your Input Manager configuration. On Keyboard Input The On Keyboard Input node listens for a specified action on a keyboard key. On Mouse Down The On Mouse Down node listens for a mouse click action on a specific GameObject in your application. On Mouse Drag The On Mouse Drag node listens for a mouse click and hold on a specific GameObject in your application. It triggers the next node connected to it as long as the mouse button is held down on that GameObject. On Mouse Enter The On Mouse Enter node listens for the user's mouse pointer location to enter the Collider of a specified GameObject. When the mouse enters the Collider or GUI element, the node triggers the next node connected to it. On Mouse Exit The On Mouse Exit node listens for the user's mouse pointer location to exit the Collider of a specified GameObject. When the mouse exits the Collider or GUI element, the node triggers the next node connected to it. On Mouse Input The On Mouse Input node listens for a specific action on a user's mouse. The action doesn't need to happen on a specific GameObject's Collider. On Mouse Over The On Mouse Over node listens for a user's mouse to land over a specified GameObject's Collider. While the user's mouse is over the Collider, it triggers the next node connected to it once every frame. On Mouse Up As Button The On Mouse Up As Button node listens for a user to release their mouse button after they click a Collider in your application. To trigger the On Mouse Up As Button node, the user must release their mouse button over the same Collider they clicked. On Mouse Up The On Mouse Up node listens for a user to release their mouse button after they click a Collider in your application. The user can release their mouse button anywhere in your application to trigger the On Mouse Up node. Additional resources Capturing input in your application Capture input using the Input System package Capture input using the Input Manager"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-interface-overview.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-interface-overview.html",
    "title": "The interface | mmo-rpg-unity",
    "keywords": "The interface Visual Scripting's main window is the Graph window. The Graph window has five main elements: The Graph Editor, where you create, arrange, and connect nodes. The fuzzy finder, which you can use to find nodes and add them to your graph. The Graph toolbar, where you can change settings specific to your view in the Graph Editor and perform some common layout operations. The Graph Inspector, where you can view detailed information about your nodes and configure additional settings for your graph. The Blackboard, where you can define and edit variables to use in your graphs. The Graph Editor The Graph Editor is the center editing area of the Graph window. You can use the Graph Editor to create your Visual Scripting graphs. You can create nodes and connect them with edges. You can change some default shortcuts and behaviors in the Graph Editor through your control scheme. For more information on the available control schemes in Visual Scripting, see Choose a control scheme. The fuzzy finder The fuzzy finder is a searchable menu that lists every node available in Visual Scripting. Right-click anywhere in the Graph Editor to open the fuzzy finder. Search for a node by name with the Search bar, or open a category from the list to view related nodes. For example, nodes related to the creation or manipulation of variables are in the Variables category. You can add new nodes to Visual Scripting from your own code, from other packages, or from other Unity features. For more information on how to add nodes to the fuzzy finder, see Configure project settings. The Graph toolbar The Graph toolbar lets you display or hide the Graph Inspector and Blackboard. The Graph toolbar also includes a breadcrumb trail for navigation through nested graphs that displays your current location. Select a graph from the trail to return to that graph file. You can also configure some additional settings that control how nodes display in the Graph Editor. Property Description Lock Lock the current Script Graph or State Graph to the Graph window. Visual Scripting keeps the current graph open, even if you select another GameObject with a graph file in the Hierarchy window. Graph Inspector Display or hide the Graph Inspector. Blackboard Display or hide the Blackboard. Breadcrumb Location Displays the name of the current graph. If you open a Subgraph or State Unit, or a State node inside a State Graph, use the breadcrumbs to navigate back to the parent graph. Zoom Set a zoom level for your view of the Graph Editor. Relations Enable Relations to display inner flow connections for Script Graph nodes. For example, on a standard Multiply node, the Relations setting draws a line from each input port that merges into a single line on the output port. The lines display the flow of data inside the node. Disable Relations to hide these inner connections. Values Enable Values to display the input and output values sent between nodes while the Unity Editor is in Play mode. This can make it easier to debug your scripts. Disable Values to hide input and output values while in Play mode. For more information on Play mode, see The Game view in the Unity User Manual. NOTE This setting corresponds to the Show Connection Values setting in the Preferences window for Visual Scripting. For more information on this preference, see Configure your preferences. Dim Enable Dim to dim any nodes in the Graph Editor that aren't yet connected to the control flow in your graph. The Dim setting provides you with a visual cue that a node isn't used in the current configuration of your graph. Disable Dim to display all nodes as active regardless of their connection state. NOTE This setting corresponds to the Dim Inactive Nodes setting in the Preferences window for Visual Scripting. For more information on this preference, see Configure your preferences. Carry Enable Carry to move all connected child nodes when you move a parent node. Disable Carry to only move the currently selected node. NOTE This setting corresponds to the Carry Children setting in the Preferences window for Visual Scripting. For more information on this preference, see Configure your preferences. Align Choose an alignment option to align any nodes in your current selection. Align Left Edges Align all nodes in the selection based on their left edge. Align Centers Align all nodes in the selection based on their vertical centers. Align Right Edges Align all nodes in the selection based on their right edges. Align Top Edges Align all nodes in the selection based on their top edges. Align Middles Align all nodes in the selection based on their horizontal middles. Align Bottom Edges Align all nodes in the selection based on their bottom edges. Distribute Choose a distribution option to evenly distribute space between any nodes in your current selection. Distribute Left Edges Distribute all nodes in the selection to leave an equal distance between the left edges of each node. Distribute Centers Distribute all nodes in the selection to leave an equal distance between the vertical centers of each node. Distribute Right Edges Distribute all nodes in the selection to leave an equal distance between the right edges of each node. Distribute Horizontal Gaps Distribute all nodes in the selection to leave an equal-sized horizontal gap between each node. This distribution affects the space between the left and right edges of nodes. Distribute Top Edges Distribute all nodes in the selection to leave an equal distance between the top edges of each node. Distribute Middles Distribute all nodes in the selection to leave an equal distance between the horizontal middles of each node. Distribute Bottom Edges Distribute all nodes in the selection to leave an equal distance between the bottom edges of each node. Distribute Vertical Gaps Distribute all nodes in the selection to leave an equal-sized vertical gap between each node. This distribution affects the space between the top and bottom edges of nodes. Overview Select Overview to automatically pan and zoom to fit all elements of your current graph within the Graph Editor. Full Screen Select Full Screen when the Graph window is docked in the Unity Editor to maximize the Graph window to the full size of the Editor window. Your Visual Scripting preferences can change some settings in the Graph toolbar or change how these settings behave. For example, you can control how fast the Graph Editor zooms in and out when you set a zoom level. For more information, see Configure your preferences. The Graph Inspector The Graph Inspector provides additional information about an open graph, or about any node you select in the Graph Editor. If a node requires additional configuration, you can use the Graph Inspector to set these values. To display or hide the Graph Inspector, select Graph Inspector () from the toolbar. To move the Graph Inspector to the other side of the Graph window, select either Dock Right () or Dock Left (). The Blackboard The Blackboard provides options to configure and manage variables in a graph. The Blackboard divides variables into five distinct scopes, across five tabs: Graph, Object, Scene, App, and Saved. For more information on the available variable scopes in Visual Scripting, see Variables. To display or hide the Blackboard, select Blackboard () from the toolbar. To move the Blackboard to the other side of the Graph window, select either Dock Right () or Dock Left ()."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-live-edit-runtime.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-live-edit-runtime.html",
    "title": "Live edit during runtime | mmo-rpg-unity",
    "keywords": "Live edit during runtime Live editing in visual scripting goes beyond adjusting values in real-time. Live editing also includes the ability to add and remove nodes as well as connectors; you can code while the game is playing and immediately affect the gameplay. Remember that: Changes you make to embed graphs are reverted when you exit play mode; they live inside components. Changes you make to graphs are saved when you exit play mode; they live inside assets. Graph variables are saved when not in an embed graph. The following variables are not saved: Object Scene App Saved Note If you’ve used an embed graph and do not want to lose your modifications, copy all the changes you made to the embed graph before exiting Play mode. Paste them back in when in edit mode. You can’t do this for any changed variables. As a visual aid, connectors in Live mode display their execution flow with animated directional droplets going in the direction of execution. The speed and number of droplets does not represent the frequency or speed of execution. To adjust the graph during runtime With a graph open do any or all of the following: In the Inspector, click in any field to change a component’s value. The values are not persistent and won’t save when you leave Play mode. Right-click in an empty spot in the graph and add a node. Connect nodes. Delete any connectors. Add an extension. Add and link Debug nodes. Change values directly in a node. Tip Select any GameObject that contains a script graph to see and work with the values of the selected GameObject during runtime. Note When you modify anything after a Start event during runtime you won’t get the update on the GameObject during that session. You need to restart the session for Unity to execute the new logic after the start event. The changes you make to a graph are instantly shared across all instances of that saved graph asset."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-live.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-live.html",
    "title": "Live edit | mmo-rpg-unity",
    "keywords": "Live edit Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Visual Scripting supports live editing. In live editing you can create and edit graphs while in play mode and see the Visual Scripting updates in real time. This provides a fast way to iterate and test ideas without the need to recompile project changes. Working in live edit Live editing is not limited to tweaking values — you can add and remove nodes, connections (edges), etc while live. Anything that can be done in a normal edit, can be done in a live edit. In accordance with the Unity convention: Changes made to embeds are reverted when you exit play mode - the changes live inside components. Changes made to graphs are saved when you exit play mode - the changes live inside assets Tip To preserve the changes made to a component graph, copy the modified nodes before exiting play mode. You'll then be able to paste back while in edit mode. When in live mode, Visual Scripting is displayed the flow as droplets on connections. To disable these animations on either the value connections, the control connections, or both, deselect the Animate Control Connections or the Animate Value Connections from the editor preferences window (Edit > Preferences > Visual Scripting > Script Graphs). Saving changes through persistence Visual Scripting graphs automatically save the changes made during play mode. Propagation across graphs Changes made to a graph are instantly shared across all instances of that graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-add-state-unit.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-add-state-unit.html",
    "title": "Add a State Unit to a Script Graph | mmo-rpg-unity",
    "keywords": "Add a State Unit to a Script Graph Add a State Unit to a Script Graph to trigger a change of state. A state is any set of behaviors that you want a GameObject to perform. For more information on state in Visual Scripting, see Graphs. You can add a new State Graph to a State Unit node, or use an existing State Graph from the project. For more information on the State Unit node, see State Unit node. Add a new State Graph as a State Unit node To add a new blank State Graph as a State Unit node to a Script Graph: [!include[with-graph-open-ff](./snippets/vs-with-graph-open-ff.md)] Go to Nesting. Select State Unit to add a State Unit node to the graph. Open the Graph Inspector. In the Graph Inspector, choose the source for the State Unit: Embed: The State Graph only exists on the State Unit node. You can only change the State Graph from the node in its parent graph. Graph: The State Graph exists in a separate file. You can change the State Graph outside of its parent graph and reuse the graph in other areas of an application. If you chose Graph: In the Graph Inspector, select New. Enter a name for the graph file. Choose where you want to save the graph file in the project. Select Save. Add an existing State Graph as a State Unit node To add an existing State Graph file as a State Unit node in a Script Graph: With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder. Go to Nesting. Select State Unit to add a State Unit node to the graph. Open the Graph Inspector. In the Graph Inspector, set the Source to Graph. Do one of the following: In the Graph field, select the object picker (circle icon) and choose a compatible State Graph from the project. Click and drag a State Graph file from the Project window and release on the Graph field. Tip For a faster way to add a State Graph as a State Unit node: Click and drag a State Graph asset from the Project window into the Graph Editor to automatically create a State Unit node. Right-click to open the fuzzy finder. Go to Graphs and select a graph file. Next steps Select Edit Graph in the Graph Inspector to edit the graph. For more information on how to create a State Graph, see Develop logic transitions with State Graphs."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-add-subgraph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-add-subgraph.html",
    "title": "Add a Subgraph to a Script Graph | mmo-rpg-unity",
    "keywords": "Add a Subgraph to a Script Graph A Subgraph is a Script Graph nested inside of another Script Graph. A Subgraph appears as a single node inside a parent Script Graph. For more information on the Subgraph node, see Subgraph node. You can add a Subgraph to a Script Graph in two ways: create a new Script Graph, or add an existing Script Graph file. Add a new Subgraph to a Script Graph To add a new blank Subgraph to an existing Script Graph: [!include[with-graph-open-ff](./snippets/vs-with-graph-open-ff.md)] Go to Nesting. Select Subgraph to add a Subgraph node to the graph. Open the Graph Inspector. In the Graph Inspector, choose the source for the Subgraph: Embed: The Subgraph only exists on the Subgraph node. You can only change the Subgraph from the node in its parent graph. Graph: The Subgraph exists in a separate file. You can change the Subgraph outside of its parent graph and reuse the graph in other areas of an application. If you chose Graph: In the Graph Inspector, select New. Enter a name for the graph file. Choose where you want to save the graph file in the project. Select Save. Add an existing Script Graph as a Subgraph To add an existing graph file as a Subgraph in a Script Graph: Note You can't nest a Script Graph as a Subgraph in its own graph file. With a Script Graph open in the Graph window, right-click on an empty space in the Graph Editor to open the fuzzy finder. Go to Nesting. Select Subgraph to add the Subgraph node to the graph. Open the Graph Inspector. In the Graph Inspector, set the Source to Graph. Do one of the following: In the Graph field, select the object picker (circle icon) and choose a compatible Script Graph from the project. Click and drag a Script Graph file from the Project window and release on the Graph field. Tip For a faster way to add a Script Graph as a Subgraph: Click and drag a Script Graph asset from the Project window into the Graph Editor to automatically create a Subgraph node. Right-click to open the fuzzy finder. Go to Graphs and select a graph file. Next steps To open the new Subgraph and edit the graph, select Edit Graph. After you've added a Subgraph to a Script Graph, define its ports. For more information, see Add a Trigger or Data port to a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-add-triggers-data-graph.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-add-triggers-data-graph.html",
    "title": "Add a Trigger or Data port to a Script Graph | mmo-rpg-unity",
    "keywords": "Add a Trigger or Data port to a Script Graph A Script Graph used as a Subgraph can receive data and logic from its parent graph. Add and define ports on a graph to choose what data graphs can send and receive. For more information about Subgraphs, see Subgraphs and State Units. Add ports from a graph To add a Trigger Input, Trigger Output, Data Input, or Data Output port to a Script Graph: Open the Script Graph you want to edit in the Graph window. With no nodes or groups selected in the graph, open the Graph Inspector. Select Add (+) under the port type you want to add: Trigger Inputs Trigger Outputs Data Inputs Data Outputs In the Key field, enter a unique key name for the port. The Key value can't match the Key of any existing ports on the current Script Graph. NOTE If two Key values are the same on the same graph, Visual Scripting ignores the second port definition and displays a warning in the Graph Inspector. If you change the Key value for a port after you've made a connection to that port in a graph, the connections break and you must reconnect them. In the Label field, enter a label to display for the port. The label displays on the Subgraph node and its Input or Output node. NOTE If you don't set a Label, Visual Scripting uses the value from the Key field. In the Summary field, enter a brief summary of the port to display in the Graph Inspector when you select the Subgraph node, Input node, or Output node. Toggle Hide Label to do the following: Enable Hide Label to hide the port label on any Subgraph node, Input node, or Output node. Disable Hide Label to display the data from the Label field. (Data Inputs and Data Outputs Only) Set a data type for the port: Select the Type list to open the Type menu. Select a data type from the list to set the data type the port accepts. (Data Inputs Only) Enable Has Default Value to display the Default Value field. Disable Has Default Value to hide the Default Value field. In the Default Value field, enter the default value the port uses if it doesn't receive a data input while the Script Graph runs. Add ports with Input and Output nodes You can also use an Input node or an Output node to define ports on a Script Graph: Open the Script Graph you want to edit in the Graph window. [!include[open-fuzzy-finder](./snippets/vs-open-fuzzy-finder.md)] Go to Nesting. Do one of the following: To add a Trigger Input or Data Input port to the graph, select Input. To add a Trigger Output or Data Output port to the graph, select Output. Select the new Input or Output node in the graph. Open the Graph Inspector. In the Key field, enter a unique key name for the port. The Key value can't match the Key of any existing ports on the current Script Graph. NOTE If two Key values are the same on the same graph, Visual Scripting ignores the second port definition and displays a warning in the Graph Inspector. If you change the Key value for a port after you've made a connection to that port in a graph, the connections break and you must reconnect them. In the Label field, enter a label to display for the port. The label displays on the Subgraph node and its Input or Output node. NOTE If you don't set a Label, Visual Scripting uses the value from the Key field. In the Summary field, enter a brief summary of the port to display in the Graph Inspector when you select the Subgraph node, Input node, or Output node. Toggle Hide Label to do the following: Enable Hide Label to hide the port label on any Subgraph node, Input node, or Output node. Disable Hide Label to display the data from the Label field. (Data Inputs and Data Outputs Only) Set a data type for the port: Select the Type list to open the Type menu. Select a data type from the list to set the data type the port accepts. (Data Inputs Only) Enable Has Default Value to display the Default Value field. Disable Has Default Value to hide the Default Value field. In the Default Value field, enter the default value the port uses if it doesn't receive a data input while the Script Graph runs. Next steps Add the Script Graph as a Subgraph in another Script Graph. For more information on how to add a Script Graph as a Subgraph, see Add a Subgraph to a Script Graph. For more information on the port types on a Script Graph, see Subgraph node. The defined Trigger and Data ports affect the ports on the Input and Output nodes in a Script Graph. For more information, see Input node and Output node."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-input-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-input-node.html",
    "title": "Input node | mmo-rpg-unity",
    "keywords": "Input node Use an Input node to control the flow of logic and data from a Script Graph's Subgraph node. An Input node takes data from a parent graph and makes it available to a Subgraph. For more information on Subgraphs, see Subgraphs and State Units and Subgraph node. For more information on Script Graphs, see Graphs. Fuzzy finder category The Input node is in the Nesting category in the fuzzy finder. Available outputs By default, an Input node has no ports. An Input node can only have output ports. Define the number and specific data type for the output ports with the Graph Inspector. For more information on how to define ports on a Script Graph, see Add a Trigger or Data port to a Script Graph. Port Type Description Trigger Input A control port. Make a connection to this port to tell Visual Scripting what node to run next in the graph. Visual Scripting triggers any node to this port after the matching Trigger Input port triggers on the Subgraph node in the parent Script Graph. Data Input A data port. Make a connection to this port to send a value or other data to another node in the graph. The data source is the matching Data Input port on the Subgraph node in a parent Script Graph. Example graph usage In the following example, the Character Move Subgraph uses an Input node to receive data from a parent graph. The Input node has one Trigger Input port and three Data Input ports. It uses the values from the parent graph and the values from two Input Get Axis nodes to create a new Vector 3 value that it sends back to its parent graph. The parent graph sends three values from the current GameObject's Transform component to the Input node. The Subgraph reduces the number of nodes in the parent graph. Related nodes Use an Input node with the following nodes: Subgraph node Output node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-nodes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-nodes.html",
    "title": "Nesting nodes | mmo-rpg-unity",
    "keywords": "Nesting nodes Use the following nodes to work with nesting Subgraphs and State Units in a Script Graph. For more information on Subgraphs and State Units, see Subgraphs and State Units. Node Description Input node Use an Input node to control the flow of logic and data from a Script Graph's Subgraph node. An Input node takes data from a parent graph and makes it available to a Subgraph. Output node Use an Output node to control the flow of logic and data from a Script Graph's Subgraph node. An Output node sends data from a Subgraph and makes it available to a parent graph. State Unit node Use a State Unit node like a Subgraph. The node references and triggers a State Graph as a State Unit inside a Script Graph. Subgraph node Use a Subgraph node to reference and trigger another Script Graph's logic from inside a parent Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-output-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-output-node.html",
    "title": "Output node | mmo-rpg-unity",
    "keywords": "Output node Use an Output node to control the flow of logic and data from a Script Graph's Subgraph node. An Output node sends data from a Subgraph and makes it available to a parent graph. For more information on Subgraphs, see Subgraphs and State Units and Subgraph node. For more information on Script Graphs, see Graphs. Fuzzy finder category The Output node is in the Nesting category in the fuzzy finder. Available inputs By default, an Output node has no ports. The Output node can only have input ports. Define the number and specific data type for the input ports with the Graph Inspector. For more information on how to define ports on a Script Graph, see Add a Trigger or Data port to a Script Graph. Port Type Description Trigger Output A control port. Make a connection to this port to tell Visual Scripting which node triggers its exit from the Subgraph and the return to the logic in a parent graph. After the Output node runs, Visual Scripting starts any connections made to the matching Trigger Output port on the Subgraph node. Data Output A data port. Make a connection to this port to send data from a Subgraph to its parent graph. Visual Scripting returns any value from a node connected to this port to any node connected to the matching Data Output port on the Subgraph node. Example graph usage In the following example, the Character Move Subgraph uses an Input node to receive data from a parent graph. The Subgraph uses three values from the parent graph and the values from two Input Get Axis nodes to create a new Vector 3 value. The graph sends the new Vector 3 value to the Output node and back to the parent Script Graph. The Subgraph reduces the number of nodes in the parent graph. The parent graph receives the Vector 3 value from the Output node. The parent graph uses that value to set a new position on the current GameObject's Transform component. Related nodes Use an Output node with the following nodes: Subgraph node Input node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-state-unit-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-state-unit-node.html",
    "title": "State Unit node | mmo-rpg-unity",
    "keywords": "State Unit node Use a State Unit node like a Subgraph. The node references and triggers a State Graph inside a Script Graph. A State Unit node: Can't send or receive any data from ports. Can only trigger its associated State Graph or other nodes inside its parent Script Graph. Can't change its number or type of ports. For more information on Subgraphs and State Units, see Subgraphs and State Units. For more information on State Graphs and Script Graphs, see Graphs. Fuzzy finder category The State Unit node is in the Nesting category in the fuzzy finder. You can go to the Graphs category and select any State Graph to create a State Unit node. For more information on how to create a State Unit node, see Add a State Unit to a Script Graph. Inputs The State Unit node has the following input ports: Name Type Description Start Input Trigger The first execution Input Trigger for the node. The connection made to this port indicates when Visual Scripting runs the nested State Graph. Visual Scripting makes all states marked as Start States in the State Graph active. Stop Input Trigger The second execution Input Trigger for the node. The connection made to this port indicates when Visual Scripting stops the nested State Graph. Visual Scripting makes all states and transitions in the State Graph inactive. Outputs The State Unit node has the following output ports: Name Type Description Started Output Trigger The first execution Output Trigger for the node. The connection made to this port indicates what Visual Scripting runs after the nested State Graph starts. Stopped Output Trigger The second execution Output Trigger for the node. The connection made to this port indicates what Visual Scripting runs after the nested State Graph stops. Example graph usage Tip A State Unit node can use a new blank State Graph or an existing State Graph from a project. For more information, see Add a State Unit to a Script Graph. In the following example, a State Unit node triggers when the Script Graph's GameObject enters a specific Collider marked as a trigger. After the State Unit node starts, the Script Graph uses a Debug Log node to log Started new state! to the console. When the GameObject leaves the Collider, the State Unit node stops, and the Script Graph uses another Debug Log node to log Exited state to the console."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-subgraph-node.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-subgraph-node.html",
    "title": "Subgraph node | mmo-rpg-unity",
    "keywords": "Subgraph node Use a Subgraph node to reference and trigger another Script Graph's logic from inside a parent Script Graph. For more information on Subgraphs, see Subgraphs and State Units. For more information on Script Graphs, see Graphs. Fuzzy finder category The Subgraph node is in the Nesting category in the fuzzy finder. You can go to the Graphs category and select any Script Graph to create a Subgraph node. For more information on how to create a Subgraph, see Add a Subgraph to a Script Graph. Available ports By default, a Subgraph node has no ports. Use the Graph Inspector to specify the following on a Script Graph: Trigger Inputs. Trigger Outputs. Data Inputs. Data Outputs. These determine the type and number of ports available on its Subgraph node. For more information on how to define ports on a Script Graph, see Add a Trigger or Data port to a Script Graph. Port type Description Trigger Input Adds a control input port to the Subgraph node for the Script Graph. Use a Trigger Input to choose which node or nodes from a parent graph triggers Visual Scripting to run the logic in the Subgraph. Trigger Output Adds a control output port to the Subgraph node for the Script Graph. Use a Trigger Output to choose which node or nodes Visual Scripting triggers after the logic contained in the Subgraph finishes. Data Input Adds a data input port to the Subgraph node for the Script Graph. Use a Data Input to receive data from a parent graph. Data Output Adds a data output port to the Subgraph node for the Script Graph. Use a Data Output to send data back to a parent graph. Example graph usage Tip A Subgraph node can use a new blank Script Graph or an existing Script Graph from a project. For more information, see Add a Subgraph to a Script Graph. In the following example, the Subgraph node Character Move references a graph that makes a GameObject move based on a user's input. It has the following: One Trigger Input port. One Trigger Output port. Three Data Input ports. One Data Output port. After every Update Event in the application, the Character Move Subgraph node triggers and takes the X, Y, and Z coordinates of the current GameObject's Transform component. The Subgraph node then outputs a new Vector 3 value, which the parent graph assigns to the current GameObject with a Transform Set Position node. The Subgraph node reduces the number of nodes in the parent graph. Tip To see the Script Graph attached to the Subgraph node in this example, see either Input node or Output node. Related nodes Use a Subgraph node with the following nodes: Input node Output node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-subgraphs-state-units.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nesting-subgraphs-state-units.html",
    "title": "Subgraphs and State Units | mmo-rpg-unity",
    "keywords": "Subgraphs and State Units In a Script Graph, you can add a node that links directly to another Script Graph or State Graph. A nested Script Graph is a Subgraph. A nested State Graph is a State Unit. A nested Script Graph or State Graph helps you to organize and reuse logic across an application. A Subgraph or State Unit can exist as the node that adds it to a graph, or it can link to an external graph file. Subgraphs A Subgraph nests a Script Graph inside another Script Graph. Use a Subgraph node to reuse a set of logic across Script Graphs in an application. A Subgraph node can take inputs or send outputs back to its parent graph. Add ports to configure what data a Subgraph and its parent graph send to each other. Subgraph inputs and outputs With the Graph Inspector, you can choose and define the ports that appear when you use a Script Graph as a Subgraph. The port definitions for a Script Graph appear in the Graph Inspector when you have no other items selected in a graph. Defined ports appear on any Subgraph node that uses that Script Graph. In the following image, the Subgraph Rotate the Cube has: A Trigger Input port. An Data Input port. An Trigger Output port. An Data Output port. A port definition also changes the Input and Output nodes for a Subgraph. These nodes control the execution and flow between a Subgraph and its parent graph. In the following image, the Input and Output nodes have the same ports as the Rotate the Cube Subgraph node from the previous example. Note You can only use a single Input node and a single Output node in a Script Graph. If you add more Input or Output nodes, Visual Scripting only uses the first Input and Output nodes you added to the graph. For more information on how to add ports to a Script Graph, see Add a Trigger or Data port to a Script Graph. For more information on the different types of ports, see Subgraph node. For more information on how to use a Subgraph, see Add a Subgraph to a Script Graph. State Units A State Unit starts a State Graph from a Script Graph. You can't change the ports that appear on a State Unit node or send data between the State Graph and its parent Script Graph. The State Unit node starts different logic in a Script Graph, at different times in code execution: When the nested State Graph starts to run. While the nested State Graph runs. When the nested State Graph stops. After the nested State Graph stops. When you start a State Unit node's Start and Started ports in a parent graph, Visual Scripting marks all Start states inside the node's State Graph as active. When you start the Stop and Stopped ports, Visual Scripting marks all Start states as inactive. For more information on State Graphs and Start states, see State Graphs. For more information on the State Unit node, see State Unit node and Add a State Unit to a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-input-system-button.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-input-system-button.html",
    "title": "On Input System Event Button node | mmo-rpg-unity",
    "keywords": "On Input System Event Button node Note The On Input System Event Button node is an Input System package node. For more information about how to use the Input System package in Visual Scripting, see Capture user input in an application. The On Input System Event Button node listens for a specific Input Action from a Player Input component. It doesn't send or read any other data. Use this node when you want to read user input but don't require any other data from an Input Action. Fuzzy finder category The On Input System Event Button node is in the Events > Input category in the fuzzy finder. Inputs The On Input System Event Button node has the following input ports: Name Type Description Target Player Input The Player Input component that Visual Scripting uses to display a list of input actions. The default is This, which is the Player Input component attached to the GameObject where Visual Scripting runs the Script Graph. You can also connect a node that outputs a Player Input component. Input Action Input Action An input action. Use the dropdown to select an input action from the Player Input component specified in Player Input, or connect a node that outputs an input action. Controls The On Input System Event Button node has the following controls: Name Type Description Input Action Change Type Input Action Change Option Set an Input Action Change Type to choose the interaction type that triggers the node. On Pressed The node triggers when a user presses the button from the selected Input Action input asset. On Hold The node triggers when a user holds the button from the selected Input Action input asset. On Released The node triggers when a user releases the button from the selected Input Action input asset. You can also set this control from the Graph Inspector. Additional node settings The On Input System Event Button node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Input System Event Button node has one output port: Name Type Description [!include[nodes-input-system-output-trigger-port](./snippets/input-system/nodes-input-system-output-trigger-port.md)] Example graph usage In the following example, an On Input System Event Button node counts how many times the user has pressed a button from the Fire Input Action and logs the result to the console. When a user presses a button associated with the Fire Input Action, Visual Scripting gets the current value of the Count Object variable with a Get Variable node. The Get Variable node sends Count's current value to an Add Inputs node's A port. Then, the Float literal node sends a value of 1 to the Add Inputs node's B port. The On Input System Event Button node triggers the Set Variable node and assigns the value from the Add Inputs node's Sum port as the New Value of Count. The Set Variable node logs the value of Count to the console with the Debug Log node: Related nodes The following nodes are related or similar to the On Input System Event Button node: On Input System Event Float node On Input System Event Vector 2 node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-input-system-float.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-input-system-float.html",
    "title": "On Input System Event Float node | mmo-rpg-unity",
    "keywords": "On Input System Event Float node Note The On Input System Event Float node is an Input System package node. For more information about how to use the Input System package in Visual Scripting, see Capture user input in an application. The On Input System Event Float node lists for a specific Input Action from a Player Input component. The node can output a single float value. Use this node when you want to read user input and return a single value, such as an axis value or input from a trigger on a controller. Fuzzy finder category The On Input System Event Float node is in the Events > Input category in the fuzzy finder. Inputs The On Input System Event Float node has the following input ports: Name Type Description Target Player Input The Player Input component that Visual Scripting uses to display a list of input actions. The default is This, which is the Player Input component attached to the GameObject where Visual Scripting runs the Script Graph. You can also connect a node that outputs a Player Input component. Input Action Input Action An input action. Use the dropdown to select an input action from the Player Input component specified in Player Input, or connect a node that outputs an input action. Controls The On Input System Event Float node has the following controls: Name Type Description Input Action Change Type Input Action Change Option Set an Input Action Change Type to choose the interaction type that triggers the node. On Pressed The node triggers when a user presses the button from the selected Input Action input asset. On Hold The node triggers when a user holds the button from the selected Input Action input asset. On Released The node triggers when a user releases the button from the selected Input Action input asset. You can also set this control from the Graph Inspector. Additional node settings The On Input System Event Float node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Input System Event Float node has the following output ports: Name Type Description [!include[nodes-input-system-output-trigger-port](./snippets/input-system/nodes-input-system-output-trigger-port.md)] Float Value Float A float output port. Visual Scripting uses your chosen Input Action and its configuration in your Input Actions asset to determine the float value returned by this port. See the Example graph usage section for an example. For more information about how to configure Input Action settings and use an Input Action asset, see Input Action Assets in the Input System package documentation. Example graph usage In the following example, an On Input System Event Float node uses the bindings assigned to the Lift Input Action. When a user presses any key from the Lift binding, Visual Scripting takes the float value it receives from the Input System and sends it as an input to the Vector 3 Create node's Y input port. At the same time, Visual Scripting triggers the Transform Set Position node and uses the output from the Vector 3 Create node to set a new position for the Script Machine's GameObject. For this example, Lift uses a Right Trigger from a Gamepad input device as a binding. When a user presses the Right Trigger, the Y value of the GameObject's transform increases, which makes the GameObject move upwards in the scene. Related nodes The following nodes are related or similar to the On Input System Event Float node: On Input System Event Button node On Input System Event Vector 2 node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-input-system-vector2.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-input-system-vector2.html",
    "title": "On Input System Event Vector 2 node | mmo-rpg-unity",
    "keywords": "On Input System Event Vector 2 node Note The On Input System Event Vector 2 node is an Input System package node. For more information about how to use the Input System package in Visual Scripting, see Capture user input in an application. The On Input System Event Vector 2 node listens for a specific Input Action from a Player Input component. The node can output two values as a Vector 2. Use this node when you want to read input and return two values, such as a joystick or mouse position. Fuzzy finder category The On Input System Event Vector 2 node is in the Events > Input category in the fuzzy finder. Inputs The On Input System Event Vector 2 node has the following input ports: Name Type Description Target Player Input The Player Input component that Visual Scripting uses to display a list of input actions. The default is This, which is the Player Input component attached to the GameObject where Visual Scripting runs the Script Graph. You can also connect a node that outputs a Player Input component. Input Action Input Action An input action. Use the dropdown to select an input action from the Player Input component specified in Player Input, or connect a node that outputs an input action. Controls The On Input System Event Vector 2 node has the following controls: Name Type Description Input Action Change Type Input Action Change Option Set an Input Action Change Type to choose the interaction type that triggers the node. On Pressed The node triggers when a user presses the button from the selected Input Action input asset. On Hold The node triggers when a user holds the button from the selected Input Action input asset. On Released The node triggers when a user releases the button from the selected Input Action input asset. You can also set this control from the Graph Inspector. Additional node settings The On Input System Event Vector 2 node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Input System Event Vector 2 node has the following output ports: Name Type Description [!include[nodes-input-system-output-trigger-port](./snippets/input-system/nodes-input-system-output-trigger-port.md)] Vector 2 Value Vector 2 A Vector 2 output port. Visual Scripting uses your chosen Input Action and its configuration in your Input Actions asset to determine the Vector 2 value returned by this port. See the Example graph usage section for an example. For more information about how to configure Input Action settings and use an Input Action asset, see Input Action Assets in the Input System package documentation. Example graph usage In the following example, an On Input System Event Vector 2 node uses the bindings assigned to the Move Input Action. When a user presses a button from the Move binding, Visual Scripting takes the Vector 2 value it receives from the Input System and sends it as an input to the Transform Set Position node's Value input port. The Vector 2 value changes the position of the GameObject associated with the Target transform. For this example, Move uses the W, A, S, and D keys. The GameObject moves up in the scene when the user presses W, moves down when the user presses S, and moves left or right when the user presses A or D. Related nodes The following nodes are related or similar to the On Input System Event Vector 2 node: On Input System Event Button node On Input System Event Float node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-button-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-button-input.html",
    "title": "On Button Input node | mmo-rpg-unity",
    "keywords": "On Button Input node Note The On Button Input node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Button Input node listens for a specified action on a virtual button from your Input Manager configuration. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. Fuzzy finder category The On Button Input node is in the Events > Input category in the fuzzy finder. Inputs The On Button Input node has the following input ports: Name Type Description Name String The name of the button the node listens to for an Input event, as it appears in the Input Manager. Action Press State The specific press state of the button that the node listens for. Hold The user holds down the button. Down The user presses the button. Up The user releases the button. Additional node settings The On Button Input node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Button Input node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Button Input node listens for the user to press the button or key assigned to the Jump axes in the Input Manager. When the user presses the button, the On Button Input node triggers the Rigidbody Add Force node, which adds an Impulse Force to the Rigidbody's Y axis: The Add Force node makes the Target Rigidbody lift into the air. Related nodes The following nodes are related or similar to the to the On Button Input node: On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-keyboard-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-keyboard-input.html",
    "title": "On Keyboard Input node | mmo-rpg-unity",
    "keywords": "On Keyboard Input node Note The On Keyboard Input node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Keyboard Input node listens for a specified action on a keyboard key. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. Fuzzy finder category The On Keyboard Input node is in the Events > Input category in the fuzzy finder. Inputs The On Keyboard Input node has the following input ports: Name Type Description Key Key Code The name of the keyboard key the node listens to for an Input event. For a list of all available keys, see the KeyCode page's Properties section in the Unity User manual. Action Press State The specific press state of the key that the node listens for. Hold The user holds down the key. Down The user presses the key. Up The user releases the key. Additional node settings The On Keyboard Input node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Keyboard Input node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Keyboard Input node listens for when the user presses the Space key. When the user presses Space, the On Keyboard Input triggers the Transform Translate node and lifts the GameObject along its Y coordinate by 5 units. This makes the GameObject jump. Related nodes The following nodes are related or similar to the the On Keyboard Input node: On Button Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-down.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-down.html",
    "title": "On Mouse Down node | mmo-rpg-unity",
    "keywords": "On Mouse Down node Note The On Mouse Down node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Down node listens for a mouse click action on a specific GameObject in your application. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Down node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Down node has one input port: Name Type Description Target GameObject The GameObject that the user needs to click with their mouse to trigger the On Mouse Down node. Additional node settings The On Mouse Down node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Down node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Down node listens for a click action on the GameObject where the graph runs. When a user clicks the GameObject, the On Mouse Down node triggers the GameObject Instantiate node. The Instantiate node creates a new GameObject, based on the Ball Prefab. It creates the Ball at a specific Position. It uses the Transform Get Local Rotation to match the new GameObject's Rotation to the GameObject where the Script Graph runs. Then, the graph adds a Rigidbody component to the new GameObject, and uses a Rigidbody Add Force node to add an Impulse force. When the user clicks the mouse button, the Script Graph creates a new Ball GameObject and sends it towards the camera. Related nodes The following nodes are related or similar to the On Mouse Down node: On Button Input node On Keyboard Input node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-drag.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-drag.html",
    "title": "On Mouse Drag node | mmo-rpg-unity",
    "keywords": "On Mouse Drag node Note The On Mouse Drag node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Drag node listens for a mouse click and hold on a specific GameObject in your application. It triggers the next node connected to it as long as the mouse button is held down on that GameObject. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Drag node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Drag node has one input port: Name Type Description Target GameObject The GameObject the user needs to click and hold with their mouse to trigger the On Mouse Drag node. Additional node settings The On Mouse Drag node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Drag node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Drag node triggers a Camera Screen To World Point node. When the user clicks and holds their mouse button over the Target GameObject from the On Mouse Drag node, the Script Graph gets the user's current mouse position with an Input Get Mouse Position node. The graph uses the X and Y values from the Get Mouse Position node's Vector 3 result to create a new Vector 3 value, with a fixed Z value. The Screen To World Point node uses the new Vector 3 and the camera saved in the Main Camera Scene variable to set the position of the Target GameObject's transform. The Script Graph allows the user to drag the Target GameObject around the scene when hold down their mouse button. Related nodes The following nodes are related or similar to the On Mouse Drag node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-enter.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-enter.html",
    "title": "On Mouse Enter node | mmo-rpg-unity",
    "keywords": "On Mouse Enter node Note The On Mouse Enter node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Enter node listens for the user's mouse pointer location to enter the Collider of a specified GameObject. When the mouse enters the Collider or GUI element, the node triggers the next node connected to it. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Enter node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Enter node has one input port: Name Type Description Target GameObject The GameObject with the Collider that triggers the On Mouse Enter node. Additional node settings The On Mouse Enter node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Enter node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Enter node triggers the Instantiate GameObject node when the user's mouse enters the Collider on the Script Machine's GameObject. The Instantiate node creates an instance of the Light Prefab, at the Prefab's Position and with the Prefab's Rotation. The graph saves the new instance of the GameObject to a Scene variable, Spotlight, so it can interact with the GameObject again later. The result is a spotlight that appears over the On Mouse Enter node's Target GameObject, when the user's mouse enters the Collider. Related nodes The following nodes are related or similar to the On Mouse Enter node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-exit.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-exit.html",
    "title": "On Mouse Exit node | mmo-rpg-unity",
    "keywords": "On Mouse Exit node Note The On Mouse Exit node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Exit node listens for the user's mouse pointer location to exit the Collider of a specified GameObject. When the mouse exits the Collider or GUI element, the node triggers the next node connected to it. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Exit node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Exit node has one input port: Name Type Description Target GameObject The GameObject with the Collider that triggers the On Mouse Exit node. Additional node settings The On Mouse Exit node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Exit node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, continued from the example from the On Mouse Enter node, the On Mouse Exit node triggers a Destroy GameObject node when the user's mouse exits the Collider on the Script Machine's GameObject. The Destroy GameObject node destroys the GameObject assigned to the Spotlight Scene variable. The GameObject was created and assigned to the variable elsewhere in the graph. When the user's mouse leaves the Collider, the Target GameObject no longer has a spotlight. Related nodes The following nodes are related or similar to the On Mouse Exit node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Input node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-input.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-input.html",
    "title": "On Mouse Input node | mmo-rpg-unity",
    "keywords": "On Mouse Input node Note The On Mouse Input node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Input node listens for a specific action on a user's mouse. The action doesn't need to happen on a specific GameObject's Collider. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Input node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Input node has the following input ports: Name Type Description Button Mouse Button The name of the mouse button that triggers the On Mouse Input node. Action Press State The specific state of the mouse button that the node listens for. Hold The user holds down the mouse button. Down The user presses the mouse button. Up The user releases the mouse button. Additional node settings The On Mouse Input node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Input node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Input node listens for the user to hold the right mouse button and triggers an Instantiate Camera node. The Instantiate node clones the camera saved as the Camera1 Scene variable and assigns it to the NewCamera Scene variable. It sets a new position for the cloned camera with a Transform Set Position node, before it switches which camera renders in the Game view with the Camera Render node. When the application runs, the default view in the Game view displays all three spheres in the scene. When the user holds the right mouse button and triggers the On Mouse Input node, the Game view changes to focus on the middle sphere. Related nodes The following nodes are related or similar to the On Mouse Input node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Over node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-over.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-over.html",
    "title": "On Mouse Over node | mmo-rpg-unity",
    "keywords": "On Mouse Over node Note The On Mouse Over node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Over node listens for a user's mouse to land over a specified GameObject's Collider. While the user's mouse is over the Collider, it triggers the next node connected to it once every frame. It doesn't send or receive any other data. Fuzzy finder category The On Mouse Over node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Over node has one input port: Name Type Description Target GameObject The GameObject with the Collider that triggers the On Mouse Over node. Additional node settings The On Mouse Over node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Over node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Over node triggers a Timer node when the user moves their mouse over the Target GameObject. The Timer runs for 2 seconds and triggers a Color Lerp node. For every Tick of the Timer node, the Color Lerp node uses the Elapsed value to calculate a new Color between Color A and Color B to make a smooth transition between colors. The Material Set Color node uses the Result from the Color Lerp node to set a new Color on the Object material. While the user's mouse is over the Target GameObject, the objects that use the Object material in the scene transition from red to blue over two seconds. The transition repeats until the user's mouse leaves the Target's Collider. Related nodes The following nodes are related or similar to the On Mouse Over node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Up node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-up-button.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-up-button.html",
    "title": "On Mouse Up As Button node | mmo-rpg-unity",
    "keywords": "On Mouse Up As Button node Note The On Mouse Up As Button node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Up As Button node listens for a user to release their mouse button after they click a Collider in your application. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. To trigger the On Mouse Up As Button node, the user must release their mouse button over the same Collider they clicked. If you want the user to trigger the node after they release their mouse button at any location in your application, use the On Mouse Up node instead. Fuzzy finder category The On Mouse Up As Button node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Up As Button node has one input port: Name Type Description Target GameObject The GameObject the user must click and release with their mouse button to trigger the node. Additional node settings The On Mouse Up As Button node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Up As Button node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Up As Button node runs as a coroutine to load a new scene after the user clicks and releases their mouse button over the Target GameObject. The Script Graph loads the scene, makes the graph wait until the scene loads, then sets the loaded scene as the active scene in the application. When the application starts, the active scene contains a plane with three spheres. After the Script Graph runs, the scene changes to a plane with a single cube. Related nodes The following nodes are related or similar to the On Mouse Up As Button node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-up.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-events-on-mouse-up.html",
    "title": "On Mouse Up node | mmo-rpg-unity",
    "keywords": "On Mouse Up node Note The On Mouse Up node is an Input Manager node. For more information about how to use the Input Manager with Visual Scripting, see Capture user input in an application. The On Mouse Up node listens for a user to release their mouse button after they click a Collider in your application. It triggers the next node connected to it after the action occurs in the application. It doesn't send or receive any other data. The user can release their mouse button anywhere in your application to trigger the On Mouse Up node. If you want the node to trigger after the user releases the mouse button over the same Collider specified in the node's Target, use the On Mouse Up As Button node instead. Fuzzy finder category The On Mouse Up node is in the Events > Input category in the fuzzy finder. Inputs The On Mouse Up node has one input port: Name Type Description Target GameObject The GameObject the user needs to click with their mouse button to have the On Mouse Up node listen for a mouse button release action. The user can release their mouse button anywhere to trigger the On Mouse Up node, but they must click the GameObject specified as the Target. Additional node settings The On Mouse Up node has additional settings. Access these settings from the Graph Inspector: Name Type Description [!include[nodes-coroutine](./snippets/nodes-coroutine.md)] Outputs The On Mouse Up node has one output port: Name Type Description [!include[nodes-input-output-trigger](./snippets/input-manager/nodes-input-output-trigger.md)] Example graph usage In the following example, the On Mouse Up node adds a force to a GameObject based on the user's mouse position when they release their mouse button. The On Mouse Up node triggers a Camera Screen To World Point node to get the user's mouse position, before it sends the X value of the mouse to a Rigidbody Add Force node to move the GameObject. When the user clicks on the sphere in the middle of the scene and releases their mouse button, the sphere moves towards their mouse location. Related nodes The following nodes are related or similar to the On Mouse Up node: On Button Input node On Keyboard Input node On Mouse Down node On Mouse Drag node On Mouse Enter node On Mouse Exit node On Mouse Input node On Mouse Over node On Mouse Up As Button node"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes-reference.html",
    "title": "Node reference | mmo-rpg-unity",
    "keywords": "Node reference Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Nodes are the most basic element of computation in visual scripting. Nodes display the required information as text, but editing is done via the Inspector. To edit them, select any node and edit its properties in the Inspector. This node The This node returns the game object that owns the machine in which the graph runs. Control nodes Control nodes branch, loop and merge the flow. Time nodes Time nodes include timer, cooldown and wait nodes. Events Scripting nodes listen for events. They are the starting point for all scripts and appear as special green nodes in graphs. Variables These nodes get, set, and check variables. Nulls Nodes that deal with the nulls, a.k.a. \"nothing\" value. Formulas Formula evaluates logical and mathematical expressions directly via a textual Formula and match with multiple arguments."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nodes.html",
    "title": "Nodes | mmo-rpg-unity",
    "keywords": "Nodes Nodes are the most basic part of scripts in Visual Scripting. A node can listen for events, get the value of a variable, modify a component on a GameObject, and more. Nodes appear as blocks in the Graph Editor. You can arrange and connect these blocks with edges to create logic for an application. Add nodes with the fuzzy finder. Click and drag a node to move it in the Graph Editor. Node anatomy Visual Scripting highlights nodes in your current selection. All nodes have a header, which displays the node's name. Some node headers might contain additional information or controls. Select a node in your graph, the Visual Scripting Graph Inspector displays the following information: The node's name and type icon. A brief description of what the node does, if available. The current warning messages or errors for the node. The additional settings for the node, if available. The required type for each input port and a brief description, if available. The type for each output port and a brief description, if available. Connections and ports Connect a port from one node to a compatible port on another node to create an edge. Edges form the logic flow in a Visual Scripting graph. Click any port to create a new edge. Edges are color-coded: edges that control the logic flow in your graph are white. Data edges are colored based on their type. For more information about types, see Object types. When you create a new edge, Visual Scripting highlights ports on any other nodes in a graph where you can make a valid connection. If you enable Dim Incompatible Nodes, Visual Scripting also dims any nodes or ports without a valid connection. Ports on the left side of a node are Input Ports. Ports on the right side of a node are Output Ports. An input port or output port can be a Control Port or a Data Port: Control Ports control the logical flow in a graph. They tell Visual Scripting what order to execute the nodes in a graph, from left to right. The icon for a control port is always an arrow. These arrows display the direction of the flow of logic in a graph. Data Ports send and receive data, such as number values or GameObjects, between nodes. They have colors that correspond to the specific type they expect to receive as inputs, or send as outputs. Their icons change based on their type. You can make multiple connections to or from the same port, with some restrictions: You can connect a single Data Output port to multiple Data Input ports. You can't connect multiple Data Output ports to a single Data Input port. Visual Scripting can't choose which value to use. You can connect multiple Control Output ports to a single Control Input port. You can't connect a single Control Output port to multiple Control Input ports. Visual Scripting can't choose which node to run first. For more information on how to connect nodes, see Connect nodes in a Script Graph. More complex nodes can have more complex or specialized ports, outside of the ports described here. Node controls and inline values A node might have additional controls that display on its header or in the Graph Inspector. Controls can change the available ports or behavior of a node. Some ports might also use inline values. Element Example Description Control A control appears as a dropdown option on the header of a node. For example, a Container Type control might tell a node to expect to receive a GameObject instead of a Script Machine. Inline Value An inline value appears as an object picker field next to a port. You can use an inline value instead of a node connection to specify a value for a node. Not all Visual Scripting types support inline values. ## Node overloads Variations of a Visual Scripting node are called overloads. Overloads change the input and output data that a node can accept, and can change the number of input or output data ports on a node. For example, the Add node has four overloads, as shown in the following image of the fuzzy finder after a search for Add. You can distinguish each overload through its subcategory in the fuzzy finder. The Add node is a part of the Math category, but each overload is a part of a different subcategory: Generic, Scalar, Vector 2, Vector 3, or Vector 4. The specific node overload changes what input and output data the Add node can accept. While a Generic Add node can input and output any object type in Visual Scripting, a Vector 3 Add node can only take 3D vectors as an input, and can only output a single 3D vector: The default type and number of ports on the Add node stays consistent across its overloads. For the Rotate node, the type and number of ports varies. Based on the Rotate node you select, you might be able to specify the angle of rotation as a vector, as separate float values, or as an angle relative to each axis. You can also choose whether the node rotates the GameObject relative to itself, or relative to the center of the scene's world space."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nulls.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-nulls.html",
    "title": "Nulls node | mmo-rpg-unity",
    "keywords": "Nulls node Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Null nodes deal with the null value, which is scripting lingo for \"nothing\". The null node The null node always returns null as a value. Leaving a Unity object reference field empty (\"None\") automatically means null. Null Check The null check is a shortcut for a branch on an equality comparison with null. It can be useful to direct the flow in different directions depending on whether a value is null. For example, it can be used to handle a situation differently whether a transform has a parent in the hierarchy or not. Null Coalesce The null coalesce node provides a fallback value in case the original input is null. For example, the null coalesce node defines a default fallback audio clip in case the one on the audio source is missing."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-open-graph-edit.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-open-graph-edit.html",
    "title": "Open a graph file | mmo-rpg-unity",
    "keywords": "Open a graph file You can open a graph file from multiple locations, based on the graph type and its source type. For information on how to create a new graph file, see Create a new graph file. From the Project window To open a graph from the Project window: Go to Window > General > Project, or press Ctrl+5 (macOS: Cmd+5) to open the Project window. Find the location in your Project window's folders where you saved the graph file you want to edit. Double-click the graph file to open it in the Graph window. From the Graph Inspector If you have a nested or embedded graph inside another graph file, you can open it from the Graph Inspector. In the Graph window, select the node that represents the graph you want to edit. This node could be a transition, Super State, Subgraph, or State Unit. Open the Graph Inspector. In the Graph Inspector, select Edit Graph. The graph opens in the same Graph window. From a Script Machine or State Machine If you've attached or embedded a graph in a Script Machine or State Machine on a GameObject, you can open the graph from the component on the GameObject: Go to Window > General > Hierarchy, or press Ctrl+4 (macOS: Cmd+4) to open the Hierarchy window. In the Hierarchy window, select the GameObject that has the Script Machine or State Machine with the graph you want to edit. With the GameObject selected in the Hierarchy window, go to Window > General > Inspector, or press Ctrl+3 (macOS: Cmd+3) to open the Inspector window. On the Script Machine or State Machine component, select Edit Graph. Next steps After you open a graph file, you can add a node to the graph. For more information on how to add a node to a Script Graph, see Add a node to a Script Graph. For more information on how to edit a State Graph, see Develop logic transitions with State Graphs. You can also add a Sticky Note to add comments to a graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-refactor-add-attribute.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-refactor-add-attribute.html",
    "title": "Add the RenamedFrom attribute to a C# script | mmo-rpg-unity",
    "keywords": "Add the RenamedFrom attribute to a C# script To use nodes generated from a custom C# script in a project after you rename a member, class, struct, type, or enum, add the [RenamedFrom] attribute to the relevant API element in the script file. For more information on the [RenamedFrom] attribute, see Refactor a C# script with Visual Scripting. To add the attribute to a C# script: [!include[open-project-window](./snippets/vs-open-project-window.md)] In the Project window, double-click the C# script file you want to refactor. Unity opens the file in the program you specified in your preferences, under External Script Editor. NOTE For more information on script editors in Unity, see Integrated development environment (IDE) support in the Unity User Manual. In your external editor, do the following: Add the [RenamedFrom] attribute above the definition of the part of the script you want to rename. Add the element's old name as a string to the [RenamedFrom] attribute, as its parameter. For example: using UnityEngine; using Unity.VisualScripting; [RenamedFrom(\"Character\")] public class Player : MonoBehaviour { [RenamedFrom(\"InflictDamage\")] public void TakeDamage(int damage) { //... } } [!include[save-script](./snippets/vs-save-script.md)] [!include[return-unity](./snippets/vs-return-unity.md)] [!include[regen-node-library](./snippets/vs-regen-node-library.md)] Note If you change the namespace or namespaces used in your script, you must include the old namespace or namespaces to use the [RenamedFrom] attribute. Next steps Unity recommends that you leave the attribute in the script file, even after a successful recompile. Nodes that use your C# script no longer have errors related to a missing member, class, struct, type, or enum. Additional resources Refactor a C# script with Visual Scripting Configure project settings Add or remove types from your Type Options Custom C# nodes Custom events"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-refactoring.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-refactoring.html",
    "title": "Refactor a C# script with Visual Scripting | mmo-rpg-unity",
    "keywords": "Refactor a C# script with Visual Scripting Visual Scripting creates nodes from methods, fields, and properties from C# script in your project. Visual Scripting creates these nodes after you regenerate your Node Library and add any relevant types to your Type Options. For example, Visual Scripting created the following Take Damage node from a custom C# script that defines the Player class. Visual Scripting generated the node with the following code, which creates a Player class with a TakeDamage member. using UnityEngine; public class Player : MonoBehaviour { public void TakeDamage(int damage) { //... } } Tip You can create your own custom node or create a custom event to customize the ports and information displayed on your nodes. If you change the name of the TakeDamage member in the C# script, Visual Scripting displays an error in Script Graphs that use the Take Damage node. To rename a member, type, class, struct, enum, or other API element that a Visual Scripting node uses in a project, add the [RenamedFrom] attribute to the relevant API element in the script file. To avoid issues with Unity's serialization, the [RenamedFrom] attribute tells Visual Scripting that an API or one of its elements has been renamed. For more information on how to add the [RenamedFrom] attribute to a C# script, see Add the RenamedFrom attribute to a C# script. Additional resources Add the RenamedFrom attribute to a C# script Configure project settings Add or remove types from your Type Options Custom C# nodes Custom events"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-relations.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-relations.html",
    "title": "Use relations to debug | mmo-rpg-unity",
    "keywords": "Use relations to debug Relations are a useful tool to understand the dependencies between each port of a node. For example, to get the result of A + B with the Add node, you need to provide a value for A and B. Likewise, before invoking the Log node, you should provide a value for its Message input port. Visual scripting uses this information in the background for Predictive Debugging. For example, if you tried to get the value of A + B without providing a value for A, the node would show up as orange to indicate that it fails in play mode. When that happens, you can use the warnings shown in the Graph Inspector to know what is missing. Relations can also help understand the ports that are required and which ports are optional. For example, in the Get Child node (under fuzzy finder Codebase > Unity Engine > Transform), there is no need to connect the control ports if the goal is to get the transform value output. Enable the Relations toggle in the toolbar for the inner connections of each node to be displayed. Note You cannot edit relations. They are predefined for each type of node."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-script-graphs-intro.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-script-graphs-intro.html",
    "title": "Develop application logic with Script Graphs | mmo-rpg-unity",
    "keywords": "Develop application logic with Script Graphs Use Script Graphs to create interactions and logic in your project. Create a graph file Create a graph file to get started. For more information, see Create a new graph file. Add and connect nodes After you have a graph file, add a node or connect nodes together to build logic. Create Subgraphs Reuse logic with Subgraphs. Debug your graphs You can use relations to help you debug your scripts, or use Visual Scripting's predictive debugging to help you catch problems."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-scripts-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-scripts-reference.html",
    "title": "Script Graph nodes | mmo-rpg-unity",
    "keywords": "Script Graph nodes Visual scripting has four nodes that you can use to identify and manipulate the Script Graphs assigned to a GameObject and its Script Machines: Set Script Graph Has Script Graph Get Script Graph Get Script Graphs Set Script Graph You can use the Set Script Graph node to assign a Script Graph to a specific Script Machine, or to the first Script Machine attached to a specific GameObject. Item Description Node Parameters Container Type Specifies whether the Target is a GameObject or Script Machine. Input Ports Enter (Input Trigger) The execution input trigger for the node. Target (GameObject or Script Machine) The GameObject or Script Machine where the node sets the Graph. Graph (Script Graph Asset) The Script Graph the node sets on the Target. Output Ports Exit (Output Trigger) The execution output trigger. Graph (Script Graph Asset; Optional) Outputs the Graph. Setting the required node parameters and inputs The Set Script Graph node has one required input parameter, called Container Type, which is set using the dropdown in the node's header. The Container Type specifies what component type the node should expect as an input for its Target: If you choose GameObject, the node expects to receive a GameObject, and assigns the graph to the first Script Machine attached to that GameObject. If you choose Script Machine, the node expects to receive a Script Machine, and you can specify the exact Script Machine where you want to set your Script Graph. Depending on which Container Type you select, the icon displayed next to the Target input port on the node changes: Container Type Target Icon GameObject Script Machine The node has three input ports, located on the left side. The first port, Enter, connects to the node that should start the execution of the Set Script Graph node. The other two ports collect the Set Script Graph node's required input data: The Target, or the GameObject or Script Machine where you want to set a Script Graph. The Graph, or the Script Graph to assign to the GameObject or Script Machine. Outputs The Set Script Graph node has two output ports, located on the right side. The first port, Exit, establishes the connection to the node that should execute after the Set Script Graph node has finished. The second port, Graph, can output the Script Graph that you assigned using the node. Has Script Graph The Has Script Graph node allows you to determine whether a GameObject or Script Machine has a specific Script Graph assigned to it. Item Description Node Parameters Container Type Specify whether the Target is a GameObject or Script Machine. Input Ports Enter (Input Trigger) The execution input trigger for the node. Target (GameObject or Script Machine) The GameObject or Script Machine where the node should check for the Graph. Graph (Script Graph Asset) The Script Graph to search for on the GameObject or Script Machine. Output Ports Exit (Output Trigger) The execution output trigger, which starts execution of the next node in the flow after checking for the specified Script Graph. Has Graph (Boolean) Outputs true if the node found the specified Script Graph, false if not. Setting the required node parameters and inputs The Has Script Graph node has one required input parameter, called Container Type, which is set using the dropdown in the node's header. The Container Type specifies what component type the node should expect as an input for its Target: If you choose GameObject, the node expects to receive a GameObject, and checks for the graph on the first Script Machine attached to that GameObject. If you choose Script Machine, the node expects to receive a Script Machine, and you can specify the exact Script Machine where you want to check for the Script Graph. Depending on which Container Type you select, the icon displayed next to the Target input port on the node changes: Container Type Target Icon GameObject Script Machine The node has three input ports, located on the left side. The first port, Enter, connects to the node that should start the execution of the Has Script Graph node. The other two ports collect the Has Script Graph node's required input data: The Target, or the GameObject or Script Machine where you want to check for a Script Graph. The Graph, or the Script Graph to search for on the GameObject or Script Machine. Outputs The Has Script Graph node returns true if it finds the specified Script Graph. Otherwise, it returns false. You can use a control node connected to the Has Script Graph's output port to change what your script does next, based on the result from Has Script Graph. For more information about control nodes, see Control nodes. Get Script Graph The Get Script Graph node returns the first Script Graph set on a GameObject. Item Description Input Ports GameObject (GameObject) The GameObject where the node should retrieve a set Script Graph. Output Ports Graph (Script Graph Asset) Outputs the first or only Script Graph set on the GameObject, or null if there is no set Script Graph. Setting the required node parameters and inputs The Get Script Graph node is a data node. It can't control any logic in your script, and is only used to return data. The node has a single input port, located on the left side, which collects the node's required input data: The GameObject where the node should retrieve the Script Graph. You can choose a specific GameObject, or leave the default selection as This to use the GameObject where your script is currently running. Outputs The Get Script Graph node has a single output port, located on the right side. The output port returns the GameObject's first set Script Graph, or null, if there is no set Script Graph. Note The Get Script Graph node returns only the first Script Graph set on a GameObject. To return all Script Graphs set on a GameObject, use the Get Script Graphs node. Get Script Graphs The Get Script Graphs node returns a list of all Script Graphs set on a GameObject. Item Description Input Ports GameObject (GameObject) The GameObject where the node should retrieve a list of set Script Graphs. Output Ports Graphs (List of Script Graph Assets) Outputs a list of all Script Graphs set on the GameObject, or an empty list if there are no set Script Graphs. Setting the required node parameters and inputs The Get Script Graphs node is a data node. It can't control any logic in your script, and is only used to return data. The node has a single input port, located on the left side, which collects the node's required input data: The GameObject where the node should retrieve a list of Script Graphs. You can choose a specific GameObject, or leave the default selection as This to use the GameObject where your script is currently running. Outputs The Get Script Graphs node has a single output port, located on the right side. The output port returns a list of all set Script Graphs for the GameObject, or an empty list, if there are no set Script Graphs."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-self.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-self.html",
    "title": "This node | mmo-rpg-unity",
    "keywords": "This node Use a This node to return a GameObject with a Script Machine component that has the Script Graph. If the Script Machine uses an Graph source and multiple GameObjects use the same graph, the returned GameObject can change. Many nodes default their target to This. For example, the following Transform nodes are the same: Not all nodes support the This inline value. Any node that doesn't support the This inline value displays None instead of This in the default value field. For example, the Destroy node displays None. In these cases, manually specify the connection if you want to use This. You can use the This node in a graph even if the graph isn't yet assigned to a GameObject. The This node represents the GameObject that owns the graph at runtime."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-set-preferences.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-set-preferences.html",
    "title": "Configure your preferences | mmo-rpg-unity",
    "keywords": "Configure your preferences You can configure specific preferences in Visual Scripting to control the behavior of the Graph window and your nodes. To configure your preferences for Visual Scripting: Go to Edit > Preferences. Select Visual Scripting. Core preferences The following preferences control general behaviors across all graph types in Visual Scripting. Preference Description Dim Inactive Nodes Enable Dim Inactive Nodes to dim any nodes in the Graph Editor that aren't connected to the logic flow in a graph. This provides you with a visual cue that a dimmed node isn't used in the graph in its current configuration. Disable Dim Inactive Nodes to display all nodes as active, regardless of their connection state. NOTE You can also control this preference from the Graph toolbar. For more information, see The interface. Dim Incompatible Nodes Enable Dim Incompatible Nodes to dim all nodes that don't have a compatible connection port when you create a new edge. Disable Dim Incompatible Nodes to display all nodes as active for a new edge. Show Variables Help Enable Show Variables Help to display a brief explanation of the selected variable scope in the Blackboard. Disable Show Variables Help to hide these explanations. Create Scene Variables Enable Create Scene Variables to automatically create a Scene Variables GameObject with a Variables component and a Scene Variables script component after you create a Scene variable. A GameObject with these components is required to use Scene variables in a project. Disable Create Scene Variables to create these components on a GameObject manually. Show Grid Enable Show Grid to display a grid on the background of the Graph Editor. Disable Show Grid to hide the grid. Snap to Grid Enable Snap to Grid to force nodes to stick or snap to points on a grid in the Graph Editor. Disable Snap to Grid to move nodes freely and disable the snap-to-point behavior. Pan Speed Set a Pan Speed to control how quickly the view in the Graph Editor moves when you pan vertically with the scroll wheel. Drag Pan Speed Set a Drag Pan Speed to control how quickly the view in the Graph Editor moves when you move a node to the edge of the Graph window. Zoom Speed Set a Zoom Speed to control how quickly the Graph Editor zooms in or zooms out while you change the zoom level in the Graph window. For more information on how to change the zoom level in the Graph Editor, see Choose a control scheme. Overview Smoothing Set an Overview Smoothing to control how gradually the Graph Editor zooms or pans after you select the Overview option in the Graph toolbar. Carry Children Enable Carry Children to move all connected child nodes when you move a parent node in the Graph Editor. Disable Carry Children to only move the currently selected node in the Graph Editor. NOTE You can also change this setting from the Graph toolbar in the Graph window. For more information, see The interface. Disable Playmode Tint Enable Disable Playmode Tint to display all nodes in the Graph window as normal while the Unity Editor is in Play mode. Disable Disable Playmode Tint to add a tint to all nodes in the Graph window while the Editor is in Play mode. For more information on Play mode, see The Game view in the Unity User Manual. Control Scheme Select a Visual Scripting control scheme. For more information, see Choose a control scheme. Default Use the Default Visual Scripting control scheme. Alternate Use the Alternate Visual Scripting control scheme. Clear Graph Selection Enable Clear Graph Selection to clear any graph displayed in the Graph window after you select a GameObject with no set graph or graphs. Disable Clear Graph Window to keep the last displayed graph if the selected GameObject has no set graph assets. NOTE Visual Scripting always updates the Graph window to display the set graph on a selected GameObject, regardless of your chosen Clear Graph Selection setting. Human Naming Enable Human Naming to convert all displayed method names from camel case to title case. For example, camelCase becomes Camel Case. Disable Human Naming to leave all names in camel case. Max Search Results Set a Max Search Results value to specify the maximum number of search results returned by the fuzzy finder after you use the search bar. Group Inherited Members Enable Group Inherited Members to group together inherited nodes from a parent or base class to your current search term in the fuzzy finder. For example, an Audio Source is a Component: it has its own specific methods and nodes, but you can interact with it as a Component with Component nodes. While you perform a search in the fuzzy finder, Visual Scripting groups the nodes inherited from Component and displays them in grey. Disable Group Inherited Members to display nodes in the search results without grouping these inherited nodes. Developer Mode Enable Developer Mode to display additional preferences in the Preferences window and add additional features in the Graph window and other areas of the Unity Editor. For more information on the additional Developer Mode preferences, see Additional Developer Mode preferences. AOT Safe Mode Enable AOT Safe Mode to exclude nodes from search results in the fuzzy finder that might cause problems for platforms that require ahead of time (AOT) compilation. For example, Visual Scripting excludes nodes that use the Generic type. Disable AOT Safe Mode to display all nodes and types in the fuzzy finder. Script Graphs preferences The following preferences change the behavior of Script Graphs in the Graph window. Preference Description Update Nodes Automatically NOTE This feature is experimental. Enable Update Nodes Automatically to let Visual Scripting automatically update your Node Library when it detects a change in any script inside your project's Assets folder. Disable Update Nodes Automatically to manually regenerate your Node Library after you make a change to a script. For more information on how to regenerate your Node Library, see Configure project settings. Predict Potential Null References A predictive debugging feature. Enable Predict Potential Null References to display warnings about potential null value inputs in your graphs. Disable Predict Potential Null References to disable these warnings. NOTE Sometimes, predictive debugging might return false positive results when you enable this setting. Predict Potential Missing Components A predictive debugging feature. Enable Predict Potential Missing Components to display warnings about potential missing components in your graphs, such as a missing node input. Disable Predict Potential Missing Components to disable these warnings. NOTE Sometimes, predictive debugging might return false positive results when you enable this setting. Show Connection Values Enable Show Connection Values to display the input and output values sent between nodes while the Editor is in Play mode. This can make it easier to debug your scripts. Disable Show Connection Values to hide these value labels while in Play mode. For more information on Play mode, see The Game view in the User Manual. NOTE You can also control this preference from the Graph toolbar. For more information, see The interface. Predict Connection Values Enable Predict Connection Values to have the Graph Editor predict what input and output values your graph sends between nodes while the Unity Editor is in Play mode. For example, Visual Scripting would display the value currently set for a variable in your script, though that value might change before it's used by a node. Disable Predict Connection Values to hide these predicted input and output values. Hide Port Labels Enable Hide Port Labels to hide the name labels for node input and output ports. Disable Hide Port Labels to display these name labels. Animate Control Connections Enable Animate Control Connections to display a droplet animation across node control port edges while the Editor is in Play mode. Disable Animate Control Connections to disable the animations. For more information about the different node port types and edges, see Nodes. For more information on Play mode, see The Game view in the User Manual. Animate Value Connections Enable Animate Value Connections to display a droplet animation across node data port edges while the Editor is in Play mode. Disable Animate Value Connections to disable the animations. For more information about the different node port types and edges, see Nodes. For more information on Play mode, see The Game view in the User Manual. Skip Context Menu Enable Skip Context Menu to always open the fuzzy finder when you right-click in the Graph Editor. To access the context menu, use Shift+right-click. Disable Skip Context Menu to open the fuzzy finder when you right-click with no nodes or groups selected in the Graph Editor. The context menu opens when you right-click with a node or group selected. State Graphs preferences The following preferences change the behavior of State Graphs in the Graph window. Preference Description States Reveal Use the dropdown to choose when a Script State node displays a list of events from its graph. If you have many Script State nodes in a State Graph, you might want to change this setting. Never Script State nodes never display their list of events. Always Script State nodes always display their list of events. On Hover Script State nodes only display their list of events when you hover over the node in the Graph window. On Hover with Alt Script State nodes only display their list of events when you hover over the node while you hold Alt. When Selected Script State nodes only display their list of events when you select the node in the Graph window. On Hover or Selected Script State nodes display their list of events when you hover over the node, or when you select the node in the Graph window. On Hover with Alt or Selected Script State nodes display their list of events when you hover over the node while you hold Alt, or when you select the node in the Graph window. Transitions Reveal Use the dropdown to choose when a transition displays a list of events from its graph. If you have many transitions in a State Graph, you might want to change this setting. Never Transitions never display a list of events. Always Transitions always display a list of events. On Hover Transitions only display a list of events when you hover over the transition in the Graph window. On Hover with Alt Transitions only display a list of events when you hover over the transition while you hold Alt. When Selected Transitions only display a list of events when you select the transition in the Graph window. On Hover or Selected Transitions display a list of events when you hover over the transition, or when you select the transition in the Graph window. On Hover with Alt or Selected Transitions display a list of events when you hover over the transition while you hold Alt, or when you select the transition in the Graph window. Transitions End Arrow Enable Transitions End Arrow to add an arrow to the end of each transition edge in a State Graph. Disable Transitions End Arrow to display edges between transitions as simple lines. If you have many transitions in your State Graphs, you might want to disable this setting. Animate Transitions Enable Animate Transitions to display a droplet animation across transition edges when the Editor is in Play mode. Disable Animate Transitions to disable the animations. For more information on Play mode, see The Game view in the User Manual. Additional Developer Mode preferences Note You can only access the following preferences after you have enabled *Developer Mode in your Core preferences. These Developer Mode preferences provide help with developing extensions or custom nodes for Visual Scripting. Their continued support in the Visual Scripting package isn't guaranteed. Preference Description Debug Enable Debug to add additional logging and visual overlays to help you debug element rendering in the Graph window. For example, if you created a custom node, use this setting to help debug your UI. Disable Debug to disable the logging and hide these overlays. Track Metadata State Enable Track Metadata State to add more information to logging. This can assist in debugging. Disable Track Metadata State to hide this additional information. Debug Inspector UI Enable Debug Inspector UI to add more overlays and additional details. The information available is greater than what Visual Scripting provides with the Debug setting, and affects more areas of the Editor's UI. Only enable this setting if you need more in-depth debugging feedback. Disable Debug Inspector UI to hide this information."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-state-graphs-intro.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-state-graphs-intro.html",
    "title": "Develop logic transitions with State Graphs | mmo-rpg-unity",
    "keywords": "Develop logic transitions with State Graphs You can use State Graphs to change behaviors of GameObjects based on specific conditions. Create a new state After you create a new graph file for a State Graph, you can create states to tell Visual Scripting what a GameObject does, and when. Create a transition Use transitions to tell Visual Scripting when a GameObject changes states. There's no restriction on how many transitions you can create. State Unit nodes You can use a State Unit node to nest a State Graph inside a Script Graph."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-states-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-states-reference.html",
    "title": "State Graph nodes | mmo-rpg-unity",
    "keywords": "State Graph nodes Visual scripting has four nodes that you can use to identify and manipulate the State Graphs assigned to a GameObject and its State Machines: Set State Graph Has State Graph Get State Graph Get State Graphs Set State Graph You can use the Set State Graph node to assign a State Graph to a specific State Machine, or to the first State Machine attached to a specific GameObject. Item Description Node Parameters Container Type Specifies whether the Target is a GameObject or State Machine. Input Ports Enter (Input Trigger) The execution input trigger for the node. Target (GameObject or State Machine) The GameObject or State Machine where the node sets the Graph. Graph (State Graph Asset) The State Graph the node sets on the Target. Output Ports Exit (Output Trigger) The execution output trigger. Graph (State Graph Asset; Optional) Outputs the Graph. Setting the required node parameters and inputs The Set State Graph node has one required input parameter, called Container Type, which is set using the dropdown in the node's header. The Container Type specifies what component type the node should expect as an input for its Target: If you choose GameObject, the node expects to receive a GameObject, and assigns the graph to the first State Machine attached to that GameObject. If you choose State Machine, the node expects to receive a State Machine, and you can specify the exact State Machine where you want to set your State Graph. Depending on which Container Type you select, the icon displayed next to the Target input port on the node changes: Container Type Target Icon GameObject State Machine The node has three input ports, located on the left side. The first port, Enter, connects to the node that should start the execution of the Set State Graph node. The other two ports collect the Set State Graph node's required input data: The Target, or the GameObject or State Machine where you want to set a State Graph. The Graph, or the State Graph to assign to the GameObject or State Machine. Outputs The Set State Graph node has two output ports, located on the right side. The first port, Exit, establishes the connection to the node that should execute after the Set State Graph node has finished. The second port, Graph, can output the State Graph that you assigned using the node. Has State Graph The Has State Graph node allows you to determine whether a GameObject or State Machine has a specific State Graph assigned to it. Item Description Node Parameters Container Type Specify whether the Target is a GameObject or State Machine. Input Ports Enter (Input Trigger) The execution input trigger for the node. Target (GameObject or State Machine) The GameObject or State Machine where the node should check for the Graph. Graph (State Graph Asset) The State Graph to search for on the GameObject or State Machine. Output Ports Exit (Output Trigger) The execution output trigger, which starts execution of the next node in the flow after checking for the specified State Graph. Has Graph (Boolean) Outputs true if the node found the specified State Graph, false if not. Setting the required node parameters and inputs The Has State Graph node has one required input parameter, called Container Type, which is set using the dropdown in the node's header. The Container Type specifies what component type the node should expect as an input for its Target: If you choose GameObject, the node expects to receive a GameObject, and checks for the graph on the first State Machine attached to that GameObject. If you choose State Machine, the node expects to receive a State Machine, and you can specify the exact State Machine where you want to check for the State Graph. Depending on which Container Type you select, the icon displayed next to the Target input port on the node changes: Container Type Target Icon GameObject State Machine The node has three input ports, located on the left side. The first port, Enter, connects to the node that should start the execution of the Has State Graph node. The other two ports collect the Has State Graph node's required input data: The Target, or the GameObject or State Machine where you want to check for a State Graph. The Graph, or the State Graph to search for on the GameObject or State Machine. Outputs The Has State Graph node returns true if it finds the specified State Graph. Otherwise, it returns false. You can use a control node connected to the Has State Graph's output port to change what your script does next, based on the result from Has State Graph. For more information about control nodes, see Control nodes. Get State Graph The Get State Graph node returns the first State Graph set on a GameObject. Item Description Input Ports GameObject (GameObject) The GameObject where the node should retrieve a set State Graph. Output Ports Graph (State Graph Asset) Outputs the first or only State Graph set on the GameObject, or null if there is no set State Graph. Setting the required node parameters and inputs The Get State Graph node is a data node. It can't control any logic in your script, and is only used to return data. The node has a single input port, located on the left side, which collects the node's required input data: The GameObject where the node should retrieve the State Graph. You can choose a specific GameObject, or leave the default selection as This to use the GameObject where your script is currently running. Outputs The Get State Graph node has a single output port, located on the right side. The output port returns the GameObject's first set State Graph, or null, if there is no set State Graph. Note The Get State Graph node returns only the first State Graph set on a GameObject. To return all State Graphs set on a GameObject, use the Get State Graphs node. Get State Graphs The Get State Graphs node returns a list of all State Graphs set on a GameObject. Item Description Input Ports GameObject (GameObject) The GameObject where the node should retrieve a list of set State Graphs. Output Ports Graphs (List of State Graph Assets) Outputs a list of all State Graphs set on the GameObject, or an empty list if there are no set State Graphs. Setting the required node parameters and inputs The Get State Graphs node is a data node. It can't control any logic in your script, and is only used to return data. The node has a single input port, located on the left side, which collects the node's required input data: The GameObject where the node should retrieve a list of State Graphs. You can choose a specific GameObject, or leave the default selection as This to use the GameObject where your script is currently running. Outputs The Get State Graphs node has a single output port, located on the right side. The output port returns a list of all set State Graphs for the GameObject, or an empty list, if there are no set State Graphs."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-sticky-notes.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-sticky-notes.html",
    "title": "Add comments to a graph | mmo-rpg-unity",
    "keywords": "Add comments to a graph Use Sticky Notes to add comments to a graph. Sticky Notes can: Describe how a section of your graph works. Leave a note for yourself or others who might work on your Unity project. You can add text to the title and body of a Sticky Note. You can use Sticky Notes in Script Graphs and State Graphs. Add a Sticky Note to a graph To add a Sticky Note to a graph: Open a graph file in the Graph window. Do one of the following: Right-click anywhere in the Graph Editor to open the fuzzy finder. Select Sticky Note. With no items selected in the graph, right-click an empty space in the Graph Editor. Select Create Sticky Note. Edit a Sticky Note To edit text in the title or body of a Sticky Note: Open a graph file in the Graph window. Do one of the following: To edit the title of the Sticky Note, double-click the title. To edit the body of the Sticky Note, double-click the body. Enter the new text for the Sticky Note. Click anywhere in the Graph Editor to close the Sticky Note text editor. Tip You can also edit the text in a Sticky Note with the Graph Inspector: Select the Sticky Note you want to edit. Select Graph Inspector () from the toolbar. Do one of the following: To edit the title of the Sticky Note, select the title. To edit the body of the Sticky Note, select (Body). Enter the new text for the Sticky Note. Move a Sticky Note To move a Sticky Note to a new location in a graph: Open a graph file in the Graph window. Click and drag the Sticky Note to a new location. Delete a Sticky Note To delete a Sticky Note from a graph: Open a graph file in the Graph window. Do one of the following: Right-click a Sticky Note and select Delete. Select a Sticky Note and press Delete (Del). Resize a Sticky Note To change the size of a Sticky Note in a graph: Open a graph file in the Graph window. Click and drag a corner of a Sticky Note. Change the color of a Sticky Note To change the color theme for a Sticky Note: Open a graph file in the Graph window. Select the Sticky Note you want to edit. Select Graph Inspector () from the toolbar. Select a Color Theme: Classic Black Dark Orange Green Blue Red Purple Teal"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-time.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-time.html",
    "title": "Time nodes | mmo-rpg-unity",
    "keywords": "Time nodes Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Time nodes include timer, cooldown and wait nodes. Wait Wait nodes delay the execution of the rest of the script. The delay can be a set amount of seconds or a condition that must be fulfilled before moving on. Asynchronicity (delayed execution) in Unity is handled by coroutines (not multithreading). You need to inform visual scripting to run the script as a coroutine in order to support wait nodes. To do this enable the Coroutine checkbox on the initial event that starts the script. Do this in the graph inspector. A small dual-arrow icon appears on the event, indicating that it runs as a coroutine. If the coroutine checkbox is not enabled, an error at runtime indicates a port 'can only be triggered in a coroutine' when reaching a wait node. All wait nodes are also used inside loops and sequences. Wait For Seconds The Wait For Seconds node is the simplest and most common wait node. It delays the execution by a certain number of seconds. Wait Until The Wait Until node stops execution until a given condition is met. For example, you could wait until an object is close enough. Wait While The Wait While node is the opposite of the Wait Until node: it stops execution as long as a given condition is met. For example, you can wait while an object is out of range. Wait For Frame As the name implies, Wait For End Of Frame and Wait For Next Frame nodes delays execution until a specific point in Unity's update loop is met. For more information, see: Execution Order of Events. Wait For Script The Wait For Script node delays execution until all input scripts have been entered at least once. It's a useful way of grouping conditions that occur over multiple events or frames. In other languages, this concept is sometimes called \"promises\". Cooldown The Cooldown node implements a time restriction when the input script can only be triggered a limited number of times. When the cooldown is available, the input script gets transferred to the Ready port. When it is not, it gets transferred to the Not Ready port. The Duration port determines how long it takes for the cooldown to become available again. Checking Unscaled makes it ignore the time scale. The Tick port gets called at every frame while a cooldown is active. It is a good place to update any GUI code that show an indicator of the remaining duration until the action can be called again. In order to get that value, you have two options: Remaining, which returns the number of seconds until ready, and Remaining %, which returns a value between 0 and 1, respectively from ready to not ready. As soon as the cooldown is ready, the Completed port is triggered. There is no need to constantly pass input script for this port to get triggered. Finally, you can force the cooldown to become ready and reset its internal timer by triggering the Reset port. For example, a simple cooldown firing mechanic with a masked sprite and text that indicates how much time is remaining until it can fire again. Timer The Timer node implements and monitors a time pausable progression. The Duration port determines how long it takes for the cooldown to become available again. Checking Unscaled makes it ignore the time scale. A timer is started by triggering the Start input, which in turn triggers the Started output. It can be paused and resumed with the Pause and Resume inputs, or it can alternate between these states with the Toggle input. The Tick port gets called at every frame while a timer is active. In order to get the time measurements, you have two options: Elapsed, which returns the time since the timer was started, or Remaining, which returns the time until the timer completes. You can get each of these measurements in absolute number of seconds, or in %, which returns a value between 0 and 1. This is useful for lerping. As soon as the timer finishes, the Completed port is triggered. For example, a simple autodestroy mechanic on a sprite that is progressively colored red before being destroyed."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-transitions.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-transitions.html",
    "title": "Transitions | mmo-rpg-unity",
    "keywords": "Transitions A transition is a connection between State nodes in a State Graph. A transition has a Script Graph that tells Visual Scripting when to switch states in a State Graph. A special transition type, called a self transition, can make a state transition to itself. You can embed the Script Graph for a transition in the Transition node itself, or link to an external graph asset file. Use Event nodes and a Trigger Transition node in the Script Graph you attach to a transition. These nodes specify which event or events must occur to trigger a change of state in your parent State Graph. For example, the following transition Script Graph switches states after a GameObject with the Player tag enters a trigger Collider. Any transition nodes with a transition Script Graph display the name of the event in the graph that triggers the state change. For example, the following parent State Graph displays the graph from the previous example as an On Trigger Enter Transition node. If you've assigned a name to a transition Script Graph, the assigned name appears on the Transition node. Tip To reduce the space taken up by transition nodes in a State Graph, you can hide their name labels. For more information, see Configure your preferences. You can create any number of transitions between states in a State Graph. For more information on how to create transitions, see Create a transition between states."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-types.html",
    "title": "Object types | mmo-rpg-unity",
    "keywords": "Object types All scripting in Unity is based on the C# programming language. C# is a \"strongly typed\" language. This means that all data and objects in Visual Scripting have a specific type. For example, a variable can be a number with an integer type, or the object provided by a node's output port can be a GameObject. Types help the computer run Visual Scripting code. Visual Scripting's behavior might not depend on the object type you give a node as an input, but sometimes, an object's type is important. For example, to add a new variable in the Blackboard, you must specify the variable's type to assign it a value. When you make a new edge in the Graph Editor, some nodes might have ports that only allow a connection if the data input is the correct type. Choose the type for an object with the Type menu. For example, you can choose the type for a Data Input port on a Script Graph with the Type menu from the Graph Inspector. Enter a search term in the Type menu to find a specific object type. You can also navigate through the namespaces listed in the Type menu to find a type. Visual Scripting identifies namespaces in the Type menu with an arrow (>). Select any namespace to view the other namespaces or available types within that namespace. Common object types Unity has hundreds of types. You can also add your own custom types. For more information on custom types, see Custom types. The following table includes some commonly used types in Visual Scripting. Type Description Float A float is a numeric value, with or without decimal places. For example, 0.25 or 13.1. Integer An integer is a numeric value without decimal places. For example, 3 or 200. Boolean A Boolean is a true or false value. Use a Boolean to create logic in a Script Graph and for toggles. For example, a Script Graph can trigger an event only if a condition is true. String A string is a sequence of characters or piece of text. For example, string, string123, and s. Char A char is a single alphanumeric character from a string. For example, s or 1. Enum An enum is a finite enumeration of options. Enums are usually represented as dropdowns. For example, a Force Mode enum can have a value of either Force, Impulse, Acceleration, or Velocity Change. Vector A vector represents a set of float coordinates. Unity uses vectors for positions or directions. Vector 2 A Vector 2 has X and Y values. You can use a Vector 2 for coordinates in 2D spaces. Vector 3 A Vector 3 has X, Y, and Z values. You can use a Vector 3 for coordinates in 3D spaces. Vector 4 A Vector 4 has X, Y, Z, and W values. You can use a Vector 4 for coordinates in 4D spaces, such as parameters for shaders. GameObject A GameObject is the basic entity used in Unity scenes. All GameObjects have a name, a transform for their position and rotation in the scene, and a list of components. List A list is an ordered collection of elements. The elements in a list can each have their own type or all have the same type. Visual Scripting indexes items in a list with the first position at 0. This means that the first element of a list is at the 0 index of the list. The second item is at the 1 index, the third is at the 2 index, and so on. Dictionary A dictionary is a collection of elements. Each element has a unique key and a value. Use a key to access and assign the values for an element in a dictionary. For example, you can use a dictionary to organize the names and ages of a group of people. The person's name is the key to the value of their age. A single element in the dictionary can be John and 33. Object An Object is a special type in Unity. If a data input port on a node has its type set to Object, the node doesn't need a specific type as an input. Supported type conversions Visual Scripting can automatically convert some data types passed between nodes. For example, the following graph gets the Transform from a child GameObject of the current GameObject, and triggers an Animator Controller to play an animation. Visual Scripting converts the Transform component sent by the Transform Get Child node to the Animator Controller component on the same GameObject. Visual Scripting can automatically perform the following type conversions: Number to Number (for example, you can convert an integer to a float, such as 5 to 5.0, or 5.0 to 5) Base class to child class Child class to base class Custom operators (for example, you can convert a Vector 2 to a Vector 3) GameObject to a component (for example, a GameObject to its Rigidbody component) Component to GameObject (for example, a Rigidbody component to its GameObject) Component to component on the same GameObject (for example, a Rigidbody component to a Transform component) Enum to array Enum to list"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-update.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-update.html",
    "title": "Update Visual Scripting | mmo-rpg-unity",
    "keywords": "Update Visual Scripting Tip Back up your data before you update to a new version of Visual Scripting. For more information on how to back up your Visual Scripting assets and settings, see Create or restore a backup. Before you update, confirm that the version of Visual Scripting is compatible with your current project and needs. For example, you shouldn't use a Preview version of Visual Scripting in a production environment. For more information on package states and the package lifecycle in Unity, see the Package state and lifecycle in the Unity User Manual. To update your current version of Visual Scripting: Go to Window > Package Manager. In the Packages drop-down menu, select In Project. In your list of packages, select Visual Scripting. Select Update to X.X.X, where X.X.X is the newest available version of Visual Scripting."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-using-custom-types.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-using-custom-types.html",
    "title": "Use a custom type | mmo-rpg-unity",
    "keywords": "Use a custom type Visual Scripting supports every class and struct type available in Unity. By default, the most common are available in the fuzzy finder. Add additional Unity assemblies, such as custom types and classes, through your project settings. You must write some additional code to use a custom type or class in a graph. You can't assign a value to a variable with a custom type from Unity's Inspector window, or initialize it from inside the Unity Editor if this additional code isn't available. You must assign a default value for a custom type through the Inspector window to use that type for a variable in Visual Scripting. You have two options to enable variable assignment and initialization: If you have access to the source code, you can add the [Inspectable] attribute to the classes and fields that you want to display and modify in the Editor. If you don't have access to the source code, you must create a custom PropertyDrawer and generate the required property provider scripts. Add the [Inspectable] attribute Add the [Inspectable] attribute to the code for your custom class to display its available properties in the Inspector window and Visual Scripting's Graph Inspector. You can't view your classes and fields in the Inspector window without the [Inspectable] attribute. Unity provides a basic UI for your types in the Inspector window, which might not give the aesthetic results you want. If you or your users want to configure a property for a custom type with a slider, for example, don't use the [Inspectable] attribute method. For more information on how to add the [Inspectable] attribute to a custom class, see Add the Inspectable attribute to the source code for a custom type. Create a custom PropertyDrawer Create a custom PropertyDrawer to choose how to display each property for a custom class in the Inspector window. Without access to the source code, you must create a PropertyDrawer to interact with custom-typed variables in Visual Scripting. If you see an error in the Unity Editor's Inspector window when you try to use a type from a third-party package, you must create a custom PropertyDrawer. Note If you are a package developer, or plan to provide your custom classes and types to other users and want those types to be available in Visual Scripting, create a custom PropertyDrawer to get the best results for your users. For more information on how to create a custom PropertyDrawer, see Create a custom PropertyDrawer for a custom type. After you create a custom PropertyDrawer for a custom type, you must generate the necessary property provider scripts. For more information, see the Generate option in Configure project settings."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-variables-api.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-variables-api.html",
    "title": "Variables API | mmo-rpg-unity",
    "keywords": "Variables API Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. Visual scripting provides an easy API to handle variables, to get or set their value and verify if they are defined. All these operations are available from the Variables class. For example: Variables.Application.Set(\"score\", 100); Usings Add the following usings to your C# script to access the API: using Unity.VisualScripting; Scopes Graph To access variables on a graph, create a graph reference. This is basically a path to the nested graph from its root machine. To get the root graph on a machine: var graphReference = GraphReference.New(flowMachine, true); To access nested graphs, pass their parent nodes as additional parameters: var graphReference = GraphReference.New(flowMachine, new IGraphParentElement[] { subGraph }, true); To pass a graph reference: Variables.Graph(graphReference) Object To access variables on an object: Variables.Object(gameObject) Scene To access scene variables, do one of the following: Variables.Scene(scene) Or: Variables.Scene(gameObjectInScene) Or: Variables.ActiveScene Application To access application variables: Variables.Application Saved To access saved variables: Variables.Saved Operations In these examples, the lowercase scope refers to one of the previous scopes. Get To get the value of a variable, use the Get method with a name parameter: scope.Get(\"name\"); Note that variables are not strongly typed; they need to be cast manually. For example: int health = (int)Variables.Object(player).Get(\"health\") Set To set the value of a variable, use the Set method with the name and value parameters: scope.Set(\"name\", value); For example: Variables.Object(player).Set(\"health\", 100); Because variables are not strongly typed, pass any value to the second parameter, even if the variable currently is of a different type. Note Using the set method with a variable name that does not yet exist defines a new variable. Is Defined To check if a variable is defined, use the IsDefined method with a name parameter: scope.IsDefined(\"name\"); For example: if (Variables.Application.IsDefined(\"score\")) { // ... }"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-variables-reference.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-variables-reference.html",
    "title": "Variables node | mmo-rpg-unity",
    "keywords": "Variables node Note For versions 2019/2020 LTS, download the Visual Scripting package from the Unity Asset Store. There are six kinds of variable nodes. Each of these variable nodes has three object nodes: Get, to retrieve the value of the variable Set, to assign a new value to the variable Is Defined, to check whether the variable is defined They are located under the Variables category in the fuzzy finder. Variable nodes are teal colored. Dynamic Typing For get / set nodes, variables are not statically typed, meaning their type can change at runtime. Their type displays as an object when defined from the blackboard window. Get Variable The get variable node requires the name of the variable as an input and returns the Value as an output. Set Variable The set variable nodes require the name of the variable and the new value assigned to it as inputs. For convenience in layouting, it returns this same value as an output. Connect the control input port to indicate when the variable should be assigned and, optionally, the control output port to indicate what to do after. Using a set node with a variable name that doesn't yet exist creates the variable. Has Variable The Has Variable nodes require the name of the variable as an input and returns an Is Defined boolean as an output. They're useful to check if a variable has been created, and often, provide a fallback value if it hasn't. Do the same thing more easily by checking the Fallback box in the graph inspector for a Get Variable node. This adds a Fallback input to the node that is returned if the variable hasn't been defined: Dynamic Variables As the name of the variable is a standard value input port, connect it to any other port that returns a string. Refer to \"dynamic variables\", that is, variables whose reference might change during play mode. Object Variables Object variable nodes require an additional input for the Source. That port indicates which game object the variable you're referring to is defined. When left to its default value, they look on the current object (self). For example, the Get Variable node gets the value of the health variable on the player2 object. Dropdowns The kind and the name dropdowns can quickly configure the variable nodes. The name suggestions are contextual and are based on the existing variables of this kind and on the other variable nodes in the current graph. Drag and Drop Drag and drop items from the blackboard window directly into the graph to create matching nodes. By default, a Get node is created. If the Alt key is held, a Set node is created. If the Shiftkey is held, an Is Defined node is created. Variables API Visual scripting provides an easy API to handle variables, to get or set their value and verify if they are defined. All these operations are available from the Variables class. For example: Variables.Application.Set(\"score\", 100); Usings Add the following usings to your C# script to access the API: using Unity.VisualScripting; Scope Graph To access variables on a graph, create a graph reference. This is basically a path to the nested graph from its root machine. To get the root graph on a machine: var graphReference = GraphReference.New(flowMachine, true); To access nested graphs, pass their parent nodes as additional parameters: var graphReference = GraphReference.New(flowMachine, new IGraphParentElement[] { superUnit }, true); To pass a graph reference: Variables.Graph(graphReference) Object To access variables on an object: Variables.Object(gameObject) Scene To access scene variables, do one of the following: Variables.Scene(scene) Or: Variables.Scene(gameObjectInScene) Or: Variables.ActiveScene Application To access application variables: Variables.Application Saved To access saved variables: Variables.Saved Operations In these examples, the lowercase scope refers to one of the previous scopes. Get To get the value of a variable, use the Get method with a name parameter: scope.Get(\"name\"); Note that variables are not strongly typed; they need to be cast manually. For example: int health = (int)Variables.Object(player).Get(\"health\") Set To set the value of a variable, use the Set method with the name and value parameters: scope.Set(\"name\", value); For example: Variables.Object(player).Set(\"health\", 100); Because variables are not strongly typed, pass any value to the second parameter, even if the variable currently is of a different type. Note Using the set method with a variable name that does not yet exist defines a new variable. Is Defined To check if a variable is defined, use the IsDefined method with a name parameter: scope.IsDefined(\"name\"); For example: if (Variables.Application.IsDefined(\"score\")) { // ... }"
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-variables.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-variables.html",
    "title": "Variables | mmo-rpg-unity",
    "keywords": "Variables Variables act as a container for a piece of information that might change as an application runs. To define a variable, you need to provide: A name for the variable, such as MyVariable. The type of data the variable holds, such as int or string . A value for the variable, such as 1 or cat. In Visual Scripting, you can give a node the name of a variable, instead of a fixed value or text. Your Script Graph uses the variable's name to access its value. For example, you can use a variable called Count, with an int type and a value of 1. You can use an Add node in Visual Scripting to add 1 to the value of Count, and save the new value in Count to use again in another part of your Script Graph, or a different Script Graph. Variables also have scopes. A variable's scope determines what parts of your Script Graph can access which variables to read or modify their values. The scope can also decide whether another Script Graph can access a variable. You can create and manage variables in a graph from the Blackboard. For more information on the Blackboard, see The Blackboard. For more information on how to use variables, see Create and add a variable to a Script Graph. Variable scopes Each variable scope has its own tab on the Blackboard, except Flow variables. Visual Scripting has six variable scopes. Variable Scope Property Flow Variables Flow variables are like local variables in a scripting language: they have the smallest scope. You can't use a Flow variable if: The Flow variable doesn’t have a direct or indirect connection to the nodes where you want to use its value. The node where the variable is defined must be a part of the logical flow where you want to use its value. The Flow variable hasn’t been set before Visual Scripting tries to run any logic that needs its value. The node where the variable is defined must come before any other logic in your graph. You can't create a Flow variable from the Blackboard - you can create one with a Set Variable node and set the Scope to Flow. Graph Variables Graph variables belong to a specific Script Graph. You can't access or modify Graph variables outside the specific Script Graph where they're defined. You also can't create a new Graph variable unless you have a Script Graph open in the Graph window. Object Variables Object variables belong to a specific GameObject. You can edit an Object variable from the Unity Editor's Inspector for the GameObject, and the Object variable is accessible in all graphs attached to the GameObject. You can't create a new Object variable unless you've opened your Script Graph from a Script Machine component on a GameObject. Scene Variables Scene variables belong to the current scene. Visual Scripting creates a new GameObject in your scene to hold references to your Scene variables. You can access your Scene variables from any Script Graph attached to a different GameObject in a single scene, but can't access a Scene variable in another scene in your project. App or Application Variables Application variables belong to your entire application. You can access an Application variable across multiple scenes while your application runs, and the Application variable would hold your changes. Any values held in an Application variable reset to their default values after your application quits. Saved Variables Saved variables are like Application variables, but they persist even after your application quits. You can use a Saved variable as a simple but powerful save system. Unity stores Saved variables in its PlayerPrefs, and they don't refer to Unity objects, like GameObjects and components. For more information on PlayerPrefs, see PlayerPrefs in the Unity User Manual Scripting Reference. Note You can still access the Blackboard and create new variables with a State Graph open in the Graph window, but you can't add a variable node and use it inside a State Graph. For Saved variables, there are two additional tabs on the Blackboard: Initial and Saved: Values defined in the Initial tab apply to all new instances of your application as default values. Values defined in the Saved tab are the last modified values for those variables, based on when you last ran your application. You can edit them manually, or delete the values to reset them to the values defined in the Initial tab."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-version-control.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Documentation~/vs-version-control.html",
    "title": "Version control systems | mmo-rpg-unity",
    "keywords": "Version control systems To avoid any problems with automatically generated files, exclude some Visual Scripting files from your version control solution. To exclude files from version control, include a file or configure your settings to specify which files and folders to exclude: Create a new file at the root of your project directory. Tip The root of your project directory is at the level above your Assets folder. Name the file based on your chosen version control system: Git: .gitignore. For more information, see Git's documentation on gitignore. Unity Collab: .collabignore. For more information, see the Unity User Manual. Subversion: Ignore the files from your svn:ignore property or runtime configuration options. For more information, see Subversion's documentation on Ignoring Unversioned Items. Open the file in a text editor. Add the appropriate files or file patterns to your ignore file or configuration. For an example and more information, see Ignore file template. Note If you have an issue when you try to create a .gitignore file on Windows, refer to Microsoft's documentation on how to create a .gitignore file from the command line. Ignore file template The following template ignores all core Visual Scripting files, but preserves your project settings and variables. It also includes the standard Unity ignore directives for files that you can exclude from version control. For more information, see the Unity.gitignore file included in GitHub's gitignore template repository. Refer to the comments in the template for which lines to comment or remove. # Optionally exclude these transient (generated) files, # because they can be easily re-generated by the package Assets/Unity.VisualScripting.Generated/VisualScripting.Flow/UnitOptions.db Assets/Unity.VisualScripting.Generated/VisualScripting.Flow/UnitOptions.db.meta Assets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers Assets/Unity.VisualScripting.Generated/VisualScripting.Core/Property Providers.meta ## Unity # From: https://github.com/github/gitignore/blob/master/Unity.gitignore /[Ll]ibrary/ /[Tt]emp/ /[Oo]bj/ /[Bb]uild/ /[Bb]uilds/ /[Ll]ogs/ /[Uu]ser[Ss]ettings/ # MemoryCaptures can get excessive in size. # They also could contain extremely sensitive data /[Mm]emoryCaptures/ # Asset meta data should only be ignored when the corresponding asset is also ignored !/[Aa]ssets/**/*.meta # Uncomment this line if you want to ignore the asset store tools plugin # /[Aa]ssets/AssetStoreTools* # Autogenerated Jetbrains Rider plugin /[Aa]ssets/Plugins/Editor/JetBrains* # Visual Studio cache directory .vs/ # Gradle cache directory .gradle/ # Autogenerated VS/MD/Consulo solution and project files ExportedObj/ .consulo/ *.csproj *.unityproj *.sln *.suo *.tmp *.user *.userprefs *.pidb *.booproj *.svd *.pdb *.opendb *.VC.db # Unity3D generated meta files *.pidb.meta *.pdb.meta *.mdb.meta # Unity3D Generated File On Crash Reports sysinfo.txt # Builds *.apk *.aab *.unitypackage # Crashlytics generated file crashlytics-build.properties # Packed Addressables /[Aa]ssets/[Aa]ddressable[Aa]ssets[Dd]ata/*.*.bin* # Temporary auto-generated Android Assets /[Aa]ssets/[Ss]treamingAssets/aa.meta /[Aa]ssets/[Ss]treamingAssets/aa/* Remove previously committed files If you committed any files to a version control solution that you want to exclude: See Git's documentation on the git-rm command. See Subversion's documentation on the svn delete command."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/LICENSE.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/LICENSE.html",
    "title": "| mmo-rpg-unity",
    "keywords": "com.unity.visualscripting copyright © 2020 Unity Technologies Licensed under the Unity Package Distribution License (see https://unity3d.com/legal/licenses/Unity_Package_Distribution_License ). Unless expressly provided otherwise, the software under this license is made available strictly on an “AS IS” BASIS WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED. Please review the license for details on these and other terms and conditions."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/README.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/README.html",
    "title": "Visual Scripting (com.unity.visualscripting) | mmo-rpg-unity",
    "keywords": "Visual Scripting (com.unity.visualscripting) Visual Scripting, previously known as BOLT, is an alternative workflow to design behaviours. Instead of the classic method of writing a C# script, visual scripting offers a way to design behaviours intuitively without code, by connecting events, actions, and data together in a graph. Both programmers and non-programmers can use node-based graphs to design final logic or to quickly create prototypes. This package also features an API that programmers can use for more advanced tasks, or to create custom nodes that can be used by other team members. Required Software Unity: Supported versions include 2021.1 Documentation Documentation is available here. For further discussion, visit the Discord or the Visual Scripting forum."
  },
  "Library/PackageCache/com.unity.visualscripting@1.9.4/Third Party Notices.html": {
    "href": "Library/PackageCache/com.unity.visualscripting@1.9.4/Third Party Notices.html",
    "title": "| mmo-rpg-unity",
    "keywords": "This package contains third-party software components governed by the license(s) indicated below: Component Name: AQN Parser License Type: Microsoft Public License Copyright © 2013 Christophe Bertrand https://www.codeproject.com/Tips/624300/AssemblyQualifiedName-Parser This license governs use of the accompanying software. If you use the software, you accept this license. If you do not accept the license, do not use the software. Definitions The terms \"reproduce,\" \"reproduction,\" \"derivative works,\" and \"distribution\" have the same meaning here as under U.S. copyright law. A \"contribution\" is the original software, or any additions or changes to the software. A \"contributor\" is any person that distributes its contribution under this license. \"Licensed patents\" are a contributor's patent claims that read directly on its contribution. Grant of Rights (A) Copyright Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free copyright license to reproduce its contribution, prepare derivative works of its contribution, and distribute its contribution or any derivative works that you create. (B) Patent Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free license under its licensed patents to make, have made, use, sell, offer for sale, import, and/or otherwise dispose of its contribution in the software or derivative works of the contribution in the software. Conditions and Limitations (A) No Trademark License- This license does not grant you rights to use any contributors' name, logo, or trademarks. (B) If you bring a patent claim against any contributor over patents that you claim are infringed by the software, your patent license from such contributor to the software ends automatically. (C) If you distribute any portion of the software, you must retain all copyright, patent, trademark, and attribution notices that are present in the software. (D) If you distribute any portion of the software in source code form, you may do so only under this license by including a complete copy of this license with your distribution. If you distribute any portion of the software in compiled or object code form, you may only do so under a license that complies with this license. (E) The software is licensed \"as-is.\" You bear the risk of using it. The contributors give no express warranties, guarantees or conditions. You may have additional consumer rights under your local laws which this license cannot change. To the extent permitted under your local laws, the contributors exclude the implied warranties of merchantability, fitness for a particular purpose and non-infringement. Component Name: Deep Copy License Type: MIT Copyright © 2014 Alexey Burtsev https://github.com/Burtsev-Alexey/net-object-deep-copy Permission is hereby granted, free of charge, to any person obtaining a copyof this software and associated documentation files (the \"Software\"), to dealin the Software without restriction, including without limitation the rightsto use, copy, modify, merge, publish, distribute, sublicense, and/or sellcopies of the Software, and to permit persons to whom the Software isfurnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included inall copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS ORIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THEAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHERLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: DotNetZip License Type: Microsoft Public License Copyright © 2017 Ionic https://dotnetzip.codeplex.com/ This license governs use of the accompanying software. If you use the software, you accept this license. If you do not accept the license, do not use the software. Definitions The terms \"reproduce,\" \"reproduction,\" \"derivative works,\" and \"distribution\" have the same meaning here as under U.S. copyright law. A \"contribution\" is the original software, or any additions or changes to the software. A \"contributor\" is any person that distributes its contribution under this license. \"Licensed patents\" are a contributor's patent claims that read directly on its contribution. Grant of Rights (A) Copyright Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free copyright license to reproduce its contribution, prepare derivative works of its contribution, and distribute its contribution or any derivative works that you create. (B) Patent Grant- Subject to the terms of this license, including the license conditions and limitations in section 3, each contributor grants you a non-exclusive, worldwide, royalty-free license under its licensed patents to make, have made, use, sell, offer for sale, import, and/or otherwise dispose of its contribution in the software or derivative works of the contribution in the software. Conditions and Limitations (A) No Trademark License- This license does not grant you rights to use any contributors' name, logo, or trademarks. (B) If you bring a patent claim against any contributor over patents that you claim are infringed by the software, your patent license from such contributor to the software ends automatically. (C) If you distribute any portion of the software, you must retain all copyright, patent, trademark, and attribution notices that are present in the software. (D) If you distribute any portion of the software in source code form, you may do so only under this license by including a complete copy of this license with your distribution. If you distribute any portion of the software in compiled or object code form, you may only do so under a license that complies with this license. (E) The software is licensed \"as-is.\" You bear the risk of using it. The contributors give no express warranties, guarantees or conditions. You may have additional consumer rights under your local laws which this license cannot change. To the extent permitted under your local laws, the contributors exclude the implied warranties of merchantability, fitness for a particular purpose and non-infringement. Component Name: FatCow Icons License Type: Creative Commons Attribution 3.0 Copyright © 2017 FatCow Web Hosting https://www.fatcow.com/free-icons THE WORK (AS DEFINED BELOW) IS PROVIDED UNDER THE TERMS OF THIS CREATIVE COMMONS PUBLIC LICENSE (\"CCPL\" OR \"LICENSE\"). THE WORK IS PROTECTED BY COPYRIGHT AND/OR OTHER APPLICABLE LAW. ANY USE OF THE WORK OTHER THAN AS AUTHORIZED UNDER THIS LICENSE OR COPYRIGHT LAW IS PROHIBITED. BY EXERCISING ANY RIGHTS TO THE WORK PROVIDED HERE, YOU ACCEPT AND AGREE TO BE BOUND BY THE TERMS OF THIS LICENSE. TO THE EXTENT THIS LICENSE MAY BE CONSIDERED TO BE A CONTRACT, THE LICENSOR GRANTS YOU THE RIGHTS CONTAINED HERE IN CONSIDERATION OF YOUR ACCEPTANCE OF SUCH TERMS AND CONDITIONS. Definitions \"Collective Work\" means a work, such as a periodical issue, anthology or encyclopedia, in which the Work in its entirety in unmodified form, along with one or more other contributions, constituting separate and independent works in themselves, are assembled into a collective whole. A work that constitutes a Collective Work will not be considered a Derivative Work (as defined below) for the purposes of this License.\"Derivative Work\" means a work based upon the Work or upon the Work and other pre-existing works, such as a translation, musical arrangement, dramatization, fictionalization, motion picture version, sound recording, art reproduction, abridgment, condensation, or any other form in which the Work may be recast, transformed, or adapted, except that a work that constitutes a Collective Work will not be considered a Derivative Work for the purpose of this License. For the avoidance of doubt, where the Work is a musical composition or sound recording, the synchronization of the Work in timed-relation with a moving image (\"synching\") will be considered a Derivative Work for the purpose of this License.\"Licensor\" means the individual, individuals, entity or entities that offers the Work under the terms of this License.\"Original Author\" means the individual, individuals, entity or entities who created the Work.\"Work\" means the copyrightable work of authorship offered under the terms of this License.\"You\" means an individual or entity exercising rights under this License who has not previously violated the terms of this License with respect to the Work, or who has received express permission from the Licensor to exercise rights under this License despite a previous violation.2. Fair Use Rights. Nothing in this license is intended to reduce, limit, or restrict any rights arising from fair use, first sale or other limitations on the exclusive rights of the copyright owner under copyright law or other applicable laws. License Grant. Subject to the terms and conditions of this License, Licensor hereby grants You a worldwide, royalty-free, non-exclusive, perpetual (for the duration of the applicable copyright) license to exercise the rights in the Work as stated below: to reproduce the Work, to incorporate the Work into one or more Collective Works, and to reproduce the Work as incorporated in the Collective Works;to create and reproduce Derivative Works provided that any such Derivative Work, including any translation in any medium, takes reasonable steps to clearly label, demarcate or otherwise identify that changes were made to the original Work. For example, a translation could be marked \"The original work was translated from English to Spanish,\" or a modification could indicate \"The original work has been modified.\";;to distribute copies or phonorecords of, display publicly, perform publicly, and perform publicly by means of a digital audio transmission the Work including as incorporated in Collective Works;to distribute copies or phonorecords of, display publicly, perform publicly, and perform publicly by means of a digital audio transmission Derivative Works.For the avoidance of doubt, where the Work is a musical composition: Performance Royalties Under Blanket Licenses. Licensor waives the exclusive right to collect, whether individually or, in the event that Licensor is a member of a performance rights society (e.g. ASCAP, BMI, SESAC), via that society, royalties for the public performance or public digital performance (e.g. webcast) of the Work.Mechanical Rights and Statutory Royalties. Licensor waives the exclusive right to collect, whether individually or via a music rights agency or designated agent (e.g. Harry Fox Agency), royalties for any phonorecord You create from the Work (\"cover version\") and distribute, subject to the compulsory license created by 17 USC Section 115 of the US Copyright Act (or the equivalent in other jurisdictions).Webcasting Rights and Statutory Royalties. For the avoidance of doubt, where the Work is a sound recording, Licensor waives the exclusive right to collect, whether individually or via a performance-rights society (e.g. SoundExchange), royalties for the public digital performance (e.g. webcast) of the Work, subject to the compulsory license created by 17 USC Section 114 of the US Copyright Act (or the equivalent in other jurisdictions).The above rights may be exercised in all media and formats whether now known or hereafter devised. The above rights include the right to make such modifications as are technically necessary to exercise the rights in other media and formats. All rights not expressly granted by Licensor are hereby reserved. Restrictions. The license granted in Section 3 above is expressly made subject to and limited by the following restrictions: You may distribute, publicly display, publicly perform, or publicly digitally perform the Work only under the terms of this License, and You must include a copy of, or the Uniform Resource Identifier for, this License with every copy or phonorecord of the Work You distribute, publicly display, publicly perform, or publicly digitally perform. You may not offer or impose any terms on the Work that restrict the terms of this License or the ability of a recipient of the Work to exercise the rights granted to that recipient under the terms of the License. You may not sublicense the Work. You must keep intact all notices that refer to this License and to the disclaimer of warranties. When You distribute, publicly display, publicly perform, or publicly digitally perform the Work, You may not impose any technological measures on the Work that restrict the ability of a recipient of the Work from You to exercise the rights granted to that recipient under the terms of the License. This Section 4(a) applies to the Work as incorporated in a Collective Work, but this does not require the Collective Work apart from the Work itself to be made subject to the terms of this License. If You create a Collective Work, upon notice from any Licensor You must, to the extent practicable, remove from the Collective Work any credit as required by Section 4(b), as requested. If You create a Derivative Work, upon notice from any Licensor You must, to the extent practicable, remove from the Derivative Work any credit as required by Section 4(b), as requested.If You distribute, publicly display, publicly perform, or publicly digitally perform the Work (as defined in Section 1 above) or any Derivative Works (as defined in Section 1 above) or Collective Works (as defined in Section 1 above), You must, unless a request has been made pursuant to Section 4(a), keep intact all copyright notices for the Work and provide, reasonable to the medium or means You are utilizing: (i) the name of the Original Author (or pseudonym, if applicable) if supplied, and/or (ii) if the Original Author and/or Licensor designate another party or parties (e.g. a sponsor institute, publishing entity, journal) for attribution (\"Attribution Parties\") in Licensor's copyright notice, terms of service or by other reasonable means, the name of such party or parties; the title of the Work if supplied; to the extent reasonably practicable, the Uniform Resource Identifier, if any, that Licensor specifies to be associated with the Work, unless such URI does not refer to the copyright notice or licensing information for the Work; and, consistent with Section 3(b) in the case of a Derivative Work, a credit identifying the use of the Work in the Derivative Work (e.g., \"French translation of the Work by Original Author,\" or \"Screenplay based on original Work by Original Author\"). The credit required by this Section 4(b) may be implemented in any reasonable manner; provided, however, that in the case of a Derivative Work or Collective Work, at a minimum such credit will appear, if a credit for all contributing authors of the Derivative Work or Collective Work appears, then as part of these credits and in a manner at least as prominent as the credits for the other contributing authors. For the avoidance of doubt, You may only use the credit required by this Section for the purpose of attribution in the manner set out above and, by exercising Your rights under this License, You may not implicitly or explicitly assert or imply any connection with, sponsorship or endorsement by the Original Author, Licensor and/or Attribution Parties, as appropriate, of You or Your use of the Work, without the separate, express prior written permission of the Original Author, Licensor and/or Attribution Parties.5. Representations, Warranties and Disclaimer UNLESS OTHERWISE MUTUALLY AGREED TO BY THE PARTIES IN WRITING, LICENSOR OFFERS THE WORK AS-IS AND ONLY TO THE EXTENT OF ANY RIGHTS HELD IN THE LICENSED WORK BY THE LICENSOR. THE LICENSOR MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE WORK, EXPRESS, IMPLIED, STATUTORY OR OTHERWISE, INCLUDING, WITHOUT LIMITATION, WARRANTIES OF TITLE, MARKETABILITY, MERCHANTIBILITY, FITNESS FOR A PARTICULAR PURPOSE, NONINFRINGEMENT, OR THE ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OF ABSENCE OF ERRORS, WHETHER OR NOT DISCOVERABLE. SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF IMPLIED WARRANTIES, SO SUCH EXCLUSION MAY NOT APPLY TO YOU. Limitation on Liability. EXCEPT TO THE EXTENT REQUIRED BY APPLICABLE LAW, IN NO EVENT WILL LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY FOR ANY SPECIAL, INCIDENTAL, CONSEQUENTIAL, PUNITIVE OR EXEMPLARY DAMAGES ARISING OUT OF THIS LICENSE OR THE USE OF THE WORK, EVEN IF LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Termination This License and the rights granted hereunder will terminate automatically upon any breach by You of the terms of this License. Individuals or entities who have received Derivative Works (as defined in Section 1 above) or Collective Works (as defined in Section 1 above) from You under this License, however, will not have their licenses terminated provided such individuals or entities remain in full compliance with those licenses. Sections 1, 2, 5, 6, 7, and 8 will survive any termination of this License.Subject to the above terms and conditions, the license granted here is perpetual (for the duration of the applicable copyright in the Work). Notwithstanding the above, Licensor reserves the right to release the Work under different license terms or to stop distributing the Work at any time; provided, however that any such election will not serve to withdraw this License (or any other license that has been, or is required to be, granted under the terms of this License), and this License will continue in full force and effect unless terminated as stated above.8. Miscellaneous Each time You distribute or publicly digitally perform the Work (as defined in Section 1 above) or a Collective Work (as defined in Section 1 above), the Licensor offers to the recipient a license to the Work on the same terms and conditions as the license granted to You under this License.Each time You distribute or publicly digitally perform a Derivative Work, Licensor offers to the recipient a license to the original Work on the same terms and conditions as the license granted to You under this License.If any provision of this License is invalid or unenforceable under applicable law, it shall not affect the validity or enforceability of the remainder of the terms of this License, and without further action by the parties to this agreement, such provision shall be reformed to the minimum extent necessary to make such provision valid and enforceable.No term or provision of this License shall be deemed waived and no breach consented to unless such waiver or consent shall be in writing and signed by the party to be charged with such waiver or consent.This License constitutes the entire agreement between the parties with respect to the Work licensed here. There are no understandings, agreements or representations with respect to the Work not specified here. Licensor shall not be bound by any additional provisions that may appear in any communication from You. This License may not be modified without the mutual written agreement of the Licensor and You. Component Name: Full Serializer License Type: MIT Copyright © 2017 Jacob Dufault https://github.com/jacobdufault/fullserializer Permission is hereby granted, free of charge, to any person obtaining a copyof this software and associated documentation files (the \"Software\"), to dealin the Software without restriction, including without limitation the rightsto use, copy, modify, merge, publish, distribute, sublicense, and/or sellcopies of the Software, and to permit persons to whom the Software isfurnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included inall copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS ORIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THEAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHERLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS INTHE SOFTWARE. Component Name: Iconmonstr Icons License Type: Bespoke Copyright (c) 2020 iconmonstr Alexander Kahlkopf https://iconmonstr.com This license agreement (the “Agreement”) sets forth the terms by which Alexander Kahlkopf, the owner of iconmonstr (the “Licensor”), shall provide access to certain Work (defined below) to you (the “Licensee”, “you” or “your”). This Agreement regulates the free use of the icons, fonts, images and other media content (collectively, the “Work”), which is made available via the website iconmonstr.com (the “Website”). By downloading or copying a Work, you agree to be bound by the following terms and conditions. Grant of Rights The Works on the Website are copyrighted property of Licensor. Licensor hereby grants Licensee a perpetual, non-exclusive, non-transferrable single-user license for the use of the Work based on the conditions of this Agreement. You agree that the Work serves as part of the design and is not the basis or main component of the product, template or application distributed by the Licensee. Furthermore, you agree not to sell, redistribute, sublicense, share or otherwise transfer the Work to other people or entities. Permitted Uses Licensee may use the Work in non-commercial and commercial projects, services or products without attribution.Licensee may use the Work for any illustrative purposes in any media, including, but not limited to, websites, web banners, newsletters, PDF documents, blogs, emails, slideshows, TV and video presentations, smartphones, splash screens, movies, magazine articles, books, advertisements, brochures, document illustrations, booklets, billboards, business cards, packages, etc.Licensee may use the Work in template or application without attribution; provided, however, that the Work serves as part of the design and is not the basis or main component of the product, template or application distributed by Licensee and is not used contrary to the terms and conditions of this Agreement.Licensee may adapt or change the Work according to his or her requirements. Prohibited Uses Licensee may not sell, redistribute, sublicense, share or otherwise transfer the Work to other people or entities.Licensee may not use the Work as part of a logo, trademark or service mark.Licensee may not use the Work for pornographic, infringing, defamatory, racist or religiously offensive illustrations. Additional Information on Rights Certain Works, such as logos or brands, are subject to copyright and require the agreement of a third party for the assignment of these rights. Licensee is responsible for providing all rights, agreements, and licenses for the use of the Work. Termination This Agreement shall automatically terminate without notice if you do not comply with the terms or conditions specified in this Agreement. If you yourself wish to terminate this Agreement, destroy the Work, all copies and derivatives of the Work and any materials related to it. Indemnification You agree to indemnify Licensor for any and all claims, liability performances, damages, costs (including attorney fees) or other liabilities that are caused by or related to a breach of this Agreement, which are caused by the use of the Website or Work, by the non-compliance of the use restrictions of a Work or which are caused by the claims of third parties regarding the use of a Work. Warranty and Liability The Website and the Works are provided “as is.” Licensor does not accept any warranty or liability regarding a Work, the Website, the accuracy of the information or rights described therein or the licenses, which are subject to this Agreement. Licensor is not liable for damages, costs, losses or claims incurred by you, another person or entity by the use of the Website or the Works. Component Name: MD4 Managed Implementation License Type: MIT Copyright (C) 2003 Motus Technologies Inc. (http://www.motus.com) Copyright (C) 2004-2005,2010 Novell, Inc (http://www.novell.com) Author: Sebastien Pouliot (sebastien@ximian.com) https://github.com/mono/mono/blob/master/mcs/class/Mono.Security/Mono.Security.Cryptography/MD4Managed.cs Permission is hereby granted, free of charge, to any person obtaininga copy of this software and associated documentation files (the\"Software\"), to deal in the Software without restriction, includingwithout limitation the rights to use, copy, modify, merge, publish,distribute, sublicense, and/or sell copies of the Software, and topermit persons to whom the Software is furnished to do so, subject tothe following conditions: The above copyright notice and this permission notice shall beincluded in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OFMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE ANDNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BELIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTIONOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTIONWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Reorderable List License Type: MIT Copyright (c) 2013-2015 Rotorz Limited Author: Rotorz Limited https://bitbucket.org/rotorz/reorderable-list-editor-field-for-unity Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: SQLite License Type: Public Domain Copyright owner not applicable https://www.sqlite.org/index.html SQLite is in the public domain and does not require a license Component Name: SQLite .NET License Type: MIT Copyright (c) Krueger Systems Inc https://github.com/praeclarum/sqlite-net Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: YamlDotNet License Type: MIT Copyright (c) 2008, 2009, 2010, 2011, 2012, 2013, 2014 Antoine Aubry and contributors http://aaubry.net/pages/yamldotnet.html Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Ensure.That License Type: MIT Copyright (c) 2015 Daniel Wertheim https://github.com/danielwertheim/Ensure.That Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: NCalc License Type: MIT Copyright (c) 2011 Sebastien Ros https://github.com/ncalc/ncalc Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Antlr 3 Runtime License Type: BSD License Copyright (c) 2011 The ANTLR Project All rights reserved. https://github.com/antlr/antlrcs [The \"BSD license\"] Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  "README.html": {
    "href": "README.html",
    "title": "mmo-rpg-unity | mmo-rpg-unity",
    "keywords": "mmo-rpg-unity An Unity client for the mmo-rpg game server. Features Technical The client communicates with by the server by establishing a WebSocket connection. The server address to connect to is user selectable in a menu. The client and server communicate using a custom protocol based on JSON messages. They engage in a basic keep-alive mechanism to ensure inactive clients are disconnected. The game also has an older \"native\" web client made in JS. The clients are fully compatible and can play together, even though the Unity client is of higher quality (thanks to better engine) and has some extra features. Game It is a 2D top-down game inspired by pixel art RPGs. The player can move around the map and attack enemies. Enemies are spawned by the server and move around the map, attacking nearby players. Player gains score by killing enemies. The player can also interact with other players in the game. Controls Use WASD or Arrow keys to move around. Press <Space> or <Left Mouse Button> to attack. Hold <Shift> to dash. Stats The player has 10 HP. There are 2 kinds of enemies: Slime and Purple Slime. They have 2 HP and 4 HP respectively. The player deals 1 damage point per attack. The slimes deal 1 and 2 damage points respectively. For attacks (both player and enemy) to hit, the attack animation must actually play out and hit the target. Installation The client is built in Unity 2022.3 targetting WebGL. It can be played in a browser. To play, you need the server. Get the server from here."
  },
  "api/Camera.Follow.html": {
    "href": "api/Camera.Follow.html",
    "title": "Class Follow | mmo-rpg-unity",
    "keywords": "Class Follow Namespace Camera Assembly Assembly-CSharp.dll public class Follow : MonoBehaviour Inheritance object Object Component Behaviour MonoBehaviour Follow Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Fields offset public Vector3 offset Field Value Vector3 smoothTime public float smoothTime Field Value float target public Transform target Field Value Transform"
  },
  "api/Camera.html": {
    "href": "api/Camera.html",
    "title": "Namespace Camera | mmo-rpg-unity",
    "keywords": "Namespace Camera Classes Follow"
  },
  "api/Entities.Direction.html": {
    "href": "api/Entities.Direction.html",
    "title": "Enum Direction | mmo-rpg-unity",
    "keywords": "Enum Direction Namespace Entities Assembly Assembly-CSharp.dll Represents the direction of an object. public enum Direction Fields Down = 0 Left = 2 Right = 3 Up = 1"
  },
  "api/Entities.Entity.html": {
    "href": "api/Entities.Entity.html",
    "title": "Class Entity | mmo-rpg-unity",
    "keywords": "Class Entity Namespace Entities Assembly Assembly-CSharp.dll Represents an abstract entity that can be moved and can attack. Requires a UnityEngine.SpriteRenderer, UnityEngine.U2D.Animation.SpriteLibrary, UnityEngine.Animator, and UnityEngine.Rigidbody2D components. [RequireComponent(typeof(SpriteRenderer))] [RequireComponent(typeof(SpriteLibrary))] [RequireComponent(typeof(Animator))] [RequireComponent(typeof(Rigidbody2D))] public abstract class Entity : MonoBehaviour, ICanAttack Inheritance object Object Component Behaviour MonoBehaviour Entity Implements ICanAttack Derived Player Slime Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Fields anim protected Animator anim Field Value Animator dir The direction the entity is facing. [HideInInspector] public Direction dir Field Value Direction health protected Health health Field Value Health isDashing Whether the entity is dashing. [HideInInspector] public bool isDashing Field Value bool isMoving Whether the entity is moving. [HideInInspector] public bool isMoving Field Value bool netId The network ID (UUID) of the entity. [HideInInspector] public string netId Field Value string nextInstantMove The position to instantly move to in the next fixed update. If null, the position will not be changed. protected Vector2? nextInstantMove Field Value Vector2? nextVel The velocity to change to in the next fixed update. If null, the velocity will not be changed. protected Vector2? nextVel Field Value Vector2? rb protected Rigidbody2D rb Field Value Rigidbody2D score The score of the entity. public int score Field Value int sprite protected SpriteRenderer sprite Field Value SpriteRenderer spriteLib protected SpriteLibrary spriteLib Field Value SpriteLibrary spriteLibraries The sprite libraries for each direction. The order is the same as the Direction enum Down, Up, Left, Right. public SpriteLibraryAsset[] spriteLibraries Field Value SpriteLibraryAsset[] Methods Attack() Make the entity attack. public void Attack() FixedUpdate() protected virtual void FixedUpdate() MoveToOverTime(Vector2, float) public void MoveToOverTime(Vector2 to, float time) Parameters to Vector2 time float OnAttackAnimationHit() Animation event that is triggered when the attack animation hits. public void OnAttackAnimationHit() OnDamage() Called when the entity takes damage. public abstract void OnDamage() OnDeath() Called when the entity dies. public void OnDeath() OnDeathFinished() Animation event that is triggered when the death animation finishes. public void OnDeathFinished() Events onAttackHit Event that is triggered when the entity's attack actually hits. public event Action onAttackHit Event Type Action"
  },
  "api/Entities.Health.html": {
    "href": "api/Entities.Health.html",
    "title": "Class Health | mmo-rpg-unity",
    "keywords": "Class Health Namespace Entities Assembly Assembly-CSharp.dll Manages the health of an object. Can take damage and die. public class Health : MonoBehaviour Inheritance object Object Component Behaviour MonoBehaviour Health Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Fields health The current health of the object. public float health Field Value float maxHealth The maximum health of the object. public float maxHealth Field Value float onDamage Event that is triggered when the object takes damage. public Action onDamage Field Value Action onDeath Event that is triggered when the object dies. public Action onDeath Field Value Action Properties Alive Property that returns whether the object is alive. public bool Alive { get; } Property Value bool True if the object is alive, false otherwise. Methods Kill() Kills the object. public void Kill() SetHealth(float) Sets the health of the object. Ignores the maximum health. Doesn't trigger the onDamage event even if the new health is lower than the current health. Does trigger the onDeath event though if the new health is 0 or lower. public void SetHealth(float newHealth) Parameters newHealth float The new health of the object. TakeDamage(float) Makes the object take damage. public void TakeDamage(float damage) Parameters damage float The amount of damage to take."
  },
  "api/Entities.Movement.html": {
    "href": "api/Entities.Movement.html",
    "title": "Class Movement | mmo-rpg-unity",
    "keywords": "Class Movement Namespace Entities Assembly Assembly-CSharp.dll Reacts to input and moves the object accordingly. Has to be attached to an object with an Entity component. [RequireComponent(typeof(Entity))] public class Movement : MonoBehaviour Inheritance object Object Component Behaviour MonoBehaviour Movement Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Fields dashSpeed The speed of dashing in m/s. public float dashSpeed Field Value float speed The speed of movement in m/s. public float speed Field Value float"
  },
  "api/Entities.Player.Player.html": {
    "href": "api/Entities.Player.Player.html",
    "title": "Class Player | mmo-rpg-unity",
    "keywords": "Class Player Namespace Entities.Player Assembly Assembly-CSharp.dll Represents the player entity. Requires a Health component. [RequireComponent(typeof(Health))] public class Player : Entity, ICanAttack Inheritance object Object Component Behaviour MonoBehaviour Entity Player Implements ICanAttack Inherited Members Entity.spriteLibraries Entity.netId Entity.dir Entity.isMoving Entity.isDashing Entity.score Entity.onAttackHit Entity.nextVel Entity.nextInstantMove Entity.sprite Entity.spriteLib Entity.anim Entity.rb Entity.health Entity.MoveToOverTime(Vector2, float) Entity.Attack() Entity.OnDeath() Entity.OnAttackAnimationHit() Entity.OnDeathFinished() Entity.FixedUpdate() MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Fields hurtColor The color to blink when the player takes damage. public Color hurtColor Field Value Color Methods OnDamage() Called when the entity takes damage. public override void OnDamage()"
  },
  "api/Entities.Player.PlayerAttack.html": {
    "href": "api/Entities.Player.PlayerAttack.html",
    "title": "Class PlayerAttack | mmo-rpg-unity",
    "keywords": "Class PlayerAttack Namespace Entities.Player Assembly Assembly-CSharp.dll Reacts to input and attacks. Requires a Player component. [RequireComponent(typeof(Player))] public class PlayerAttack : MonoBehaviour Inheritance object Object Component Behaviour MonoBehaviour PlayerAttack Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Fields atackCooldown The cooldown between attacks in seconds. public float atackCooldown Field Value float attackPoints The three points where the attack colliders are placed. The order is: Down, Up, Side. The side is determined by the Player.dir and rotates with the player. public Transform[] attackPoints Field Value Transform[] attackRange The range of the attack in meters. public float attackRange Field Value float attackableLayers The layers that can be attacked. public LayerMask attackableLayers Field Value LayerMask onAttack Event that is triggered when the player starts an attack. public Action onAttack Field Value Action onHit Event that is triggered when the player hits an entity with an attack. The entity hit is passed as an argument. public Action<Entity> onHit Field Value Action<Entity>"
  },
  "api/Entities.Player.PlayerUpdater.html": {
    "href": "api/Entities.Player.PlayerUpdater.html",
    "title": "Class PlayerUpdater | mmo-rpg-unity",
    "keywords": "Class PlayerUpdater Namespace Entities.Player Assembly Assembly-CSharp.dll Sends updates regarding the player to the server. Requires a Player and a PlayerAttack component. [RequireComponent(typeof(Player))] [RequireComponent(typeof(PlayerAttack))] public class PlayerUpdater : MonoBehaviour Inheritance object Object Component Behaviour MonoBehaviour PlayerUpdater Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object)"
  },
  "api/Entities.Player.html": {
    "href": "api/Entities.Player.html",
    "title": "Namespace Entities.Player | mmo-rpg-unity",
    "keywords": "Namespace Entities.Player Classes Player Represents the player entity. Requires a Health component. PlayerAttack Reacts to input and attacks. Requires a Player component. PlayerUpdater Sends updates regarding the player to the server. Requires a Player and a PlayerAttack component."
  },
  "api/Entities.Slime.Slime.html": {
    "href": "api/Entities.Slime.Slime.html",
    "title": "Class Slime | mmo-rpg-unity",
    "keywords": "Class Slime Namespace Entities.Slime Assembly Assembly-CSharp.dll Represents a slime entity. Requires a Health component. [RequireComponent(typeof(Health))] public class Slime : Entity, ICanAttack Inheritance object Object Component Behaviour MonoBehaviour Entity Slime Implements ICanAttack Inherited Members Entity.spriteLibraries Entity.netId Entity.dir Entity.isMoving Entity.isDashing Entity.score Entity.onAttackHit Entity.nextVel Entity.nextInstantMove Entity.sprite Entity.spriteLib Entity.anim Entity.rb Entity.health Entity.MoveToOverTime(Vector2, float) Entity.Attack() Entity.OnDeath() Entity.OnAttackAnimationHit() Entity.OnDeathFinished() Entity.FixedUpdate() MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Methods OnDamage() Called when the entity takes damage. public override void OnDamage()"
  },
  "api/Entities.Slime.html": {
    "href": "api/Entities.Slime.html",
    "title": "Namespace Entities.Slime | mmo-rpg-unity",
    "keywords": "Namespace Entities.Slime Classes Slime Represents a slime entity. Requires a Health component."
  },
  "api/Entities.html": {
    "href": "api/Entities.html",
    "title": "Namespace Entities | mmo-rpg-unity",
    "keywords": "Namespace Entities Classes Entity Represents an abstract entity that can be moved and can attack. Requires a UnityEngine.SpriteRenderer, UnityEngine.U2D.Animation.SpriteLibrary, UnityEngine.Animator, and UnityEngine.Rigidbody2D components. Health Manages the health of an object. Can take damage and die. Movement Reacts to input and moves the object accordingly. Has to be attached to an object with an Entity component. Enums Direction Represents the direction of an object."
  },
  "api/Interfaces.ICanAttack.html": {
    "href": "api/Interfaces.ICanAttack.html",
    "title": "Interface ICanAttack | mmo-rpg-unity",
    "keywords": "Interface ICanAttack Namespace Interfaces Assembly Assembly-CSharp.dll Represents an object that can attack. public interface ICanAttack Methods Attack() Do the attack. void Attack() Events onAttackHit Event that is triggered when the attack actually hits (eg. the animation hits the target). event Action onAttackHit Event Type Action"
  },
  "api/Interfaces.html": {
    "href": "api/Interfaces.html",
    "title": "Namespace Interfaces | mmo-rpg-unity",
    "keywords": "Namespace Interfaces Interfaces ICanAttack Represents an object that can attack."
  },
  "api/UI.HUD.html": {
    "href": "api/UI.HUD.html",
    "title": "Class HUD | mmo-rpg-unity",
    "keywords": "Class HUD Namespace UI Assembly Assembly-CSharp.dll Manages the HUD that displays the player's score. public class HUD : MonoBehaviour Inheritance object Object Component Behaviour MonoBehaviour HUD Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Fields player [HideInInspector] public Entity player Field Value Entity"
  },
  "api/UI.MainMenu.html": {
    "href": "api/UI.MainMenu.html",
    "title": "Class MainMenu | mmo-rpg-unity",
    "keywords": "Class MainMenu Namespace UI Assembly Assembly-CSharp.dll Manages the main menu. public class MainMenu : MonoBehaviour Inheritance object Object Component Behaviour MonoBehaviour MainMenu Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object)"
  },
  "api/UI.html": {
    "href": "api/UI.html",
    "title": "Namespace UI | mmo-rpg-unity",
    "keywords": "Namespace UI Classes HUD Manages the HUD that displays the player's score. MainMenu Manages the main menu."
  },
  "api/WebSockets.GameManager.html": {
    "href": "api/WebSockets.GameManager.html",
    "title": "Class GameManager | mmo-rpg-unity",
    "keywords": "Class GameManager Namespace WebSockets Assembly Assembly-CSharp.dll Provides handlers for incoming messages and manages the existing entities. public class GameManager : MonoBehaviour Inheritance object Object Component Behaviour MonoBehaviour GameManager Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Fields controlledPlayerPrefab public GameObject controlledPlayerPrefab Field Value GameObject entityPrefabs public GameObject[] entityPrefabs Field Value GameObject[] id [HideInInspector] public string id Field Value string playerName public string playerName Field Value string registered [HideInInspector] public bool registered Field Value bool Methods Register() public void Register() SpawnSelf() public void SpawnSelf()"
  },
  "api/WebSockets.InMessageData.EntityAttackData.html": {
    "href": "api/WebSockets.InMessageData.EntityAttackData.html",
    "title": "Class EntityAttackData | mmo-rpg-unity",
    "keywords": "Class EntityAttackData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the entity attack message data. This message is sent by the server when an entity attacks (the attack animation starts). public sealed class EntityAttackData : MessageData Inheritance object MessageData EntityAttackData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString()"
  },
  "api/WebSockets.InMessageData.EntityDamageData.html": {
    "href": "api/WebSockets.InMessageData.EntityDamageData.html",
    "title": "Class EntityDamageData | mmo-rpg-unity",
    "keywords": "Class EntityDamageData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the entity damage message data. This message is sent by the server when an entity takes damage. public sealed class EntityDamageData : MessageData Inheritance object MessageData EntityDamageData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString() Properties damage public float damage { get; set; } Property Value float sourceX public float sourceX { get; set; } Property Value float sourceY public float sourceY { get; set; } Property Value float"
  },
  "api/WebSockets.InMessageData.EntityDespawnData.html": {
    "href": "api/WebSockets.InMessageData.EntityDespawnData.html",
    "title": "Class EntityDespawnData | mmo-rpg-unity",
    "keywords": "Class EntityDespawnData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the entity despawn message data. public sealed class EntityDespawnData : MessageData Inheritance object MessageData EntityDespawnData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString()"
  },
  "api/WebSockets.InMessageData.EntityMoveData.html": {
    "href": "api/WebSockets.InMessageData.EntityMoveData.html",
    "title": "Class EntityMoveData | mmo-rpg-unity",
    "keywords": "Class EntityMoveData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the entity move message data. public sealed class EntityMoveData : PositionedMessageData Inheritance object MessageData PositionedMessageData EntityMoveData Inherited Members PositionedMessageData.x PositionedMessageData.y MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString() Properties time public float time { get; set; } Property Value float"
  },
  "api/WebSockets.InMessageData.EntitySpawnData.html": {
    "href": "api/WebSockets.InMessageData.EntitySpawnData.html",
    "title": "Class EntitySpawnData | mmo-rpg-unity",
    "keywords": "Class EntitySpawnData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the entity spawn message data. public sealed class EntitySpawnData : PositionedMessageData Inheritance object MessageData PositionedMessageData EntitySpawnData Inherited Members PositionedMessageData.x PositionedMessageData.y MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString() Properties entity public EntityType entity { get; set; } Property Value EntityType"
  },
  "api/WebSockets.InMessageData.EntityType.html": {
    "href": "api/WebSockets.InMessageData.EntityType.html",
    "title": "Enum EntityType | mmo-rpg-unity",
    "keywords": "Enum EntityType Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the type of entity. The order of the enum values determines the order in the inspector field. public enum EntityType Fields Player = 0 Slime = 1 SlimePurple = 2"
  },
  "api/WebSockets.InMessageData.EntityUpdateData.html": {
    "href": "api/WebSockets.InMessageData.EntityUpdateData.html",
    "title": "Class EntityUpdateData | mmo-rpg-unity",
    "keywords": "Class EntityUpdateData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the entity update message data. public sealed class EntityUpdateData : MessageData Inheritance object MessageData EntityUpdateData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString() Properties dir public Direction dir { get; set; } Property Value Direction hp public float hp { get; set; } Property Value float isDashing public bool isDashing { get; set; } Property Value bool isMoving public bool isMoving { get; set; } Property Value bool score public int score { get; set; } Property Value int"
  },
  "api/WebSockets.InMessageData.HeartbeatData.html": {
    "href": "api/WebSockets.InMessageData.HeartbeatData.html",
    "title": "Class HeartbeatData | mmo-rpg-unity",
    "keywords": "Class HeartbeatData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the heartbeat message data. public sealed class HeartbeatData : MessageData Inheritance object MessageData HeartbeatData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString()"
  },
  "api/WebSockets.InMessageData.JoinData.html": {
    "href": "api/WebSockets.InMessageData.JoinData.html",
    "title": "Class JoinData | mmo-rpg-unity",
    "keywords": "Class JoinData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the player join message data. public sealed class JoinData : MessageData Inheritance object MessageData JoinData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString()"
  },
  "api/WebSockets.InMessageData.LeaveData.html": {
    "href": "api/WebSockets.InMessageData.LeaveData.html",
    "title": "Class LeaveData | mmo-rpg-unity",
    "keywords": "Class LeaveData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents the player leave message data. public sealed class LeaveData : MessageData Inheritance object MessageData LeaveData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString()"
  },
  "api/WebSockets.InMessageData.MessageData.html": {
    "href": "api/WebSockets.InMessageData.MessageData.html",
    "title": "Class MessageData | mmo-rpg-unity",
    "keywords": "Class MessageData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents abstract incoming message data. public abstract class MessageData Inheritance object MessageData Derived EntityAttackData EntityDamageData EntityDespawnData EntityUpdateData HeartbeatData JoinData LeaveData PositionedMessageData Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Properties id public string id { get; set; } Property Value string"
  },
  "api/WebSockets.InMessageData.PositionedMessageData.html": {
    "href": "api/WebSockets.InMessageData.PositionedMessageData.html",
    "title": "Class PositionedMessageData | mmo-rpg-unity",
    "keywords": "Class PositionedMessageData Namespace WebSockets.InMessageData Assembly Assembly-CSharp.dll Represents incoming message data that contains a position. public abstract class PositionedMessageData : MessageData Inheritance object MessageData PositionedMessageData Derived EntityMoveData EntitySpawnData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Properties x public float x { get; set; } Property Value float y public float y { get; set; } Property Value float"
  },
  "api/WebSockets.InMessageData.html": {
    "href": "api/WebSockets.InMessageData.html",
    "title": "Namespace WebSockets.InMessageData | mmo-rpg-unity",
    "keywords": "Namespace WebSockets.InMessageData Classes EntityAttackData Represents the entity attack message data. This message is sent by the server when an entity attacks (the attack animation starts). EntityDamageData Represents the entity damage message data. This message is sent by the server when an entity takes damage. EntityDespawnData Represents the entity despawn message data. EntityMoveData Represents the entity move message data. EntitySpawnData Represents the entity spawn message data. EntityUpdateData Represents the entity update message data. HeartbeatData Represents the heartbeat message data. JoinData Represents the player join message data. LeaveData Represents the player leave message data. MessageData Represents abstract incoming message data. PositionedMessageData Represents incoming message data that contains a position. Enums EntityType Represents the type of entity. The order of the enum values determines the order in the inspector field."
  },
  "api/WebSockets.OutMessageData.AttackData.html": {
    "href": "api/WebSockets.OutMessageData.AttackData.html",
    "title": "Class AttackData | mmo-rpg-unity",
    "keywords": "Class AttackData Namespace WebSockets.OutMessageData Assembly Assembly-CSharp.dll Represents the player attack message data. It is used to report the player's attack (the animation) to the server. public sealed class AttackData : MessageData Inheritance object MessageData AttackData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString()"
  },
  "api/WebSockets.OutMessageData.HeartbeatData.html": {
    "href": "api/WebSockets.OutMessageData.HeartbeatData.html",
    "title": "Class HeartbeatData | mmo-rpg-unity",
    "keywords": "Class HeartbeatData Namespace WebSockets.OutMessageData Assembly Assembly-CSharp.dll Represents the heartbeat message data. public sealed class HeartbeatData : MessageData Inheritance object MessageData HeartbeatData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString()"
  },
  "api/WebSockets.OutMessageData.HitData.html": {
    "href": "api/WebSockets.OutMessageData.HitData.html",
    "title": "Class HitData | mmo-rpg-unity",
    "keywords": "Class HitData Namespace WebSockets.OutMessageData Assembly Assembly-CSharp.dll Represents the player hit message data. It is used to report the player's hit to the server. Each hit message reports one hit. public sealed class HitData : MessageData Inheritance object MessageData HitData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString() Properties targetId public string targetId { get; set; } Property Value string"
  },
  "api/WebSockets.OutMessageData.JoinData.html": {
    "href": "api/WebSockets.OutMessageData.JoinData.html",
    "title": "Class JoinData | mmo-rpg-unity",
    "keywords": "Class JoinData Namespace WebSockets.OutMessageData Assembly Assembly-CSharp.dll Represents the player join message data. This is sent when the client wants to register the new player with the server. public sealed class JoinData Inheritance object JoinData Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString() Properties playerName public string playerName { get; set; } Property Value string"
  },
  "api/WebSockets.OutMessageData.LeaveData.html": {
    "href": "api/WebSockets.OutMessageData.LeaveData.html",
    "title": "Class LeaveData | mmo-rpg-unity",
    "keywords": "Class LeaveData Namespace WebSockets.OutMessageData Assembly Assembly-CSharp.dll Represents the player leave message data. This is sent when the client wants to leave the server. public sealed class LeaveData : MessageData Inheritance object MessageData LeaveData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString()"
  },
  "api/WebSockets.OutMessageData.MessageData.html": {
    "href": "api/WebSockets.OutMessageData.MessageData.html",
    "title": "Class MessageData | mmo-rpg-unity",
    "keywords": "Class MessageData Namespace WebSockets.OutMessageData Assembly Assembly-CSharp.dll Represents abstract outgoing message data. public abstract class MessageData Inheritance object MessageData Derived AttackData HeartbeatData HitData LeaveData MoveData SpawnData UpdateData Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Properties id public string id { get; set; } Property Value string"
  },
  "api/WebSockets.OutMessageData.MoveData.html": {
    "href": "api/WebSockets.OutMessageData.MoveData.html",
    "title": "Class MoveData | mmo-rpg-unity",
    "keywords": "Class MoveData Namespace WebSockets.OutMessageData Assembly Assembly-CSharp.dll Represents the player move message data. It is used to report the player's movement to the server. public sealed class MoveData : MessageData Inheritance object MessageData MoveData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString() Properties x public float x { get; set; } Property Value float y public float y { get; set; } Property Value float"
  },
  "api/WebSockets.OutMessageData.SpawnData.html": {
    "href": "api/WebSockets.OutMessageData.SpawnData.html",
    "title": "Class SpawnData | mmo-rpg-unity",
    "keywords": "Class SpawnData Namespace WebSockets.OutMessageData Assembly Assembly-CSharp.dll Represents the player spawn message data. This is sent when the client wants to spawn the player. public sealed class SpawnData : MessageData Inheritance object MessageData SpawnData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString()"
  },
  "api/WebSockets.OutMessageData.UpdateData.html": {
    "href": "api/WebSockets.OutMessageData.UpdateData.html",
    "title": "Class UpdateData | mmo-rpg-unity",
    "keywords": "Class UpdateData Namespace WebSockets.OutMessageData Assembly Assembly-CSharp.dll Represents the player update message data. It is used to report the current state of the player to the server. public sealed class UpdateData : MessageData Inheritance object MessageData UpdateData Inherited Members MessageData.id object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.ReferenceEquals(object, object) object.ToString() Properties dir public Direction dir { get; set; } Property Value Direction isDashing public bool isDashing { get; set; } Property Value bool isMoving public bool isMoving { get; set; } Property Value bool"
  },
  "api/WebSockets.OutMessageData.html": {
    "href": "api/WebSockets.OutMessageData.html",
    "title": "Namespace WebSockets.OutMessageData | mmo-rpg-unity",
    "keywords": "Namespace WebSockets.OutMessageData Classes AttackData Represents the player attack message data. It is used to report the player's attack (the animation) to the server. HeartbeatData Represents the heartbeat message data. HitData Represents the player hit message data. It is used to report the player's hit to the server. Each hit message reports one hit. JoinData Represents the player join message data. This is sent when the client wants to register the new player with the server. LeaveData Represents the player leave message data. This is sent when the client wants to leave the server. MessageData Represents abstract outgoing message data. MoveData Represents the player move message data. It is used to report the player's movement to the server. SpawnData Represents the player spawn message data. This is sent when the client wants to spawn the player. UpdateData Represents the player update message data. It is used to report the current state of the player to the server."
  },
  "api/WebSockets.WebSocketManager.html": {
    "href": "api/WebSockets.WebSocketManager.html",
    "title": "Class WebSocketManager | mmo-rpg-unity",
    "keywords": "Class WebSocketManager Namespace WebSockets Assembly Assembly-CSharp.dll Manages the WebSocket connection to the server. Allows sending messages to the server and binding event handlers for incoming messages. Uses the NativeWebSocket package. Requires a GameManager component. [RequireComponent(typeof(GameManager))] public class WebSocketManager : MonoBehaviour Inheritance object Object Component Behaviour MonoBehaviour WebSocketManager Inherited Members MonoBehaviour.IsInvoking() MonoBehaviour.CancelInvoke() MonoBehaviour.Invoke(string, float) MonoBehaviour.InvokeRepeating(string, float, float) MonoBehaviour.CancelInvoke(string) MonoBehaviour.IsInvoking(string) MonoBehaviour.StartCoroutine(string) MonoBehaviour.StartCoroutine(string, object) MonoBehaviour.StartCoroutine(IEnumerator) MonoBehaviour.StartCoroutine_Auto(IEnumerator) MonoBehaviour.StopCoroutine(IEnumerator) MonoBehaviour.StopCoroutine(Coroutine) MonoBehaviour.StopCoroutine(string) MonoBehaviour.StopAllCoroutines() MonoBehaviour.print(object) MonoBehaviour.destroyCancellationToken MonoBehaviour.useGUILayout MonoBehaviour.runInEditMode Behaviour.enabled Behaviour.isActiveAndEnabled Component.GetComponent(Type) Component.GetComponent<T>() Component.TryGetComponent(Type, out Component) Component.TryGetComponent<T>(out T) Component.GetComponent(string) Component.GetComponentInChildren(Type, bool) Component.GetComponentInChildren(Type) Component.GetComponentInChildren<T>(bool) Component.GetComponentInChildren<T>() Component.GetComponentsInChildren(Type, bool) Component.GetComponentsInChildren(Type) Component.GetComponentsInChildren<T>(bool) Component.GetComponentsInChildren<T>(bool, List<T>) Component.GetComponentsInChildren<T>() Component.GetComponentsInChildren<T>(List<T>) Component.GetComponentInParent(Type, bool) Component.GetComponentInParent(Type) Component.GetComponentInParent<T>(bool) Component.GetComponentInParent<T>() Component.GetComponentsInParent(Type, bool) Component.GetComponentsInParent(Type) Component.GetComponentsInParent<T>(bool) Component.GetComponentsInParent<T>(bool, List<T>) Component.GetComponentsInParent<T>() Component.GetComponents(Type) Component.GetComponents(Type, List<Component>) Component.GetComponents<T>(List<T>) Component.GetComponents<T>() Component.GetComponentIndex() Component.CompareTag(string) Component.SendMessageUpwards(string, object, SendMessageOptions) Component.SendMessageUpwards(string, object) Component.SendMessageUpwards(string) Component.SendMessageUpwards(string, SendMessageOptions) Component.SendMessage(string, object) Component.SendMessage(string) Component.SendMessage(string, object, SendMessageOptions) Component.SendMessage(string, SendMessageOptions) Component.BroadcastMessage(string, object, SendMessageOptions) Component.BroadcastMessage(string, object) Component.BroadcastMessage(string) Component.BroadcastMessage(string, SendMessageOptions) Component.transform Component.gameObject Component.tag Object.GetInstanceID() Object.GetHashCode() Object.Equals(object) Object.InstantiateAsync<T>(T) Object.InstantiateAsync<T>(T, Transform) Object.InstantiateAsync<T>(T, Vector3, Quaternion) Object.InstantiateAsync<T>(T, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int) Object.InstantiateAsync<T>(T, int, Transform) Object.InstantiateAsync<T>(T, int, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.InstantiateAsync<T>(T, int, Transform, Vector3, Quaternion) Object.InstantiateAsync<T>(T, int, Transform, ReadOnlySpan<Vector3>, ReadOnlySpan<Quaternion>) Object.Instantiate(Object, Vector3, Quaternion) Object.Instantiate(Object, Vector3, Quaternion, Transform) Object.Instantiate(Object) Object.Instantiate(Object, Scene) Object.Instantiate(Object, Transform) Object.Instantiate(Object, Transform, bool) Object.Instantiate<T>(T) Object.Instantiate<T>(T, Vector3, Quaternion) Object.Instantiate<T>(T, Vector3, Quaternion, Transform) Object.Instantiate<T>(T, Transform) Object.Instantiate<T>(T, Transform, bool) Object.Destroy(Object, float) Object.Destroy(Object) Object.DestroyImmediate(Object, bool) Object.DestroyImmediate(Object) Object.FindObjectsOfType(Type) Object.FindObjectsOfType(Type, bool) Object.FindObjectsByType(Type, FindObjectsSortMode) Object.FindObjectsByType(Type, FindObjectsInactive, FindObjectsSortMode) Object.DontDestroyOnLoad(Object) Object.DestroyObject(Object, float) Object.DestroyObject(Object) Object.FindSceneObjectsOfType(Type) Object.FindObjectsOfTypeIncludingAssets(Type) Object.FindObjectsOfType<T>() Object.FindObjectsByType<T>(FindObjectsSortMode) Object.FindObjectsOfType<T>(bool) Object.FindObjectsByType<T>(FindObjectsInactive, FindObjectsSortMode) Object.FindObjectOfType<T>() Object.FindObjectOfType<T>(bool) Object.FindFirstObjectByType<T>() Object.FindAnyObjectByType<T>() Object.FindFirstObjectByType<T>(FindObjectsInactive) Object.FindAnyObjectByType<T>(FindObjectsInactive) Object.FindObjectsOfTypeAll(Type) Object.FindObjectOfType(Type) Object.FindFirstObjectByType(Type) Object.FindAnyObjectByType(Type) Object.FindObjectOfType(Type, bool) Object.FindFirstObjectByType(Type, FindObjectsInactive) Object.FindAnyObjectByType(Type, FindObjectsInactive) Object.ToString() Object.name Object.hideFlags object.Equals(object, object) object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) Fields ServerAddress The WebSocket server address that will be used by Connect(). Changing this value will not affect the current connection. public string ServerAddress Field Value string Properties Connected Returns whether the WebSocket connection is open. public bool Connected { get; } Property Value bool True if the connection is open, false otherwise. State Exposes the WebSocket connection state. public WebSocketState State { get; } Property Value WebSocketState The current NativeWebSocket.WebSocketState of the connection. Methods CloseConnection() Closes the WebSocket connection. public void CloseConnection() Connect() Connects to the WebSocket server. Uses the value from ServerAddress. If a connection is already open, it will be closed. public void Connect() SendWSMessage(string, object) Sends a message to the server. public void SendWSMessage(string eventName, object data) Parameters eventName string The event name. data object The event data. bindHandler(string, Action<string>) Binds a handler to an event. public void bindHandler(string @event, Action<string> handler) Parameters event string The event name. handler Action<string> The handler."
  },
  "api/WebSockets.html": {
    "href": "api/WebSockets.html",
    "title": "Namespace WebSockets | mmo-rpg-unity",
    "keywords": "Namespace WebSockets Classes GameManager Provides handlers for incoming messages and manages the existing entities. WebSocketManager Manages the WebSocket connection to the server. Allows sending messages to the server and binding event handlers for incoming messages. Uses the NativeWebSocket package. Requires a GameManager component."
  },
  "docs/index.html": {
    "href": "docs/index.html",
    "title": "Docs | mmo-rpg-unity",
    "keywords": "Docs"
  },
  "index.html": {
    "href": "index.html",
    "title": "mmo-rpg-unity | mmo-rpg-unity",
    "keywords": "mmo-rpg-unity Refer to README for the introduction and installation instructions. The technical details are in Docs."
  }
}